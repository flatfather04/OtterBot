Meeting: New Theory
Mon, Jun 17, 2024
10:25 AM
30 min
Priyesh P
Incorporating geometry in deep learning model
URL: https://otter.ai/u/8cALlqivPxneNiofgiOCLF5QrZ0
Downloaded: 2025-12-22T15:12:53.562783
Method: text_extraction
============================================================

S Speaker 10:00In a 3d space, what is it can be conducted? There's a lot of math in time to accurate some software.
In a 3d space, what is it can be conducted? There's a lot of math in time to accurate some software.
In a 3d space, what is it can be conducted? There's a lot of math in time to accurate some software.
In a 3d space, what is it can be conducted? There's a lot of math in time to accurate some software.
S Speaker 30:48compare that to transformers? So rather than just seeing strings of pixels, strings of pixels, or tokens and trying to guess the next set of tokens, you actually have geometric representations of things and maybe explain that a little bit.
compare that to transformers? So rather than just seeing strings of pixels, strings of pixels, or tokens and trying to guess the next set of tokens, you actually have geometric representations of things and maybe explain that a little bit.
compare that to transformers? So rather than just seeing strings of pixels, strings of pixels, or tokens and trying to guess the next set of tokens, you actually have geometric representations of things and maybe explain that a little bit.
compare that to transformers? So rather than just seeing strings of pixels, strings of pixels, or tokens and trying to guess the next set of tokens, you actually have geometric representations of things and maybe explain that a little bit.
S Speaker 21:02Yeah, so I think, probably important also to note that introducing geometry or introducing these ideas doesn't preclude the use of a transformer or self attention mechanism. This can be combined and indeed, this paper is probably the most exemplary that that we're talking about. Or, let's see, I think Cohen and also Bremmer, that group of Qualcomm show that you can incorporate geometry into transformers and also season these gains and temporal complexity how many samples you need, so they're not at odds with each other they can be combined. The question is, essentially what are the right principles you should use for constructing architectures in geometry? Geometry, the argument is that geometry isn't essential for this kind of generalization.
Yeah, so I think, probably important also to note that introducing geometry or introducing these ideas doesn't preclude the use of a transformer or self attention mechanism. This can be combined and indeed, this paper is probably the most exemplary that that we're talking about. Or, let's see, I think Cohen and also Bremmer, that group of Qualcomm show that you can incorporate geometry into transformers and also season these gains and temporal complexity how many samples you need, so they're not at odds with each other they can be combined. The question is, essentially what are the right principles you should use for constructing architectures in geometry? Geometry, the argument is that geometry isn't essential for this kind of generalization.
Yeah, so I think, probably important also to note that introducing geometry or introducing these ideas doesn't preclude the use of a transformer or self attention mechanism. This can be combined and indeed, this paper is probably the most exemplary that that we're talking about. Or, let's see, I think Cohen and also Bremmer, that group of Qualcomm show that you can incorporate geometry into transformers and also season these gains and temporal complexity how many samples you need, so they're not at odds with each other they can be combined. The question is, essentially what are the right principles you should use for constructing architectures in geometry? Geometry, the argument is that geometry isn't essential for this kind of generalization.
Yeah, so I think, probably important also to note that introducing geometry or introducing these ideas doesn't preclude the use of a transformer or self attention mechanism. This can be combined and indeed, this paper is probably the most exemplary that that we're talking about. Or, let's see, I think Cohen and also Bremmer, that group of Qualcomm show that you can incorporate geometry into transformers and also season these gains and temporal complexity how many samples you need, so they're not at odds with each other they can be combined. The question is, essentially what are the right principles you should use for constructing architectures in geometry? Geometry, the argument is that geometry isn't essential for this kind of generalization.
S Speaker 41:42But questions in in this deep learning stuff is still probabilistic. Right? And the geometry part is doesn't do away with probabilistic inference. Right? Correct.
But questions in in this deep learning stuff is still probabilistic. Right? And the geometry part is doesn't do away with probabilistic inference. Right? Correct.
But questions in in this deep learning stuff is still probabilistic. Right? And the geometry part is doesn't do away with probabilistic inference. Right? Correct.
But questions in in this deep learning stuff is still probabilistic. Right? And the geometry part is doesn't do away with probabilistic inference. Right? Correct.
S Speaker 21:57So I'm glad you're bringing this up. Because this is a really important part of GDL. It's largely missing, which is the yes like this, these problems, the learning are probabilistic. The sort of the discriminative learning paradigm, you sort of, sort of doesn't really invoke the machinery of Bayesian inference in the way in the way one ought to and that's actually part of our contribution is bringing together Bayesian inference with geometric methods. So you'll you're right to the point.
So I'm glad you're bringing this up. Because this is a really important part of GDL. It's largely missing, which is the yes like this, these problems, the learning are probabilistic. The sort of the discriminative learning paradigm, you sort of, sort of doesn't really invoke the machinery of Bayesian inference in the way in the way one ought to and that's actually part of our contribution is bringing together Bayesian inference with geometric methods. So you'll you're right to the point.
So I'm glad you're bringing this up. Because this is a really important part of GDL. It's largely missing, which is the yes like this, these problems, the learning are probabilistic. The sort of the discriminative learning paradigm, you sort of, sort of doesn't really invoke the machinery of Bayesian inference in the way in the way one ought to and that's actually part of our contribution is bringing together Bayesian inference with geometric methods. So you'll you're right to the point.
So I'm glad you're bringing this up. Because this is a really important part of GDL. It's largely missing, which is the yes like this, these problems, the learning are probabilistic. The sort of the discriminative learning paradigm, you sort of, sort of doesn't really invoke the machinery of Bayesian inference in the way in the way one ought to and that's actually part of our contribution is bringing together Bayesian inference with geometric methods. So you'll you're right to the point.
S Speaker 42:23So they're really impressed. You're there you just bring geometry or some human directed differentiate differential equation or something. Right, so make it better.
So they're really impressed. You're there you just bring geometry or some human directed differentiate differential equation or something. Right, so make it better.
So they're really impressed. You're there you just bring geometry or some human directed differentiate differential equation or something. Right, so make it better.
So they're really impressed. You're there you just bring geometry or some human directed differentiate differential equation or something. Right, so make it better.
S Speaker 22:36Yeah, that's right. So if you say, you know, imagine you have a probabilistic generative model of the world in a way in the in the old school way of graphical models are something that what we're seeing now is that instead of just like having a big collection of variables and a bunch of numbers that maybe represent pixels, there's actually some underlying causal process which has geometry to it, and your probability distributions are over these geometric structures. And that's sort of what enables this really rich reasoning ternal reasoning.
Yeah, that's right. So if you say, you know, imagine you have a probabilistic generative model of the world in a way in the in the old school way of graphical models are something that what we're seeing now is that instead of just like having a big collection of variables and a bunch of numbers that maybe represent pixels, there's actually some underlying causal process which has geometry to it, and your probability distributions are over these geometric structures. And that's sort of what enables this really rich reasoning ternal reasoning.
Yeah, that's right. So if you say, you know, imagine you have a probabilistic generative model of the world in a way in the in the old school way of graphical models are something that what we're seeing now is that instead of just like having a big collection of variables and a bunch of numbers that maybe represent pixels, there's actually some underlying causal process which has geometry to it, and your probability distributions are over these geometric structures. And that's sort of what enables this really rich reasoning ternal reasoning.
Yeah, that's right. So if you say, you know, imagine you have a probabilistic generative model of the world in a way in the in the old school way of graphical models are something that what we're seeing now is that instead of just like having a big collection of variables and a bunch of numbers that maybe represent pixels, there's actually some underlying causal process which has geometry to it, and your probability distributions are over these geometric structures. And that's sort of what enables this really rich reasoning ternal reasoning.
S Speaker 43:03But there's a because you introduced this geometric, geometric, geometric element. Doesn't that make things overly more complex? Intuitively?
But there's a because you introduced this geometric, geometric, geometric element. Doesn't that make things overly more complex? Intuitively?
But there's a because you introduced this geometric, geometric, geometric element. Doesn't that make things overly more complex? Intuitively?
But there's a because you introduced this geometric, geometric, geometric element. Doesn't that make things overly more complex? Intuitively?
S Speaker 23:14It depends on I guess what you know what's your priors are and listen to it. Everyone's what's not you know, some people say it's intuitive to just wire up a massive neural net and have, you know, some latent vector and say, let's pray that it learns something meaningful about the world. It's a beta paper, right? So you know, well, it's intuitive or not, who knows, but what brands seem to use and also what's been affected in practice. building networks is that including these kinds of inductive biases.
It depends on I guess what you know what's your priors are and listen to it. Everyone's what's not you know, some people say it's intuitive to just wire up a massive neural net and have, you know, some latent vector and say, let's pray that it learns something meaningful about the world. It's a beta paper, right? So you know, well, it's intuitive or not, who knows, but what brands seem to use and also what's been affected in practice. building networks is that including these kinds of inductive biases.
It depends on I guess what you know what's your priors are and listen to it. Everyone's what's not you know, some people say it's intuitive to just wire up a massive neural net and have, you know, some latent vector and say, let's pray that it learns something meaningful about the world. It's a beta paper, right? So you know, well, it's intuitive or not, who knows, but what brands seem to use and also what's been affected in practice. building networks is that including these kinds of inductive biases.
It depends on I guess what you know what's your priors are and listen to it. Everyone's what's not you know, some people say it's intuitive to just wire up a massive neural net and have, you know, some latent vector and say, let's pray that it learns something meaningful about the world. It's a beta paper, right? So you know, well, it's intuitive or not, who knows, but what brands seem to use and also what's been affected in practice. building networks is that including these kinds of inductive biases.
S Speaker 33:40I think what we'll see next year is really good reflection of the paper that was produced in the fall as well as the first model that the team builds and kind of the astounding
I think what we'll see next year is really good reflection of the paper that was produced in the fall as well as the first model that the team builds and kind of the astounding
I think what we'll see next year is really good reflection of the paper that was produced in the fall as well as the first model that the team builds and kind of the astounding
I think what we'll see next year is really good reflection of the paper that was produced in the fall as well as the first model that the team builds and kind of the astounding
S Speaker 23:52results. concertina for me. So we have several papers on this trajectory of the grant. One of them is about, I think you might find interesting questions about how you learn that geometry, just from data rather than having to build it in from scratch. And that can be more abstract than just reading conservation,
results. concertina for me. So we have several papers on this trajectory of the grant. One of them is about, I think you might find interesting questions about how you learn that geometry, just from data rather than having to build it in from scratch. And that can be more abstract than just reading conservation,
results. concertina for me. So we have several papers on this trajectory of the grant. One of them is about, I think you might find interesting questions about how you learn that geometry, just from data rather than having to build it in from scratch. And that can be more abstract than just reading conservation,
results. concertina for me. So we have several papers on this trajectory of the grant. One of them is about, I think you might find interesting questions about how you learn that geometry, just from data rather than having to build it in from scratch. And that can be more abstract than just reading conservation,
S Speaker 34:09political and so we're not hardwiring objects into the Model and Model or
political and so we're not hardwiring objects into the Model and Model or
political and so we're not hardwiring objects into the Model and Model or
political and so we're not hardwiring objects into the Model and Model or
S Speaker 24:13even the notion of transformations or rotations, but those notions themselves and learn about the architecture. But this piece, in particular, just the highlight, and this is the piece that Colin mentioned as a proof point we were so excited about is this has been this long standing question of how do you represent things like you know, in these recurrent nets and maybe
even the notion of transformations or rotations, but those notions themselves and learn about the architecture. But this piece, in particular, just the highlight, and this is the piece that Colin mentioned as a proof point we were so excited about is this has been this long standing question of how do you represent things like you know, in these recurrent nets and maybe
even the notion of transformations or rotations, but those notions themselves and learn about the architecture. But this piece, in particular, just the highlight, and this is the piece that Colin mentioned as a proof point we were so excited about is this has been this long standing question of how do you represent things like you know, in these recurrent nets and maybe
even the notion of transformations or rotations, but those notions themselves and learn about the architecture. But this piece, in particular, just the highlight, and this is the piece that Colin mentioned as a proof point we were so excited about is this has been this long standing question of how do you represent things like you know, in these recurrent nets and maybe
S Speaker 24:32progress? Perfect. Yeah, maybe. Julia you can comment on this to the standard setting of geometric deep learning is when the whole image for example, gets translated or rotated when it goes into the neural net. So all the theory a lot of the theorems are written in that setting. It's lacking this probabilistic formalism, which is that okay, actually, there's something behind the image which generates what you see, and that the symmetries in the geometry or they're not in the image itself. And so formalizing that for learning how to incorporate that in an architecture was one of the big contributions of this line of work. Maybe just I'll come in at a high level of what's significant about this piece. So what we created was just to demonstrate the effectiveness of incorporating these geometric structures and inference was you can you can create a simple universe, a simple world, which is composed of objects, simple objects in a 2d environment. So these objects can be placed in a scene and arbitrary positions or orientations. So if you were to count up through the combinatorics, on how many possible scenes you can generate, with this number of objects, these possible transformations, you get billions of possible scenes, that could be your dataset you encounter and suddenly your camera might be out there in the world. What we showed in this paper, both the geometric ideas and the network design and these ideas of interest. And you can trade on a few 100 samples and probably generalize the Ophelia because the model is actually learned and underlying representation and understanding a separation between what were which of these two like what the objects are and the fact that they can be posed. So why don't we show okay, you, you actually do obtain this exponential sample complexity game, no sort of formal statements of that and also in the architecture when you actually train them. But also it gives rise to these tiny models that don't require much to hit the trend. So this this is very exciting, because it also paves the road to okay that I know this diagram is a bit maybe abstract, but what it's showing is that we actually understand the activations of the neural network, in terms of where the objects are, so what the objects are, and what the poses are, for example, in the scene, and then has that correspondence property for multiple objects at once. And this is the perfect candidate then for downstream training, for example, for a robot or for being able to compress for example, images or video with just minimal representation.
progress? Perfect. Yeah, maybe. Julia you can comment on this to the standard setting of geometric deep learning is when the whole image for example, gets translated or rotated when it goes into the neural net. So all the theory a lot of the theorems are written in that setting. It's lacking this probabilistic formalism, which is that okay, actually, there's something behind the image which generates what you see, and that the symmetries in the geometry or they're not in the image itself. And so formalizing that for learning how to incorporate that in an architecture was one of the big contributions of this line of work. Maybe just I'll come in at a high level of what's significant about this piece. So what we created was just to demonstrate the effectiveness of incorporating these geometric structures and inference was you can you can create a simple universe, a simple world, which is composed of objects, simple objects in a 2d environment. So these objects can be placed in a scene and arbitrary positions or orientations. So if you were to count up through the combinatorics, on how many possible scenes you can generate, with this number of objects, these possible transformations, you get billions of possible scenes, that could be your dataset you encounter and suddenly your camera might be out there in the world. What we showed in this paper, both the geometric ideas and the network design and these ideas of interest. And you can trade on a few 100 samples and probably generalize the Ophelia because the model is actually learned and underlying representation and understanding a separation between what were which of these two like what the objects are and the fact that they can be posed. So why don't we show okay, you, you actually do obtain this exponential sample complexity game, no sort of formal statements of that and also in the architecture when you actually train them. But also it gives rise to these tiny models that don't require much to hit the trend. So this this is very exciting, because it also paves the road to okay that I know this diagram is a bit maybe abstract, but what it's showing is that we actually understand the activations of the neural network, in terms of where the objects are, so what the objects are, and what the poses are, for example, in the scene, and then has that correspondence property for multiple objects at once. And this is the perfect candidate then for downstream training, for example, for a robot or for being able to compress for example, images or video with just minimal representation.
progress? Perfect. Yeah, maybe. Julia you can comment on this to the standard setting of geometric deep learning is when the whole image for example, gets translated or rotated when it goes into the neural net. So all the theory a lot of the theorems are written in that setting. It's lacking this probabilistic formalism, which is that okay, actually, there's something behind the image which generates what you see, and that the symmetries in the geometry or they're not in the image itself. And so formalizing that for learning how to incorporate that in an architecture was one of the big contributions of this line of work. Maybe just I'll come in at a high level of what's significant about this piece. So what we created was just to demonstrate the effectiveness of incorporating these geometric structures and inference was you can you can create a simple universe, a simple world, which is composed of objects, simple objects in a 2d environment. So these objects can be placed in a scene and arbitrary positions or orientations. So if you were to count up through the combinatorics, on how many possible scenes you can generate, with this number of objects, these possible transformations, you get billions of possible scenes, that could be your dataset you encounter and suddenly your camera might be out there in the world. What we showed in this paper, both the geometric ideas and the network design and these ideas of interest. And you can trade on a few 100 samples and probably generalize the Ophelia because the model is actually learned and underlying representation and understanding a separation between what were which of these two like what the objects are and the fact that they can be posed. So why don't we show okay, you, you actually do obtain this exponential sample complexity game, no sort of formal statements of that and also in the architecture when you actually train them. But also it gives rise to these tiny models that don't require much to hit the trend. So this this is very exciting, because it also paves the road to okay that I know this diagram is a bit maybe abstract, but what it's showing is that we actually understand the activations of the neural network, in terms of where the objects are, so what the objects are, and what the poses are, for example, in the scene, and then has that correspondence property for multiple objects at once. And this is the perfect candidate then for downstream training, for example, for a robot or for being able to compress for example, images or video with just minimal representation.
progress? Perfect. Yeah, maybe. Julia you can comment on this to the standard setting of geometric deep learning is when the whole image for example, gets translated or rotated when it goes into the neural net. So all the theory a lot of the theorems are written in that setting. It's lacking this probabilistic formalism, which is that okay, actually, there's something behind the image which generates what you see, and that the symmetries in the geometry or they're not in the image itself. And so formalizing that for learning how to incorporate that in an architecture was one of the big contributions of this line of work. Maybe just I'll come in at a high level of what's significant about this piece. So what we created was just to demonstrate the effectiveness of incorporating these geometric structures and inference was you can you can create a simple universe, a simple world, which is composed of objects, simple objects in a 2d environment. So these objects can be placed in a scene and arbitrary positions or orientations. So if you were to count up through the combinatorics, on how many possible scenes you can generate, with this number of objects, these possible transformations, you get billions of possible scenes, that could be your dataset you encounter and suddenly your camera might be out there in the world. What we showed in this paper, both the geometric ideas and the network design and these ideas of interest. And you can trade on a few 100 samples and probably generalize the Ophelia because the model is actually learned and underlying representation and understanding a separation between what were which of these two like what the objects are and the fact that they can be posed. So why don't we show okay, you, you actually do obtain this exponential sample complexity game, no sort of formal statements of that and also in the architecture when you actually train them. But also it gives rise to these tiny models that don't require much to hit the trend. So this this is very exciting, because it also paves the road to okay that I know this diagram is a bit maybe abstract, but what it's showing is that we actually understand the activations of the neural network, in terms of where the objects are, so what the objects are, and what the poses are, for example, in the scene, and then has that correspondence property for multiple objects at once. And this is the perfect candidate then for downstream training, for example, for a robot or for being able to compress for example, images or video with just minimal representation.
S Speaker 36:49So just for reference in this model, measuring the kilobytes, a couple 100,000 parameters, right. And so incredibly small, incredibly small number of samples. And this is, this is sorry, this is where we're starting from and now we're already working on the next version. of this model, which is actually taking this 2d, 2d world and bringing into three dimensional
So just for reference in this model, measuring the kilobytes, a couple 100,000 parameters, right. And so incredibly small, incredibly small number of samples. And this is, this is sorry, this is where we're starting from and now we're already working on the next version. of this model, which is actually taking this 2d, 2d world and bringing into three dimensional
So just for reference in this model, measuring the kilobytes, a couple 100,000 parameters, right. And so incredibly small, incredibly small number of samples. And this is, this is sorry, this is where we're starting from and now we're already working on the next version. of this model, which is actually taking this 2d, 2d world and bringing into three dimensional
So just for reference in this model, measuring the kilobytes, a couple 100,000 parameters, right. And so incredibly small, incredibly small number of samples. And this is, this is sorry, this is where we're starting from and now we're already working on the next version. of this model, which is actually taking this 2d, 2d world and bringing into three dimensional
S Speaker 27:16and I'll say basically, that it's the same mathematics and not only is it the same mathematics for dealing with images and maybe 3d worlds, but also for thinking about structure and proteins or structure in these other domains. And this is just sort of our team's focus. has been a lot on vision and 3d vision. So So,
and I'll say basically, that it's the same mathematics and not only is it the same mathematics for dealing with images and maybe 3d worlds, but also for thinking about structure and proteins or structure in these other domains. And this is just sort of our team's focus. has been a lot on vision and 3d vision. So So,
and I'll say basically, that it's the same mathematics and not only is it the same mathematics for dealing with images and maybe 3d worlds, but also for thinking about structure and proteins or structure in these other domains. And this is just sort of our team's focus. has been a lot on vision and 3d vision. So So,
and I'll say basically, that it's the same mathematics and not only is it the same mathematics for dealing with images and maybe 3d worlds, but also for thinking about structure and proteins or structure in these other domains. And this is just sort of our team's focus. has been a lot on vision and 3d vision. So So,
S Speaker 17:33so a couple questions. First of all, is this paper appearing somewhere or this is more of an internal study?
so a couple questions. First of all, is this paper appearing somewhere or this is more of an internal study?
so a couple questions. First of all, is this paper appearing somewhere or this is more of an internal study?
so a couple questions. First of all, is this paper appearing somewhere or this is more of an internal study?
S Speaker 27:44It was it was presented at last year's neurips conference. That's right, the Spartan runner ups paper. It was Yeah. And then it was it'll be released in PLR. It was
It was it was presented at last year's neurips conference. That's right, the Spartan runner ups paper. It was Yeah. And then it was it'll be released in PLR. It was
It was it was presented at last year's neurips conference. That's right, the Spartan runner ups paper. It was Yeah. And then it was it'll be released in PLR. It was
It was it was presented at last year's neurips conference. That's right, the Spartan runner ups paper. It was Yeah. And then it was it'll be released in PLR. It was
S Speaker 37:57actually was this was the one that was selected as the best paper
actually was this was the one that was selected as the best paper
actually was this was the one that was selected as the best paper
actually was this was the one that was selected as the best paper
S Speaker 28:01and then it was selected as best paper but I run the workshop, so I suppressed that it just didn't seem fair to you know, the optics of it.
and then it was selected as best paper but I run the workshop, so I suppressed that it just didn't seem fair to you know, the optics of it.
and then it was selected as best paper but I run the workshop, so I suppressed that it just didn't seem fair to you know, the optics of it.
and then it was selected as best paper but I run the workshop, so I suppressed that it just didn't seem fair to you know, the optics of it.
S Speaker 28:10or some maintenance work for the workshop, but a workshop where
or some maintenance work for the workshop, but a workshop where
or some maintenance work for the workshop, but a workshop where
or some maintenance work for the workshop, but a workshop where
S Speaker 38:16we're, you know, this is some of the initial core, the direction we've, we've built over the past several months on top of this, that's all internal IP. This is out there, but you know, we're not we do we do but
we're, you know, this is some of the initial core, the direction we've, we've built over the past several months on top of this, that's all internal IP. This is out there, but you know, we're not we do we do but
we're, you know, this is some of the initial core, the direction we've, we've built over the past several months on top of this, that's all internal IP. This is out there, but you know, we're not we do we do but
we're, you know, this is some of the initial core, the direction we've, we've built over the past several months on top of this, that's all internal IP. This is out there, but you know, we're not we do we do but
S Speaker 18:33once you've demonstrated here, right So, neuro net, you know, demonstrates what is concrete real world scenario which will say, Hey, this is something very very cool bear with me protein structure prediction alpha, for example. So, before doing that, like light work already, right.
once you've demonstrated here, right So, neuro net, you know, demonstrates what is concrete real world scenario which will say, Hey, this is something very very cool bear with me protein structure prediction alpha, for example. So, before doing that, like light work already, right.
once you've demonstrated here, right So, neuro net, you know, demonstrates what is concrete real world scenario which will say, Hey, this is something very very cool bear with me protein structure prediction alpha, for example. So, before doing that, like light work already, right.
once you've demonstrated here, right So, neuro net, you know, demonstrates what is concrete real world scenario which will say, Hey, this is something very very cool bear with me protein structure prediction alpha, for example. So, before doing that, like light work already, right.
S Speaker 29:25Sick comments, so, domain protein infections, it's simpler to do. It's fully observable, you have like the atom location, for example, some sort of projection of the 3d world. So a lot of the conditions of covariance don't pose on images. They called on the leak, which the 3d world that's what this paper solves is it says Ecuadorian says it's impossible to bring these principles to vision until now. So this is some Yeah, it's part of you know, it's been featured at the CVPR eco vision workshop. So maybe just the insert vision so let's see vision. So are you saying you providing a general vision foundation model are you saying a specifically using stone certain ways? Yeah, I think our goal is to build the best role model out there for representing the structure of the physical world. In 3d. For example, from the field, I can provide us an image you can infer this rich 3d representation. And you can use that for example to compose what and where for the first time, it's useful to know what's out there in the scene in order to react to that, as I'm planning. You can also use that for things like generation in general as possible 3d Scenes video
Sick comments, so, domain protein infections, it's simpler to do. It's fully observable, you have like the atom location, for example, some sort of projection of the 3d world. So a lot of the conditions of covariance don't pose on images. They called on the leak, which the 3d world that's what this paper solves is it says Ecuadorian says it's impossible to bring these principles to vision until now. So this is some Yeah, it's part of you know, it's been featured at the CVPR eco vision workshop. So maybe just the insert vision so let's see vision. So are you saying you providing a general vision foundation model are you saying a specifically using stone certain ways? Yeah, I think our goal is to build the best role model out there for representing the structure of the physical world. In 3d. For example, from the field, I can provide us an image you can infer this rich 3d representation. And you can use that for example to compose what and where for the first time, it's useful to know what's out there in the scene in order to react to that, as I'm planning. You can also use that for things like generation in general as possible 3d Scenes video
Sick comments, so, domain protein infections, it's simpler to do. It's fully observable, you have like the atom location, for example, some sort of projection of the 3d world. So a lot of the conditions of covariance don't pose on images. They called on the leak, which the 3d world that's what this paper solves is it says Ecuadorian says it's impossible to bring these principles to vision until now. So this is some Yeah, it's part of you know, it's been featured at the CVPR eco vision workshop. So maybe just the insert vision so let's see vision. So are you saying you providing a general vision foundation model are you saying a specifically using stone certain ways? Yeah, I think our goal is to build the best role model out there for representing the structure of the physical world. In 3d. For example, from the field, I can provide us an image you can infer this rich 3d representation. And you can use that for example to compose what and where for the first time, it's useful to know what's out there in the scene in order to react to that, as I'm planning. You can also use that for things like generation in general as possible 3d Scenes video
Sick comments, so, domain protein infections, it's simpler to do. It's fully observable, you have like the atom location, for example, some sort of projection of the 3d world. So a lot of the conditions of covariance don't pose on images. They called on the leak, which the 3d world that's what this paper solves is it says Ecuadorian says it's impossible to bring these principles to vision until now. So this is some Yeah, it's part of you know, it's been featured at the CVPR eco vision workshop. So maybe just the insert vision so let's see vision. So are you saying you providing a general vision foundation model are you saying a specifically using stone certain ways? Yeah, I think our goal is to build the best role model out there for representing the structure of the physical world. In 3d. For example, from the field, I can provide us an image you can infer this rich 3d representation. And you can use that for example to compose what and where for the first time, it's useful to know what's out there in the scene in order to react to that, as I'm planning. You can also use that for things like generation in general as possible 3d Scenes video
S Speaker 310:41for the products is a world model and the first application is perception and perception. You know, thanks in large parts of the work that your team has done is perception of everywhere. And we have you know, from robotics, consumer devices, you know, the Ray Ban wayfarers from meta to watch his cell phones, you know, Vision pro driver assist autonomous vehicles. Perception is everywhere in Britain doorbells, you know. And so if you have a tiny model and measured in megabytes, and it's able to do real time, incredibly fast, accurate tasks on whatever it's seeing. There's this enormous opportunity to start to bring reception for those who have service to these edge devices. The flip side of that is if you're able to have this role model, that kind of rich understanding of the world, you can do generative AI you can do that extremely low cost imprints, train on small sample tests sets. And we're able to be able to do things that no one else has been able to do like, video is just a nascent space that is incredibly costly to do this a long time. We could do that very quickly and low costs at the same time. We can also do things like 3d world generation, we think that has huge opportunities just for fun stuff sharing a 3d version of the world you're looking at that's generated from your cell phone to, you know, real time gaming environment. So we think this has massive, you know, cross industry obligation. Okay,
for the products is a world model and the first application is perception and perception. You know, thanks in large parts of the work that your team has done is perception of everywhere. And we have you know, from robotics, consumer devices, you know, the Ray Ban wayfarers from meta to watch his cell phones, you know, Vision pro driver assist autonomous vehicles. Perception is everywhere in Britain doorbells, you know. And so if you have a tiny model and measured in megabytes, and it's able to do real time, incredibly fast, accurate tasks on whatever it's seeing. There's this enormous opportunity to start to bring reception for those who have service to these edge devices. The flip side of that is if you're able to have this role model, that kind of rich understanding of the world, you can do generative AI you can do that extremely low cost imprints, train on small sample tests sets. And we're able to be able to do things that no one else has been able to do like, video is just a nascent space that is incredibly costly to do this a long time. We could do that very quickly and low costs at the same time. We can also do things like 3d world generation, we think that has huge opportunities just for fun stuff sharing a 3d version of the world you're looking at that's generated from your cell phone to, you know, real time gaming environment. So we think this has massive, you know, cross industry obligation. Okay,
for the products is a world model and the first application is perception and perception. You know, thanks in large parts of the work that your team has done is perception of everywhere. And we have you know, from robotics, consumer devices, you know, the Ray Ban wayfarers from meta to watch his cell phones, you know, Vision pro driver assist autonomous vehicles. Perception is everywhere in Britain doorbells, you know. And so if you have a tiny model and measured in megabytes, and it's able to do real time, incredibly fast, accurate tasks on whatever it's seeing. There's this enormous opportunity to start to bring reception for those who have service to these edge devices. The flip side of that is if you're able to have this role model, that kind of rich understanding of the world, you can do generative AI you can do that extremely low cost imprints, train on small sample tests sets. And we're able to be able to do things that no one else has been able to do like, video is just a nascent space that is incredibly costly to do this a long time. We could do that very quickly and low costs at the same time. We can also do things like 3d world generation, we think that has huge opportunities just for fun stuff sharing a 3d version of the world you're looking at that's generated from your cell phone to, you know, real time gaming environment. So we think this has massive, you know, cross industry obligation. Okay,
for the products is a world model and the first application is perception and perception. You know, thanks in large parts of the work that your team has done is perception of everywhere. And we have you know, from robotics, consumer devices, you know, the Ray Ban wayfarers from meta to watch his cell phones, you know, Vision pro driver assist autonomous vehicles. Perception is everywhere in Britain doorbells, you know. And so if you have a tiny model and measured in megabytes, and it's able to do real time, incredibly fast, accurate tasks on whatever it's seeing. There's this enormous opportunity to start to bring reception for those who have service to these edge devices. The flip side of that is if you're able to have this role model, that kind of rich understanding of the world, you can do generative AI you can do that extremely low cost imprints, train on small sample tests sets. And we're able to be able to do things that no one else has been able to do like, video is just a nascent space that is incredibly costly to do this a long time. We could do that very quickly and low costs at the same time. We can also do things like 3d world generation, we think that has huge opportunities just for fun stuff sharing a 3d version of the world you're looking at that's generated from your cell phone to, you know, real time gaming environment. So we think this has massive, you know, cross industry obligation. Okay,
S Speaker 112:24let's keep going. I understand some of the potential here but we're many right now has one question towards making sure
let's keep going. I understand some of the potential here but we're many right now has one question towards making sure
let's keep going. I understand some of the potential here but we're many right now has one question towards making sure
let's keep going. I understand some of the potential here but we're many right now has one question towards making sure
S Speaker 312:30you know, we're up against some stiff competition. This is a massive explosion that's happening right now in the industry. And we're actually incredibly grateful for people like open AI and anthropic for making an industry. A market for this that seems like every industry in the world right now is waiting for AI to come to their doorstep and it's unclear whether it's going to be a GPT that delivers on the promise of that. We don't see anyone really with the depth and focus on geometric deep learning out there. We see some, you know, interesting potential competitors, but no one is really focused on earnings geometric deep learning in over our current direction. So exciting. We're all very well capitalized. You know, we're not naive to think that. This isn't a very heavily capitalized preview, but we're getting ready to take them on. We did talk about our trajectory here from Grant publishing to proof of concept. We think next, the next year is gonna bring some great milestones, getting them the prototype model done and out there this 3d world model. Doing some early market validation. We're looking at some potential partners in the robotics space for perception, but also thinking about generative AI as a great place to kick us off. And, you know, closing next year with a incredibly powerful demo that says it sets us up for a kind of rinse and repeat cycle. We do see spending some significant capital on compute this year. Really so that we can run multiple researchers running multiple experiments in parallel. But most of our focus is on bringing on researchers that were about seven people now. One of them is our goal. Small go to market team products, business development. You've heard about us, but I think you know, you might recognize some of the folks in our advisory group like Krishnan
you know, we're up against some stiff competition. This is a massive explosion that's happening right now in the industry. And we're actually incredibly grateful for people like open AI and anthropic for making an industry. A market for this that seems like every industry in the world right now is waiting for AI to come to their doorstep and it's unclear whether it's going to be a GPT that delivers on the promise of that. We don't see anyone really with the depth and focus on geometric deep learning out there. We see some, you know, interesting potential competitors, but no one is really focused on earnings geometric deep learning in over our current direction. So exciting. We're all very well capitalized. You know, we're not naive to think that. This isn't a very heavily capitalized preview, but we're getting ready to take them on. We did talk about our trajectory here from Grant publishing to proof of concept. We think next, the next year is gonna bring some great milestones, getting them the prototype model done and out there this 3d world model. Doing some early market validation. We're looking at some potential partners in the robotics space for perception, but also thinking about generative AI as a great place to kick us off. And, you know, closing next year with a incredibly powerful demo that says it sets us up for a kind of rinse and repeat cycle. We do see spending some significant capital on compute this year. Really so that we can run multiple researchers running multiple experiments in parallel. But most of our focus is on bringing on researchers that were about seven people now. One of them is our goal. Small go to market team products, business development. You've heard about us, but I think you know, you might recognize some of the folks in our advisory group like Krishnan
you know, we're up against some stiff competition. This is a massive explosion that's happening right now in the industry. And we're actually incredibly grateful for people like open AI and anthropic for making an industry. A market for this that seems like every industry in the world right now is waiting for AI to come to their doorstep and it's unclear whether it's going to be a GPT that delivers on the promise of that. We don't see anyone really with the depth and focus on geometric deep learning out there. We see some, you know, interesting potential competitors, but no one is really focused on earnings geometric deep learning in over our current direction. So exciting. We're all very well capitalized. You know, we're not naive to think that. This isn't a very heavily capitalized preview, but we're getting ready to take them on. We did talk about our trajectory here from Grant publishing to proof of concept. We think next, the next year is gonna bring some great milestones, getting them the prototype model done and out there this 3d world model. Doing some early market validation. We're looking at some potential partners in the robotics space for perception, but also thinking about generative AI as a great place to kick us off. And, you know, closing next year with a incredibly powerful demo that says it sets us up for a kind of rinse and repeat cycle. We do see spending some significant capital on compute this year. Really so that we can run multiple researchers running multiple experiments in parallel. But most of our focus is on bringing on researchers that were about seven people now. One of them is our goal. Small go to market team products, business development. You've heard about us, but I think you know, you might recognize some of the folks in our advisory group like Krishnan
you know, we're up against some stiff competition. This is a massive explosion that's happening right now in the industry. And we're actually incredibly grateful for people like open AI and anthropic for making an industry. A market for this that seems like every industry in the world right now is waiting for AI to come to their doorstep and it's unclear whether it's going to be a GPT that delivers on the promise of that. We don't see anyone really with the depth and focus on geometric deep learning out there. We see some, you know, interesting potential competitors, but no one is really focused on earnings geometric deep learning in over our current direction. So exciting. We're all very well capitalized. You know, we're not naive to think that. This isn't a very heavily capitalized preview, but we're getting ready to take them on. We did talk about our trajectory here from Grant publishing to proof of concept. We think next, the next year is gonna bring some great milestones, getting them the prototype model done and out there this 3d world model. Doing some early market validation. We're looking at some potential partners in the robotics space for perception, but also thinking about generative AI as a great place to kick us off. And, you know, closing next year with a incredibly powerful demo that says it sets us up for a kind of rinse and repeat cycle. We do see spending some significant capital on compute this year. Really so that we can run multiple researchers running multiple experiments in parallel. But most of our focus is on bringing on researchers that were about seven people now. One of them is our goal. Small go to market team products, business development. You've heard about us, but I think you know, you might recognize some of the folks in our advisory group like Krishnan
S Speaker 214:31Yeah, I'd say we're very fortunate that we have some very active advisors so Eric Becker's who's obviously best served. Versus Amsterdam, who's just one just an incredibly kind human, but also, your son has created a lot of the novel work in this area are going to work together this past summer. And we've also co authored since then, and he's, you know, he's on our Slack, sending code back and forth and jumping in on calls multiple times a week, and connecting us to students in different parts. of the policy. The second would be Nina Milan. She's a professor at UC Santa Barbara, X physicist who's now focused on geometric deep learning, and she's really extended the field in a significant way. The largest sort of one of the largest Python packages for computational money and geometry. Out there, which is like some serious, some seriously hard work that's gone into that from many people. She's actually here in our house. Now. She's living. She's living here next month to hack on this with us. And then there's real old housing, who was my PhD advisor at Berkeley to support kind of Yeah, he's a well well thought of in theoretical neuroscience as well. Just say again, when will you join a team of seven and she's she's having a baby. And we're, yeah, but she, but she's, she's very committed to staying involved, and she's essentially targeted several of her PhD students to come in and take her place. So that's
Yeah, I'd say we're very fortunate that we have some very active advisors so Eric Becker's who's obviously best served. Versus Amsterdam, who's just one just an incredibly kind human, but also, your son has created a lot of the novel work in this area are going to work together this past summer. And we've also co authored since then, and he's, you know, he's on our Slack, sending code back and forth and jumping in on calls multiple times a week, and connecting us to students in different parts. of the policy. The second would be Nina Milan. She's a professor at UC Santa Barbara, X physicist who's now focused on geometric deep learning, and she's really extended the field in a significant way. The largest sort of one of the largest Python packages for computational money and geometry. Out there, which is like some serious, some seriously hard work that's gone into that from many people. She's actually here in our house. Now. She's living. She's living here next month to hack on this with us. And then there's real old housing, who was my PhD advisor at Berkeley to support kind of Yeah, he's a well well thought of in theoretical neuroscience as well. Just say again, when will you join a team of seven and she's she's having a baby. And we're, yeah, but she, but she's, she's very committed to staying involved, and she's essentially targeted several of her PhD students to come in and take her place. So that's
Yeah, I'd say we're very fortunate that we have some very active advisors so Eric Becker's who's obviously best served. Versus Amsterdam, who's just one just an incredibly kind human, but also, your son has created a lot of the novel work in this area are going to work together this past summer. And we've also co authored since then, and he's, you know, he's on our Slack, sending code back and forth and jumping in on calls multiple times a week, and connecting us to students in different parts. of the policy. The second would be Nina Milan. She's a professor at UC Santa Barbara, X physicist who's now focused on geometric deep learning, and she's really extended the field in a significant way. The largest sort of one of the largest Python packages for computational money and geometry. Out there, which is like some serious, some seriously hard work that's gone into that from many people. She's actually here in our house. Now. She's living. She's living here next month to hack on this with us. And then there's real old housing, who was my PhD advisor at Berkeley to support kind of Yeah, he's a well well thought of in theoretical neuroscience as well. Just say again, when will you join a team of seven and she's she's having a baby. And we're, yeah, but she, but she's, she's very committed to staying involved, and she's essentially targeted several of her PhD students to come in and take her place. So that's
Yeah, I'd say we're very fortunate that we have some very active advisors so Eric Becker's who's obviously best served. Versus Amsterdam, who's just one just an incredibly kind human, but also, your son has created a lot of the novel work in this area are going to work together this past summer. And we've also co authored since then, and he's, you know, he's on our Slack, sending code back and forth and jumping in on calls multiple times a week, and connecting us to students in different parts. of the policy. The second would be Nina Milan. She's a professor at UC Santa Barbara, X physicist who's now focused on geometric deep learning, and she's really extended the field in a significant way. The largest sort of one of the largest Python packages for computational money and geometry. Out there, which is like some serious, some seriously hard work that's gone into that from many people. She's actually here in our house. Now. She's living. She's living here next month to hack on this with us. And then there's real old housing, who was my PhD advisor at Berkeley to support kind of Yeah, he's a well well thought of in theoretical neuroscience as well. Just say again, when will you join a team of seven and she's she's having a baby. And we're, yeah, but she, but she's, she's very committed to staying involved, and she's essentially targeted several of her PhD students to come in and take her place. So that's
S Speaker 316:01a ongoing discussion where we see a long arc. And I think important to note is that these are kind of three of the top centers are this thinking and so we see this as a great PhD pipeline network for us. So this is one of the primary roles for these kind of in house academics is to competing us
a ongoing discussion where we see a long arc. And I think important to note is that these are kind of three of the top centers are this thinking and so we see this as a great PhD pipeline network for us. So this is one of the primary roles for these kind of in house academics is to competing us
a ongoing discussion where we see a long arc. And I think important to note is that these are kind of three of the top centers are this thinking and so we see this as a great PhD pipeline network for us. So this is one of the primary roles for these kind of in house academics is to competing us
a ongoing discussion where we see a long arc. And I think important to note is that these are kind of three of the top centers are this thinking and so we see this as a great PhD pipeline network for us. So this is one of the primary roles for these kind of in house academics is to competing us
S Speaker 316:25We have just been pitching all last week, we just start pitching last Monday. Think Qualcomm was one of our first conversations and we've had several cents so really love the engagement. We've met with many, many people. We're currently How about 12 million soft circled, we're in discussions with potential leads first through talking about cheque size in the 20 to $30 million range. And working through that and talking about allocation and things like that. So things are moving along quickly. And yeah, that's the end of this, the slide deck. So we really believe that these principles of mathematics and understanding of the brain are going to lead to more robust and expressive AI that's gonna surpass human capabilities become integrated into everything around us, and really open up a new era of human flourishing is our goal.
We have just been pitching all last week, we just start pitching last Monday. Think Qualcomm was one of our first conversations and we've had several cents so really love the engagement. We've met with many, many people. We're currently How about 12 million soft circled, we're in discussions with potential leads first through talking about cheque size in the 20 to $30 million range. And working through that and talking about allocation and things like that. So things are moving along quickly. And yeah, that's the end of this, the slide deck. So we really believe that these principles of mathematics and understanding of the brain are going to lead to more robust and expressive AI that's gonna surpass human capabilities become integrated into everything around us, and really open up a new era of human flourishing is our goal.
We have just been pitching all last week, we just start pitching last Monday. Think Qualcomm was one of our first conversations and we've had several cents so really love the engagement. We've met with many, many people. We're currently How about 12 million soft circled, we're in discussions with potential leads first through talking about cheque size in the 20 to $30 million range. And working through that and talking about allocation and things like that. So things are moving along quickly. And yeah, that's the end of this, the slide deck. So we really believe that these principles of mathematics and understanding of the brain are going to lead to more robust and expressive AI that's gonna surpass human capabilities become integrated into everything around us, and really open up a new era of human flourishing is our goal.
We have just been pitching all last week, we just start pitching last Monday. Think Qualcomm was one of our first conversations and we've had several cents so really love the engagement. We've met with many, many people. We're currently How about 12 million soft circled, we're in discussions with potential leads first through talking about cheque size in the 20 to $30 million range. And working through that and talking about allocation and things like that. So things are moving along quickly. And yeah, that's the end of this, the slide deck. So we really believe that these principles of mathematics and understanding of the brain are going to lead to more robust and expressive AI that's gonna surpass human capabilities become integrated into everything around us, and really open up a new era of human flourishing is our goal.
S Speaker 417:24in column D, you have are you looking for lead currently?
in column D, you have are you looking for lead currently?
in column D, you have are you looking for lead currently?
in column D, you have are you looking for lead currently?
S Speaker 317:30We're in discussion with several near ones and said I'd say notables. Okay,
We're in discussion with several near ones and said I'd say notables. Okay,
We're in discussion with several near ones and said I'd say notables. Okay,
We're in discussion with several near ones and said I'd say notables. Okay,
S Speaker 317:41decision process? Well, we've had we're, we were targeting this week, but we actually have a couple more first conversations happening today and tomorrow. So we're gonna give ourselves the time to really choose the right partner because there's obviously a long term decision. They have to be rushed into. So we wanted to run a tight process, but we also want to make sure we're thoughtful. Yeah.
decision process? Well, we've had we're, we were targeting this week, but we actually have a couple more first conversations happening today and tomorrow. So we're gonna give ourselves the time to really choose the right partner because there's obviously a long term decision. They have to be rushed into. So we wanted to run a tight process, but we also want to make sure we're thoughtful. Yeah.
decision process? Well, we've had we're, we were targeting this week, but we actually have a couple more first conversations happening today and tomorrow. So we're gonna give ourselves the time to really choose the right partner because there's obviously a long term decision. They have to be rushed into. So we wanted to run a tight process, but we also want to make sure we're thoughtful. Yeah.
decision process? Well, we've had we're, we were targeting this week, but we actually have a couple more first conversations happening today and tomorrow. So we're gonna give ourselves the time to really choose the right partner because there's obviously a long term decision. They have to be rushed into. So we wanted to run a tight process, but we also want to make sure we're thoughtful. Yeah.
S Speaker 418:11Okay. And then what are the key milestones, if you will, with this raise? You had one slide talk. About few things that what do you want to say, key milestone that you'll be able to demonstrate whatever it may be at that point, right.
Okay. And then what are the key milestones, if you will, with this raise? You had one slide talk. About few things that what do you want to say, key milestone that you'll be able to demonstrate whatever it may be at that point, right.
Okay. And then what are the key milestones, if you will, with this raise? You had one slide talk. About few things that what do you want to say, key milestone that you'll be able to demonstrate whatever it may be at that point, right.
Okay. And then what are the key milestones, if you will, with this raise? You had one slide talk. About few things that what do you want to say, key milestone that you'll be able to demonstrate whatever it may be at that point, right.
S Speaker 218:29on the research side, I think if you're thinking about it in terms of things like foundation models, really your role model foundation model, which is something which really understands not only the composition and the world around us, sort of lighting, all those things, but also the physics of the world. So the interaction of objects and their being able to reason about what happens physically. So I think, you know, that that manifests. That's something like if you wanted to interact with it through an API, let's say and that might be able to provide an image and and get a 3d representation of the world we can move around them. That would, for example, being able to modify those things play out scenarios in time. Some of the really exciting ways of grounding language models are emerging from this where you could say something like, You know what? would happen if I were to drop this object on that one? And then the mind of the model then rolls out possible scenarios of what would happen in this 3d space, those collisions and so on, and then informs that response. There's really interesting, I think, all these applications that come from the central core of developing this role model so we have a very tight research trajectory on how to how to get those pieces in place.
on the research side, I think if you're thinking about it in terms of things like foundation models, really your role model foundation model, which is something which really understands not only the composition and the world around us, sort of lighting, all those things, but also the physics of the world. So the interaction of objects and their being able to reason about what happens physically. So I think, you know, that that manifests. That's something like if you wanted to interact with it through an API, let's say and that might be able to provide an image and and get a 3d representation of the world we can move around them. That would, for example, being able to modify those things play out scenarios in time. Some of the really exciting ways of grounding language models are emerging from this where you could say something like, You know what? would happen if I were to drop this object on that one? And then the mind of the model then rolls out possible scenarios of what would happen in this 3d space, those collisions and so on, and then informs that response. There's really interesting, I think, all these applications that come from the central core of developing this role model so we have a very tight research trajectory on how to how to get those pieces in place.
on the research side, I think if you're thinking about it in terms of things like foundation models, really your role model foundation model, which is something which really understands not only the composition and the world around us, sort of lighting, all those things, but also the physics of the world. So the interaction of objects and their being able to reason about what happens physically. So I think, you know, that that manifests. That's something like if you wanted to interact with it through an API, let's say and that might be able to provide an image and and get a 3d representation of the world we can move around them. That would, for example, being able to modify those things play out scenarios in time. Some of the really exciting ways of grounding language models are emerging from this where you could say something like, You know what? would happen if I were to drop this object on that one? And then the mind of the model then rolls out possible scenarios of what would happen in this 3d space, those collisions and so on, and then informs that response. There's really interesting, I think, all these applications that come from the central core of developing this role model so we have a very tight research trajectory on how to how to get those pieces in place.
on the research side, I think if you're thinking about it in terms of things like foundation models, really your role model foundation model, which is something which really understands not only the composition and the world around us, sort of lighting, all those things, but also the physics of the world. So the interaction of objects and their being able to reason about what happens physically. So I think, you know, that that manifests. That's something like if you wanted to interact with it through an API, let's say and that might be able to provide an image and and get a 3d representation of the world we can move around them. That would, for example, being able to modify those things play out scenarios in time. Some of the really exciting ways of grounding language models are emerging from this where you could say something like, You know what? would happen if I were to drop this object on that one? And then the mind of the model then rolls out possible scenarios of what would happen in this 3d space, those collisions and so on, and then informs that response. There's really interesting, I think, all these applications that come from the central core of developing this role model so we have a very tight research trajectory on how to how to get those pieces in place.
S Speaker 319:35So I'd say that on the research roadmap, we have several off ramps that major milestones and so from a business perspective, what are our goals? Pretty simple, simply put in customers. So you know, within we're already in discussion with some potential partners, getting this out there and starting to get the market validation money coming in. You know, we obviously don't want to keep too soon and just become focused on some small niche area. But I think it's really important for us to start that rolling, both as a value creation point, but also as starting the sort of flywheel coming back and getting the research team. So I think that's very achievable and the timeline that we're we're talking about,
So I'd say that on the research roadmap, we have several off ramps that major milestones and so from a business perspective, what are our goals? Pretty simple, simply put in customers. So you know, within we're already in discussion with some potential partners, getting this out there and starting to get the market validation money coming in. You know, we obviously don't want to keep too soon and just become focused on some small niche area. But I think it's really important for us to start that rolling, both as a value creation point, but also as starting the sort of flywheel coming back and getting the research team. So I think that's very achievable and the timeline that we're we're talking about,
So I'd say that on the research roadmap, we have several off ramps that major milestones and so from a business perspective, what are our goals? Pretty simple, simply put in customers. So you know, within we're already in discussion with some potential partners, getting this out there and starting to get the market validation money coming in. You know, we obviously don't want to keep too soon and just become focused on some small niche area. But I think it's really important for us to start that rolling, both as a value creation point, but also as starting the sort of flywheel coming back and getting the research team. So I think that's very achievable and the timeline that we're we're talking about,
So I'd say that on the research roadmap, we have several off ramps that major milestones and so from a business perspective, what are our goals? Pretty simple, simply put in customers. So you know, within we're already in discussion with some potential partners, getting this out there and starting to get the market validation money coming in. You know, we obviously don't want to keep too soon and just become focused on some small niche area. But I think it's really important for us to start that rolling, both as a value creation point, but also as starting the sort of flywheel coming back and getting the research team. So I think that's very achievable and the timeline that we're we're talking about,
S Speaker 320:28We'd like to be in markets, a private beta and a 12 month range and then taking that into paying customers the following year and really growing that into you know, you know, kind of this to pork, were very early, but there's two parts here one is kind of like going in deep with a partner and really developing with them and the other is maybe a more of a consumer sort of Gen AI approach which they each have their own benefits Gen AI is really interesting to us because we get to build a world model through that out, you know, and at the same time, don't have to worry about hardening the model and putting out other people's hands and all that kind of distributed federated aspects of that. And we could just sort of hide behind a web server and still have API calls. So we were excited about the, you know, the opportunity rich environment that we have for a revenue generating products.
We'd like to be in markets, a private beta and a 12 month range and then taking that into paying customers the following year and really growing that into you know, you know, kind of this to pork, were very early, but there's two parts here one is kind of like going in deep with a partner and really developing with them and the other is maybe a more of a consumer sort of Gen AI approach which they each have their own benefits Gen AI is really interesting to us because we get to build a world model through that out, you know, and at the same time, don't have to worry about hardening the model and putting out other people's hands and all that kind of distributed federated aspects of that. And we could just sort of hide behind a web server and still have API calls. So we were excited about the, you know, the opportunity rich environment that we have for a revenue generating products.
We'd like to be in markets, a private beta and a 12 month range and then taking that into paying customers the following year and really growing that into you know, you know, kind of this to pork, were very early, but there's two parts here one is kind of like going in deep with a partner and really developing with them and the other is maybe a more of a consumer sort of Gen AI approach which they each have their own benefits Gen AI is really interesting to us because we get to build a world model through that out, you know, and at the same time, don't have to worry about hardening the model and putting out other people's hands and all that kind of distributed federated aspects of that. And we could just sort of hide behind a web server and still have API calls. So we were excited about the, you know, the opportunity rich environment that we have for a revenue generating products.
We'd like to be in markets, a private beta and a 12 month range and then taking that into paying customers the following year and really growing that into you know, you know, kind of this to pork, were very early, but there's two parts here one is kind of like going in deep with a partner and really developing with them and the other is maybe a more of a consumer sort of Gen AI approach which they each have their own benefits Gen AI is really interesting to us because we get to build a world model through that out, you know, and at the same time, don't have to worry about hardening the model and putting out other people's hands and all that kind of distributed federated aspects of that. And we could just sort of hide behind a web server and still have API calls. So we were excited about the, you know, the opportunity rich environment that we have for a revenue generating products.
S Speaker 421:28So if I understand it correctly, you guys correct me here. So check the PDS very much with techspace. With large language might write you envision and here's more of a vision based systems stuff like based on what I understand, right? So, for example, if you developed a model to do equivalent things with China let's say right, that's not the focus, correct.
So if I understand it correctly, you guys correct me here. So check the PDS very much with techspace. With large language might write you envision and here's more of a vision based systems stuff like based on what I understand, right? So, for example, if you developed a model to do equivalent things with China let's say right, that's not the focus, correct.
So if I understand it correctly, you guys correct me here. So check the PDS very much with techspace. With large language might write you envision and here's more of a vision based systems stuff like based on what I understand, right? So, for example, if you developed a model to do equivalent things with China let's say right, that's not the focus, correct.
So if I understand it correctly, you guys correct me here. So check the PDS very much with techspace. With large language might write you envision and here's more of a vision based systems stuff like based on what I understand, right? So, for example, if you developed a model to do equivalent things with China let's say right, that's not the focus, correct.
S Speaker 321:55We couldn't go after them sort of do what they do better search for. Yeah, well, we can do something that they can't do at all, and which is a great place to compete at first, but about the problems that GPT suffers from right now and police donations. And saying things that are improbable or you know, not really understanding, that's a reflection of not really understanding the world, right? So if we have a world model that actually understands the world, right, building a text interface to that in text generation output is actually very possible. It's just not the first thing that we're gonna go after, because it's such a gigantic competitor right now. So we're better off I think going after this brand new domain. Again, just
We couldn't go after them sort of do what they do better search for. Yeah, well, we can do something that they can't do at all, and which is a great place to compete at first, but about the problems that GPT suffers from right now and police donations. And saying things that are improbable or you know, not really understanding, that's a reflection of not really understanding the world, right? So if we have a world model that actually understands the world, right, building a text interface to that in text generation output is actually very possible. It's just not the first thing that we're gonna go after, because it's such a gigantic competitor right now. So we're better off I think going after this brand new domain. Again, just
We couldn't go after them sort of do what they do better search for. Yeah, well, we can do something that they can't do at all, and which is a great place to compete at first, but about the problems that GPT suffers from right now and police donations. And saying things that are improbable or you know, not really understanding, that's a reflection of not really understanding the world, right? So if we have a world model that actually understands the world, right, building a text interface to that in text generation output is actually very possible. It's just not the first thing that we're gonna go after, because it's such a gigantic competitor right now. So we're better off I think going after this brand new domain. Again, just
We couldn't go after them sort of do what they do better search for. Yeah, well, we can do something that they can't do at all, and which is a great place to compete at first, but about the problems that GPT suffers from right now and police donations. And saying things that are improbable or you know, not really understanding, that's a reflection of not really understanding the world, right? So if we have a world model that actually understands the world, right, building a text interface to that in text generation output is actually very possible. It's just not the first thing that we're gonna go after, because it's such a gigantic competitor right now. So we're better off I think going after this brand new domain. Again, just
S Speaker 323:30fair to say that sort of our early training is really training on image data and vision data, which is the way we learn in the natural world is not by just being born and reading every book on the planet, you start to observe how things interact and build that world model. And so we believe that's the right place to start. So
fair to say that sort of our early training is really training on image data and vision data, which is the way we learn in the natural world is not by just being born and reading every book on the planet, you start to observe how things interact and build that world model. And so we believe that's the right place to start. So
fair to say that sort of our early training is really training on image data and vision data, which is the way we learn in the natural world is not by just being born and reading every book on the planet, you start to observe how things interact and build that world model. And so we believe that's the right place to start. So
fair to say that sort of our early training is really training on image data and vision data, which is the way we learn in the natural world is not by just being born and reading every book on the planet, you start to observe how things interact and build that world model. And so we believe that's the right place to start. So
S Speaker 423:50initially, it's going to be perception, image data and so forth. Right? And then maybe build 3d models, wherever that'd be the journey I use case you're right. That's
initially, it's going to be perception, image data and so forth. Right? And then maybe build 3d models, wherever that'd be the journey I use case you're right. That's
initially, it's going to be perception, image data and so forth. Right? And then maybe build 3d models, wherever that'd be the journey I use case you're right. That's
initially, it's going to be perception, image data and so forth. Right? And then maybe build 3d models, wherever that'd be the journey I use case you're right. That's
S Speaker 223:59right. That's right. And we got going with users. So we should develop more efficient, faster methods. There's the engineering of whittling that down, but I think we're really excited about what happened when that gets into hardware. And
right. That's right. And we got going with users. So we should develop more efficient, faster methods. There's the engineering of whittling that down, but I think we're really excited about what happened when that gets into hardware. And
right. That's right. And we got going with users. So we should develop more efficient, faster methods. There's the engineering of whittling that down, but I think we're really excited about what happened when that gets into hardware. And
right. That's right. And we got going with users. So we should develop more efficient, faster methods. There's the engineering of whittling that down, but I think we're really excited about what happened when that gets into hardware. And
S Speaker 324:09that's, that's a question about Qualcomm and it got me excited, right, right when it shouldn't, and I when I really started to understand the possibilities if you have a model and the megabytes or maybe even kilobytes, you know, what would happen in the world if you could build that kind of incredibly fast, accurate AI into the objects around us and solve so many problems that time delivers on the probably, I think part of this viewpoint and anyone has an idea of what the world looks like shipping distribution and what happens when you have more time intelligence tips
that's, that's a question about Qualcomm and it got me excited, right, right when it shouldn't, and I when I really started to understand the possibilities if you have a model and the megabytes or maybe even kilobytes, you know, what would happen in the world if you could build that kind of incredibly fast, accurate AI into the objects around us and solve so many problems that time delivers on the probably, I think part of this viewpoint and anyone has an idea of what the world looks like shipping distribution and what happens when you have more time intelligence tips
that's, that's a question about Qualcomm and it got me excited, right, right when it shouldn't, and I when I really started to understand the possibilities if you have a model and the megabytes or maybe even kilobytes, you know, what would happen in the world if you could build that kind of incredibly fast, accurate AI into the objects around us and solve so many problems that time delivers on the probably, I think part of this viewpoint and anyone has an idea of what the world looks like shipping distribution and what happens when you have more time intelligence tips
that's, that's a question about Qualcomm and it got me excited, right, right when it shouldn't, and I when I really started to understand the possibilities if you have a model and the megabytes or maybe even kilobytes, you know, what would happen in the world if you could build that kind of incredibly fast, accurate AI into the objects around us and solve so many problems that time delivers on the probably, I think part of this viewpoint and anyone has an idea of what the world looks like shipping distribution and what happens when you have more time intelligence tips
S Speaker 524:47is your customer learns what they believe? So called facial intelligence? He's she's also trying to build a support model. What was her word? And somehow I cannot correlate this to this. Yeah,
is your customer learns what they believe? So called facial intelligence? He's she's also trying to build a support model. What was her word? And somehow I cannot correlate this to this. Yeah,
is your customer learns what they believe? So called facial intelligence? He's she's also trying to build a support model. What was her word? And somehow I cannot correlate this to this. Yeah,
is your customer learns what they believe? So called facial intelligence? He's she's also trying to build a support model. What was her word? And somehow I cannot correlate this to this. Yeah,
S Speaker 225:03I think it can be it's got some fantastic students doing work and like robotic manipulation and deleveraging kind of role model. So part of the question there is what's the necessary mathematics to then construct such world model, the other could also has a formula, a joint embedding prediction architecture, many, many people recognize this as an important problem to solve. And that's important for intelligent reasoning. I think there's a question of architecturally how does that obtain and that's, that's what we're really focusing on
I think it can be it's got some fantastic students doing work and like robotic manipulation and deleveraging kind of role model. So part of the question there is what's the necessary mathematics to then construct such world model, the other could also has a formula, a joint embedding prediction architecture, many, many people recognize this as an important problem to solve. And that's important for intelligent reasoning. I think there's a question of architecturally how does that obtain and that's, that's what we're really focusing on
I think it can be it's got some fantastic students doing work and like robotic manipulation and deleveraging kind of role model. So part of the question there is what's the necessary mathematics to then construct such world model, the other could also has a formula, a joint embedding prediction architecture, many, many people recognize this as an important problem to solve. And that's important for intelligent reasoning. I think there's a question of architecturally how does that obtain and that's, that's what we're really focusing on
I think it can be it's got some fantastic students doing work and like robotic manipulation and deleveraging kind of role model. So part of the question there is what's the necessary mathematics to then construct such world model, the other could also has a formula, a joint embedding prediction architecture, many, many people recognize this as an important problem to solve. And that's important for intelligent reasoning. I think there's a question of architecturally how does that obtain and that's, that's what we're really focusing on
S Speaker 625:31your architecture, which is going to go smaller than hers, or, you know, physical intelligence with Chelsea fence building.
your architecture, which is going to go smaller than hers, or, you know, physical intelligence with Chelsea fence building.
your architecture, which is going to go smaller than hers, or, you know, physical intelligence with Chelsea fence building.
your architecture, which is going to go smaller than hers, or, you know, physical intelligence with Chelsea fence building.
S Speaker 225:37Yeah, yeah, that's, I mean, I do yeah, I do think these are these are built on sort of existing transformer based methods. Yeah, I think you know, I think maybe we will be reaching out to some of our students very soon. So. Yeah. That
Yeah, yeah, that's, I mean, I do yeah, I do think these are these are built on sort of existing transformer based methods. Yeah, I think you know, I think maybe we will be reaching out to some of our students very soon. So. Yeah. That
Yeah, yeah, that's, I mean, I do yeah, I do think these are these are built on sort of existing transformer based methods. Yeah, I think you know, I think maybe we will be reaching out to some of our students very soon. So. Yeah. That
Yeah, yeah, that's, I mean, I do yeah, I do think these are these are built on sort of existing transformer based methods. Yeah, I think you know, I think maybe we will be reaching out to some of our students very soon. So. Yeah. That
25:54was a question. Yeah. Are there are there things I'm trying to figure out? I know, I'm
was a question. Yeah. Are there are there things I'm trying to figure out? I know, I'm
was a question. Yeah. Are there are there things I'm trying to figure out? I know, I'm
was a question. Yeah. Are there are there things I'm trying to figure out? I know, I'm
S Speaker 426:01obviously not an expert in this area, or there's other things that this geometric deep learning, that's not good at solving. So perception, I sort of get when I showed the example of rotating this ball go, you know, moving in and out or whatever the case, but there are things that you know, there's lots of language model is just learning the language right? And it's using probabilistic inference. try to predict what, what the answer should be and then just digest a lot of text or whatever things right here and you're, you're saying you can train a lot of images that you layer this geometric understanding on top of it, Right. And you can do much smaller model so I didn't think that this thing's not good at
obviously not an expert in this area, or there's other things that this geometric deep learning, that's not good at solving. So perception, I sort of get when I showed the example of rotating this ball go, you know, moving in and out or whatever the case, but there are things that you know, there's lots of language model is just learning the language right? And it's using probabilistic inference. try to predict what, what the answer should be and then just digest a lot of text or whatever things right here and you're, you're saying you can train a lot of images that you layer this geometric understanding on top of it, Right. And you can do much smaller model so I didn't think that this thing's not good at
obviously not an expert in this area, or there's other things that this geometric deep learning, that's not good at solving. So perception, I sort of get when I showed the example of rotating this ball go, you know, moving in and out or whatever the case, but there are things that you know, there's lots of language model is just learning the language right? And it's using probabilistic inference. try to predict what, what the answer should be and then just digest a lot of text or whatever things right here and you're, you're saying you can train a lot of images that you layer this geometric understanding on top of it, Right. And you can do much smaller model so I didn't think that this thing's not good at
obviously not an expert in this area, or there's other things that this geometric deep learning, that's not good at solving. So perception, I sort of get when I showed the example of rotating this ball go, you know, moving in and out or whatever the case, but there are things that you know, there's lots of language model is just learning the language right? And it's using probabilistic inference. try to predict what, what the answer should be and then just digest a lot of text or whatever things right here and you're, you're saying you can train a lot of images that you layer this geometric understanding on top of it, Right. And you can do much smaller model so I didn't think that this thing's not good at
S Speaker 226:44things which wouldn't be suitable would be spaces when new data comes from a space that doesn't have some underlying topological structure, and so.
things which wouldn't be suitable would be spaces when new data comes from a space that doesn't have some underlying topological structure, and so.
things which wouldn't be suitable would be spaces when new data comes from a space that doesn't have some underlying topological structure, and so.
things which wouldn't be suitable would be spaces when new data comes from a space that doesn't have some underlying topological structure, and so.
S Speaker 427:07But I think there's you know, you need that structure you need some physical representation of things right
But I think there's you know, you need that structure you need some physical representation of things right
But I think there's you know, you need that structure you need some physical representation of things right
But I think there's you know, you need that structure you need some physical representation of things right
S Speaker 227:13to be some structure, but I'll say that actually graph neural networks are also having these structures, their graphs sorry also have a lot of these you have a notion of locality notion of topological structure. So actually GDL includes also, you know, deep learning on graphs on point clouds on you know, now images, but also, you know, even people look at the way people look at Transformers even as as a special kind of message passing on a topology, which is just a chain of nodes. But it sort of there's not much interesting structure in the fact that there's a sequence of tokens, and it's just saying like, Oh, index time is a topological space. And I feel like it's somewhat of a shallower invocation of topology, in my view. Yeah. I think we had a question for the last five minutes.
to be some structure, but I'll say that actually graph neural networks are also having these structures, their graphs sorry also have a lot of these you have a notion of locality notion of topological structure. So actually GDL includes also, you know, deep learning on graphs on point clouds on you know, now images, but also, you know, even people look at the way people look at Transformers even as as a special kind of message passing on a topology, which is just a chain of nodes. But it sort of there's not much interesting structure in the fact that there's a sequence of tokens, and it's just saying like, Oh, index time is a topological space. And I feel like it's somewhat of a shallower invocation of topology, in my view. Yeah. I think we had a question for the last five minutes.
to be some structure, but I'll say that actually graph neural networks are also having these structures, their graphs sorry also have a lot of these you have a notion of locality notion of topological structure. So actually GDL includes also, you know, deep learning on graphs on point clouds on you know, now images, but also, you know, even people look at the way people look at Transformers even as as a special kind of message passing on a topology, which is just a chain of nodes. But it sort of there's not much interesting structure in the fact that there's a sequence of tokens, and it's just saying like, Oh, index time is a topological space. And I feel like it's somewhat of a shallower invocation of topology, in my view. Yeah. I think we had a question for the last five minutes.
to be some structure, but I'll say that actually graph neural networks are also having these structures, their graphs sorry also have a lot of these you have a notion of locality notion of topological structure. So actually GDL includes also, you know, deep learning on graphs on point clouds on you know, now images, but also, you know, even people look at the way people look at Transformers even as as a special kind of message passing on a topology, which is just a chain of nodes. But it sort of there's not much interesting structure in the fact that there's a sequence of tokens, and it's just saying like, Oh, index time is a topological space. And I feel like it's somewhat of a shallower invocation of topology, in my view. Yeah. I think we had a question for the last five minutes.
S Speaker 128:05No, it's okay. I mean, to be honest, this is more just your team, your team's meeting yet. So postpone anyway, because I know this topic reasonably well. So the way you're approaching this, right. It's a more about building efficiency, model efficiency, or do you bring new capability to the table?
No, it's okay. I mean, to be honest, this is more just your team, your team's meeting yet. So postpone anyway, because I know this topic reasonably well. So the way you're approaching this, right. It's a more about building efficiency, model efficiency, or do you bring new capability to the table?
No, it's okay. I mean, to be honest, this is more just your team, your team's meeting yet. So postpone anyway, because I know this topic reasonably well. So the way you're approaching this, right. It's a more about building efficiency, model efficiency, or do you bring new capability to the table?
No, it's okay. I mean, to be honest, this is more just your team, your team's meeting yet. So postpone anyway, because I know this topic reasonably well. So the way you're approaching this, right. It's a more about building efficiency, model efficiency, or do you bring new capability to the table?
S Speaker 228:28I'd say all three, all three. So the, the, if you were to take standard geometric deep learning, which doesn't have this idea of like a latent Bayesian
I'd say all three, all three. So the, the, if you were to take standard geometric deep learning, which doesn't have this idea of like a latent Bayesian
I'd say all three, all three. So the, the, if you were to take standard geometric deep learning, which doesn't have this idea of like a latent Bayesian
I'd say all three, all three. So the, the, if you were to take standard geometric deep learning, which doesn't have this idea of like a latent Bayesian
S Speaker 128:35or new capability I have been, I'm thinking about in our venture team a world don't think about you bring new technology capable, new utility you bring to the table that was solving the real world problem, that is essential. So I'm just saying geometric geometric capability. I think it's a very nice property. We need to translate to real world difference maker what is that? I'd like to hear your comment.
or new capability I have been, I'm thinking about in our venture team a world don't think about you bring new technology capable, new utility you bring to the table that was solving the real world problem, that is essential. So I'm just saying geometric geometric capability. I think it's a very nice property. We need to translate to real world difference maker what is that? I'd like to hear your comment.
or new capability I have been, I'm thinking about in our venture team a world don't think about you bring new technology capable, new utility you bring to the table that was solving the real world problem, that is essential. So I'm just saying geometric geometric capability. I think it's a very nice property. We need to translate to real world difference maker what is that? I'd like to hear your comment.
or new capability I have been, I'm thinking about in our venture team a world don't think about you bring new technology capable, new utility you bring to the table that was solving the real world problem, that is essential. So I'm just saying geometric geometric capability. I think it's a very nice property. We need to translate to real world difference maker what is that? I'd like to hear your comment.
S Speaker 329:05So like if it's brand new, I can do this too. So like if you were to do text to 3d world generation as an example of something that would be brand new thing able to, you know, capture 3d World accurate with your phone or your your eyeglasses and turn that into a
So like if it's brand new, I can do this too. So like if you were to do text to 3d world generation as an example of something that would be brand new thing able to, you know, capture 3d World accurate with your phone or your your eyeglasses and turn that into a
So like if it's brand new, I can do this too. So like if you were to do text to 3d world generation as an example of something that would be brand new thing able to, you know, capture 3d World accurate with your phone or your your eyeglasses and turn that into a
So like if it's brand new, I can do this too. So like if you were to do text to 3d world generation as an example of something that would be brand new thing able to, you know, capture 3d World accurate with your phone or your your eyeglasses and turn that into a
S Speaker 129:22party doing that, including the geometric inductive bias into that texture 3d model. What I'm trying to say, Yeah, we're performing impressive. What I'm trying to say is even from a vision foundational models, workout, even more to say, when you go from a kid to a real problem solving, what is the modalities you can provide? I need to see a little more grinding.
party doing that, including the geometric inductive bias into that texture 3d model. What I'm trying to say, Yeah, we're performing impressive. What I'm trying to say is even from a vision foundational models, workout, even more to say, when you go from a kid to a real problem solving, what is the modalities you can provide? I need to see a little more grinding.
party doing that, including the geometric inductive bias into that texture 3d model. What I'm trying to say, Yeah, we're performing impressive. What I'm trying to say is even from a vision foundational models, workout, even more to say, when you go from a kid to a real problem solving, what is the modalities you can provide? I need to see a little more grinding.
party doing that, including the geometric inductive bias into that texture 3d model. What I'm trying to say, Yeah, we're performing impressive. What I'm trying to say is even from a vision foundational models, workout, even more to say, when you go from a kid to a real problem solving, what is the modalities you can provide? I need to see a little more grinding.
S Speaker 229:59Yeah, I'd say you know, just trying to use it to that I think is lacking in a lot of people is this this explicit representation of, of what and where and, suddenly so if I'm, if I'm trying to design a robot
Yeah, I'd say you know, just trying to use it to that I think is lacking in a lot of people is this this explicit representation of, of what and where and, suddenly so if I'm, if I'm trying to design a robot
Yeah, I'd say you know, just trying to use it to that I think is lacking in a lot of people is this this explicit representation of, of what and where and, suddenly so if I'm, if I'm trying to design a robot
Yeah, I'd say you know, just trying to use it to that I think is lacking in a lot of people is this this explicit representation of, of what and where and, suddenly so if I'm, if I'm trying to design a robot