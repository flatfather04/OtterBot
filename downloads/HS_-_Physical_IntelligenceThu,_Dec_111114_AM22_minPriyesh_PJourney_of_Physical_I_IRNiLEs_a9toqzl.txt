Meeting: HS - Physical Intelligence
Thu, Dec 11
11:14 AM
22 min
Priyesh P
Journey of Physical Intelligence (P
URL: https://otter.ai/u/IRNiLEs_a9toqzlh7Vf6BaHU83U
Downloaded: 2025-12-21T19:14:52.598254
Method: text_extraction
============================================================

S Speaker 10:00Hi, thanks for having me. My name is Alan. I'm a researcher at physical intelligence or pi. Today I want to tell you a little bit about our journey since the beginning of the company. So from the very beginning of the company, we are super committed to one mission, which is we want to build a generalist robot policy. That's a model that control any robot to perform any physical task in the real world. And when I think about physical intelligence, I think there are many things that really encompasses it. There's the spatial understanding of the world, there's the low level motor control, planning, and reasoning rewards, so understanding what's good and what's bad, long term and short term memories and all of these things are really knowledge that enables us humans to perform tasks like sweeping floors or cooking that we think are easy but still very difficult for robots and at pi we are we want To build such a model that is able to do all of this, and then we can eventually have the robots able to do all the tasks that humans can do. So to do that, we've been committed to training vision, language, action models, or VOA models. So this is where we put all the data into a large model. And usually we start with a pre trained foundation model, and we feed in camera observation for the robot to the model, as well as the task instruction. And the model will output continuous actions, such as joint angles for the robot to execute. And we really bootstrap on the foundation knowledge that's already from this Priyesh Foundation model, and we won't tell this model exactly how to perceive the world, how to understand human instructions and then perform the right actions to form a task. So besides the model, we also need data, and we need a lot of data, and we've been thinking data is super, super critical to get the performance on these models. So for the beginning, we've been building a data engine in our office from ground up. So this involves starts with a small set of tasks that we think is possible. We let the human operators pass these tasks on a custom runtime, and with the teleop system, we see which one can be possible, and then we have the operator start to have more data with it. And after collecting data, we have annotation pipeline, so that means we will look at the data again, and, for example, label what kind of strategies are taken by the human for performing a task, as well as quality labels, for example, indicating how well the task was performed at the end of the episode. So all of these led to the first milestone of the company, which is the Pi Zero model that was released back in October last year, just over a year ago. So here is a demo of the robots actually autonomously doing the laundry. So taking the laundry from the washing machine, bring it to the table and starts to fold them and stack them up on the table. And as many of us know, working with different mobile objects can be particularly challenging. And what we found really surprising here is that with enough data and with enough diverse data, the robot is able to conquer these tasks that we think are really, really difficult before, and is able to really demonstrate dextrous behavior at different conditions,
Hi, thanks for having me. My name is Alan. I'm a researcher at physical intelligence or pi. Today I want to tell you a little bit about our journey since the beginning of the company. So from the very beginning of the company, we are super committed to one mission, which is we want to build a generalist robot policy. That's a model that control any robot to perform any physical task in the real world. And when I think about physical intelligence, I think there are many things that really encompasses it. There's the spatial understanding of the world, there's the low level motor control, planning, and reasoning rewards, so understanding what's good and what's bad, long term and short term memories and all of these things are really knowledge that enables us humans to perform tasks like sweeping floors or cooking that we think are easy but still very difficult for robots and at pi we are we want To build such a model that is able to do all of this, and then we can eventually have the robots able to do all the tasks that humans can do. So to do that, we've been committed to training vision, language, action models, or VOA models. So this is where we put all the data into a large model. And usually we start with a pre trained foundation model, and we feed in camera observation for the robot to the model, as well as the task instruction. And the model will output continuous actions, such as joint angles for the robot to execute. And we really bootstrap on the foundation knowledge that's already from this Priyesh Foundation model, and we won't tell this model exactly how to perceive the world, how to understand human instructions and then perform the right actions to form a task. So besides the model, we also need data, and we need a lot of data, and we've been thinking data is super, super critical to get the performance on these models. So for the beginning, we've been building a data engine in our office from ground up. So this involves starts with a small set of tasks that we think is possible. We let the human operators pass these tasks on a custom runtime, and with the teleop system, we see which one can be possible, and then we have the operator start to have more data with it. And after collecting data, we have annotation pipeline, so that means we will look at the data again, and, for example, label what kind of strategies are taken by the human for performing a task, as well as quality labels, for example, indicating how well the task was performed at the end of the episode. So all of these led to the first milestone of the company, which is the Pi Zero model that was released back in October last year, just over a year ago. So here is a demo of the robots actually autonomously doing the laundry. So taking the laundry from the washing machine, bring it to the table and starts to fold them and stack them up on the table. And as many of us know, working with different mobile objects can be particularly challenging. And what we found really surprising here is that with enough data and with enough diverse data, the robot is able to conquer these tasks that we think are really, really difficult before, and is able to really demonstrate dextrous behavior at different conditions,
Hi, thanks for having me. My name is Alan. I'm a researcher at physical intelligence or pi. Today I want to tell you a little bit about our journey since the beginning of the company. So from the very beginning of the company, we are super committed to one mission, which is we want to build a generalist robot policy. That's a model that control any robot to perform any physical task in the real world. And when I think about physical intelligence, I think there are many things that really encompasses it. There's the spatial understanding of the world, there's the low level motor control, planning, and reasoning rewards, so understanding what's good and what's bad, long term and short term memories and all of these things are really knowledge that enables us humans to perform tasks like sweeping floors or cooking that we think are easy but still very difficult for robots and at pi we are we want To build such a model that is able to do all of this, and then we can eventually have the robots able to do all the tasks that humans can do. So to do that, we've been committed to training vision, language, action models, or VOA models. So this is where we put all the data into a large model. And usually we start with a pre trained foundation model, and we feed in camera observation for the robot to the model, as well as the task instruction. And the model will output continuous actions, such as joint angles for the robot to execute. And we really bootstrap on the foundation knowledge that's already from this Priyesh Foundation model, and we won't tell this model exactly how to perceive the world, how to understand human instructions and then perform the right actions to form a task. So besides the model, we also need data, and we need a lot of data, and we've been thinking data is super, super critical to get the performance on these models. So for the beginning, we've been building a data engine in our office from ground up. So this involves starts with a small set of tasks that we think is possible. We let the human operators pass these tasks on a custom runtime, and with the teleop system, we see which one can be possible, and then we have the operator start to have more data with it. And after collecting data, we have annotation pipeline, so that means we will look at the data again, and, for example, label what kind of strategies are taken by the human for performing a task, as well as quality labels, for example, indicating how well the task was performed at the end of the episode. So all of these led to the first milestone of the company, which is the Pi Zero model that was released back in October last year, just over a year ago. So here is a demo of the robots actually autonomously doing the laundry. So taking the laundry from the washing machine, bring it to the table and starts to fold them and stack them up on the table. And as many of us know, working with different mobile objects can be particularly challenging. And what we found really surprising here is that with enough data and with enough diverse data, the robot is able to conquer these tasks that we think are really, really difficult before, and is able to really demonstrate dextrous behavior at different conditions,
Hi, thanks for having me. My name is Alan. I'm a researcher at physical intelligence or pi. Today I want to tell you a little bit about our journey since the beginning of the company. So from the very beginning of the company, we are super committed to one mission, which is we want to build a generalist robot policy. That's a model that control any robot to perform any physical task in the real world. And when I think about physical intelligence, I think there are many things that really encompasses it. There's the spatial understanding of the world, there's the low level motor control, planning, and reasoning rewards, so understanding what's good and what's bad, long term and short term memories and all of these things are really knowledge that enables us humans to perform tasks like sweeping floors or cooking that we think are easy but still very difficult for robots and at pi we are we want To build such a model that is able to do all of this, and then we can eventually have the robots able to do all the tasks that humans can do. So to do that, we've been committed to training vision, language, action models, or VOA models. So this is where we put all the data into a large model. And usually we start with a pre trained foundation model, and we feed in camera observation for the robot to the model, as well as the task instruction. And the model will output continuous actions, such as joint angles for the robot to execute. And we really bootstrap on the foundation knowledge that's already from this Priyesh Foundation model, and we won't tell this model exactly how to perceive the world, how to understand human instructions and then perform the right actions to form a task. So besides the model, we also need data, and we need a lot of data, and we've been thinking data is super, super critical to get the performance on these models. So for the beginning, we've been building a data engine in our office from ground up. So this involves starts with a small set of tasks that we think is possible. We let the human operators pass these tasks on a custom runtime, and with the teleop system, we see which one can be possible, and then we have the operator start to have more data with it. And after collecting data, we have annotation pipeline, so that means we will look at the data again, and, for example, label what kind of strategies are taken by the human for performing a task, as well as quality labels, for example, indicating how well the task was performed at the end of the episode. So all of these led to the first milestone of the company, which is the Pi Zero model that was released back in October last year, just over a year ago. So here is a demo of the robots actually autonomously doing the laundry. So taking the laundry from the washing machine, bring it to the table and starts to fold them and stack them up on the table. And as many of us know, working with different mobile objects can be particularly challenging. And what we found really surprising here is that with enough data and with enough diverse data, the robot is able to conquer these tasks that we think are really, really difficult before, and is able to really demonstrate dextrous behavior at different conditions,
S Speaker 114:33sort of the final recipe that we put together in this recent release, which we call pi star over six so the star indicates that we're doing some kind of policy improvements on a baseball and I think this is a continual improvement recipe with data flywheel. So the data fly we always hear is that we train the policy, we deploy the policy, we collect more data on the fly. We have human intervenors policy sometimes. And all of these data is used to train a reward model, which let the model know what's good and bad. And then we keep all the data in the training. We feed all these data back into the training. We tell the model which one is good which one's bad. We train the policy, and then we use a new policy to do more data collection, so as we speed up this wheel, the model, we're getting more and more data, more and more diverse data, and it improves over time. So this is the final result that we had for the espresso machine. So as I said, this is a machine that we set up in our office, and we just put a camera behind it, and this robot ran from 5am during days until 7pm and it did not require any major human connection. The robot was doing all these fun stuff. And we can actually see like people in the background walking by. We actually have Slack channels set up in our office. You can just order the drink of Slack. So you can just order our Slack
sort of the final recipe that we put together in this recent release, which we call pi star over six so the star indicates that we're doing some kind of policy improvements on a baseball and I think this is a continual improvement recipe with data flywheel. So the data fly we always hear is that we train the policy, we deploy the policy, we collect more data on the fly. We have human intervenors policy sometimes. And all of these data is used to train a reward model, which let the model know what's good and bad. And then we keep all the data in the training. We feed all these data back into the training. We tell the model which one is good which one's bad. We train the policy, and then we use a new policy to do more data collection, so as we speed up this wheel, the model, we're getting more and more data, more and more diverse data, and it improves over time. So this is the final result that we had for the espresso machine. So as I said, this is a machine that we set up in our office, and we just put a camera behind it, and this robot ran from 5am during days until 7pm and it did not require any major human connection. The robot was doing all these fun stuff. And we can actually see like people in the background walking by. We actually have Slack channels set up in our office. You can just order the drink of Slack. So you can just order our Slack
sort of the final recipe that we put together in this recent release, which we call pi star over six so the star indicates that we're doing some kind of policy improvements on a baseball and I think this is a continual improvement recipe with data flywheel. So the data fly we always hear is that we train the policy, we deploy the policy, we collect more data on the fly. We have human intervenors policy sometimes. And all of these data is used to train a reward model, which let the model know what's good and bad. And then we keep all the data in the training. We feed all these data back into the training. We tell the model which one is good which one's bad. We train the policy, and then we use a new policy to do more data collection, so as we speed up this wheel, the model, we're getting more and more data, more and more diverse data, and it improves over time. So this is the final result that we had for the espresso machine. So as I said, this is a machine that we set up in our office, and we just put a camera behind it, and this robot ran from 5am during days until 7pm and it did not require any major human connection. The robot was doing all these fun stuff. And we can actually see like people in the background walking by. We actually have Slack channels set up in our office. You can just order the drink of Slack. So you can just order our Slack
sort of the final recipe that we put together in this recent release, which we call pi star over six so the star indicates that we're doing some kind of policy improvements on a baseball and I think this is a continual improvement recipe with data flywheel. So the data fly we always hear is that we train the policy, we deploy the policy, we collect more data on the fly. We have human intervenors policy sometimes. And all of these data is used to train a reward model, which let the model know what's good and bad. And then we keep all the data in the training. We feed all these data back into the training. We tell the model which one is good which one's bad. We train the policy, and then we use a new policy to do more data collection, so as we speed up this wheel, the model, we're getting more and more data, more and more diverse data, and it improves over time. So this is the final result that we had for the espresso machine. So as I said, this is a machine that we set up in our office, and we just put a camera behind it, and this robot ran from 5am during days until 7pm and it did not require any major human connection. The robot was doing all these fun stuff. And we can actually see like people in the background walking by. We actually have Slack channels set up in our office. You can just order the drink of Slack. So you can just order our Slack
19:04Alan, I have good and bad news. Are there any questions for Alan? We have one here, virgins.
Alan, I have good and bad news. Are there any questions for Alan? We have one here, virgins.
Alan, I have good and bad news. Are there any questions for Alan? We have one here, virgins.
Alan, I have good and bad news. Are there any questions for Alan? We have one here, virgins.
S Speaker 219:21Great presentation. So have you guys benchmark your performance, like pi, Star 06 against German a robotics 1.5 which was just
Great presentation. So have you guys benchmark your performance, like pi, Star 06 against German a robotics 1.5 which was just
Great presentation. So have you guys benchmark your performance, like pi, Star 06 against German a robotics 1.5 which was just
Great presentation. So have you guys benchmark your performance, like pi, Star 06 against German a robotics 1.5 which was just
S Speaker 119:32launched about I signed up for access.
launched about I signed up for access.
launched about I signed up for access.
launched about I signed up for access.
S Speaker 219:39Yeah, well, I guess, yeah, that's something that we can talk separately. But what's the particular reason of using
Yeah, well, I guess, yeah, that's something that we can talk separately. But what's the particular reason of using
Yeah, well, I guess, yeah, that's something that we can talk separately. But what's the particular reason of using
Yeah, well, I guess, yeah, that's something that we can talk separately. But what's the particular reason of using
19:48conditioning advantage?
conditioning advantage?
conditioning advantage?
conditioning advantage?
S Speaker 119:50Yeah, yeah, that's a super good question. Yeah, I don't get into very technical details upon that part. I really think I. My thoughts here is that we're not at the stage here. We like language model. We have a standing data set. We take an existing data set and you train a model on it. I think robotics will happen is we keep collecting more and more data in the wild, and we need a scalable way of getting these new data back into pre training. It's not even just the fine tuning part. We want the data back into pre training, actually. So this means we don't want to throw away data in a way. We want to keep all the data because we want to pre train all to learn for good and bad, learn for enough diversity. And I think doing conditioning instead of like filtering or more aggressive
Yeah, yeah, that's a super good question. Yeah, I don't get into very technical details upon that part. I really think I. My thoughts here is that we're not at the stage here. We like language model. We have a standing data set. We take an existing data set and you train a model on it. I think robotics will happen is we keep collecting more and more data in the wild, and we need a scalable way of getting these new data back into pre training. It's not even just the fine tuning part. We want the data back into pre training, actually. So this means we don't want to throw away data in a way. We want to keep all the data because we want to pre train all to learn for good and bad, learn for enough diversity. And I think doing conditioning instead of like filtering or more aggressive
Yeah, yeah, that's a super good question. Yeah, I don't get into very technical details upon that part. I really think I. My thoughts here is that we're not at the stage here. We like language model. We have a standing data set. We take an existing data set and you train a model on it. I think robotics will happen is we keep collecting more and more data in the wild, and we need a scalable way of getting these new data back into pre training. It's not even just the fine tuning part. We want the data back into pre training, actually. So this means we don't want to throw away data in a way. We want to keep all the data because we want to pre train all to learn for good and bad, learn for enough diversity. And I think doing conditioning instead of like filtering or more aggressive
Yeah, yeah, that's a super good question. Yeah, I don't get into very technical details upon that part. I really think I. My thoughts here is that we're not at the stage here. We like language model. We have a standing data set. We take an existing data set and you train a model on it. I think robotics will happen is we keep collecting more and more data in the wild, and we need a scalable way of getting these new data back into pre training. It's not even just the fine tuning part. We want the data back into pre training, actually. So this means we don't want to throw away data in a way. We want to keep all the data because we want to pre train all to learn for good and bad, learn for enough diversity. And I think doing conditioning instead of like filtering or more aggressive
20:40recipes can really preserve, like, all these
recipes can really preserve, like, all these
recipes can really preserve, like, all these
recipes can really preserve, like, all these
S Speaker 120:44data, because we can just tell the model this is good this is bad, and we want the pre trained model to absorb all of this knowledge, instead of throwing away those Kids
data, because we can just tell the model this is good this is bad, and we want the pre trained model to absorb all of this knowledge, instead of throwing away those Kids
data, because we can just tell the model this is good this is bad, and we want the pre trained model to absorb all of this knowledge, instead of throwing away those Kids
data, because we can just tell the model this is good this is bad, and we want the pre trained model to absorb all of this knowledge, instead of throwing away those Kids
S Speaker 320:54time for probably one or two more quick
time for probably one or two more quick
time for probably one or two more quick
time for probably one or two more quick
S Speaker 121:02questions. Cumulative. I didn't show this. We actually was able to demo, like a collaboration with AGI model in China. We'll actually train a policy, and that was working perfectly fine, accumulator. So our model is inherently cross embodiment. We have probably also close to like 50 different robots in our training assets. So the robot has seen many, many data, including five figureheads.
questions. Cumulative. I didn't show this. We actually was able to demo, like a collaboration with AGI model in China. We'll actually train a policy, and that was working perfectly fine, accumulator. So our model is inherently cross embodiment. We have probably also close to like 50 different robots in our training assets. So the robot has seen many, many data, including five figureheads.
questions. Cumulative. I didn't show this. We actually was able to demo, like a collaboration with AGI model in China. We'll actually train a policy, and that was working perfectly fine, accumulator. So our model is inherently cross embodiment. We have probably also close to like 50 different robots in our training assets. So the robot has seen many, many data, including five figureheads.
questions. Cumulative. I didn't show this. We actually was able to demo, like a collaboration with AGI model in China. We'll actually train a policy, and that was working perfectly fine, accumulator. So our model is inherently cross embodiment. We have probably also close to like 50 different robots in our training assets. So the robot has seen many, many data, including five figureheads.
21:31Actually one more question.
Actually one more question.
Actually one more question.
Actually one more question.
S Speaker 121:33But continuing on, that portion of it, you mentioned a lot about the manipulation aspect of the training sample, about the locomotion? Yeah, I think local motion hasn't been a big focus of our project. We think, I think at pi, we really think that fine grained motor control at the gripper at the hands are more challenging at the moment, so we're super committed to that. I think we're gonna start looking more locomotion soon. There's also a lot of existing data set that we can use for the commercial. So, yeah, we're pretty excited about it.
But continuing on, that portion of it, you mentioned a lot about the manipulation aspect of the training sample, about the locomotion? Yeah, I think local motion hasn't been a big focus of our project. We think, I think at pi, we really think that fine grained motor control at the gripper at the hands are more challenging at the moment, so we're super committed to that. I think we're gonna start looking more locomotion soon. There's also a lot of existing data set that we can use for the commercial. So, yeah, we're pretty excited about it.
But continuing on, that portion of it, you mentioned a lot about the manipulation aspect of the training sample, about the locomotion? Yeah, I think local motion hasn't been a big focus of our project. We think, I think at pi, we really think that fine grained motor control at the gripper at the hands are more challenging at the moment, so we're super committed to that. I think we're gonna start looking more locomotion soon. There's also a lot of existing data set that we can use for the commercial. So, yeah, we're pretty excited about it.
But continuing on, that portion of it, you mentioned a lot about the manipulation aspect of the training sample, about the locomotion? Yeah, I think local motion hasn't been a big focus of our project. We think, I think at pi, we really think that fine grained motor control at the gripper at the hands are more challenging at the moment, so we're super committed to that. I think we're gonna start looking more locomotion soon. There's also a lot of existing data set that we can use for the commercial. So, yeah, we're pretty excited about it.
S Speaker 322:08Awesome. Well, thank you. Really appreciate this. Okay, I said earlier, one
Awesome. Well, thank you. Really appreciate this. Okay, I said earlier, one
Awesome. Well, thank you. Really appreciate this. Okay, I said earlier, one
Awesome. Well, thank you. Really appreciate this. Okay, I said earlier, one
S Speaker 322:18of the reasons you should be excited to be here is because of all the amazing people and the amazing conversations we're about to have, one of those amazing conversations right here on stage we're about to have fireside chat. So I would really love it if you would welcome our guests. I think this is correct. Rafe, is that correct? Yes. Raves, Rosen, Rosener, Gooden and James wells.
of the reasons you should be excited to be here is because of all the amazing people and the amazing conversations we're about to have, one of those amazing conversations right here on stage we're about to have fireside chat. So I would really love it if you would welcome our guests. I think this is correct. Rafe, is that correct? Yes. Raves, Rosen, Rosener, Gooden and James wells.
of the reasons you should be excited to be here is because of all the amazing people and the amazing conversations we're about to have, one of those amazing conversations right here on stage we're about to have fireside chat. So I would really love it if you would welcome our guests. I think this is correct. Rafe, is that correct? Yes. Raves, Rosen, Rosener, Gooden and James wells.
of the reasons you should be excited to be here is because of all the amazing people and the amazing conversations we're about to have, one of those amazing conversations right here on stage we're about to have fireside chat. So I would really love it if you would welcome our guests. I think this is correct. Rafe, is that correct? Yes. Raves, Rosen, Rosener, Gooden and James wells.