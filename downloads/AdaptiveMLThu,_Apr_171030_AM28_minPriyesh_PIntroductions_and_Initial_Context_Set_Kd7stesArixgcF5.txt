Meeting: AdaptiveML
Thu, Apr 17
10:30 AM
28 min
Priyesh P
Introductions and Initial Context Setting
0:31
Qual
URL: https://otter.ai/u/Kd7stesArixgcF51vUE5gOqrXmo
Downloaded: 2025-12-22T11:45:00.992361
Method: text_extraction
============================================================

0:31Hey. Hi, Andrew, great to meet you. Hi. Julian,
Hey. Hi, Andrew, great to meet you. Hi. Julian,
Hey. Hi, Andrew, great to meet you. Hi. Julian,
Hey. Hi, Andrew, great to meet you. Hi. Julian,
S Speaker 10:34yeah, likewise, good, good to speak. I don't think we actually met when we were at GTC, but we can't been too far away from each other, yeah,
yeah, likewise, good, good to speak. I don't think we actually met when we were at GTC, but we can't been too far away from each other, yeah,
yeah, likewise, good, good to speak. I don't think we actually met when we were at GTC, but we can't been too far away from each other, yeah,
yeah, likewise, good, good to speak. I don't think we actually met when we were at GTC, but we can't been too far away from each other, yeah,
S Speaker 20:43yeah. I remember speaking to Pearson. I had great conversation with him, but probably not met you there, yeah, maybe I was
yeah. I remember speaking to Pearson. I had great conversation with him, but probably not met you there, yeah, maybe I was
yeah. I remember speaking to Pearson. I had great conversation with him, but probably not met you there, yeah, maybe I was
yeah. I remember speaking to Pearson. I had great conversation with him, but probably not met you there, yeah, maybe I was
S Speaker 10:51talking to some people, obviously, like, it's very difficult at the booth. We have so many people coming past you always just trying to, like, talk to as many people as you can.
talking to some people, obviously, like, it's very difficult at the booth. We have so many people coming past you always just trying to, like, talk to as many people as you can.
talking to some people, obviously, like, it's very difficult at the booth. We have so many people coming past you always just trying to, like, talk to as many people as you can.
talking to some people, obviously, like, it's very difficult at the booth. We have so many people coming past you always just trying to, like, talk to as many people as you can.
S Speaker 21:00I can. The event seemed very busy. I hope it was a good success for you. Yeah,
I can. The event seemed very busy. I hope it was a good success for you. Yeah,
I can. The event seemed very busy. I hope it was a good success for you. Yeah,
I can. The event seemed very busy. I hope it was a good success for you. Yeah,
S Speaker 11:05no, it was very good. We had a lot of interest. Cool. Priyesh, is there anyone else joining from the Qualcomm side? Is it just going to be
no, it was very good. We had a lot of interest. Cool. Priyesh, is there anyone else joining from the Qualcomm side? Is it just going to be
no, it was very good. We had a lot of interest. Cool. Priyesh, is there anyone else joining from the Qualcomm side? Is it just going to be
no, it was very good. We had a lot of interest. Cool. Priyesh, is there anyone else joining from the Qualcomm side? Is it just going to be
S Speaker 21:14you just going to be me for today, Andrew, and maybe I can set the context of for the conversation here. So I am from the Qualcomm ventures team. So we are the corporate venture arm of Qualcomm. What we typically do is we work with a lot of startups, often from an investment perspective, but at the same time, we have a good pulse of what is going on in internally, within our business unit teams, and what technologies can be adopt at the same time. So we also talk to companies from that perspective. Often we make recommendations internally to business units on adopting some of the solutions. Use that as a evaluation criteria to understand how these businesses are doing and then follow up with the investment. Or sometimes it happens the other way. So this conversation, I believe, would be more introductory, have what we are doing internally is, currently, we do not have a lot of AI stack that we use within the corporate we have something internally built for customer success, and then we use Microsoft co pilot for an enterprise wide generative AI solution. But as you can imagine, it's not the best out there. So evaluating a few solutions, looking at them both from an adoption and investment perspective, okay,
you just going to be me for today, Andrew, and maybe I can set the context of for the conversation here. So I am from the Qualcomm ventures team. So we are the corporate venture arm of Qualcomm. What we typically do is we work with a lot of startups, often from an investment perspective, but at the same time, we have a good pulse of what is going on in internally, within our business unit teams, and what technologies can be adopt at the same time. So we also talk to companies from that perspective. Often we make recommendations internally to business units on adopting some of the solutions. Use that as a evaluation criteria to understand how these businesses are doing and then follow up with the investment. Or sometimes it happens the other way. So this conversation, I believe, would be more introductory, have what we are doing internally is, currently, we do not have a lot of AI stack that we use within the corporate we have something internally built for customer success, and then we use Microsoft co pilot for an enterprise wide generative AI solution. But as you can imagine, it's not the best out there. So evaluating a few solutions, looking at them both from an adoption and investment perspective, okay,
you just going to be me for today, Andrew, and maybe I can set the context of for the conversation here. So I am from the Qualcomm ventures team. So we are the corporate venture arm of Qualcomm. What we typically do is we work with a lot of startups, often from an investment perspective, but at the same time, we have a good pulse of what is going on in internally, within our business unit teams, and what technologies can be adopt at the same time. So we also talk to companies from that perspective. Often we make recommendations internally to business units on adopting some of the solutions. Use that as a evaluation criteria to understand how these businesses are doing and then follow up with the investment. Or sometimes it happens the other way. So this conversation, I believe, would be more introductory, have what we are doing internally is, currently, we do not have a lot of AI stack that we use within the corporate we have something internally built for customer success, and then we use Microsoft co pilot for an enterprise wide generative AI solution. But as you can imagine, it's not the best out there. So evaluating a few solutions, looking at them both from an adoption and investment perspective, okay,
you just going to be me for today, Andrew, and maybe I can set the context of for the conversation here. So I am from the Qualcomm ventures team. So we are the corporate venture arm of Qualcomm. What we typically do is we work with a lot of startups, often from an investment perspective, but at the same time, we have a good pulse of what is going on in internally, within our business unit teams, and what technologies can be adopt at the same time. So we also talk to companies from that perspective. Often we make recommendations internally to business units on adopting some of the solutions. Use that as a evaluation criteria to understand how these businesses are doing and then follow up with the investment. Or sometimes it happens the other way. So this conversation, I believe, would be more introductory, have what we are doing internally is, currently, we do not have a lot of AI stack that we use within the corporate we have something internally built for customer success, and then we use Microsoft co pilot for an enterprise wide generative AI solution. But as you can imagine, it's not the best out there. So evaluating a few solutions, looking at them both from an adoption and investment perspective, okay,
S Speaker 12:34fantastic context. I'm wondering if you could go a little bit deeper on that, but before we do just like some introductions on our side. So we have Julian, who's our CEO, on the call. Hi
fantastic context. I'm wondering if you could go a little bit deeper on that, but before we do just like some introductions on our side. So we have Julian, who's our CEO, on the call. Hi
fantastic context. I'm wondering if you could go a little bit deeper on that, but before we do just like some introductions on our side. So we have Julian, who's our CEO, on the call. Hi
fantastic context. I'm wondering if you could go a little bit deeper on that, but before we do just like some introductions on our side. So we have Julian, who's our CEO, on the call. Hi
2:46Julian. Very nice to meet
Julian. Very nice to meet
Julian. Very nice to meet
Julian. Very nice to meet
S Speaker 12:50And then, if just so you know my role, I'm the head of go to market here at adaptive.
And then, if just so you know my role, I'm the head of go to market here at adaptive.
And then, if just so you know my role, I'm the head of go to market here at adaptive.
And then, if just so you know my role, I'm the head of go to market here at adaptive.
2:56Very nice to meet you too as well. Andrew,
Very nice to meet you too as well. Andrew,
Very nice to meet you too as well. Andrew,
Very nice to meet you too as well. Andrew,
S Speaker 13:00cool. So yeah, as I was mentioning, it'll be good to get a little deeper understanding of what Qualcomm is doing, if you know, over and above what you said so far. So I'd be curious. Do you know if anyone in Qualcomm is currently looking at doing model fine tuning and using smaller, open source models at all? Or is that not something you're familiar
cool. So yeah, as I was mentioning, it'll be good to get a little deeper understanding of what Qualcomm is doing, if you know, over and above what you said so far. So I'd be curious. Do you know if anyone in Qualcomm is currently looking at doing model fine tuning and using smaller, open source models at all? Or is that not something you're familiar
cool. So yeah, as I was mentioning, it'll be good to get a little deeper understanding of what Qualcomm is doing, if you know, over and above what you said so far. So I'd be curious. Do you know if anyone in Qualcomm is currently looking at doing model fine tuning and using smaller, open source models at all? Or is that not something you're familiar
cool. So yeah, as I was mentioning, it'll be good to get a little deeper understanding of what Qualcomm is doing, if you know, over and above what you said so far. So I'd be curious. Do you know if anyone in Qualcomm is currently looking at doing model fine tuning and using smaller, open source models at all? Or is that not something you're familiar
S Speaker 23:23we know across different business units. So the corporate operates in silos across different business units. And you can imagine we have a mobile business unit, an automobile business unit, a PC business unit, cloud business units, ar, VR, XR. So all of them, I would say, have some use of reinforcement learning or small models, open source model that we planning to adopt for many of our workflows. We have internal engineering team which work on some of these. And for some of them, we have partnered with external solutions. Specifically like we for one external solution partnership, we are using contextual for our customer support use case, not the best accuracy that we would have expected out of it. And hence, we are in the market for evaluating a few more solutions.
we know across different business units. So the corporate operates in silos across different business units. And you can imagine we have a mobile business unit, an automobile business unit, a PC business unit, cloud business units, ar, VR, XR. So all of them, I would say, have some use of reinforcement learning or small models, open source model that we planning to adopt for many of our workflows. We have internal engineering team which work on some of these. And for some of them, we have partnered with external solutions. Specifically like we for one external solution partnership, we are using contextual for our customer support use case, not the best accuracy that we would have expected out of it. And hence, we are in the market for evaluating a few more solutions.
we know across different business units. So the corporate operates in silos across different business units. And you can imagine we have a mobile business unit, an automobile business unit, a PC business unit, cloud business units, ar, VR, XR. So all of them, I would say, have some use of reinforcement learning or small models, open source model that we planning to adopt for many of our workflows. We have internal engineering team which work on some of these. And for some of them, we have partnered with external solutions. Specifically like we for one external solution partnership, we are using contextual for our customer support use case, not the best accuracy that we would have expected out of it. And hence, we are in the market for evaluating a few more solutions.
we know across different business units. So the corporate operates in silos across different business units. And you can imagine we have a mobile business unit, an automobile business unit, a PC business unit, cloud business units, ar, VR, XR. So all of them, I would say, have some use of reinforcement learning or small models, open source model that we planning to adopt for many of our workflows. We have internal engineering team which work on some of these. And for some of them, we have partnered with external solutions. Specifically like we for one external solution partnership, we are using contextual for our customer support use case, not the best accuracy that we would have expected out of it. And hence, we are in the market for evaluating a few more solutions.
4:27tell you about what parts of our solution would be better,
tell you about what parts of our solution would be better,
tell you about what parts of our solution would be better,
tell you about what parts of our solution would be better,
S Speaker 14:53Okay, do you know what is causing like the sub 80% accuracy? Is it because you're not being able to retrieve the correct information, or is it because, once you have that context, is maybe not being used by the LLM correctly?
Okay, do you know what is causing like the sub 80% accuracy? Is it because you're not being able to retrieve the correct information, or is it because, once you have that context, is maybe not being used by the LLM correctly?
Okay, do you know what is causing like the sub 80% accuracy? Is it because you're not being able to retrieve the correct information, or is it because, once you have that context, is maybe not being used by the LLM correctly?
Okay, do you know what is causing like the sub 80% accuracy? Is it because you're not being able to retrieve the correct information, or is it because, once you have that context, is maybe not being used by the LLM correctly?
S Speaker 25:09So I would say two pronged one, we are not able to retrieve the best information. Some of these code bases are very complex internally as well, and then they also have to adopt or adapt to external clients interfaces, which has been a challenge as well.
So I would say two pronged one, we are not able to retrieve the best information. Some of these code bases are very complex internally as well, and then they also have to adopt or adapt to external clients interfaces, which has been a challenge as well.
So I would say two pronged one, we are not able to retrieve the best information. Some of these code bases are very complex internally as well, and then they also have to adopt or adapt to external clients interfaces, which has been a challenge as well.
So I would say two pronged one, we are not able to retrieve the best information. Some of these code bases are very complex internally as well, and then they also have to adopt or adapt to external clients interfaces, which has been a challenge as well.
S Speaker 15:28Okay, so it's like a two part problem. There's an issue on the retrieval side, and there's also an issue on the generative side, because you want to adapt your responses to like the particular style and requirement of different users across different businesses,
Okay, so it's like a two part problem. There's an issue on the retrieval side, and there's also an issue on the generative side, because you want to adapt your responses to like the particular style and requirement of different users across different businesses,
Okay, so it's like a two part problem. There's an issue on the retrieval side, and there's also an issue on the generative side, because you want to adapt your responses to like the particular style and requirement of different users across different businesses,
Okay, so it's like a two part problem. There's an issue on the retrieval side, and there's also an issue on the generative side, because you want to adapt your responses to like the particular style and requirement of different users across different businesses,
S Speaker 25:41yeah, but that's only one of the use cases, I would say. Not really familiar with exact research that is going on in a lot of these other business units, but I'm sure there are a lot of other use cases that could be internally.
yeah, but that's only one of the use cases, I would say. Not really familiar with exact research that is going on in a lot of these other business units, but I'm sure there are a lot of other use cases that could be internally.
yeah, but that's only one of the use cases, I would say. Not really familiar with exact research that is going on in a lot of these other business units, but I'm sure there are a lot of other use cases that could be internally.
yeah, but that's only one of the use cases, I would say. Not really familiar with exact research that is going on in a lot of these other business units, but I'm sure there are a lot of other use cases that could be internally.
S Speaker 26:15I am not particularly sure we have an investment in weights and biases. So we do. We have recommended some of our teams to use that, but I'm not really sure what this tech stack is today. Maybe it's useful. I can, I can have a discussion internally let you know about that.
I am not particularly sure we have an investment in weights and biases. So we do. We have recommended some of our teams to use that, but I'm not really sure what this tech stack is today. Maybe it's useful. I can, I can have a discussion internally let you know about that.
I am not particularly sure we have an investment in weights and biases. So we do. We have recommended some of our teams to use that, but I'm not really sure what this tech stack is today. Maybe it's useful. I can, I can have a discussion internally let you know about that.
I am not particularly sure we have an investment in weights and biases. So we do. We have recommended some of our teams to use that, but I'm not really sure what this tech stack is today. Maybe it's useful. I can, I can have a discussion internally let you know about that.
6:54Julian, was there anything you wanted to add? No,
Julian, was there anything you wanted to add? No,
Julian, was there anything you wanted to add? No,
Julian, was there anything you wanted to add? No,
S Speaker 36:57I think it's no. I think that. Thank you very much. I think it's good useful to get the picture on the on the usage. Thanks.
I think it's no. I think that. Thank you very much. I think it's good useful to get the picture on the on the usage. Thanks.
I think it's no. I think that. Thank you very much. I think it's good useful to get the picture on the on the usage. Thanks.
I think it's no. I think that. Thank you very much. I think it's good useful to get the picture on the on the usage. Thanks.
S Speaker 17:06All right, cool. So let me bring up some slides. Make sure I have the right ones. Do we go through a bit of an intro? You?
All right, cool. So let me bring up some slides. Make sure I have the right ones. Do we go through a bit of an intro? You?
All right, cool. So let me bring up some slides. Make sure I have the right ones. Do we go through a bit of an intro? You?
All right, cool. So let me bring up some slides. Make sure I have the right ones. Do we go through a bit of an intro? You?
7:27I should be seeing my screen. Yep, hold on, just
I should be seeing my screen. Yep, hold on, just
I should be seeing my screen. Yep, hold on, just
I should be seeing my screen. Yep, hold on, just
S Speaker 17:36one second. Okay, so there's a few moments for the presentation to load. Okay? So, yeah, provide a high level context. Adaptive engine is the platform and product that we offer. Adaptive engine is a reinforcement learning platform that makes it really easy for you to fine tune your own smaller, open weight llms that will go beyond the performance of what you can achieve from both frontier models, but also just using prompt engineering on its own. And so we regularly see that we can tune smaller models that will outperform all of the frontier models, whether that's Gemini Claude or GPT, we can outperform all of those with small models
one second. Okay, so there's a few moments for the presentation to load. Okay? So, yeah, provide a high level context. Adaptive engine is the platform and product that we offer. Adaptive engine is a reinforcement learning platform that makes it really easy for you to fine tune your own smaller, open weight llms that will go beyond the performance of what you can achieve from both frontier models, but also just using prompt engineering on its own. And so we regularly see that we can tune smaller models that will outperform all of the frontier models, whether that's Gemini Claude or GPT, we can outperform all of those with small models
one second. Okay, so there's a few moments for the presentation to load. Okay? So, yeah, provide a high level context. Adaptive engine is the platform and product that we offer. Adaptive engine is a reinforcement learning platform that makes it really easy for you to fine tune your own smaller, open weight llms that will go beyond the performance of what you can achieve from both frontier models, but also just using prompt engineering on its own. And so we regularly see that we can tune smaller models that will outperform all of the frontier models, whether that's Gemini Claude or GPT, we can outperform all of those with small models
one second. Okay, so there's a few moments for the presentation to load. Okay? So, yeah, provide a high level context. Adaptive engine is the platform and product that we offer. Adaptive engine is a reinforcement learning platform that makes it really easy for you to fine tune your own smaller, open weight llms that will go beyond the performance of what you can achieve from both frontier models, but also just using prompt engineering on its own. And so we regularly see that we can tune smaller models that will outperform all of the frontier models, whether that's Gemini Claude or GPT, we can outperform all of those with small models
S Speaker 28:19and Andrew the focus here specifically is on SLM and pure reinforcement learning. Is that correct? Yeah,
and Andrew the focus here specifically is on SLM and pure reinforcement learning. Is that correct? Yeah,
and Andrew the focus here specifically is on SLM and pure reinforcement learning. Is that correct? Yeah,
and Andrew the focus here specifically is on SLM and pure reinforcement learning. Is that correct? Yeah,
S Speaker 18:27so there's a bit of a nuance point here. So oftentimes we speak with customers about SlMs because that's kind of where the demand is. They want to use small models because they're cost effective, they're faster. They don't need as many GPUs to serve them. But the reality is adaptive engine as a platform can be used to fine tune models of exercise. So we could train lava 400 B, if you want. But yes, the point around reinforcement learning, the core technologies that we use are one reinforcement learning, which is like a much better form of fine tuning and finding gives significantly better results. And then the second thing that we put on a lot is synthetic data. So obviously, like one of the historic barriers to fine tuning has been, where do I get the data to do that fine tuning? We solve that by providing pre made synthetic data pipelines that mean you don't have to go and collect data. Then you can train models and ship them very quickly. I'll skip over this is about who we are, who we work with. Coming back to the problems that we solve. Getting Gen AI into production is hard. There are lots of different problems that prevent people getting into production. We can't solve all of them, but we focus on what we think are the two biggest problems, and those problems are evaluation and performance. I think the evaluation problem is pretty self explanatory. Creating evals that are relevant to your tasks in your business is quite a lot of work to like yourself put the elbow agrees in and that's because off the shelf benchmarks don't provide useful information relative to what you're trying to do. And so we try and solve this by providing a set of different tools that you can use to make evals easier to build. And then on the performance side, I think this is actually the more interesting problem, and what we see a lot of times from customers similar to what you were just echoing, is when you're trying to get into production with potential complex, multi step agentic pipelines, or customer facing type AI agents, it can actually be very, very difficult to Get the levels of accuracy and reliability you need using prompt engineering. And so what we do is we make it easy for you to fine tune models, which increases the level of accuracy and reliability so you can actually confidently shift into production. And the type of fine tuning that we really emphasize is reinforcement learning. The reason for that is kind of twofold. One is that it just gives much, much better results. I'll show you some information on that in a second. And the second part is it's kind of a newer paradigm that lets you train in a slightly different way, where if you can measure something that you care about with RL, you can directly optimize for that thing as a target. So given the like the support ticket use case that you just mentioned in RL, you could be collecting business metrics around what your customer response is to certain ticket answers. You can then directly optimize that so it could maybe be like response success rate, or like customer satisfaction from responses like you can directly optimize your model to maximize the business metrics that you care about. Okay, this is just a bit of research that we did last year comparing the performance of supervised fine tuning versus reinforcement learning as we won't go through all the details now, but we'll send you this deck so you can take a look through it. The TLDR Reinforcement learning is significantly more performant than supervised fine tuning, to the point where it almost never makes sense to use SFT apart in the curve like a few edge cases, right? Yeah. Great. And then in terms of working with us as a business, of course, we're a software provider, so if you have a team of engineers, you can just use our platform with active engine to fine tune models yourself. You can work with us that way. However, if you want to get to production really, really fast. We also provide a consulting service called kickstart, where we can come in and we can tune models specifically for your needs, get them to the point where you're ready to ship them into production, and then you continue to use them and continue to improve them using our software, adaptive,
so there's a bit of a nuance point here. So oftentimes we speak with customers about SlMs because that's kind of where the demand is. They want to use small models because they're cost effective, they're faster. They don't need as many GPUs to serve them. But the reality is adaptive engine as a platform can be used to fine tune models of exercise. So we could train lava 400 B, if you want. But yes, the point around reinforcement learning, the core technologies that we use are one reinforcement learning, which is like a much better form of fine tuning and finding gives significantly better results. And then the second thing that we put on a lot is synthetic data. So obviously, like one of the historic barriers to fine tuning has been, where do I get the data to do that fine tuning? We solve that by providing pre made synthetic data pipelines that mean you don't have to go and collect data. Then you can train models and ship them very quickly. I'll skip over this is about who we are, who we work with. Coming back to the problems that we solve. Getting Gen AI into production is hard. There are lots of different problems that prevent people getting into production. We can't solve all of them, but we focus on what we think are the two biggest problems, and those problems are evaluation and performance. I think the evaluation problem is pretty self explanatory. Creating evals that are relevant to your tasks in your business is quite a lot of work to like yourself put the elbow agrees in and that's because off the shelf benchmarks don't provide useful information relative to what you're trying to do. And so we try and solve this by providing a set of different tools that you can use to make evals easier to build. And then on the performance side, I think this is actually the more interesting problem, and what we see a lot of times from customers similar to what you were just echoing, is when you're trying to get into production with potential complex, multi step agentic pipelines, or customer facing type AI agents, it can actually be very, very difficult to Get the levels of accuracy and reliability you need using prompt engineering. And so what we do is we make it easy for you to fine tune models, which increases the level of accuracy and reliability so you can actually confidently shift into production. And the type of fine tuning that we really emphasize is reinforcement learning. The reason for that is kind of twofold. One is that it just gives much, much better results. I'll show you some information on that in a second. And the second part is it's kind of a newer paradigm that lets you train in a slightly different way, where if you can measure something that you care about with RL, you can directly optimize for that thing as a target. So given the like the support ticket use case that you just mentioned in RL, you could be collecting business metrics around what your customer response is to certain ticket answers. You can then directly optimize that so it could maybe be like response success rate, or like customer satisfaction from responses like you can directly optimize your model to maximize the business metrics that you care about. Okay, this is just a bit of research that we did last year comparing the performance of supervised fine tuning versus reinforcement learning as we won't go through all the details now, but we'll send you this deck so you can take a look through it. The TLDR Reinforcement learning is significantly more performant than supervised fine tuning, to the point where it almost never makes sense to use SFT apart in the curve like a few edge cases, right? Yeah. Great. And then in terms of working with us as a business, of course, we're a software provider, so if you have a team of engineers, you can just use our platform with active engine to fine tune models yourself. You can work with us that way. However, if you want to get to production really, really fast. We also provide a consulting service called kickstart, where we can come in and we can tune models specifically for your needs, get them to the point where you're ready to ship them into production, and then you continue to use them and continue to improve them using our software, adaptive,
so there's a bit of a nuance point here. So oftentimes we speak with customers about SlMs because that's kind of where the demand is. They want to use small models because they're cost effective, they're faster. They don't need as many GPUs to serve them. But the reality is adaptive engine as a platform can be used to fine tune models of exercise. So we could train lava 400 B, if you want. But yes, the point around reinforcement learning, the core technologies that we use are one reinforcement learning, which is like a much better form of fine tuning and finding gives significantly better results. And then the second thing that we put on a lot is synthetic data. So obviously, like one of the historic barriers to fine tuning has been, where do I get the data to do that fine tuning? We solve that by providing pre made synthetic data pipelines that mean you don't have to go and collect data. Then you can train models and ship them very quickly. I'll skip over this is about who we are, who we work with. Coming back to the problems that we solve. Getting Gen AI into production is hard. There are lots of different problems that prevent people getting into production. We can't solve all of them, but we focus on what we think are the two biggest problems, and those problems are evaluation and performance. I think the evaluation problem is pretty self explanatory. Creating evals that are relevant to your tasks in your business is quite a lot of work to like yourself put the elbow agrees in and that's because off the shelf benchmarks don't provide useful information relative to what you're trying to do. And so we try and solve this by providing a set of different tools that you can use to make evals easier to build. And then on the performance side, I think this is actually the more interesting problem, and what we see a lot of times from customers similar to what you were just echoing, is when you're trying to get into production with potential complex, multi step agentic pipelines, or customer facing type AI agents, it can actually be very, very difficult to Get the levels of accuracy and reliability you need using prompt engineering. And so what we do is we make it easy for you to fine tune models, which increases the level of accuracy and reliability so you can actually confidently shift into production. And the type of fine tuning that we really emphasize is reinforcement learning. The reason for that is kind of twofold. One is that it just gives much, much better results. I'll show you some information on that in a second. And the second part is it's kind of a newer paradigm that lets you train in a slightly different way, where if you can measure something that you care about with RL, you can directly optimize for that thing as a target. So given the like the support ticket use case that you just mentioned in RL, you could be collecting business metrics around what your customer response is to certain ticket answers. You can then directly optimize that so it could maybe be like response success rate, or like customer satisfaction from responses like you can directly optimize your model to maximize the business metrics that you care about. Okay, this is just a bit of research that we did last year comparing the performance of supervised fine tuning versus reinforcement learning as we won't go through all the details now, but we'll send you this deck so you can take a look through it. The TLDR Reinforcement learning is significantly more performant than supervised fine tuning, to the point where it almost never makes sense to use SFT apart in the curve like a few edge cases, right? Yeah. Great. And then in terms of working with us as a business, of course, we're a software provider, so if you have a team of engineers, you can just use our platform with active engine to fine tune models yourself. You can work with us that way. However, if you want to get to production really, really fast. We also provide a consulting service called kickstart, where we can come in and we can tune models specifically for your needs, get them to the point where you're ready to ship them into production, and then you continue to use them and continue to improve them using our software, adaptive,
so there's a bit of a nuance point here. So oftentimes we speak with customers about SlMs because that's kind of where the demand is. They want to use small models because they're cost effective, they're faster. They don't need as many GPUs to serve them. But the reality is adaptive engine as a platform can be used to fine tune models of exercise. So we could train lava 400 B, if you want. But yes, the point around reinforcement learning, the core technologies that we use are one reinforcement learning, which is like a much better form of fine tuning and finding gives significantly better results. And then the second thing that we put on a lot is synthetic data. So obviously, like one of the historic barriers to fine tuning has been, where do I get the data to do that fine tuning? We solve that by providing pre made synthetic data pipelines that mean you don't have to go and collect data. Then you can train models and ship them very quickly. I'll skip over this is about who we are, who we work with. Coming back to the problems that we solve. Getting Gen AI into production is hard. There are lots of different problems that prevent people getting into production. We can't solve all of them, but we focus on what we think are the two biggest problems, and those problems are evaluation and performance. I think the evaluation problem is pretty self explanatory. Creating evals that are relevant to your tasks in your business is quite a lot of work to like yourself put the elbow agrees in and that's because off the shelf benchmarks don't provide useful information relative to what you're trying to do. And so we try and solve this by providing a set of different tools that you can use to make evals easier to build. And then on the performance side, I think this is actually the more interesting problem, and what we see a lot of times from customers similar to what you were just echoing, is when you're trying to get into production with potential complex, multi step agentic pipelines, or customer facing type AI agents, it can actually be very, very difficult to Get the levels of accuracy and reliability you need using prompt engineering. And so what we do is we make it easy for you to fine tune models, which increases the level of accuracy and reliability so you can actually confidently shift into production. And the type of fine tuning that we really emphasize is reinforcement learning. The reason for that is kind of twofold. One is that it just gives much, much better results. I'll show you some information on that in a second. And the second part is it's kind of a newer paradigm that lets you train in a slightly different way, where if you can measure something that you care about with RL, you can directly optimize for that thing as a target. So given the like the support ticket use case that you just mentioned in RL, you could be collecting business metrics around what your customer response is to certain ticket answers. You can then directly optimize that so it could maybe be like response success rate, or like customer satisfaction from responses like you can directly optimize your model to maximize the business metrics that you care about. Okay, this is just a bit of research that we did last year comparing the performance of supervised fine tuning versus reinforcement learning as we won't go through all the details now, but we'll send you this deck so you can take a look through it. The TLDR Reinforcement learning is significantly more performant than supervised fine tuning, to the point where it almost never makes sense to use SFT apart in the curve like a few edge cases, right? Yeah. Great. And then in terms of working with us as a business, of course, we're a software provider, so if you have a team of engineers, you can just use our platform with active engine to fine tune models yourself. You can work with us that way. However, if you want to get to production really, really fast. We also provide a consulting service called kickstart, where we can come in and we can tune models specifically for your needs, get them to the point where you're ready to ship them into production, and then you continue to use them and continue to improve them using our software, adaptive,
S Speaker 212:58understood and Andrew, you mentioned you provide a set of tools to create custom evals. Can we double click on that as a bit?
understood and Andrew, you mentioned you provide a set of tools to create custom evals. Can we double click on that as a bit?
understood and Andrew, you mentioned you provide a set of tools to create custom evals. Can we double click on that as a bit?
understood and Andrew, you mentioned you provide a set of tools to create custom evals. Can we double click on that as a bit?
S Speaker 113:06Yeah, absolutely. I'll go through that in just a second. Okay, so now getting into the software adaptive engine, what does it do? So it's an end to end platform. It does both evaluation, fine tuning and also serving of llms will focus on the evaluation functionality to your point, as well as the different types of reinforcement learning which we support. So in terms of reinforcement learning, is a few different methods which you can use in the platform itself. The first one is RL, a, i, f, so using synthetic data to trade models like we were just talking about. We have pre made pipelines for this. To give you an example of one pre made pipeline that I think could be quite relevant actually to what you do, we have one for the rag Q and A task where, in order to tune a model for rag Q and A on a particular set of documents, all you need to do is provide the underlying documents. We will then synthetically generate example prompts or questions you might ask about those, and then, using those example prompts, we then provide synthetic feedback from several AI judges that will evaluate completions for the kind of behaviors that are important to you, and you can define those behaviors just in written natural language. So if it's important for you to define how a model responds to a particular customer, or maybe a certain customer has like a certain format they always want answers provided in, you can enforce that and train models using an AI judge, just by describing that behavior
Yeah, absolutely. I'll go through that in just a second. Okay, so now getting into the software adaptive engine, what does it do? So it's an end to end platform. It does both evaluation, fine tuning and also serving of llms will focus on the evaluation functionality to your point, as well as the different types of reinforcement learning which we support. So in terms of reinforcement learning, is a few different methods which you can use in the platform itself. The first one is RL, a, i, f, so using synthetic data to trade models like we were just talking about. We have pre made pipelines for this. To give you an example of one pre made pipeline that I think could be quite relevant actually to what you do, we have one for the rag Q and A task where, in order to tune a model for rag Q and A on a particular set of documents, all you need to do is provide the underlying documents. We will then synthetically generate example prompts or questions you might ask about those, and then, using those example prompts, we then provide synthetic feedback from several AI judges that will evaluate completions for the kind of behaviors that are important to you, and you can define those behaviors just in written natural language. So if it's important for you to define how a model responds to a particular customer, or maybe a certain customer has like a certain format they always want answers provided in, you can enforce that and train models using an AI judge, just by describing that behavior
Yeah, absolutely. I'll go through that in just a second. Okay, so now getting into the software adaptive engine, what does it do? So it's an end to end platform. It does both evaluation, fine tuning and also serving of llms will focus on the evaluation functionality to your point, as well as the different types of reinforcement learning which we support. So in terms of reinforcement learning, is a few different methods which you can use in the platform itself. The first one is RL, a, i, f, so using synthetic data to trade models like we were just talking about. We have pre made pipelines for this. To give you an example of one pre made pipeline that I think could be quite relevant actually to what you do, we have one for the rag Q and A task where, in order to tune a model for rag Q and A on a particular set of documents, all you need to do is provide the underlying documents. We will then synthetically generate example prompts or questions you might ask about those, and then, using those example prompts, we then provide synthetic feedback from several AI judges that will evaluate completions for the kind of behaviors that are important to you, and you can define those behaviors just in written natural language. So if it's important for you to define how a model responds to a particular customer, or maybe a certain customer has like a certain format they always want answers provided in, you can enforce that and train models using an AI judge, just by describing that behavior
Yeah, absolutely. I'll go through that in just a second. Okay, so now getting into the software adaptive engine, what does it do? So it's an end to end platform. It does both evaluation, fine tuning and also serving of llms will focus on the evaluation functionality to your point, as well as the different types of reinforcement learning which we support. So in terms of reinforcement learning, is a few different methods which you can use in the platform itself. The first one is RL, a, i, f, so using synthetic data to trade models like we were just talking about. We have pre made pipelines for this. To give you an example of one pre made pipeline that I think could be quite relevant actually to what you do, we have one for the rag Q and A task where, in order to tune a model for rag Q and A on a particular set of documents, all you need to do is provide the underlying documents. We will then synthetically generate example prompts or questions you might ask about those, and then, using those example prompts, we then provide synthetic feedback from several AI judges that will evaluate completions for the kind of behaviors that are important to you, and you can define those behaviors just in written natural language. So if it's important for you to define how a model responds to a particular customer, or maybe a certain customer has like a certain format they always want answers provided in, you can enforce that and train models using an AI judge, just by describing that behavior
S Speaker 214:45your AI feedback. I'm sure the accuracy levels would vary, but typically, just by using this to what level of accuracy can
your AI feedback. I'm sure the accuracy levels would vary, but typically, just by using this to what level of accuracy can
your AI feedback. I'm sure the accuracy levels would vary, but typically, just by using this to what level of accuracy can
your AI feedback. I'm sure the accuracy levels would vary, but typically, just by using this to what level of accuracy can
14:56adapt as platform reach? Yeah,
adapt as platform reach? Yeah,
adapt as platform reach? Yeah,
adapt as platform reach? Yeah,
S Speaker 114:59it's a really good question. I can't give you a single number because, of course, it will depend on the specific use case, but what we see generally is that using just AI feedback, we can get a model in the 8 billion parameter size category to either meet or exceed the performance of Frontier models. So it will be better than GPT 4.1 better than core 3.7 using an AP and only synthetic data. Interesting, yeah, so that's the first part of RL we support. In addition to that, the platform also supports RL on execution feedback as well as production feedback. So if you have a use case where there is a verifiable right or wrong answer we can connect to, like any point or a reward server that you might define yourself, and we can use that as a signal to tune the model. Example, use cases for this would be something like text to SQL for data analysis, maybe function calling. These are tasks where you can just check if the model created the right answer or not. And then once you've created a first aid model with either synthetic feedback or execution feedback, and you've deployed that into production, we then continuously improve these models using production feedback, like I was mentioning earlier, and we COVID.
it's a really good question. I can't give you a single number because, of course, it will depend on the specific use case, but what we see generally is that using just AI feedback, we can get a model in the 8 billion parameter size category to either meet or exceed the performance of Frontier models. So it will be better than GPT 4.1 better than core 3.7 using an AP and only synthetic data. Interesting, yeah, so that's the first part of RL we support. In addition to that, the platform also supports RL on execution feedback as well as production feedback. So if you have a use case where there is a verifiable right or wrong answer we can connect to, like any point or a reward server that you might define yourself, and we can use that as a signal to tune the model. Example, use cases for this would be something like text to SQL for data analysis, maybe function calling. These are tasks where you can just check if the model created the right answer or not. And then once you've created a first aid model with either synthetic feedback or execution feedback, and you've deployed that into production, we then continuously improve these models using production feedback, like I was mentioning earlier, and we COVID.
it's a really good question. I can't give you a single number because, of course, it will depend on the specific use case, but what we see generally is that using just AI feedback, we can get a model in the 8 billion parameter size category to either meet or exceed the performance of Frontier models. So it will be better than GPT 4.1 better than core 3.7 using an AP and only synthetic data. Interesting, yeah, so that's the first part of RL we support. In addition to that, the platform also supports RL on execution feedback as well as production feedback. So if you have a use case where there is a verifiable right or wrong answer we can connect to, like any point or a reward server that you might define yourself, and we can use that as a signal to tune the model. Example, use cases for this would be something like text to SQL for data analysis, maybe function calling. These are tasks where you can just check if the model created the right answer or not. And then once you've created a first aid model with either synthetic feedback or execution feedback, and you've deployed that into production, we then continuously improve these models using production feedback, like I was mentioning earlier, and we COVID.
it's a really good question. I can't give you a single number because, of course, it will depend on the specific use case, but what we see generally is that using just AI feedback, we can get a model in the 8 billion parameter size category to either meet or exceed the performance of Frontier models. So it will be better than GPT 4.1 better than core 3.7 using an AP and only synthetic data. Interesting, yeah, so that's the first part of RL we support. In addition to that, the platform also supports RL on execution feedback as well as production feedback. So if you have a use case where there is a verifiable right or wrong answer we can connect to, like any point or a reward server that you might define yourself, and we can use that as a signal to tune the model. Example, use cases for this would be something like text to SQL for data analysis, maybe function calling. These are tasks where you can just check if the model created the right answer or not. And then once you've created a first aid model with either synthetic feedback or execution feedback, and you've deployed that into production, we then continuously improve these models using production feedback, like I was mentioning earlier, and we COVID.
S Speaker 116:32Yeah, absolutely. So I was just going to mention that. So in terms of collecting production feedback in the platform, you can define custom metrics that are relevant to your tasks, and they can really be anything at all. And that data is collected Boolean or a scalar value. And then we collect that through a feedback endpoint, so you can just submit it to the platform. Very interesting. So these first two parts, these are all productized. You can use them through the UI, very straightforward and fast to use. And these cover the majority of use cases. For edge use cases where you want more customization. We also give you the ability to define custom recipes, both training and synthetic data through our SDK as well. Okay, so that's fine tuning. Tuning, of course, very important, but can't exist in isolation, because you can't ship models until you've evaluated them. So we also have evaluation platform. We support that with AI judges. We are both pre made and also customizable AI judges. So if you're working on a use case that is like very standardized, like rag, rag Q, a on documents, we have pre made AI judges you can just use very quickly, but if you're doing it something very bespoke, like what you were mentioning was, I need my model to respond in a particular way for different customers. That's something you would define of a custom AI judge, right? Ai judges are great, but they do have some limitations. So before shipping into production, we always recommend running an AB test so you can expose answers to actual human users, either internal testers or maybe in the future, actual users, like a small percentage of live traffic. We do that by just providing a completions endpoint. And then we switch the models that are serving that endpoint behind the scenes so you can do a blind AB test and actually understand which ones are best performing for your particular use case. And then finally, once models are in production, we also support guardrails, both training guardrail models, logging metrics, so you have visibility into performance in production, and then also logging traces, so you can see the individual interactions of llms with your users and to see what's going on there. All of this, by the way, if I haven't mentioned, it, can be deployed anywhere you want, so on premise or in your own private VPC as well. As we can have a SaaS offering as well, if that's preferable, although I would assume that Qualcomm would prefer to deploy in your own private
Yeah, absolutely. So I was just going to mention that. So in terms of collecting production feedback in the platform, you can define custom metrics that are relevant to your tasks, and they can really be anything at all. And that data is collected Boolean or a scalar value. And then we collect that through a feedback endpoint, so you can just submit it to the platform. Very interesting. So these first two parts, these are all productized. You can use them through the UI, very straightforward and fast to use. And these cover the majority of use cases. For edge use cases where you want more customization. We also give you the ability to define custom recipes, both training and synthetic data through our SDK as well. Okay, so that's fine tuning. Tuning, of course, very important, but can't exist in isolation, because you can't ship models until you've evaluated them. So we also have evaluation platform. We support that with AI judges. We are both pre made and also customizable AI judges. So if you're working on a use case that is like very standardized, like rag, rag Q, a on documents, we have pre made AI judges you can just use very quickly, but if you're doing it something very bespoke, like what you were mentioning was, I need my model to respond in a particular way for different customers. That's something you would define of a custom AI judge, right? Ai judges are great, but they do have some limitations. So before shipping into production, we always recommend running an AB test so you can expose answers to actual human users, either internal testers or maybe in the future, actual users, like a small percentage of live traffic. We do that by just providing a completions endpoint. And then we switch the models that are serving that endpoint behind the scenes so you can do a blind AB test and actually understand which ones are best performing for your particular use case. And then finally, once models are in production, we also support guardrails, both training guardrail models, logging metrics, so you have visibility into performance in production, and then also logging traces, so you can see the individual interactions of llms with your users and to see what's going on there. All of this, by the way, if I haven't mentioned, it, can be deployed anywhere you want, so on premise or in your own private VPC as well. As we can have a SaaS offering as well, if that's preferable, although I would assume that Qualcomm would prefer to deploy in your own private
Yeah, absolutely. So I was just going to mention that. So in terms of collecting production feedback in the platform, you can define custom metrics that are relevant to your tasks, and they can really be anything at all. And that data is collected Boolean or a scalar value. And then we collect that through a feedback endpoint, so you can just submit it to the platform. Very interesting. So these first two parts, these are all productized. You can use them through the UI, very straightforward and fast to use. And these cover the majority of use cases. For edge use cases where you want more customization. We also give you the ability to define custom recipes, both training and synthetic data through our SDK as well. Okay, so that's fine tuning. Tuning, of course, very important, but can't exist in isolation, because you can't ship models until you've evaluated them. So we also have evaluation platform. We support that with AI judges. We are both pre made and also customizable AI judges. So if you're working on a use case that is like very standardized, like rag, rag Q, a on documents, we have pre made AI judges you can just use very quickly, but if you're doing it something very bespoke, like what you were mentioning was, I need my model to respond in a particular way for different customers. That's something you would define of a custom AI judge, right? Ai judges are great, but they do have some limitations. So before shipping into production, we always recommend running an AB test so you can expose answers to actual human users, either internal testers or maybe in the future, actual users, like a small percentage of live traffic. We do that by just providing a completions endpoint. And then we switch the models that are serving that endpoint behind the scenes so you can do a blind AB test and actually understand which ones are best performing for your particular use case. And then finally, once models are in production, we also support guardrails, both training guardrail models, logging metrics, so you have visibility into performance in production, and then also logging traces, so you can see the individual interactions of llms with your users and to see what's going on there. All of this, by the way, if I haven't mentioned, it, can be deployed anywhere you want, so on premise or in your own private VPC as well. As we can have a SaaS offering as well, if that's preferable, although I would assume that Qualcomm would prefer to deploy in your own private
Yeah, absolutely. So I was just going to mention that. So in terms of collecting production feedback in the platform, you can define custom metrics that are relevant to your tasks, and they can really be anything at all. And that data is collected Boolean or a scalar value. And then we collect that through a feedback endpoint, so you can just submit it to the platform. Very interesting. So these first two parts, these are all productized. You can use them through the UI, very straightforward and fast to use. And these cover the majority of use cases. For edge use cases where you want more customization. We also give you the ability to define custom recipes, both training and synthetic data through our SDK as well. Okay, so that's fine tuning. Tuning, of course, very important, but can't exist in isolation, because you can't ship models until you've evaluated them. So we also have evaluation platform. We support that with AI judges. We are both pre made and also customizable AI judges. So if you're working on a use case that is like very standardized, like rag, rag Q, a on documents, we have pre made AI judges you can just use very quickly, but if you're doing it something very bespoke, like what you were mentioning was, I need my model to respond in a particular way for different customers. That's something you would define of a custom AI judge, right? Ai judges are great, but they do have some limitations. So before shipping into production, we always recommend running an AB test so you can expose answers to actual human users, either internal testers or maybe in the future, actual users, like a small percentage of live traffic. We do that by just providing a completions endpoint. And then we switch the models that are serving that endpoint behind the scenes so you can do a blind AB test and actually understand which ones are best performing for your particular use case. And then finally, once models are in production, we also support guardrails, both training guardrail models, logging metrics, so you have visibility into performance in production, and then also logging traces, so you can see the individual interactions of llms with your users and to see what's going on there. All of this, by the way, if I haven't mentioned, it, can be deployed anywhere you want, so on premise or in your own private VPC as well. As we can have a SaaS offering as well, if that's preferable, although I would assume that Qualcomm would prefer to deploy in your own private
S Speaker 219:14Yeah, yeah. We have a big push for edge compute as well. So I think that on prem is everything we would hope for,
Yeah, yeah. We have a big push for edge compute as well. So I think that on prem is everything we would hope for,
Yeah, yeah. We have a big push for edge compute as well. So I think that on prem is everything we would hope for,
Yeah, yeah. We have a big push for edge compute as well. So I think that on prem is everything we would hope for,
S Speaker 119:23okay? And then, actually, this is not the case study I wanted to show you. Let me just exit this one few
okay? And then, actually, this is not the case study I wanted to show you. Let me just exit this one few
okay? And then, actually, this is not the case study I wanted to show you. Let me just exit this one few
okay? And then, actually, this is not the case study I wanted to show you. Let me just exit this one few
S Speaker 122:12I think in the interest of time, I'll stop there, but if you have any other questions, happy to answer them. Otherwise, we'll be curious to hear your feedback.
I think in the interest of time, I'll stop there, but if you have any other questions, happy to answer them. Otherwise, we'll be curious to hear your feedback.
I think in the interest of time, I'll stop there, but if you have any other questions, happy to answer them. Otherwise, we'll be curious to hear your feedback.
I think in the interest of time, I'll stop there, but if you have any other questions, happy to answer them. Otherwise, we'll be curious to hear your feedback.
S Speaker 323:27I think what's very different, Priyesh that we have been focused on reinforcement learning from day one. So that has really been something like that has really been all focused since we started this company. You are starting to see a little bit of, like basic reinforcement, fine tuning, APIs, pop ups, you know, in some providers. But I think these are like to get these systems to production and to get them to the full extent of their capabilities. These are like complete pipelines and systems, actually, that you need, not just, you know, an API. I think this is like where we really excel, is that, and that includes a lot of stuff and so on. Synthetic data generation, where we also do a lot of data, human data, where, like, you get, you know, maybe 1020, 30 samples from expert users that are, like, you know, extremely smart. But obviously their time is worth a lot, so you are not going to ask them to annotate, you know, 1000s of samples that wouldn't be really tractable. And, you know, just from this 1020, 30, we augment them, you know, with the synthetic data to drive, you know, like safety data generation. And this is very effective. And this is, I think this is a kind of stuff that there isn't really that many people, you know, doing this. And I think especially the holistic approach to it is very unique to us. And that's really, I would say, or differentiator.
I think what's very different, Priyesh that we have been focused on reinforcement learning from day one. So that has really been something like that has really been all focused since we started this company. You are starting to see a little bit of, like basic reinforcement, fine tuning, APIs, pop ups, you know, in some providers. But I think these are like to get these systems to production and to get them to the full extent of their capabilities. These are like complete pipelines and systems, actually, that you need, not just, you know, an API. I think this is like where we really excel, is that, and that includes a lot of stuff and so on. Synthetic data generation, where we also do a lot of data, human data, where, like, you get, you know, maybe 1020, 30 samples from expert users that are, like, you know, extremely smart. But obviously their time is worth a lot, so you are not going to ask them to annotate, you know, 1000s of samples that wouldn't be really tractable. And, you know, just from this 1020, 30, we augment them, you know, with the synthetic data to drive, you know, like safety data generation. And this is very effective. And this is, I think this is a kind of stuff that there isn't really that many people, you know, doing this. And I think especially the holistic approach to it is very unique to us. And that's really, I would say, or differentiator.
I think what's very different, Priyesh that we have been focused on reinforcement learning from day one. So that has really been something like that has really been all focused since we started this company. You are starting to see a little bit of, like basic reinforcement, fine tuning, APIs, pop ups, you know, in some providers. But I think these are like to get these systems to production and to get them to the full extent of their capabilities. These are like complete pipelines and systems, actually, that you need, not just, you know, an API. I think this is like where we really excel, is that, and that includes a lot of stuff and so on. Synthetic data generation, where we also do a lot of data, human data, where, like, you get, you know, maybe 1020, 30 samples from expert users that are, like, you know, extremely smart. But obviously their time is worth a lot, so you are not going to ask them to annotate, you know, 1000s of samples that wouldn't be really tractable. And, you know, just from this 1020, 30, we augment them, you know, with the synthetic data to drive, you know, like safety data generation. And this is very effective. And this is, I think this is a kind of stuff that there isn't really that many people, you know, doing this. And I think especially the holistic approach to it is very unique to us. And that's really, I would say, or differentiator.
I think what's very different, Priyesh that we have been focused on reinforcement learning from day one. So that has really been something like that has really been all focused since we started this company. You are starting to see a little bit of, like basic reinforcement, fine tuning, APIs, pop ups, you know, in some providers. But I think these are like to get these systems to production and to get them to the full extent of their capabilities. These are like complete pipelines and systems, actually, that you need, not just, you know, an API. I think this is like where we really excel, is that, and that includes a lot of stuff and so on. Synthetic data generation, where we also do a lot of data, human data, where, like, you get, you know, maybe 1020, 30 samples from expert users that are, like, you know, extremely smart. But obviously their time is worth a lot, so you are not going to ask them to annotate, you know, 1000s of samples that wouldn't be really tractable. And, you know, just from this 1020, 30, we augment them, you know, with the synthetic data to drive, you know, like safety data generation. And this is very effective. And this is, I think this is a kind of stuff that there isn't really that many people, you know, doing this. And I think especially the holistic approach to it is very unique to us. And that's really, I would say, or differentiator.
S Speaker 224:42That makes sense. Julian, a lot. It makes sense a lot. Did you see once the deep sick came out and open? Ai mentioned that their latest models were reinforcement line. Did you see an inflection point in the company?
That makes sense. Julian, a lot. It makes sense a lot. Did you see once the deep sick came out and open? Ai mentioned that their latest models were reinforcement line. Did you see an inflection point in the company?
That makes sense. Julian, a lot. It makes sense a lot. Did you see once the deep sick came out and open? Ai mentioned that their latest models were reinforcement line. Did you see an inflection point in the company?
That makes sense. Julian, a lot. It makes sense a lot. Did you see once the deep sick came out and open? Ai mentioned that their latest models were reinforcement line. Did you see an inflection point in the company?
S Speaker 225:31I get that totally, totally must make the job easier for you. And that's great that you've already been working on the entire stack way before some of these things became hot. So that's and Julian, I guess, last question from my end, and this is coming from the venture again, I saw you raised a big seed round earlier last year. Is there a plan to do another fundraising sometime soon,
I get that totally, totally must make the job easier for you. And that's great that you've already been working on the entire stack way before some of these things became hot. So that's and Julian, I guess, last question from my end, and this is coming from the venture again, I saw you raised a big seed round earlier last year. Is there a plan to do another fundraising sometime soon,
I get that totally, totally must make the job easier for you. And that's great that you've already been working on the entire stack way before some of these things became hot. So that's and Julian, I guess, last question from my end, and this is coming from the venture again, I saw you raised a big seed round earlier last year. Is there a plan to do another fundraising sometime soon,
I get that totally, totally must make the job easier for you. And that's great that you've already been working on the entire stack way before some of these things became hot. So that's and Julian, I guess, last question from my end, and this is coming from the venture again, I saw you raised a big seed round earlier last year. Is there a plan to do another fundraising sometime soon,
S Speaker 325:56probably this year, but a bit early to say, you know, like exactly, I think we were still very focused, you know, like, fundraising is a little bit distracting as something that you know. And even in the best of worlds, you know, right, even when it's very fast, and when you know, you know people with whom you want fundraise, it goes very quickly. I mean, it still take, you know, a few months to get, like, to get all of the legal stuff done. And I was saying at the moment, you know, we are still very focused on scaling our customer engagements that we have with at&t, like, that's we really want to continue growing our products to be really, to be really, really cool. And so we are still waiting a little bit for, like, putting the trigger on for anything. Just this is a question of focus. I think this is, this is something we'll probably do this year, because we are very happy with the traction we are getting. And we think there is a lot we could do with additional cash. Like, I think there is kind of doubling down on some of our, some of our strategy that we could do. But for now, I think, for the for the immediate coming months, is we are still very, like, very focused on, on, on building,
probably this year, but a bit early to say, you know, like exactly, I think we were still very focused, you know, like, fundraising is a little bit distracting as something that you know. And even in the best of worlds, you know, right, even when it's very fast, and when you know, you know people with whom you want fundraise, it goes very quickly. I mean, it still take, you know, a few months to get, like, to get all of the legal stuff done. And I was saying at the moment, you know, we are still very focused on scaling our customer engagements that we have with at&t, like, that's we really want to continue growing our products to be really, to be really, really cool. And so we are still waiting a little bit for, like, putting the trigger on for anything. Just this is a question of focus. I think this is, this is something we'll probably do this year, because we are very happy with the traction we are getting. And we think there is a lot we could do with additional cash. Like, I think there is kind of doubling down on some of our, some of our strategy that we could do. But for now, I think, for the for the immediate coming months, is we are still very, like, very focused on, on, on building,
probably this year, but a bit early to say, you know, like exactly, I think we were still very focused, you know, like, fundraising is a little bit distracting as something that you know. And even in the best of worlds, you know, right, even when it's very fast, and when you know, you know people with whom you want fundraise, it goes very quickly. I mean, it still take, you know, a few months to get, like, to get all of the legal stuff done. And I was saying at the moment, you know, we are still very focused on scaling our customer engagements that we have with at&t, like, that's we really want to continue growing our products to be really, to be really, really cool. And so we are still waiting a little bit for, like, putting the trigger on for anything. Just this is a question of focus. I think this is, this is something we'll probably do this year, because we are very happy with the traction we are getting. And we think there is a lot we could do with additional cash. Like, I think there is kind of doubling down on some of our, some of our strategy that we could do. But for now, I think, for the for the immediate coming months, is we are still very, like, very focused on, on, on building,
probably this year, but a bit early to say, you know, like exactly, I think we were still very focused, you know, like, fundraising is a little bit distracting as something that you know. And even in the best of worlds, you know, right, even when it's very fast, and when you know, you know people with whom you want fundraise, it goes very quickly. I mean, it still take, you know, a few months to get, like, to get all of the legal stuff done. And I was saying at the moment, you know, we are still very focused on scaling our customer engagements that we have with at&t, like, that's we really want to continue growing our products to be really, to be really, really cool. And so we are still waiting a little bit for, like, putting the trigger on for anything. Just this is a question of focus. I think this is, this is something we'll probably do this year, because we are very happy with the traction we are getting. And we think there is a lot we could do with additional cash. Like, I think there is kind of doubling down on some of our, some of our strategy that we could do. But for now, I think, for the for the immediate coming months, is we are still very, like, very focused on, on, on building,
S Speaker 126:57yeah, Priyesh, just to come back to, like, the support certificate use case that I think you've been having some troubles with. This is the kind of thing that we're really bullish on, and we think our platform is uniquely good for because of the ability to learn from production feedback. If that's something where you would be interested to engage, I think we would be very aggressive in terms of a partnership, I know it's obviously not your decision to make, but it's a kind of scenario where I think we would ourselves a significant amount of risk based on the results that we could achieve. And we've been doing some similar things, actually, with Deloitte, who is one of our kind of resellers and system integrators. So we've been working with, like a very large airline, and a lot of our revenue is on the line. We can't get the results that they need. So the risks a lot from Qualcomm's perspective, if you were interested to explore that and
yeah, Priyesh, just to come back to, like, the support certificate use case that I think you've been having some troubles with. This is the kind of thing that we're really bullish on, and we think our platform is uniquely good for because of the ability to learn from production feedback. If that's something where you would be interested to engage, I think we would be very aggressive in terms of a partnership, I know it's obviously not your decision to make, but it's a kind of scenario where I think we would ourselves a significant amount of risk based on the results that we could achieve. And we've been doing some similar things, actually, with Deloitte, who is one of our kind of resellers and system integrators. So we've been working with, like a very large airline, and a lot of our revenue is on the line. We can't get the results that they need. So the risks a lot from Qualcomm's perspective, if you were interested to explore that and
yeah, Priyesh, just to come back to, like, the support certificate use case that I think you've been having some troubles with. This is the kind of thing that we're really bullish on, and we think our platform is uniquely good for because of the ability to learn from production feedback. If that's something where you would be interested to engage, I think we would be very aggressive in terms of a partnership, I know it's obviously not your decision to make, but it's a kind of scenario where I think we would ourselves a significant amount of risk based on the results that we could achieve. And we've been doing some similar things, actually, with Deloitte, who is one of our kind of resellers and system integrators. So we've been working with, like a very large airline, and a lot of our revenue is on the line. We can't get the results that they need. So the risks a lot from Qualcomm's perspective, if you were interested to explore that and
yeah, Priyesh, just to come back to, like, the support certificate use case that I think you've been having some troubles with. This is the kind of thing that we're really bullish on, and we think our platform is uniquely good for because of the ability to learn from production feedback. If that's something where you would be interested to engage, I think we would be very aggressive in terms of a partnership, I know it's obviously not your decision to make, but it's a kind of scenario where I think we would ourselves a significant amount of risk based on the results that we could achieve. And we've been doing some similar things, actually, with Deloitte, who is one of our kind of resellers and system integrators. So we've been working with, like a very large airline, and a lot of our revenue is on the line. We can't get the results that they need. So the risks a lot from Qualcomm's perspective, if you were interested to explore that and
S Speaker 227:54when on that, we are evaluating, we have evaluated a couple other solutions post our deployment with contextual on whether we can improve the entire process, and we would be excited to one as well. Maybe what I can do is I can in a follow up call, also loop in our Managing Director from the ventures fund. He was a person who led the entire contextual partnership, so would like to introduce him as well to the team, and we'll also come back with our follow up questions on the same front internally. I think we have done enough work there that we understand what it means to quickly evaluate a solution. So we will be aggressive here as well. I'll let you know.
when on that, we are evaluating, we have evaluated a couple other solutions post our deployment with contextual on whether we can improve the entire process, and we would be excited to one as well. Maybe what I can do is I can in a follow up call, also loop in our Managing Director from the ventures fund. He was a person who led the entire contextual partnership, so would like to introduce him as well to the team, and we'll also come back with our follow up questions on the same front internally. I think we have done enough work there that we understand what it means to quickly evaluate a solution. So we will be aggressive here as well. I'll let you know.
when on that, we are evaluating, we have evaluated a couple other solutions post our deployment with contextual on whether we can improve the entire process, and we would be excited to one as well. Maybe what I can do is I can in a follow up call, also loop in our Managing Director from the ventures fund. He was a person who led the entire contextual partnership, so would like to introduce him as well to the team, and we'll also come back with our follow up questions on the same front internally. I think we have done enough work there that we understand what it means to quickly evaluate a solution. So we will be aggressive here as well. I'll let you know.
when on that, we are evaluating, we have evaluated a couple other solutions post our deployment with contextual on whether we can improve the entire process, and we would be excited to one as well. Maybe what I can do is I can in a follow up call, also loop in our Managing Director from the ventures fund. He was a person who led the entire contextual partnership, so would like to introduce him as well to the team, and we'll also come back with our follow up questions on the same front internally. I think we have done enough work there that we understand what it means to quickly evaluate a solution. So we will be aggressive here as well. I'll let you know.
S Speaker 128:37Okay, fantastic. Priyesh, it was really good to meet you. I will send over the materials, and then look forward to hearing on next steps. Absolutely.
Okay, fantastic. Priyesh, it was really good to meet you. I will send over the materials, and then look forward to hearing on next steps. Absolutely.
Okay, fantastic. Priyesh, it was really good to meet you. I will send over the materials, and then look forward to hearing on next steps. Absolutely.
Okay, fantastic. Priyesh, it was really good to meet you. I will send over the materials, and then look forward to hearing on next steps. Absolutely.
S Speaker 228:45It was a pleasure. Andrew, thanks Julian, happy, she's your time. Thank you very much, bye bye now.
It was a pleasure. Andrew, thanks Julian, happy, she's your time. Thank you very much, bye bye now.
It was a pleasure. Andrew, thanks Julian, happy, she's your time. Thank you very much, bye bye now.
It was a pleasure. Andrew, thanks Julian, happy, she's your time. Thank you very much, bye bye now.