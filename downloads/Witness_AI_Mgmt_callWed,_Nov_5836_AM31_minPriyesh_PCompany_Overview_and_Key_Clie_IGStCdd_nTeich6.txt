Meeting: Witness AI Mgmt call
Wed, Nov 5
8:36 AM
31 min
Priyesh P
Company Overview and Key Clients
0:00
Team 
URL: https://otter.ai/u/IGStCdd_nTeich6uGP5csNi3R-8
Downloaded: 2025-12-21T19:43:35.365235
Method: text_extraction
============================================================

S Speaker 18:16elements, so let me go into the technical differentiators, because that's how we enable these things. The first is, unlike the competition, we don't work with like an endpoint agent or a browser plugin. We work at the network level. We connect to someone's C scale or Palo checkpoint netscope. We do proxy chaining off of that we capture the network traffic. The reason why this is important is there's a lot of very important AI traffic that does not go through a browser. Copilot is the current big driver here, like copilot in Windows, copilot in native office, doesn't go through a browser. The only way you're going to see it is at the network level, like we do also when people use anthropic, you know, chat, GPT, cloud, whatever desktop apps you're not going to see those in the browser plugin. So one of the big differentiators is by living in the network, we see things people don't see. I'll, I'll jump ahead a little bit to the remediation. Because we live in the network, we can reroute prompts on the fly. So one big use case right now is a developer use case where people say, Hey, listen, my developers are pasting all our source code into chat GPT, or they're using GitHub copilot with some IDE I want them to get answers, but I don't want this to leave the network. And witness can intercept the prompt and reroute it to an internal model for a customer, so it allows them to get balance, you know, employees getting answers without data, leaving the network. It also lets us control things like routing to models based on cost and risk. So we can say, okay, there's running this kind of prompt internally. The customer has four or five different types of models. It's going to be cheaper to route it to this model. So we'll do it. And then we can tack that on, add that up over the year, and say, in terms of the amount of tokens you're burning and the way we're routing, you know, we're saving you this much, this much cost over the year, and we've eliminated this many risky potential conversations. The second thing we do that's that's interesting, is we've just kind of two parts to the product. There's a high scale network services
elements, so let me go into the technical differentiators, because that's how we enable these things. The first is, unlike the competition, we don't work with like an endpoint agent or a browser plugin. We work at the network level. We connect to someone's C scale or Palo checkpoint netscope. We do proxy chaining off of that we capture the network traffic. The reason why this is important is there's a lot of very important AI traffic that does not go through a browser. Copilot is the current big driver here, like copilot in Windows, copilot in native office, doesn't go through a browser. The only way you're going to see it is at the network level, like we do also when people use anthropic, you know, chat, GPT, cloud, whatever desktop apps you're not going to see those in the browser plugin. So one of the big differentiators is by living in the network, we see things people don't see. I'll, I'll jump ahead a little bit to the remediation. Because we live in the network, we can reroute prompts on the fly. So one big use case right now is a developer use case where people say, Hey, listen, my developers are pasting all our source code into chat GPT, or they're using GitHub copilot with some IDE I want them to get answers, but I don't want this to leave the network. And witness can intercept the prompt and reroute it to an internal model for a customer, so it allows them to get balance, you know, employees getting answers without data, leaving the network. It also lets us control things like routing to models based on cost and risk. So we can say, okay, there's running this kind of prompt internally. The customer has four or five different types of models. It's going to be cheaper to route it to this model. So we'll do it. And then we can tack that on, add that up over the year, and say, in terms of the amount of tokens you're burning and the way we're routing, you know, we're saving you this much, this much cost over the year, and we've eliminated this many risky potential conversations. The second thing we do that's that's interesting, is we've just kind of two parts to the product. There's a high scale network services
elements, so let me go into the technical differentiators, because that's how we enable these things. The first is, unlike the competition, we don't work with like an endpoint agent or a browser plugin. We work at the network level. We connect to someone's C scale or Palo checkpoint netscope. We do proxy chaining off of that we capture the network traffic. The reason why this is important is there's a lot of very important AI traffic that does not go through a browser. Copilot is the current big driver here, like copilot in Windows, copilot in native office, doesn't go through a browser. The only way you're going to see it is at the network level, like we do also when people use anthropic, you know, chat, GPT, cloud, whatever desktop apps you're not going to see those in the browser plugin. So one of the big differentiators is by living in the network, we see things people don't see. I'll, I'll jump ahead a little bit to the remediation. Because we live in the network, we can reroute prompts on the fly. So one big use case right now is a developer use case where people say, Hey, listen, my developers are pasting all our source code into chat GPT, or they're using GitHub copilot with some IDE I want them to get answers, but I don't want this to leave the network. And witness can intercept the prompt and reroute it to an internal model for a customer, so it allows them to get balance, you know, employees getting answers without data, leaving the network. It also lets us control things like routing to models based on cost and risk. So we can say, okay, there's running this kind of prompt internally. The customer has four or five different types of models. It's going to be cheaper to route it to this model. So we'll do it. And then we can tack that on, add that up over the year, and say, in terms of the amount of tokens you're burning and the way we're routing, you know, we're saving you this much, this much cost over the year, and we've eliminated this many risky potential conversations. The second thing we do that's that's interesting, is we've just kind of two parts to the product. There's a high scale network services
elements, so let me go into the technical differentiators, because that's how we enable these things. The first is, unlike the competition, we don't work with like an endpoint agent or a browser plugin. We work at the network level. We connect to someone's C scale or Palo checkpoint netscope. We do proxy chaining off of that we capture the network traffic. The reason why this is important is there's a lot of very important AI traffic that does not go through a browser. Copilot is the current big driver here, like copilot in Windows, copilot in native office, doesn't go through a browser. The only way you're going to see it is at the network level, like we do also when people use anthropic, you know, chat, GPT, cloud, whatever desktop apps you're not going to see those in the browser plugin. So one of the big differentiators is by living in the network, we see things people don't see. I'll, I'll jump ahead a little bit to the remediation. Because we live in the network, we can reroute prompts on the fly. So one big use case right now is a developer use case where people say, Hey, listen, my developers are pasting all our source code into chat GPT, or they're using GitHub copilot with some IDE I want them to get answers, but I don't want this to leave the network. And witness can intercept the prompt and reroute it to an internal model for a customer, so it allows them to get balance, you know, employees getting answers without data, leaving the network. It also lets us control things like routing to models based on cost and risk. So we can say, okay, there's running this kind of prompt internally. The customer has four or five different types of models. It's going to be cheaper to route it to this model. So we'll do it. And then we can tack that on, add that up over the year, and say, in terms of the amount of tokens you're burning and the way we're routing, you know, we're saving you this much, this much cost over the year, and we've eliminated this many risky potential conversations. The second thing we do that's that's interesting, is we've just kind of two parts to the product. There's a high scale network services
S Speaker 310:40platform wanted to follow up on our conversation
platform wanted to follow up on our conversation
platform wanted to follow up on our conversation
platform wanted to follow up on our conversation
S Speaker 110:45scale, low latency, packet management traffic.
scale, low latency, packet management traffic.
scale, low latency, packet management traffic.
scale, low latency, packet management traffic.
10:51Then we've also built a set of high speed
Then we've also built a set of high speed
Then we've also built a set of high speed
Then we've also built a set of high speed
S Speaker 310:54I'm moving in Tushar, who is the managing director at Qualcomm ventures and leads at US investments. We would love to do an intro chat with Tushar. Would sometime tomorrow, 9am
I'm moving in Tushar, who is the managing director at Qualcomm ventures and leads at US investments. We would love to do an intro chat with Tushar. Would sometime tomorrow, 9am
I'm moving in Tushar, who is the managing director at Qualcomm ventures and leads at US investments. We would love to do an intro chat with Tushar. Would sometime tomorrow, 9am
I'm moving in Tushar, who is the managing director at Qualcomm ventures and leads at US investments. We would love to do an intro chat with Tushar. Would sometime tomorrow, 9am
11:11to 4pm PST, work for you,
to 4pm PST, work for you,
to 4pm PST, work for you,
to 4pm PST, work for you,
S Speaker 111:16or route it somewhere else, so that real time model processing of traffic is is pretty big deal for us,
or route it somewhere else, so that real time model processing of traffic is is pretty big deal for us,
or route it somewhere else, so that real time model processing of traffic is is pretty big deal for us,
or route it somewhere else, so that real time model processing of traffic is is pretty big deal for us,
11:25and latency is important to you, right? Rick,
and latency is important to you, right? Rick,
and latency is important to you, right? Rick,
and latency is important to you, right? Rick,
S Speaker 111:27yeah, so this is a this is a key. So right now our end to end latency from an average from user typing in a prompt, going to their proxy, chaining to us, us acting on it, doing some level of filtering, sending on to the destination model, taking the response and all the way back, is averaging about 60 milliseconds, very, very low latency. This was very hard
yeah, so this is a this is a key. So right now our end to end latency from an average from user typing in a prompt, going to their proxy, chaining to us, us acting on it, doing some level of filtering, sending on to the destination model, taking the response and all the way back, is averaging about 60 milliseconds, very, very low latency. This was very hard
yeah, so this is a this is a key. So right now our end to end latency from an average from user typing in a prompt, going to their proxy, chaining to us, us acting on it, doing some level of filtering, sending on to the destination model, taking the response and all the way back, is averaging about 60 milliseconds, very, very low latency. This was very hard
yeah, so this is a this is a key. So right now our end to end latency from an average from user typing in a prompt, going to their proxy, chaining to us, us acting on it, doing some level of filtering, sending on to the destination model, taking the response and all the way back, is averaging about 60 milliseconds, very, very low latency. This was very hard
S Speaker 411:56to do. What's the overhead that your solution is
to do. What's the overhead that your solution is
to do. What's the overhead that your solution is
to do. What's the overhead that your solution is
S Speaker 315:11Hi Prakash. Was a pleasure speaking last week as we chatted, I'd love to loop in Tushar, Managing Director at Qualcomm ventures, who leads our US investments and explore partnerships. What we'd love to meet in person, over lunch, and can make it either tomorrow or Tuesday, Thursday and Friday of next week, anything work for you. And Kabir a
Hi Prakash. Was a pleasure speaking last week as we chatted, I'd love to loop in Tushar, Managing Director at Qualcomm ventures, who leads our US investments and explore partnerships. What we'd love to meet in person, over lunch, and can make it either tomorrow or Tuesday, Thursday and Friday of next week, anything work for you. And Kabir a
Hi Prakash. Was a pleasure speaking last week as we chatted, I'd love to loop in Tushar, Managing Director at Qualcomm ventures, who leads our US investments and explore partnerships. What we'd love to meet in person, over lunch, and can make it either tomorrow or Tuesday, Thursday and Friday of next week, anything work for you. And Kabir a
Hi Prakash. Was a pleasure speaking last week as we chatted, I'd love to loop in Tushar, Managing Director at Qualcomm ventures, who leads our US investments and explore partnerships. What we'd love to meet in person, over lunch, and can make it either tomorrow or Tuesday, Thursday and Friday of next week, anything work for you. And Kabir a
S Speaker 115:36thing you know, the startups that just have, like a browser plug in some kind of multi tenant back end, so I'll stop and take a breath. Does that make sense? I kind of dug into the technology a little bit more, hopefully that that's useful
thing you know, the startups that just have, like a browser plug in some kind of multi tenant back end, so I'll stop and take a breath. Does that make sense? I kind of dug into the technology a little bit more, hopefully that that's useful
thing you know, the startups that just have, like a browser plug in some kind of multi tenant back end, so I'll stop and take a breath. Does that make sense? I kind of dug into the technology a little bit more, hopefully that that's useful
thing you know, the startups that just have, like a browser plug in some kind of multi tenant back end, so I'll stop and take a breath. Does that make sense? I kind of dug into the technology a little bit more, hopefully that that's useful
S Speaker 415:50for people. Any other questions?
for people. Any other questions?
for people. Any other questions?
for people. Any other questions?
S Speaker 215:53And Rick, if you can talk about how quickly or how easy it is to deploy, and also size and scale, because you talked about multiple features of the platform.
And Rick, if you can talk about how quickly or how easy it is to deploy, and also size and scale, because you talked about multiple features of the platform.
And Rick, if you can talk about how quickly or how easy it is to deploy, and also size and scale, because you talked about multiple features of the platform.
And Rick, if you can talk about how quickly or how easy it is to deploy, and also size and scale, because you talked about multiple features of the platform.
16:01But how does it work in the field?
But how does it work in the field?
But how does it work in the field?
But how does it work in the field?
S Speaker 116:07Yeah, go ahead. So think NTT. So NTT came to us and said they licensed 150,000 employees June 6. They said, if you can get 150,000 employees into production in 30 days go through the contract. We put the first 150,000 into production in three days, they turned off their firewall rules. The Board of Directors told the global CISO, stop screwing around. I want the employees to use AI in three days, we had 150,001 in production. It turned off all the blocking of these things working great. No noticeable delays. Customers are very happy.
Yeah, go ahead. So think NTT. So NTT came to us and said they licensed 150,000 employees June 6. They said, if you can get 150,000 employees into production in 30 days go through the contract. We put the first 150,000 into production in three days, they turned off their firewall rules. The Board of Directors told the global CISO, stop screwing around. I want the employees to use AI in three days, we had 150,001 in production. It turned off all the blocking of these things working great. No noticeable delays. Customers are very happy.
Yeah, go ahead. So think NTT. So NTT came to us and said they licensed 150,000 employees June 6. They said, if you can get 150,000 employees into production in 30 days go through the contract. We put the first 150,000 into production in three days, they turned off their firewall rules. The Board of Directors told the global CISO, stop screwing around. I want the employees to use AI in three days, we had 150,001 in production. It turned off all the blocking of these things working great. No noticeable delays. Customers are very happy.
Yeah, go ahead. So think NTT. So NTT came to us and said they licensed 150,000 employees June 6. They said, if you can get 150,000 employees into production in 30 days go through the contract. We put the first 150,000 into production in three days, they turned off their firewall rules. The Board of Directors told the global CISO, stop screwing around. I want the employees to use AI in three days, we had 150,001 in production. It turned off all the blocking of these things working great. No noticeable delays. Customers are very happy.
16:47They're pumping a bunch of traffic through the system, working great,
They're pumping a bunch of traffic through the system, working great,
They're pumping a bunch of traffic through the system, working great,
They're pumping a bunch of traffic through the system, working great,
16:52on the strength of that that was in q2
on the strength of that that was in q2
on the strength of that that was in q2
on the strength of that that was in q2
S Speaker 116:55NT Japan tested the product here.
NT Japan tested the product here.
NT Japan tested the product here.
NT Japan tested the product here.
16:59Hope things are going great. Warrant check now,
Hope things are going great. Warrant check now,
Hope things are going great. Warrant check now,
Hope things are going great. Warrant check now,
S Speaker 117:08my first $2 million a year customer, I've got another $600,000 extension coming this quarter. Guardrails so we're able to put these guys into production fairly quickly. Delta currently has 38,000
my first $2 million a year customer, I've got another $600,000 extension coming this quarter. Guardrails so we're able to put these guys into production fairly quickly. Delta currently has 38,000
my first $2 million a year customer, I've got another $600,000 extension coming this quarter. Guardrails so we're able to put these guys into production fairly quickly. Delta currently has 38,000
my first $2 million a year customer, I've got another $600,000 extension coming this quarter. Guardrails so we're able to put these guys into production fairly quickly. Delta currently has 38,000
17:23employees deployed in the
employees deployed in the
employees deployed in the
employees deployed in the
S Speaker 117:25first month is put like 30,000 custom employees into deployment. So this rolls out extremely quickly, because I don't have to push anything out. All the endpoints hook to the network, connect to their identity system. They hook us up at lunchtime, and by the time they go home that evening, we're showing them all the traffic, literally. Yeah, sorry, hand up. Yeah. Shashank, yeah.
first month is put like 30,000 custom employees into deployment. So this rolls out extremely quickly, because I don't have to push anything out. All the endpoints hook to the network, connect to their identity system. They hook us up at lunchtime, and by the time they go home that evening, we're showing them all the traffic, literally. Yeah, sorry, hand up. Yeah. Shashank, yeah.
first month is put like 30,000 custom employees into deployment. So this rolls out extremely quickly, because I don't have to push anything out. All the endpoints hook to the network, connect to their identity system. They hook us up at lunchtime, and by the time they go home that evening, we're showing them all the traffic, literally. Yeah, sorry, hand up. Yeah. Shashank, yeah.
first month is put like 30,000 custom employees into deployment. So this rolls out extremely quickly, because I don't have to push anything out. All the endpoints hook to the network, connect to their identity system. They hook us up at lunchtime, and by the time they go home that evening, we're showing them all the traffic, literally. Yeah, sorry, hand up. Yeah. Shashank, yeah.
S Speaker 517:50Hey, Rick. My question is, what if my LLM is running on device, it's pretty much in offline mode,
Hey, Rick. My question is, what if my LLM is running on device, it's pretty much in offline mode,
Hey, Rick. My question is, what if my LLM is running on device, it's pretty much in offline mode,
Hey, Rick. My question is, what if my LLM is running on device, it's pretty much in offline mode,
S Speaker 117:56yeah, yeah. That is, yeah, you're right. So there are some corner cases here that today we really don't touch the one is going to be the main one is going to be what you describe a case, and this is really the more agentic than the user case, which is, what if my agent is talking to a local LLM and never touches the network? And today, our answer is, I'm not going to see that traffic. But also, in practice, so far, no one really cares about that. What they care about is an agent that's talking to an LLM and posted somewhere else for that particular thing where everything is local to one person's machine. The only way I'm going to see that is if we then build some little endpoint thing that gets pushed out today, I don't today. I don't support that use case. I could, but we don't today.
yeah, yeah. That is, yeah, you're right. So there are some corner cases here that today we really don't touch the one is going to be the main one is going to be what you describe a case, and this is really the more agentic than the user case, which is, what if my agent is talking to a local LLM and never touches the network? And today, our answer is, I'm not going to see that traffic. But also, in practice, so far, no one really cares about that. What they care about is an agent that's talking to an LLM and posted somewhere else for that particular thing where everything is local to one person's machine. The only way I'm going to see that is if we then build some little endpoint thing that gets pushed out today, I don't today. I don't support that use case. I could, but we don't today.
yeah, yeah. That is, yeah, you're right. So there are some corner cases here that today we really don't touch the one is going to be the main one is going to be what you describe a case, and this is really the more agentic than the user case, which is, what if my agent is talking to a local LLM and never touches the network? And today, our answer is, I'm not going to see that traffic. But also, in practice, so far, no one really cares about that. What they care about is an agent that's talking to an LLM and posted somewhere else for that particular thing where everything is local to one person's machine. The only way I'm going to see that is if we then build some little endpoint thing that gets pushed out today, I don't today. I don't support that use case. I could, but we don't today.
yeah, yeah. That is, yeah, you're right. So there are some corner cases here that today we really don't touch the one is going to be the main one is going to be what you describe a case, and this is really the more agentic than the user case, which is, what if my agent is talking to a local LLM and never touches the network? And today, our answer is, I'm not going to see that traffic. But also, in practice, so far, no one really cares about that. What they care about is an agent that's talking to an LLM and posted somewhere else for that particular thing where everything is local to one person's machine. The only way I'm going to see that is if we then build some little endpoint thing that gets pushed out today, I don't today. I don't support that use case. I could, but we don't today.
S Speaker 518:50Okay. Another question I have is, so on device llms? Like, if I take off the shelf, open source LLM like, when 3b, 4b, and just put it on my phone, it's still prone to jail breaks. So from fitness, AI that AI guardrail, like, are these modular components that I can use to guardrail my LM against, like, some fishy stuff that people can do
Okay. Another question I have is, so on device llms? Like, if I take off the shelf, open source LLM like, when 3b, 4b, and just put it on my phone, it's still prone to jail breaks. So from fitness, AI that AI guardrail, like, are these modular components that I can use to guardrail my LM against, like, some fishy stuff that people can do
Okay. Another question I have is, so on device llms? Like, if I take off the shelf, open source LLM like, when 3b, 4b, and just put it on my phone, it's still prone to jail breaks. So from fitness, AI that AI guardrail, like, are these modular components that I can use to guardrail my LM against, like, some fishy stuff that people can do
Okay. Another question I have is, so on device llms? Like, if I take off the shelf, open source LLM like, when 3b, 4b, and just put it on my phone, it's still prone to jail breaks. So from fitness, AI that AI guardrail, like, are these modular components that I can use to guardrail my LM against, like, some fishy stuff that people can do
S Speaker 119:14absolutely so here's, here's the we give you for the, think of it for the for the jailbreak and prompt injection. It's very simple, we give you two APIs, one on the input, one on the output, and you know, you're not talking to, you know, users aren't talking to an LLM, they're talking to an app talking to an LLN. So what the customers have done is they've told the app developers, when you build this chatbot for any prompt and any response call these two APIs, or in some cases, they're not even doing that. They're standing up an LLM gateway, like light that all in, and we just connect to that and see all the traffic. But if you're standing up some onboard model and you want to protect it, then in the app, or generally in the app that the user is talking to, you would use our APIs, and we would protect it from
absolutely so here's, here's the we give you for the, think of it for the for the jailbreak and prompt injection. It's very simple, we give you two APIs, one on the input, one on the output, and you know, you're not talking to, you know, users aren't talking to an LLM, they're talking to an app talking to an LLN. So what the customers have done is they've told the app developers, when you build this chatbot for any prompt and any response call these two APIs, or in some cases, they're not even doing that. They're standing up an LLM gateway, like light that all in, and we just connect to that and see all the traffic. But if you're standing up some onboard model and you want to protect it, then in the app, or generally in the app that the user is talking to, you would use our APIs, and we would protect it from
absolutely so here's, here's the we give you for the, think of it for the for the jailbreak and prompt injection. It's very simple, we give you two APIs, one on the input, one on the output, and you know, you're not talking to, you know, users aren't talking to an LLM, they're talking to an app talking to an LLN. So what the customers have done is they've told the app developers, when you build this chatbot for any prompt and any response call these two APIs, or in some cases, they're not even doing that. They're standing up an LLM gateway, like light that all in, and we just connect to that and see all the traffic. But if you're standing up some onboard model and you want to protect it, then in the app, or generally in the app that the user is talking to, you would use our APIs, and we would protect it from
absolutely so here's, here's the we give you for the, think of it for the for the jailbreak and prompt injection. It's very simple, we give you two APIs, one on the input, one on the output, and you know, you're not talking to, you know, users aren't talking to an LLM, they're talking to an app talking to an LLN. So what the customers have done is they've told the app developers, when you build this chatbot for any prompt and any response call these two APIs, or in some cases, they're not even doing that. They're standing up an LLM gateway, like light that all in, and we just connect to that and see all the traffic. But if you're standing up some onboard model and you want to protect it, then in the app, or generally in the app that the user is talking to, you would use our APIs, and we would protect it from
20:05jumping fully module. Okay, awesome.
jumping fully module. Okay, awesome.
jumping fully module. Okay, awesome.
jumping fully module. Okay, awesome.
S Speaker 520:09Okay, I think I'll have more questions, but I'm gonna hold off. Maybe we need to skip to more another call for some of the things that I'm working on.
Okay, I think I'll have more questions, but I'm gonna hold off. Maybe we need to skip to more another call for some of the things that I'm working on.
Okay, I think I'll have more questions, but I'm gonna hold off. Maybe we need to skip to more another call for some of the things that I'm working on.
Okay, I think I'll have more questions, but I'm gonna hold off. Maybe we need to skip to more another call for some of the things that I'm working on.
S Speaker 120:18So that's us at a at a high level, trying to think about what else is useful. I know some people have to drop in, like, maybe, maybe talk about competition, because we've seen
So that's us at a at a high level, trying to think about what else is useful. I know some people have to drop in, like, maybe, maybe talk about competition, because we've seen
So that's us at a at a high level, trying to think about what else is useful. I know some people have to drop in, like, maybe, maybe talk about competition, because we've seen
So that's us at a at a high level, trying to think about what else is useful. I know some people have to drop in, like, maybe, maybe talk about competition, because we've seen
S Speaker 620:30what is in this domain, but it'd be great to see how your perspective on that,
what is in this domain, but it'd be great to see how your perspective on that,
what is in this domain, but it'd be great to see how your perspective on that,
what is in this domain, but it'd be great to see how your perspective on that,
S Speaker 120:34sure, sure, sure. I'm going to stop sharing so I can actually see you guys, so that it's changed quite a bit. If I go back, say, six months, the competition was primarily other startups. What we have seen is at the enterprise level, very few of those guys got any traction involved, and the ones that are still in the market are still not getting much traction. And we think that's because architecturally, they just don't make sense. Like the browser plugin is an easy way to get going. It misses all the stuff that people care about, like compiling. So I'm not seeing a lot of startups in my deals. What's happened is the market has started to consolidate, and your big guys have started to acquire, and I see those guys in my deals. I see palo, I see Netskope, I see cscaler, I see Google. Those are the ones we see the most, and we compete against them in the ways any sort of peer play specialist would I have more capability? I move faster. We work in a heterogeneous environment and customers are getting the technical win every time the company has these guys. So when we built the company and I did the series, a
sure, sure, sure. I'm going to stop sharing so I can actually see you guys, so that it's changed quite a bit. If I go back, say, six months, the competition was primarily other startups. What we have seen is at the enterprise level, very few of those guys got any traction involved, and the ones that are still in the market are still not getting much traction. And we think that's because architecturally, they just don't make sense. Like the browser plugin is an easy way to get going. It misses all the stuff that people care about, like compiling. So I'm not seeing a lot of startups in my deals. What's happened is the market has started to consolidate, and your big guys have started to acquire, and I see those guys in my deals. I see palo, I see Netskope, I see cscaler, I see Google. Those are the ones we see the most, and we compete against them in the ways any sort of peer play specialist would I have more capability? I move faster. We work in a heterogeneous environment and customers are getting the technical win every time the company has these guys. So when we built the company and I did the series, a
sure, sure, sure. I'm going to stop sharing so I can actually see you guys, so that it's changed quite a bit. If I go back, say, six months, the competition was primarily other startups. What we have seen is at the enterprise level, very few of those guys got any traction involved, and the ones that are still in the market are still not getting much traction. And we think that's because architecturally, they just don't make sense. Like the browser plugin is an easy way to get going. It misses all the stuff that people care about, like compiling. So I'm not seeing a lot of startups in my deals. What's happened is the market has started to consolidate, and your big guys have started to acquire, and I see those guys in my deals. I see palo, I see Netskope, I see cscaler, I see Google. Those are the ones we see the most, and we compete against them in the ways any sort of peer play specialist would I have more capability? I move faster. We work in a heterogeneous environment and customers are getting the technical win every time the company has these guys. So when we built the company and I did the series, a
sure, sure, sure. I'm going to stop sharing so I can actually see you guys, so that it's changed quite a bit. If I go back, say, six months, the competition was primarily other startups. What we have seen is at the enterprise level, very few of those guys got any traction involved, and the ones that are still in the market are still not getting much traction. And we think that's because architecturally, they just don't make sense. Like the browser plugin is an easy way to get going. It misses all the stuff that people care about, like compiling. So I'm not seeing a lot of startups in my deals. What's happened is the market has started to consolidate, and your big guys have started to acquire, and I see those guys in my deals. I see palo, I see Netskope, I see cscaler, I see Google. Those are the ones we see the most, and we compete against them in the ways any sort of peer play specialist would I have more capability? I move faster. We work in a heterogeneous environment and customers are getting the technical win every time the company has these guys. So when we built the company and I did the series, a
S Speaker 321:53here vishek, hope things are going great. We had an internal discussion, and I'd like to loop in Tushar, Managing Director at Qualcomm ventures, for a chat with you. Hopefully we can do it in person. Would you have some availability for us to visit your office? Say, next week, Tuesday, Thursday or Friday?
here vishek, hope things are going great. We had an internal discussion, and I'd like to loop in Tushar, Managing Director at Qualcomm ventures, for a chat with you. Hopefully we can do it in person. Would you have some availability for us to visit your office? Say, next week, Tuesday, Thursday or Friday?
here vishek, hope things are going great. We had an internal discussion, and I'd like to loop in Tushar, Managing Director at Qualcomm ventures, for a chat with you. Hopefully we can do it in person. Would you have some availability for us to visit your office? Say, next week, Tuesday, Thursday or Friday?
here vishek, hope things are going great. We had an internal discussion, and I'd like to loop in Tushar, Managing Director at Qualcomm ventures, for a chat with you. Hopefully we can do it in person. Would you have some availability for us to visit your office? Say, next week, Tuesday, Thursday or Friday?
S Speaker 122:17Fire to disappear and one or two companies come through the other end to be the next peer play specialist, like netscope and CASB, ground strike and endpoint, Okta and identity, like, that's what we're trying to do here, and we've built the company to do it. So I beat Paulo on heterogeneity, having a full platform where they don't and having more functionality. I beat Google on the same thing. I beat Zscaler in the same way. Charles Schwab and NTT are two of Z scalers biggest customers. They put both products and a lot of other products through all their paces, and did large deals with us. So we'll that's how we see the competition, and that's how we'll continue
Fire to disappear and one or two companies come through the other end to be the next peer play specialist, like netscope and CASB, ground strike and endpoint, Okta and identity, like, that's what we're trying to do here, and we've built the company to do it. So I beat Paulo on heterogeneity, having a full platform where they don't and having more functionality. I beat Google on the same thing. I beat Zscaler in the same way. Charles Schwab and NTT are two of Z scalers biggest customers. They put both products and a lot of other products through all their paces, and did large deals with us. So we'll that's how we see the competition, and that's how we'll continue
Fire to disappear and one or two companies come through the other end to be the next peer play specialist, like netscope and CASB, ground strike and endpoint, Okta and identity, like, that's what we're trying to do here, and we've built the company to do it. So I beat Paulo on heterogeneity, having a full platform where they don't and having more functionality. I beat Google on the same thing. I beat Zscaler in the same way. Charles Schwab and NTT are two of Z scalers biggest customers. They put both products and a lot of other products through all their paces, and did large deals with us. So we'll that's how we see the competition, and that's how we'll continue
Fire to disappear and one or two companies come through the other end to be the next peer play specialist, like netscope and CASB, ground strike and endpoint, Okta and identity, like, that's what we're trying to do here, and we've built the company to do it. So I beat Paulo on heterogeneity, having a full platform where they don't and having more functionality. I beat Google on the same thing. I beat Zscaler in the same way. Charles Schwab and NTT are two of Z scalers biggest customers. They put both products and a lot of other products through all their paces, and did large deals with us. So we'll that's how we see the competition, and that's how we'll continue
S Speaker 623:05to have to drop maximum questions, but we can pull up later. You can also email me questions if you want. I can answer them offline. No, no, right now I will. I will. Feedback will be our thanks. You. Okay. Okay, what else
to have to drop maximum questions, but we can pull up later. You can also email me questions if you want. I can answer them offline. No, no, right now I will. I will. Feedback will be our thanks. You. Okay. Okay, what else
to have to drop maximum questions, but we can pull up later. You can also email me questions if you want. I can answer them offline. No, no, right now I will. I will. Feedback will be our thanks. You. Okay. Okay, what else
to have to drop maximum questions, but we can pull up later. You can also email me questions if you want. I can answer them offline. No, no, right now I will. I will. Feedback will be our thanks. You. Okay. Okay, what else
S Speaker 423:27kind of like? Pie Chart, how much is for the first product, how much the second product, how much third product,
kind of like? Pie Chart, how much is for the first product, how much the second product, how much third product,
kind of like? Pie Chart, how much is for the first product, how much the second product, how much third product,
kind of like? Pie Chart, how much is for the first product, how much the second product, how much third product,
S Speaker 123:36for sure. So pie chart, it's going to be 80 to 85% first product, but that's because that's the problem. We can sell it the most. Second one. We really started selling it two quarters ago. I did two deals on it, pure play deals, the quarter that just ended last week. And there's some add on deals going forward. It's about a quarter of my pipeline. So historical, smaller going forward, it's about a quarter. The genetic product we're shipping, the visibility, genetic visibility this quarter, so I don't have any revenue
for sure. So pie chart, it's going to be 80 to 85% first product, but that's because that's the problem. We can sell it the most. Second one. We really started selling it two quarters ago. I did two deals on it, pure play deals, the quarter that just ended last week. And there's some add on deals going forward. It's about a quarter of my pipeline. So historical, smaller going forward, it's about a quarter. The genetic product we're shipping, the visibility, genetic visibility this quarter, so I don't have any revenue
for sure. So pie chart, it's going to be 80 to 85% first product, but that's because that's the problem. We can sell it the most. Second one. We really started selling it two quarters ago. I did two deals on it, pure play deals, the quarter that just ended last week. And there's some add on deals going forward. It's about a quarter of my pipeline. So historical, smaller going forward, it's about a quarter. The genetic product we're shipping, the visibility, genetic visibility this quarter, so I don't have any revenue
for sure. So pie chart, it's going to be 80 to 85% first product, but that's because that's the problem. We can sell it the most. Second one. We really started selling it two quarters ago. I did two deals on it, pure play deals, the quarter that just ended last week. And there's some add on deals going forward. It's about a quarter of my pipeline. So historical, smaller going forward, it's about a quarter. The genetic product we're shipping, the visibility, genetic visibility this quarter, so I don't have any revenue
S Speaker 424:13on it yet. Thanks, Rick. Another really quick question. So there are numerous, almost infinite AI tools that an employee can reach out to. So how do you handle new tools that are joining the market?
on it yet. Thanks, Rick. Another really quick question. So there are numerous, almost infinite AI tools that an employee can reach out to. So how do you handle new tools that are joining the market?
on it yet. Thanks, Rick. Another really quick question. So there are numerous, almost infinite AI tools that an employee can reach out to. So how do you handle new tools that are joining the market?
on it yet. Thanks, Rick. Another really quick question. So there are numerous, almost infinite AI tools that an employee can reach out to. So how do you handle new tools that are joining the market?
S Speaker 124:25Yeah, there's a couple of parts. So one, we built a database of these. We've got about 5000 in it. Now we're adding more every day. We scrape, we scrape for new sites. Our customers can also add a crowd source to the database, and they do that, so we're adding those realistically. This is a long tail kind of thing, so there's 1000s. But in practice, what you see is, in a customer, you see the top 10 Gemini, it's other ones, and then you see a few others. So we're pretty good about showing those, and we're pretty accurate, more accurate than the big guys. But then there's a second thing, which is once I can so I can show you the AI apps, the shadow AI apps, then we also are going back and scraping like supply chain info. We can really tell you more than just, hey, here are the users going to this app. We can tell you where they host data and things like that, and you can choose to block it. And we have a little model that recommends whether you should block this or not. If you choose not to block it, then we can actually capture the prompt and do something with it. We the first few, we had to build by hand. We had to figure out how to do this by hand, how to inject our JavaScript, kind of pull the prompt out. We figured out a way to automate it. So now we're rolling out another 2000 of those, actually, this month, and we've built a way to automate it. We've built an AI model, sort of look at the automation to see if it ever breaks, and tune it. The way this will really work is getting that thing built so that just constantly wiring itself into new apps. Because there's more than just noticing the app. You have to figure out how to pick the prompt out of the app too, right?
Yeah, there's a couple of parts. So one, we built a database of these. We've got about 5000 in it. Now we're adding more every day. We scrape, we scrape for new sites. Our customers can also add a crowd source to the database, and they do that, so we're adding those realistically. This is a long tail kind of thing, so there's 1000s. But in practice, what you see is, in a customer, you see the top 10 Gemini, it's other ones, and then you see a few others. So we're pretty good about showing those, and we're pretty accurate, more accurate than the big guys. But then there's a second thing, which is once I can so I can show you the AI apps, the shadow AI apps, then we also are going back and scraping like supply chain info. We can really tell you more than just, hey, here are the users going to this app. We can tell you where they host data and things like that, and you can choose to block it. And we have a little model that recommends whether you should block this or not. If you choose not to block it, then we can actually capture the prompt and do something with it. We the first few, we had to build by hand. We had to figure out how to do this by hand, how to inject our JavaScript, kind of pull the prompt out. We figured out a way to automate it. So now we're rolling out another 2000 of those, actually, this month, and we've built a way to automate it. We've built an AI model, sort of look at the automation to see if it ever breaks, and tune it. The way this will really work is getting that thing built so that just constantly wiring itself into new apps. Because there's more than just noticing the app. You have to figure out how to pick the prompt out of the app too, right?
Yeah, there's a couple of parts. So one, we built a database of these. We've got about 5000 in it. Now we're adding more every day. We scrape, we scrape for new sites. Our customers can also add a crowd source to the database, and they do that, so we're adding those realistically. This is a long tail kind of thing, so there's 1000s. But in practice, what you see is, in a customer, you see the top 10 Gemini, it's other ones, and then you see a few others. So we're pretty good about showing those, and we're pretty accurate, more accurate than the big guys. But then there's a second thing, which is once I can so I can show you the AI apps, the shadow AI apps, then we also are going back and scraping like supply chain info. We can really tell you more than just, hey, here are the users going to this app. We can tell you where they host data and things like that, and you can choose to block it. And we have a little model that recommends whether you should block this or not. If you choose not to block it, then we can actually capture the prompt and do something with it. We the first few, we had to build by hand. We had to figure out how to do this by hand, how to inject our JavaScript, kind of pull the prompt out. We figured out a way to automate it. So now we're rolling out another 2000 of those, actually, this month, and we've built a way to automate it. We've built an AI model, sort of look at the automation to see if it ever breaks, and tune it. The way this will really work is getting that thing built so that just constantly wiring itself into new apps. Because there's more than just noticing the app. You have to figure out how to pick the prompt out of the app too, right?
Yeah, there's a couple of parts. So one, we built a database of these. We've got about 5000 in it. Now we're adding more every day. We scrape, we scrape for new sites. Our customers can also add a crowd source to the database, and they do that, so we're adding those realistically. This is a long tail kind of thing, so there's 1000s. But in practice, what you see is, in a customer, you see the top 10 Gemini, it's other ones, and then you see a few others. So we're pretty good about showing those, and we're pretty accurate, more accurate than the big guys. But then there's a second thing, which is once I can so I can show you the AI apps, the shadow AI apps, then we also are going back and scraping like supply chain info. We can really tell you more than just, hey, here are the users going to this app. We can tell you where they host data and things like that, and you can choose to block it. And we have a little model that recommends whether you should block this or not. If you choose not to block it, then we can actually capture the prompt and do something with it. We the first few, we had to build by hand. We had to figure out how to do this by hand, how to inject our JavaScript, kind of pull the prompt out. We figured out a way to automate it. So now we're rolling out another 2000 of those, actually, this month, and we've built a way to automate it. We've built an AI model, sort of look at the automation to see if it ever breaks, and tune it. The way this will really work is getting that thing built so that just constantly wiring itself into new apps. Because there's more than just noticing the app. You have to figure out how to pick the prompt out of the app too, right?
S Speaker 426:11You automated that, and you heard like another chair. It's a great moment, yeah?
You automated that, and you heard like another chair. It's a great moment, yeah?
You automated that, and you heard like another chair. It's a great moment, yeah?
You automated that, and you heard like another chair. It's a great moment, yeah?
S Speaker 126:16So that's, that's what we've got. We're scaling it up. It works really well. But here's the here's the thing, Ross, it's, um, it's a spectrum. So for and the reason I say that is, copilot is really hard. There's 20 different web sockets, like cracking that was hard. They change it all the time. So we have to, like, keep that one, that one is hard a web page. A lot of the web apps, AI, web apps are not that hard. So you can, you know, so there's a spectrum, and depending on what the customers want, we sort of shuffle them in the priority of the ones that need hand built, bespoke
So that's, that's what we've got. We're scaling it up. It works really well. But here's the here's the thing, Ross, it's, um, it's a spectrum. So for and the reason I say that is, copilot is really hard. There's 20 different web sockets, like cracking that was hard. They change it all the time. So we have to, like, keep that one, that one is hard a web page. A lot of the web apps, AI, web apps are not that hard. So you can, you know, so there's a spectrum, and depending on what the customers want, we sort of shuffle them in the priority of the ones that need hand built, bespoke
So that's, that's what we've got. We're scaling it up. It works really well. But here's the here's the thing, Ross, it's, um, it's a spectrum. So for and the reason I say that is, copilot is really hard. There's 20 different web sockets, like cracking that was hard. They change it all the time. So we have to, like, keep that one, that one is hard a web page. A lot of the web apps, AI, web apps are not that hard. So you can, you know, so there's a spectrum, and depending on what the customers want, we sort of shuffle them in the priority of the ones that need hand built, bespoke
So that's, that's what we've got. We're scaling it up. It works really well. But here's the here's the thing, Ross, it's, um, it's a spectrum. So for and the reason I say that is, copilot is really hard. There's 20 different web sockets, like cracking that was hard. They change it all the time. So we have to, like, keep that one, that one is hard a web page. A lot of the web apps, AI, web apps are not that hard. So you can, you know, so there's a spectrum, and depending on what the customers want, we sort of shuffle them in the priority of the ones that need hand built, bespoke
S Speaker 227:00integration, very good, and maybe Rick. I know this was the first year of selling. How do you see the expansions play out? Because 80% is discover. Can you give maybe a couple of anecdotal data points on the expansion potentially? Yeah, sure, sure, sure.
integration, very good, and maybe Rick. I know this was the first year of selling. How do you see the expansions play out? Because 80% is discover. Can you give maybe a couple of anecdotal data points on the expansion potentially? Yeah, sure, sure, sure.
integration, very good, and maybe Rick. I know this was the first year of selling. How do you see the expansions play out? Because 80% is discover. Can you give maybe a couple of anecdotal data points on the expansion potentially? Yeah, sure, sure, sure.
integration, very good, and maybe Rick. I know this was the first year of selling. How do you see the expansions play out? Because 80% is discover. Can you give maybe a couple of anecdotal data points on the expansion potentially? Yeah, sure, sure, sure.
S Speaker 127:17So. We have nobody who has an ELA, nobody. So I can, I can get expansion in two directions. One, I can add more users. No customer has been licensed for all its users. A license for a subset. Delta, it was half the company, Southern Company. It's like 50% 60% of the company, Schwab, it's like a third of the company. So there's a subset of users for visibility. We start with, then we have, you know, nine guardrails that are all upgrades, and no customer has all the guardrails. So I can get you through expansion and more users, and I can get you through upgrades of added guardrails. So I'll give you an MTT subset of users for visibility in q2
So. We have nobody who has an ELA, nobody. So I can, I can get expansion in two directions. One, I can add more users. No customer has been licensed for all its users. A license for a subset. Delta, it was half the company, Southern Company. It's like 50% 60% of the company, Schwab, it's like a third of the company. So there's a subset of users for visibility. We start with, then we have, you know, nine guardrails that are all upgrades, and no customer has all the guardrails. So I can get you through expansion and more users, and I can get you through upgrades of added guardrails. So I'll give you an MTT subset of users for visibility in q2
So. We have nobody who has an ELA, nobody. So I can, I can get expansion in two directions. One, I can add more users. No customer has been licensed for all its users. A license for a subset. Delta, it was half the company, Southern Company. It's like 50% 60% of the company, Schwab, it's like a third of the company. So there's a subset of users for visibility. We start with, then we have, you know, nine guardrails that are all upgrades, and no customer has all the guardrails. So I can get you through expansion and more users, and I can get you through upgrades of added guardrails. So I'll give you an MTT subset of users for visibility in q2
So. We have nobody who has an ELA, nobody. So I can, I can get expansion in two directions. One, I can add more users. No customer has been licensed for all its users. A license for a subset. Delta, it was half the company, Southern Company. It's like 50% 60% of the company, Schwab, it's like a third of the company. So there's a subset of users for visibility. We start with, then we have, you know, nine guardrails that are all upgrades, and no customer has all the guardrails. So I can get you through expansion and more users, and I can get you through upgrades of added guardrails. So I'll give you an MTT subset of users for visibility in q2
28:12added more users for visibility in q3
added more users for visibility in q3
added more users for visibility in q3
added more users for visibility in q3
S Speaker 128:16in q4 we're going to sell them a couple of data protection and behavioral guardrails across those users, and there's still more economics delta. In fact, we talked to the talk to the GM for cyber on Monday, and as you know, as he told you, they licensed for half the company. When I add the iOS stuff, they license the other half. They've got about half of our guardrails licensed. So you know, our expectation is we will expand the use cases so employee B to C, bot, agentic, so I can expand use cases and more users for each of those, and then add guardrails across the top. So it's we've barely scratched the surface, even with the customers we have, which can aren't that many.
in q4 we're going to sell them a couple of data protection and behavioral guardrails across those users, and there's still more economics delta. In fact, we talked to the talk to the GM for cyber on Monday, and as you know, as he told you, they licensed for half the company. When I add the iOS stuff, they license the other half. They've got about half of our guardrails licensed. So you know, our expectation is we will expand the use cases so employee B to C, bot, agentic, so I can expand use cases and more users for each of those, and then add guardrails across the top. So it's we've barely scratched the surface, even with the customers we have, which can aren't that many.
in q4 we're going to sell them a couple of data protection and behavioral guardrails across those users, and there's still more economics delta. In fact, we talked to the talk to the GM for cyber on Monday, and as you know, as he told you, they licensed for half the company. When I add the iOS stuff, they license the other half. They've got about half of our guardrails licensed. So you know, our expectation is we will expand the use cases so employee B to C, bot, agentic, so I can expand use cases and more users for each of those, and then add guardrails across the top. So it's we've barely scratched the surface, even with the customers we have, which can aren't that many.
in q4 we're going to sell them a couple of data protection and behavioral guardrails across those users, and there's still more economics delta. In fact, we talked to the talk to the GM for cyber on Monday, and as you know, as he told you, they licensed for half the company. When I add the iOS stuff, they license the other half. They've got about half of our guardrails licensed. So you know, our expectation is we will expand the use cases so employee B to C, bot, agentic, so I can expand use cases and more users for each of those, and then add guardrails across the top. So it's we've barely scratched the surface, even with the customers we have, which can aren't that many.
S Speaker 229:06Yeah, no. Thanks. Thanks for that. And and those were the questions from my end team on the call. If there any follow up. I know Shashank also dropped off on the business side, but any other key questions that we should dig into. Maybe
Yeah, no. Thanks. Thanks for that. And and those were the questions from my end team on the call. If there any follow up. I know Shashank also dropped off on the business side, but any other key questions that we should dig into. Maybe
Yeah, no. Thanks. Thanks for that. And and those were the questions from my end team on the call. If there any follow up. I know Shashank also dropped off on the business side, but any other key questions that we should dig into. Maybe
Yeah, no. Thanks. Thanks for that. And and those were the questions from my end team on the call. If there any follow up. I know Shashank also dropped off on the business side, but any other key questions that we should dig into. Maybe
29:30another one, if nobody has queen or Sergio
another one, if nobody has queen or Sergio
another one, if nobody has queen or Sergio
another one, if nobody has queen or Sergio
S Speaker 229:35Priyesh, no, they've heard they've heard the pitch before, so
Priyesh, no, they've heard they've heard the pitch before, so
Priyesh, no, they've heard they've heard the pitch before, so
Priyesh, no, they've heard they've heard the pitch before, so
29:40and but go ahead, go ahead. Russ,
and but go ahead, go ahead. Russ,
and but go ahead, go ahead. Russ,
and but go ahead, go ahead. Russ,
S Speaker 429:42just some of the large enterprises in that domain already done acquisitions. So how do you see the exit plan? By whom, when? What's your plan?
just some of the large enterprises in that domain already done acquisitions. So how do you see the exit plan? By whom, when? What's your plan?
just some of the large enterprises in that domain already done acquisitions. So how do you see the exit plan? By whom, when? What's your plan?
just some of the large enterprises in that domain already done acquisitions. So how do you see the exit plan? By whom, when? What's your plan?
S Speaker 129:55Yeah, so, like, like I said, Every time there are these big waves, one or two companies come out to be a big player. So we've been driving the company to be the AI security specialist player, like when I ran products at ArcSight, we took the company public. We were the sim specialists, right? So the plan is to do that. I've had, I've turned down two acquisition offers. So our plan is to keep going and grow this thing and turn into something big. That being said, there's got to be at least a dozen companies that are potentially acquirers if something were to come along. So it's not like, you know, because f5 bought failing Calypso for 180 million. Like, they're out forever. I think a lot of these guys were back in the market, but that's not our you know, the plan was to build something big and grow it. I've been acquired five times. Like, I kind of prefer not to do it again. Wonderful.
Yeah, so, like, like I said, Every time there are these big waves, one or two companies come out to be a big player. So we've been driving the company to be the AI security specialist player, like when I ran products at ArcSight, we took the company public. We were the sim specialists, right? So the plan is to do that. I've had, I've turned down two acquisition offers. So our plan is to keep going and grow this thing and turn into something big. That being said, there's got to be at least a dozen companies that are potentially acquirers if something were to come along. So it's not like, you know, because f5 bought failing Calypso for 180 million. Like, they're out forever. I think a lot of these guys were back in the market, but that's not our you know, the plan was to build something big and grow it. I've been acquired five times. Like, I kind of prefer not to do it again. Wonderful.
Yeah, so, like, like I said, Every time there are these big waves, one or two companies come out to be a big player. So we've been driving the company to be the AI security specialist player, like when I ran products at ArcSight, we took the company public. We were the sim specialists, right? So the plan is to do that. I've had, I've turned down two acquisition offers. So our plan is to keep going and grow this thing and turn into something big. That being said, there's got to be at least a dozen companies that are potentially acquirers if something were to come along. So it's not like, you know, because f5 bought failing Calypso for 180 million. Like, they're out forever. I think a lot of these guys were back in the market, but that's not our you know, the plan was to build something big and grow it. I've been acquired five times. Like, I kind of prefer not to do it again. Wonderful.
Yeah, so, like, like I said, Every time there are these big waves, one or two companies come out to be a big player. So we've been driving the company to be the AI security specialist player, like when I ran products at ArcSight, we took the company public. We were the sim specialists, right? So the plan is to do that. I've had, I've turned down two acquisition offers. So our plan is to keep going and grow this thing and turn into something big. That being said, there's got to be at least a dozen companies that are potentially acquirers if something were to come along. So it's not like, you know, because f5 bought failing Calypso for 180 million. Like, they're out forever. I think a lot of these guys were back in the market, but that's not our you know, the plan was to build something big and grow it. I've been acquired five times. Like, I kind of prefer not to do it again. Wonderful.
S Speaker 230:57Rick, you know, I, I think these were all the questions the team had. I want to acknowledge thanks again for taking the time on such short notice and spending time. And I'll give you a few minutes back. I know we have a catch up due later today, so we'll see you again. But thanks again. Team, the Qualcomm team, on the call for joining.
Rick, you know, I, I think these were all the questions the team had. I want to acknowledge thanks again for taking the time on such short notice and spending time. And I'll give you a few minutes back. I know we have a catch up due later today, so we'll see you again. But thanks again. Team, the Qualcomm team, on the call for joining.
Rick, you know, I, I think these were all the questions the team had. I want to acknowledge thanks again for taking the time on such short notice and spending time. And I'll give you a few minutes back. I know we have a catch up due later today, so we'll see you again. But thanks again. Team, the Qualcomm team, on the call for joining.
Rick, you know, I, I think these were all the questions the team had. I want to acknowledge thanks again for taking the time on such short notice and spending time. And I'll give you a few minutes back. I know we have a catch up due later today, so we'll see you again. But thanks again. Team, the Qualcomm team, on the call for joining.
S Speaker 131:19Thanks guys. Good to meet you. Take care. Thanks, Rick, appreciate it. You.
Thanks guys. Good to meet you. Take care. Thanks, Rick, appreciate it. You.
Thanks guys. Good to meet you. Take care. Thanks, Rick, appreciate it. You.
Thanks guys. Good to meet you. Take care. Thanks, Rick, appreciate it. You.