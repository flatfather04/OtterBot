Meeting: HS - Generalist
Thu, Dec 11
10:55 AM
18 min
Priyesh P
Introduction and Personal Story
0:00
Demonstra
URL: https://otter.ai/u/6xy24Y9sgqe5CnroU8shJXNG9Co
Downloaded: 2025-12-21T19:15:21.016971
Method: text_extraction
============================================================

S Speaker 10:00I get the slides pulled up here. Thank you again for inviting me and giving me the chance to tell you a little bit about generals. So I have some slides to show you, but first I want to tell you a little story. And it's a little story about a little moment where my 18 month old daughter is sitting in my lap, and I'm about to show her, for the very first time, a robot demo video from gems. And as you may know, tiny kids can be tough to impress, and I'm a little nervous, and, you know, I have no idea how she's going to respond. To be honest, I hope she likes it, but she's her own little person. And sorry, where's my little clicker? Perfect. Do Perfect.
I get the slides pulled up here. Thank you again for inviting me and giving me the chance to tell you a little bit about generals. So I have some slides to show you, but first I want to tell you a little story. And it's a little story about a little moment where my 18 month old daughter is sitting in my lap, and I'm about to show her, for the very first time, a robot demo video from gems. And as you may know, tiny kids can be tough to impress, and I'm a little nervous, and, you know, I have no idea how she's going to respond. To be honest, I hope she likes it, but she's her own little person. And sorry, where's my little clicker? Perfect. Do Perfect.
I get the slides pulled up here. Thank you again for inviting me and giving me the chance to tell you a little bit about generals. So I have some slides to show you, but first I want to tell you a little story. And it's a little story about a little moment where my 18 month old daughter is sitting in my lap, and I'm about to show her, for the very first time, a robot demo video from gems. And as you may know, tiny kids can be tough to impress, and I'm a little nervous, and, you know, I have no idea how she's going to respond. To be honest, I hope she likes it, but she's her own little person. And sorry, where's my little clicker? Perfect. Do Perfect.
I get the slides pulled up here. Thank you again for inviting me and giving me the chance to tell you a little bit about generals. So I have some slides to show you, but first I want to tell you a little story. And it's a little story about a little moment where my 18 month old daughter is sitting in my lap, and I'm about to show her, for the very first time, a robot demo video from gems. And as you may know, tiny kids can be tough to impress, and I'm a little nervous, and, you know, I have no idea how she's going to respond. To be honest, I hope she likes it, but she's her own little person. And sorry, where's my little clicker? Perfect. Do Perfect.
S Speaker 11:06Thank you. What I show my daughter is I show her this video.
Thank you. What I show my daughter is I show her this video.
Thank you. What I show my daughter is I show her this video.
Thank you. What I show my daughter is I show her this video.
S Speaker 12:02We're over some of the first moments I'm really starting to get this stuff to work. Here's another one. This is more recent. This is an extremely simple task, but a very long duration of task at the very end of it. Oh. Robot is surprising the team with the ability for it to just improvise, how to recover from some of its mistakes completely out of distribution from the training set. And so you get the sense that, you know, internally, we have a huge amount of passion that we bring to our work, but I think there's something that's just so pure about my daughter's response in that moment. And that is, you know, there's something just so raw about the ability of humans to be amazed and inspired by what robots can do. And you know, my daughter, she she doesn't care about chat GPT. She's not impressed. She's not impressed by Sora. She doesn't understand any of that. She doesn't appreciate any of you know, for us, it's hard for me to separate all the all the work that we pour in to getting these robots to do what they can do, are just fascination with the technology itself. But for her, it's just she sees something physically moving and interacting in the world with a level of competence and grace
We're over some of the first moments I'm really starting to get this stuff to work. Here's another one. This is more recent. This is an extremely simple task, but a very long duration of task at the very end of it. Oh. Robot is surprising the team with the ability for it to just improvise, how to recover from some of its mistakes completely out of distribution from the training set. And so you get the sense that, you know, internally, we have a huge amount of passion that we bring to our work, but I think there's something that's just so pure about my daughter's response in that moment. And that is, you know, there's something just so raw about the ability of humans to be amazed and inspired by what robots can do. And you know, my daughter, she she doesn't care about chat GPT. She's not impressed. She's not impressed by Sora. She doesn't understand any of that. She doesn't appreciate any of you know, for us, it's hard for me to separate all the all the work that we pour in to getting these robots to do what they can do, are just fascination with the technology itself. But for her, it's just she sees something physically moving and interacting in the world with a level of competence and grace
We're over some of the first moments I'm really starting to get this stuff to work. Here's another one. This is more recent. This is an extremely simple task, but a very long duration of task at the very end of it. Oh. Robot is surprising the team with the ability for it to just improvise, how to recover from some of its mistakes completely out of distribution from the training set. And so you get the sense that, you know, internally, we have a huge amount of passion that we bring to our work, but I think there's something that's just so pure about my daughter's response in that moment. And that is, you know, there's something just so raw about the ability of humans to be amazed and inspired by what robots can do. And you know, my daughter, she she doesn't care about chat GPT. She's not impressed. She's not impressed by Sora. She doesn't understand any of that. She doesn't appreciate any of you know, for us, it's hard for me to separate all the all the work that we pour in to getting these robots to do what they can do, are just fascination with the technology itself. But for her, it's just she sees something physically moving and interacting in the world with a level of competence and grace
We're over some of the first moments I'm really starting to get this stuff to work. Here's another one. This is more recent. This is an extremely simple task, but a very long duration of task at the very end of it. Oh. Robot is surprising the team with the ability for it to just improvise, how to recover from some of its mistakes completely out of distribution from the training set. And so you get the sense that, you know, internally, we have a huge amount of passion that we bring to our work, but I think there's something that's just so pure about my daughter's response in that moment. And that is, you know, there's something just so raw about the ability of humans to be amazed and inspired by what robots can do. And you know, my daughter, she she doesn't care about chat GPT. She's not impressed. She's not impressed by Sora. She doesn't understand any of that. She doesn't appreciate any of you know, for us, it's hard for me to separate all the all the work that we pour in to getting these robots to do what they can do, are just fascination with the technology itself. But for her, it's just she sees something physically moving and interacting in the world with a level of competence and grace
3:33and generality that that she relates to.
and generality that that she relates to.
and generality that that she relates to.
and generality that that she relates to.
4:24which is the story of Gen zero,
which is the story of Gen zero,
which is the story of Gen zero,
which is the story of Gen zero,
S Speaker 14:28our new model that we just announced a little over a month ago. And I'm going to tell you about some numbers and some scaling laws and connect it to the core narrative of AI. And that's all very important, but I think it's also very important to be clear eyed about in robotics, I think ultimately what matters most is capabilities, not numbers of hours or in your data set or number of parameters in your model. That doesn't matter. What does matter is capabilities. And you know, it's, it's hard in robotics to to measure all this stuff, but a leading indicator that I like, it's, of course, subjective, but we've had for a while, and it's basically the number of demo videos that we are able to create internally, a generalist that passed some arbitrary threshold. For me, of it's impressive enough. And if you squinted this graph, and this is over the course of a year or so, you can see that there's kind of this knee in the curve, and that corresponded with the arrival of Gen zero. And it's something that we very much felt, very much felt in Turkey. This is what an explosion of capabilities looks like when you have a real foundation model. Some of these tasks, by the way, are not yet public, and we'll have more to talk about them in the near future.
our new model that we just announced a little over a month ago. And I'm going to tell you about some numbers and some scaling laws and connect it to the core narrative of AI. And that's all very important, but I think it's also very important to be clear eyed about in robotics, I think ultimately what matters most is capabilities, not numbers of hours or in your data set or number of parameters in your model. That doesn't matter. What does matter is capabilities. And you know, it's, it's hard in robotics to to measure all this stuff, but a leading indicator that I like, it's, of course, subjective, but we've had for a while, and it's basically the number of demo videos that we are able to create internally, a generalist that passed some arbitrary threshold. For me, of it's impressive enough. And if you squinted this graph, and this is over the course of a year or so, you can see that there's kind of this knee in the curve, and that corresponded with the arrival of Gen zero. And it's something that we very much felt, very much felt in Turkey. This is what an explosion of capabilities looks like when you have a real foundation model. Some of these tasks, by the way, are not yet public, and we'll have more to talk about them in the near future.
our new model that we just announced a little over a month ago. And I'm going to tell you about some numbers and some scaling laws and connect it to the core narrative of AI. And that's all very important, but I think it's also very important to be clear eyed about in robotics, I think ultimately what matters most is capabilities, not numbers of hours or in your data set or number of parameters in your model. That doesn't matter. What does matter is capabilities. And you know, it's, it's hard in robotics to to measure all this stuff, but a leading indicator that I like, it's, of course, subjective, but we've had for a while, and it's basically the number of demo videos that we are able to create internally, a generalist that passed some arbitrary threshold. For me, of it's impressive enough. And if you squinted this graph, and this is over the course of a year or so, you can see that there's kind of this knee in the curve, and that corresponded with the arrival of Gen zero. And it's something that we very much felt, very much felt in Turkey. This is what an explosion of capabilities looks like when you have a real foundation model. Some of these tasks, by the way, are not yet public, and we'll have more to talk about them in the near future.
our new model that we just announced a little over a month ago. And I'm going to tell you about some numbers and some scaling laws and connect it to the core narrative of AI. And that's all very important, but I think it's also very important to be clear eyed about in robotics, I think ultimately what matters most is capabilities, not numbers of hours or in your data set or number of parameters in your model. That doesn't matter. What does matter is capabilities. And you know, it's, it's hard in robotics to to measure all this stuff, but a leading indicator that I like, it's, of course, subjective, but we've had for a while, and it's basically the number of demo videos that we are able to create internally, a generalist that passed some arbitrary threshold. For me, of it's impressive enough. And if you squinted this graph, and this is over the course of a year or so, you can see that there's kind of this knee in the curve, and that corresponded with the arrival of Gen zero. And it's something that we very much felt, very much felt in Turkey. This is what an explosion of capabilities looks like when you have a real foundation model. Some of these tasks, by the way, are not yet public, and we'll have more to talk about them in the near future.
6:02Think of a task, you name it,
Think of a task, you name it,
Think of a task, you name it,
Think of a task, you name it,
S Speaker 16:05we're approaching the ability to just get whatever it is you want, going in just a few days and climbing down from there.
we're approaching the ability to just get whatever it is you want, going in just a few days and climbing down from there.
we're approaching the ability to just get whatever it is you want, going in just a few days and climbing down from there.
we're approaching the ability to just get whatever it is you want, going in just a few days and climbing down from there.
6:16So what is Gen zero?
S Speaker 16:52you know, what, what we have seen before, and what we only see now with Gen zero.
you know, what, what we have seen before, and what we only see now with Gen zero.
you know, what, what we have seen before, and what we only see now with Gen zero.
you know, what, what we have seen before, and what we only see now with Gen zero.
6:59And you know, apart from some of my prior work back at Google,
And you know, apart from some of my prior work back at Google,
And you know, apart from some of my prior work back at Google,
And you know, apart from some of my prior work back at Google,
12:49task specific fine tuning reading.
task specific fine tuning reading.
task specific fine tuning reading.
task specific fine tuning reading.
12:53So that was what I wanted to tell you about. Gen
So that was what I wanted to tell you about. Gen
So that was what I wanted to tell you about. Gen
So that was what I wanted to tell you about. Gen
12:57zero, just really quickly, on the team, a generalist,
zero, just really quickly, on the team, a generalist,
zero, just really quickly, on the team, a generalist,
zero, just really quickly, on the team, a generalist,
S Speaker 113:01we have an absolutely world class team at journalists, I think we have the best team in the world. I feel so lucky to get to work every day with the extremely talented folks that we have. Much of the core team was behind things like call me
we have an absolutely world class team at journalists, I think we have the best team in the world. I feel so lucky to get to work every day with the extremely talented folks that we have. Much of the core team was behind things like call me
we have an absolutely world class team at journalists, I think we have the best team in the world. I feel so lucky to get to work every day with the extremely talented folks that we have. Much of the core team was behind things like call me
we have an absolutely world class team at journalists, I think we have the best team in the world. I feel so lucky to get to work every day with the extremely talented folks that we have. Much of the core team was behind things like call me
13:16and others back at Google,
and others back at Google,
and others back at Google,
and others back at Google,
S Speaker 113:20little product called Chat, GBT, GB 3.5 and four over open AI, others as well from from AI research world and now the robot side, just a large smattering of the robots that you might know and love From the past decade, folks on the team have really been behind many
little product called Chat, GBT, GB 3.5 and four over open AI, others as well from from AI research world and now the robot side, just a large smattering of the robots that you might know and love From the past decade, folks on the team have really been behind many
little product called Chat, GBT, GB 3.5 and four over open AI, others as well from from AI research world and now the robot side, just a large smattering of the robots that you might know and love From the past decade, folks on the team have really been behind many
little product called Chat, GBT, GB 3.5 and four over open AI, others as well from from AI research world and now the robot side, just a large smattering of the robots that you might know and love From the past decade, folks on the team have really been behind many
13:46So in closing, just a couple things, a
So in closing, just a couple things, a
So in closing, just a couple things, a
So in closing, just a couple things, a
S Speaker 113:51generalist and wrong mission to make general purpose robots. Really, really, really Adam and with Gen zero scaling laws are yours. Reach out if you want to partner with us. We'd love to hear from you to hear from you. And
generalist and wrong mission to make general purpose robots. Really, really, really Adam and with Gen zero scaling laws are yours. Reach out if you want to partner with us. We'd love to hear from you to hear from you. And
generalist and wrong mission to make general purpose robots. Really, really, really Adam and with Gen zero scaling laws are yours. Reach out if you want to partner with us. We'd love to hear from you to hear from you. And
generalist and wrong mission to make general purpose robots. Really, really, really Adam and with Gen zero scaling laws are yours. Reach out if you want to partner with us. We'd love to hear from you to hear from you. And
14:27We don't have that number public, but
We don't have that number public, but
We don't have that number public, but
We don't have that number public, but
14:41months, making sure those were
months, making sure those were
months, making sure those were
months, making sure those were
S Speaker 314:44so I noticed that you said you started for like a check to you three point type of error, so to speak, so does that mean you were using, where you were fine tuning the the underlying model code underneath it, for example, when you talk about open, AI started with The vicci code, or the victory formula, so to speak, in that kind of fine tune and drill into now what we have a chatgpt five approaching off about the formal aspect. Is it more that type of approach that you took, or is it more like you guys kind of started from scratch stereo have built all the way up, so to speak, from a training perspective, that's a little bit hard.
so I noticed that you said you started for like a check to you three point type of error, so to speak, so does that mean you were using, where you were fine tuning the the underlying model code underneath it, for example, when you talk about open, AI started with The vicci code, or the victory formula, so to speak, in that kind of fine tune and drill into now what we have a chatgpt five approaching off about the formal aspect. Is it more that type of approach that you took, or is it more like you guys kind of started from scratch stereo have built all the way up, so to speak, from a training perspective, that's a little bit hard.
so I noticed that you said you started for like a check to you three point type of error, so to speak, so does that mean you were using, where you were fine tuning the the underlying model code underneath it, for example, when you talk about open, AI started with The vicci code, or the victory formula, so to speak, in that kind of fine tune and drill into now what we have a chatgpt five approaching off about the formal aspect. Is it more that type of approach that you took, or is it more like you guys kind of started from scratch stereo have built all the way up, so to speak, from a training perspective, that's a little bit hard.
so I noticed that you said you started for like a check to you three point type of error, so to speak, so does that mean you were using, where you were fine tuning the the underlying model code underneath it, for example, when you talk about open, AI started with The vicci code, or the victory formula, so to speak, in that kind of fine tune and drill into now what we have a chatgpt five approaching off about the formal aspect. Is it more that type of approach that you took, or is it more like you guys kind of started from scratch stereo have built all the way up, so to speak, from a training perspective, that's a little bit hard.
S Speaker 115:21That's a lot of stuff in there. So all those models that you mentioned, they also started from scratch. So I think the important thing to be honest, and this is like a comment that we haven't said publicly, it's a very expensive experiment to run, but we increasingly feel like we could cut all of the pre training outside of our own robotics retraining, and the result was basically used so very much like the crucible of the models is all the training that we do with drilling.
That's a lot of stuff in there. So all those models that you mentioned, they also started from scratch. So I think the important thing to be honest, and this is like a comment that we haven't said publicly, it's a very expensive experiment to run, but we increasingly feel like we could cut all of the pre training outside of our own robotics retraining, and the result was basically used so very much like the crucible of the models is all the training that we do with drilling.
That's a lot of stuff in there. So all those models that you mentioned, they also started from scratch. So I think the important thing to be honest, and this is like a comment that we haven't said publicly, it's a very expensive experiment to run, but we increasingly feel like we could cut all of the pre training outside of our own robotics retraining, and the result was basically used so very much like the crucible of the models is all the training that we do with drilling.
That's a lot of stuff in there. So all those models that you mentioned, they also started from scratch. So I think the important thing to be honest, and this is like a comment that we haven't said publicly, it's a very expensive experiment to run, but we increasingly feel like we could cut all of the pre training outside of our own robotics retraining, and the result was basically used so very much like the crucible of the models is all the training that we do with drilling.
15:53And yeah, we we build them, we and we train you.
And yeah, we we build them, we and we train you.
And yeah, we we build them, we and we train you.
And yeah, we we build them, we and we train you.
S Speaker 416:04It is. So you have to show a very good result about the scaling ways of analysis.
It is. So you have to show a very good result about the scaling ways of analysis.
It is. So you have to show a very good result about the scaling ways of analysis.
It is. So you have to show a very good result about the scaling ways of analysis.
S Speaker 516:18So you didn't show a lot of result. There's a success rate. I'm pretty sure that's something you inside a correlation between loss and success rate.
So you didn't show a lot of result. There's a success rate. I'm pretty sure that's something you inside a correlation between loss and success rate.
So you didn't show a lot of result. There's a success rate. I'm pretty sure that's something you inside a correlation between loss and success rate.
So you didn't show a lot of result. There's a success rate. I'm pretty sure that's something you inside a correlation between loss and success rate.
S Speaker 616:29I know there's kind of a partial secret you're learning right now, but how do you expect?
I know there's kind of a partial secret you're learning right now, but how do you expect?
I know there's kind of a partial secret you're learning right now, but how do you expect?
I know there's kind of a partial secret you're learning right now, but how do you expect?
S Speaker 416:36I mean, maybe I should form a question very easily, like, what kind of loss
I mean, maybe I should form a question very easily, like, what kind of loss
I mean, maybe I should form a question very easily, like, what kind of loss
I mean, maybe I should form a question very easily, like, what kind of loss
16:40give you 95% of success rate,
give you 95% of success rate,
give you 95% of success rate,
give you 95% of success rate,
16:44do you want to give a guess?
do you want to give a guess?
do you want to give a guess?
do you want to give a guess?
S Speaker 116:49I think when you are measuring success rate, the best thing to do is to measure success rate.
I think when you are measuring success rate, the best thing to do is to measure success rate.
I think when you are measuring success rate, the best thing to do is to measure success rate.
I think when you are measuring success rate, the best thing to do is to measure success rate.
16:55So sorry, not sure if that answers your question, but
So sorry, not sure if that answers your question, but
So sorry, not sure if that answers your question, but
So sorry, not sure if that answers your question, but
S Speaker 116:59overall, there's a lot of different signals that we can use to guide model development. But, you know, simple validation loss, when done very carefully, is one and of course, like scaling laws in robotics, argument language models are established with the y axis of validation loss, and then there's a little bit better understood mapping between validation loss and downstream, you know, sort of closing performance or chat box over language models. But even there, they're still not necessarily one to one. But for us, yeah, we, you know, we do a mixture of a lot of different metrics that we analyze that are easier to measure, and then a lot of different types of closing the values. And, you know, 95% success rate increasingly and increasingly easier to do when you have a powerful
overall, there's a lot of different signals that we can use to guide model development. But, you know, simple validation loss, when done very carefully, is one and of course, like scaling laws in robotics, argument language models are established with the y axis of validation loss, and then there's a little bit better understood mapping between validation loss and downstream, you know, sort of closing performance or chat box over language models. But even there, they're still not necessarily one to one. But for us, yeah, we, you know, we do a mixture of a lot of different metrics that we analyze that are easier to measure, and then a lot of different types of closing the values. And, you know, 95% success rate increasingly and increasingly easier to do when you have a powerful
overall, there's a lot of different signals that we can use to guide model development. But, you know, simple validation loss, when done very carefully, is one and of course, like scaling laws in robotics, argument language models are established with the y axis of validation loss, and then there's a little bit better understood mapping between validation loss and downstream, you know, sort of closing performance or chat box over language models. But even there, they're still not necessarily one to one. But for us, yeah, we, you know, we do a mixture of a lot of different metrics that we analyze that are easier to measure, and then a lot of different types of closing the values. And, you know, 95% success rate increasingly and increasingly easier to do when you have a powerful
overall, there's a lot of different signals that we can use to guide model development. But, you know, simple validation loss, when done very carefully, is one and of course, like scaling laws in robotics, argument language models are established with the y axis of validation loss, and then there's a little bit better understood mapping between validation loss and downstream, you know, sort of closing performance or chat box over language models. But even there, they're still not necessarily one to one. But for us, yeah, we, you know, we do a mixture of a lot of different metrics that we analyze that are easier to measure, and then a lot of different types of closing the values. And, you know, 95% success rate increasingly and increasingly easier to do when you have a powerful
S Speaker 217:53feature. All right? Well, that sounds like that's it. So thank you very much. Pete, it was great
feature. All right? Well, that sounds like that's it. So thank you very much. Pete, it was great
feature. All right? Well, that sounds like that's it. So thank you very much. Pete, it was great
feature. All right? Well, that sounds like that's it. So thank you very much. Pete, it was great
S Speaker 218:02next to our next speaker is Alan alarem. He's a.
next to our next speaker is Alan alarem. He's a.
next to our next speaker is Alan alarem. He's a.
next to our next speaker is Alan alarem. He's a.