Meeting: Refuel - Product
Tue, Nov 5, 2024
9:02 AM
24 min
Priyesh P
Discussion on Sorghum Market and Expansio
URL: https://otter.ai/u/zOdTMqDrEXvXuy5D3QmlQkLuq_8
Downloaded: 2025-12-22T13:53:12.313749
Method: text_extraction
============================================================

S Speaker 10:05Oh, now I before we were able to hear you. Now you lost your audio. Let's just try without influence. It's better. Yeah. All right,
Oh, now I before we were able to hear you. Now you lost your audio. Let's just try without influence. It's better. Yeah. All right,
Oh, now I before we were able to hear you. Now you lost your audio. Let's just try without influence. It's better. Yeah. All right,
Oh, now I before we were able to hear you. Now you lost your audio. Let's just try without influence. It's better. Yeah. All right,
0:22cool. Good morning, morning.
cool. Good morning, morning.
cool. Good morning, morning.
cool. Good morning, morning.
S Speaker 10:28extra trip, so we discussed with our team, and so, of course, we're going to continue the diligence. Awkward. There's a few things that I would I think we've been discussing. So we
extra trip, so we discussed with our team, and so, of course, we're going to continue the diligence. Awkward. There's a few things that I would I think we've been discussing. So we
extra trip, so we discussed with our team, and so, of course, we're going to continue the diligence. Awkward. There's a few things that I would I think we've been discussing. So we
extra trip, so we discussed with our team, and so, of course, we're going to continue the diligence. Awkward. There's a few things that I would I think we've been discussing. So we
0:40should talk about sorghum. It
should talk about sorghum. It
should talk about sorghum. It
should talk about sorghum. It
0:45seems you talk to
S Speaker 10:49a good market leader from sorghum. So would
a good market leader from sorghum. So would
a good market leader from sorghum. So would
a good market leader from sorghum. So would
0:56like to get us there as well. And
like to get us there as well. And
like to get us there as well. And
like to get us there as well. And
0:57then the other thing I actually, right now I
then the other thing I actually, right now I
then the other thing I actually, right now I
then the other thing I actually, right now I
1:00have a hard stop at the interview.
have a hard stop at the interview.
have a hard stop at the interview.
have a hard stop at the interview.
1:01We have another, I see that,
We have another, I see that,
We have another, I see that,
We have another, I see that,
1:05but we can even today, if you're available.
but we can even today, if you're available.
but we can even today, if you're available.
but we can even today, if you're available.
S Speaker 11:13I think would be good to also now understand
I think would be good to also now understand
I think would be good to also now understand
I think would be good to also now understand
S Speaker 11:22customers and I know you have it across mostly three verticals, right?
customers and I know you have it across mostly three verticals, right?
customers and I know you have it across mostly three verticals, right?
customers and I know you have it across mostly three verticals, right?
1:25And Is that intentional?
And Is that intentional?
And Is that intentional?
And Is that intentional?
1:27Is that good market motion, intentional? And
Is that good market motion, intentional? And
Is that good market motion, intentional? And
Is that good market motion, intentional? And
S Speaker 11:37you want to expand beyond that within the next year or the years after? Think
you want to expand beyond that within the next year or the years after? Think
you want to expand beyond that within the next year or the years after? Think
you want to expand beyond that within the next year or the years after? Think
1:44so we should cover those two
so we should cover those two
so we should cover those two
so we should cover those two
S Speaker 12:31think that was good, but I think sharing, I mean, that was good, but, but essentially, but is that true, that you know they're more of a legacy company with a more legacy workflow because their website flow? Yes, that you know they're building the pipelines for the modern day? LLM, yes, you know, let
think that was good, but I think sharing, I mean, that was good, but, but essentially, but is that true, that you know they're more of a legacy company with a more legacy workflow because their website flow? Yes, that you know they're building the pipelines for the modern day? LLM, yes, you know, let
think that was good, but I think sharing, I mean, that was good, but, but essentially, but is that true, that you know they're more of a legacy company with a more legacy workflow because their website flow? Yes, that you know they're building the pipelines for the modern day? LLM, yes, you know, let
think that was good, but I think sharing, I mean, that was good, but, but essentially, but is that true, that you know they're more of a legacy company with a more legacy workflow because their website flow? Yes, that you know they're building the pipelines for the modern day? LLM, yes, you know, let
S Speaker 14:29about the technology stack, per se, that talks about. But it seems that golden market is more around regulated industries, yeah, and, and the need for snorted in those industries, right? Yeah, but that doesn't talk about their technology per se, which
about the technology stack, per se, that talks about. But it seems that golden market is more around regulated industries, yeah, and, and the need for snorted in those industries, right? Yeah, but that doesn't talk about their technology per se, which
about the technology stack, per se, that talks about. But it seems that golden market is more around regulated industries, yeah, and, and the need for snorted in those industries, right? Yeah, but that doesn't talk about their technology per se, which
about the technology stack, per se, that talks about. But it seems that golden market is more around regulated industries, yeah, and, and the need for snorted in those industries, right? Yeah, but that doesn't talk about their technology per se, which
4:51is the technology stack similar,
is the technology stack similar,
is the technology stack similar,
is the technology stack similar,
4:55technology different?
technology different?
technology different?
technology different?
4:58You know, that's it's
You know, that's it's
You know, that's it's
You know, that's it's
6:08And this is still fairly different from something like a clean
And this is still fairly different from something like a clean
And this is still fairly different from something like a clean
And this is still fairly different from something like a clean
S Speaker 16:17labs, right? Yeah, now something like a clean lab, and now I get it. Clean Labs also focuses on computer vision and a bunch of other things. Yeah. I also would like to understand a little more clearly, where does the buck stop with you know, I know you spent what the first two years building something like a clean labs, where does a Bucha with something like a clean labs where they're trying to serve ml engineers, which is. Is, it is auto labeling
labs, right? Yeah, now something like a clean lab, and now I get it. Clean Labs also focuses on computer vision and a bunch of other things. Yeah. I also would like to understand a little more clearly, where does the buck stop with you know, I know you spent what the first two years building something like a clean labs, where does a Bucha with something like a clean labs where they're trying to serve ml engineers, which is. Is, it is auto labeling
labs, right? Yeah, now something like a clean lab, and now I get it. Clean Labs also focuses on computer vision and a bunch of other things. Yeah. I also would like to understand a little more clearly, where does the buck stop with you know, I know you spent what the first two years building something like a clean labs, where does a Bucha with something like a clean labs where they're trying to serve ml engineers, which is. Is, it is auto labeling
labs, right? Yeah, now something like a clean lab, and now I get it. Clean Labs also focuses on computer vision and a bunch of other things. Yeah. I also would like to understand a little more clearly, where does the buck stop with you know, I know you spent what the first two years building something like a clean labs, where does a Bucha with something like a clean labs where they're trying to serve ml engineers, which is. Is, it is auto labeling
S Speaker 16:54more precisely, in order to serve build a product for engineers, not just general engineers, what is it that you are adding more precisely, like in the entire workflow. What is the entire workflow? Clean labs, you know, focus on and then I know they've got a good
more precisely, in order to serve build a product for engineers, not just general engineers, what is it that you are adding more precisely, like in the entire workflow. What is the entire workflow? Clean labs, you know, focus on and then I know they've got a good
more precisely, in order to serve build a product for engineers, not just general engineers, what is it that you are adding more precisely, like in the entire workflow. What is the entire workflow? Clean labs, you know, focus on and then I know they've got a good
more precisely, in order to serve build a product for engineers, not just general engineers, what is it that you are adding more precisely, like in the entire workflow. What is the entire workflow? Clean labs, you know, focus on and then I know they've got a good
S Speaker 17:18that hasn't translated as much into, you know, like, for example, revenue, because it started becoming like services. So we'd like to understand from your perspective as to, where do they where do you like make the product more focused?
that hasn't translated as much into, you know, like, for example, revenue, because it started becoming like services. So we'd like to understand from your perspective as to, where do they where do you like make the product more focused?
that hasn't translated as much into, you know, like, for example, revenue, because it started becoming like services. So we'd like to understand from your perspective as to, where do they where do you like make the product more focused?
that hasn't translated as much into, you know, like, for example, revenue, because it started becoming like services. So we'd like to understand from your perspective as to, where do they where do you like make the product more focused?
S Speaker 27:34Yeah, I mean, cleanup, you know. And again, we've checked out their open source library, so we have a reasonable sense of the capabilities there, a little bit about the product, although we haven't talked to any customers of theirs like we're sort of actively using them. A lot of
Yeah, I mean, cleanup, you know. And again, we've checked out their open source library, so we have a reasonable sense of the capabilities there, a little bit about the product, although we haven't talked to any customers of theirs like we're sort of actively using them. A lot of
Yeah, I mean, cleanup, you know. And again, we've checked out their open source library, so we have a reasonable sense of the capabilities there, a little bit about the product, although we haven't talked to any customers of theirs like we're sort of actively using them. A lot of
Yeah, I mean, cleanup, you know. And again, we've checked out their open source library, so we have a reasonable sense of the capabilities there, a little bit about the product, although we haven't talked to any customers of theirs like we're sort of actively using them. A lot of
S Speaker 17:52the focus run into the same customers at all. No,
the focus run into the same customers at all. No,
the focus run into the same customers at all. No,
the focus run into the same customers at all. No,
9:51too, right? Yeah,
9:53but we do some of that as well,
but we do some of that as well,
but we do some of that as well,
but we do some of that as well,
S Speaker 111:01Got it, got it. But so that's a layer of abstraction, yeah, that you're providing. But. Underneath, is it the same steps that you're doing,
Got it, got it. But so that's a layer of abstraction, yeah, that you're providing. But. Underneath, is it the same steps that you're doing,
Got it, got it. But so that's a layer of abstraction, yeah, that you're providing. But. Underneath, is it the same steps that you're doing,
Got it, got it. But so that's a layer of abstraction, yeah, that you're providing. But. Underneath, is it the same steps that you're doing,
S Speaker 211:14if you think about, like, I mean, generally good practices of like, how to do machine learning successfully. And there's, there's, frankly, there's nothing drastically new right in how people have do, people should do machine learning. If you're thinking about like a training data set for some model, you're typically thinking about like a few axes. You're thinking about, Okay, for this size model, what's the rough data set size that I'll be looking at? Because different models have different capacities. You're looking to figure out how many data points based on the complexity of the problem. You're looking at some notions. Of diversity, right? You're looking for some notions of, like, data distribution, right, in terms of the output labels, you're looking generally for these broad patterns. And then you're looking for patterns around. Look, if I'm seeing some things that are low confidence, can I find more examples like that that are low confidence, right, as they use the user, sort of like, can give us some feedback on those so the general principles are always the same. Right now, the question really is like, okay, what are what do you have to build out in order to make the path of going from nothing or just unlabeled data to a curated data set that is good enough, as short as possible, as little human effort as possible? So that's where like technology build out, ends up happening, and so for us, right? One of the nice things is that, because llms require. Don't require 10s of 1000s of labels. They require 100 100 labels, right? We've actually made like, our life is made much simpler, right? Because what we have to do is like, give users an interface to say, like, hey, spend 20 minutes doing thumbs up, thumbs down, right? Hit a button, and you'll see what quality looks like today, right? And then, if you want to customize the model, here's another button. Go, click that right? We deploy a model that is much smaller, that five. Was the and so our life is becoming easier as these models are becoming capable, and now we just have to operate on sort of the edges right of being able to say, look from the last seven days worth of data. Here are the 30 examples that you should review, or somebody on your team should review. Because if you just do thumbs up, thumbs down on these 30 examples, like our guarantee to you is the model will become even better, even more attuned to. Your data problem. So, because models are getting better, our job in terms of, like, curation is becoming easier and it's becoming even sort of, the interface is becoming even easier for that end user, interesting.
if you think about, like, I mean, generally good practices of like, how to do machine learning successfully. And there's, there's, frankly, there's nothing drastically new right in how people have do, people should do machine learning. If you're thinking about like a training data set for some model, you're typically thinking about like a few axes. You're thinking about, Okay, for this size model, what's the rough data set size that I'll be looking at? Because different models have different capacities. You're looking to figure out how many data points based on the complexity of the problem. You're looking at some notions. Of diversity, right? You're looking for some notions of, like, data distribution, right, in terms of the output labels, you're looking generally for these broad patterns. And then you're looking for patterns around. Look, if I'm seeing some things that are low confidence, can I find more examples like that that are low confidence, right, as they use the user, sort of like, can give us some feedback on those so the general principles are always the same. Right now, the question really is like, okay, what are what do you have to build out in order to make the path of going from nothing or just unlabeled data to a curated data set that is good enough, as short as possible, as little human effort as possible? So that's where like technology build out, ends up happening, and so for us, right? One of the nice things is that, because llms require. Don't require 10s of 1000s of labels. They require 100 100 labels, right? We've actually made like, our life is made much simpler, right? Because what we have to do is like, give users an interface to say, like, hey, spend 20 minutes doing thumbs up, thumbs down, right? Hit a button, and you'll see what quality looks like today, right? And then, if you want to customize the model, here's another button. Go, click that right? We deploy a model that is much smaller, that five. Was the and so our life is becoming easier as these models are becoming capable, and now we just have to operate on sort of the edges right of being able to say, look from the last seven days worth of data. Here are the 30 examples that you should review, or somebody on your team should review. Because if you just do thumbs up, thumbs down on these 30 examples, like our guarantee to you is the model will become even better, even more attuned to. Your data problem. So, because models are getting better, our job in terms of, like, curation is becoming easier and it's becoming even sort of, the interface is becoming even easier for that end user, interesting.
if you think about, like, I mean, generally good practices of like, how to do machine learning successfully. And there's, there's, frankly, there's nothing drastically new right in how people have do, people should do machine learning. If you're thinking about like a training data set for some model, you're typically thinking about like a few axes. You're thinking about, Okay, for this size model, what's the rough data set size that I'll be looking at? Because different models have different capacities. You're looking to figure out how many data points based on the complexity of the problem. You're looking at some notions. Of diversity, right? You're looking for some notions of, like, data distribution, right, in terms of the output labels, you're looking generally for these broad patterns. And then you're looking for patterns around. Look, if I'm seeing some things that are low confidence, can I find more examples like that that are low confidence, right, as they use the user, sort of like, can give us some feedback on those so the general principles are always the same. Right now, the question really is like, okay, what are what do you have to build out in order to make the path of going from nothing or just unlabeled data to a curated data set that is good enough, as short as possible, as little human effort as possible? So that's where like technology build out, ends up happening, and so for us, right? One of the nice things is that, because llms require. Don't require 10s of 1000s of labels. They require 100 100 labels, right? We've actually made like, our life is made much simpler, right? Because what we have to do is like, give users an interface to say, like, hey, spend 20 minutes doing thumbs up, thumbs down, right? Hit a button, and you'll see what quality looks like today, right? And then, if you want to customize the model, here's another button. Go, click that right? We deploy a model that is much smaller, that five. Was the and so our life is becoming easier as these models are becoming capable, and now we just have to operate on sort of the edges right of being able to say, look from the last seven days worth of data. Here are the 30 examples that you should review, or somebody on your team should review. Because if you just do thumbs up, thumbs down on these 30 examples, like our guarantee to you is the model will become even better, even more attuned to. Your data problem. So, because models are getting better, our job in terms of, like, curation is becoming easier and it's becoming even sort of, the interface is becoming even easier for that end user, interesting.
if you think about, like, I mean, generally good practices of like, how to do machine learning successfully. And there's, there's, frankly, there's nothing drastically new right in how people have do, people should do machine learning. If you're thinking about like a training data set for some model, you're typically thinking about like a few axes. You're thinking about, Okay, for this size model, what's the rough data set size that I'll be looking at? Because different models have different capacities. You're looking to figure out how many data points based on the complexity of the problem. You're looking at some notions. Of diversity, right? You're looking for some notions of, like, data distribution, right, in terms of the output labels, you're looking generally for these broad patterns. And then you're looking for patterns around. Look, if I'm seeing some things that are low confidence, can I find more examples like that that are low confidence, right, as they use the user, sort of like, can give us some feedback on those so the general principles are always the same. Right now, the question really is like, okay, what are what do you have to build out in order to make the path of going from nothing or just unlabeled data to a curated data set that is good enough, as short as possible, as little human effort as possible? So that's where like technology build out, ends up happening, and so for us, right? One of the nice things is that, because llms require. Don't require 10s of 1000s of labels. They require 100 100 labels, right? We've actually made like, our life is made much simpler, right? Because what we have to do is like, give users an interface to say, like, hey, spend 20 minutes doing thumbs up, thumbs down, right? Hit a button, and you'll see what quality looks like today, right? And then, if you want to customize the model, here's another button. Go, click that right? We deploy a model that is much smaller, that five. Was the and so our life is becoming easier as these models are becoming capable, and now we just have to operate on sort of the edges right of being able to say, look from the last seven days worth of data. Here are the 30 examples that you should review, or somebody on your team should review. Because if you just do thumbs up, thumbs down on these 30 examples, like our guarantee to you is the model will become even better, even more attuned to. Your data problem. So, because models are getting better, our job in terms of, like, curation is becoming easier and it's becoming even sort of, the interface is becoming even easier for that end user, interesting.
S Speaker 113:41So, so that's because So, but that's essentially serving the user with an interface of saying that, go,
So, so that's because So, but that's essentially serving the user with an interface of saying that, go,
So, so that's because So, but that's essentially serving the user with an interface of saying that, go,
So, so that's because So, but that's essentially serving the user with an interface of saying that, go,
13:51do thumbs up. Thumbs down on these question answer pairs,
do thumbs up. Thumbs down on these question answer pairs,
do thumbs up. Thumbs down on these question answer pairs,
do thumbs up. Thumbs down on these question answer pairs,
S Speaker 113:56on these data sets that I found that you are serving up those question answers to the users, right? That's right, yeah.
on these data sets that I found that you are serving up those question answers to the users, right? That's right, yeah.
on these data sets that I found that you are serving up those question answers to the users, right? That's right, yeah.
on these data sets that I found that you are serving up those question answers to the users, right? That's right, yeah.
S Speaker 214:09And by the way, what a machine learning person would be doing, right if these. Companies would actually hire a large number of machine learning engineers. Like, they would actually be spending this time on the data, to build all sorts of stuff, to highlight which examples are, you know, making, where there are mistakes, WHICH EXAMPLES should be reviewed. Like, it would basically be the machine learning team that is doing it, and our goal is how much to be productize this so that you basically don't have. Have to, like, hire, involve a machine learning team to go and solve the same problem and deliver the same level of outcome. Interesting. Got it so.
And by the way, what a machine learning person would be doing, right if these. Companies would actually hire a large number of machine learning engineers. Like, they would actually be spending this time on the data, to build all sorts of stuff, to highlight which examples are, you know, making, where there are mistakes, WHICH EXAMPLES should be reviewed. Like, it would basically be the machine learning team that is doing it, and our goal is how much to be productize this so that you basically don't have. Have to, like, hire, involve a machine learning team to go and solve the same problem and deliver the same level of outcome. Interesting. Got it so.
And by the way, what a machine learning person would be doing, right if these. Companies would actually hire a large number of machine learning engineers. Like, they would actually be spending this time on the data, to build all sorts of stuff, to highlight which examples are, you know, making, where there are mistakes, WHICH EXAMPLES should be reviewed. Like, it would basically be the machine learning team that is doing it, and our goal is how much to be productize this so that you basically don't have. Have to, like, hire, involve a machine learning team to go and solve the same problem and deliver the same level of outcome. Interesting. Got it so.
And by the way, what a machine learning person would be doing, right if these. Companies would actually hire a large number of machine learning engineers. Like, they would actually be spending this time on the data, to build all sorts of stuff, to highlight which examples are, you know, making, where there are mistakes, WHICH EXAMPLES should be reviewed. Like, it would basically be the machine learning team that is doing it, and our goal is how much to be productize this so that you basically don't have. Have to, like, hire, involve a machine learning team to go and solve the same problem and deliver the same level of outcome. Interesting. Got it so.
14:52And how do you so?
14:56Let's say, you know,
14:58I'm making, let's say.
I'm making, let's say.
I'm making, let's say.
I'm making, let's say.
S Speaker 115:01If you were to engage with, let's say VC, and you were to say, and they were to give you a problem statement that, hey, go find me startups to source based on, based on a bunch of things, based on my email, based on LinkedIn. Based on Twitter, based on newsletters, and based on Stevie insights and pitch book, yeah, and and then. And here's my criteria, yeah, area stage, founder, background. Company all that, right, and and then, if you were to go train a model for something like that, then essentially, you would ask someone like me to to go, you serve up startups, and you would say, here's a. It die, and you'll say thumbs up and thumbs down, yeah. And essentially, then you'll train a model, yeah, that serves this up to me or not. Train a model. You will essentially curate it. You could also train a model,
If you were to engage with, let's say VC, and you were to say, and they were to give you a problem statement that, hey, go find me startups to source based on, based on a bunch of things, based on my email, based on LinkedIn. Based on Twitter, based on newsletters, and based on Stevie insights and pitch book, yeah, and and then. And here's my criteria, yeah, area stage, founder, background. Company all that, right, and and then, if you were to go train a model for something like that, then essentially, you would ask someone like me to to go, you serve up startups, and you would say, here's a. It die, and you'll say thumbs up and thumbs down, yeah. And essentially, then you'll train a model, yeah, that serves this up to me or not. Train a model. You will essentially curate it. You could also train a model,
If you were to engage with, let's say VC, and you were to say, and they were to give you a problem statement that, hey, go find me startups to source based on, based on a bunch of things, based on my email, based on LinkedIn. Based on Twitter, based on newsletters, and based on Stevie insights and pitch book, yeah, and and then. And here's my criteria, yeah, area stage, founder, background. Company all that, right, and and then, if you were to go train a model for something like that, then essentially, you would ask someone like me to to go, you serve up startups, and you would say, here's a. It die, and you'll say thumbs up and thumbs down, yeah. And essentially, then you'll train a model, yeah, that serves this up to me or not. Train a model. You will essentially curate it. You could also train a model,
If you were to engage with, let's say VC, and you were to say, and they were to give you a problem statement that, hey, go find me startups to source based on, based on a bunch of things, based on my email, based on LinkedIn. Based on Twitter, based on newsletters, and based on Stevie insights and pitch book, yeah, and and then. And here's my criteria, yeah, area stage, founder, background. Company all that, right, and and then, if you were to go train a model for something like that, then essentially, you would ask someone like me to to go, you serve up startups, and you would say, here's a. It die, and you'll say thumbs up and thumbs down, yeah. And essentially, then you'll train a model, yeah, that serves this up to me or not. Train a model. You will essentially curate it. You could also train a model,
S Speaker 216:11yeah, the goal is to give you the outcome, which is, you know, startups that are to your liking, right? Based on the draw. Criteria and the feedback that you've given us, and incorporating all the signals that matter.
yeah, the goal is to give you the outcome, which is, you know, startups that are to your liking, right? Based on the draw. Criteria and the feedback that you've given us, and incorporating all the signals that matter.
yeah, the goal is to give you the outcome, which is, you know, startups that are to your liking, right? Based on the draw. Criteria and the feedback that you've given us, and incorporating all the signals that matter.
yeah, the goal is to give you the outcome, which is, you know, startups that are to your liking, right? Based on the draw. Criteria and the feedback that you've given us, and incorporating all the signals that matter.
S Speaker 116:23Yes, okay, and then you would serve that up. Yeah.
Yes, okay, and then you would serve that up. Yeah.
Yes, okay, and then you would serve that up. Yeah.
Yes, okay, and then you would serve that up. Yeah.
S Speaker 216:28So are we talking about a refuel Qualcomm ventures contract, where you use refill to do this?
So are we talking about a refuel Qualcomm ventures contract, where you use refill to do this?
So are we talking about a refuel Qualcomm ventures contract, where you use refill to do this?
So are we talking about a refuel Qualcomm ventures contract, where you use refill to do this?
16:34We good very well.
16:38The problem is a. A
S Speaker 116:42pitch book, APIs or whatever. I don't know, do you have you work with any VC
pitch book, APIs or whatever. I don't know, do you have you work with any VC
pitch book, APIs or whatever. I don't know, do you have you work with any VC
pitch book, APIs or whatever. I don't know, do you have you work with any VC
16:46that's like a good problem statement.
that's like a good problem statement.
that's like a good problem statement.
that's like a good problem statement.
16:48If you build something like that, that
If you build something like that, that
If you build something like that, that
If you build something like that, that
S Speaker 216:50is powerful. Actually, once people have seen our demo, like, there's been a few folks who've asked us, like, Hey, can we could we build this with big. Is, you know, even the demo like it just exactly it fits that model, which is, you get some data, you like, there's daily data, let's say that it's coming in, right? You combine it with different APIs. Sources. You write your rules, and then the output is sort of like scores aligned with the API sources. You
is powerful. Actually, once people have seen our demo, like, there's been a few folks who've asked us, like, Hey, can we could we build this with big. Is, you know, even the demo like it just exactly it fits that model, which is, you get some data, you like, there's daily data, let's say that it's coming in, right? You combine it with different APIs. Sources. You write your rules, and then the output is sort of like scores aligned with the API sources. You
is powerful. Actually, once people have seen our demo, like, there's been a few folks who've asked us, like, Hey, can we could we build this with big. Is, you know, even the demo like it just exactly it fits that model, which is, you get some data, you like, there's daily data, let's say that it's coming in, right? You combine it with different APIs. Sources. You write your rules, and then the output is sort of like scores aligned with the API sources. You
is powerful. Actually, once people have seen our demo, like, there's been a few folks who've asked us, like, Hey, can we could we build this with big. Is, you know, even the demo like it just exactly it fits that model, which is, you get some data, you like, there's daily data, let's say that it's coming in, right? You combine it with different APIs. Sources. You write your rules, and then the output is sort of like scores aligned with the API sources. You
S Speaker 217:13so you will have to purchase. The long term, we will probably have a ticket. You will have integrations into many of the common API sources. Today, you would have to go purchase the API, and you would have to just give us the curl command, and then we can then integrate using that right. But over time, you can imagine these will be very native and. Integrations. I mean, today, we already have native integrations into Google searches, Google Maps, because these are common asks for us. But over time, this will be a lot of places where there's common APIs to get access to external or internal data that matters to our users. Internal data would be even things like. Imagine connectors into notion search, or glean search right? Because we want to grab all this enterprise context. External will be, of course, like the ones that we've just discussed the pitch book, the crunch pieces of the world, but also like a lot of like LinkedIn APIs and a bunch of APIs that get us like, let's say, for sales and marketing types of teams. But. Then, you know, for us, like it just boils down into which verticals are we serving today? And I think this maybe goes into the conversation the second part of your question, which is, what is a very specific kind of time today? Because over time, this will be every industry, many use cases per industry, but we have to start somewhere. And so. Where do we start, where we know there are dollars that are available for us, where there's good customers that we can solve meaningful problems today, but yeah, look often like customers when they're sort of inbound to us, right? They teach us about the problems that they have. And so you know, even though it doesn't exactly fit. Our current ICP, we had an inbound from a healthcare customer who's actually now starting to use refuel, and we haven't signed a BA with them yet, but like they're asking us to because they have a very specific kind of categorization problem that they haven't been able to solve on their own with just llms.
so you will have to purchase. The long term, we will probably have a ticket. You will have integrations into many of the common API sources. Today, you would have to go purchase the API, and you would have to just give us the curl command, and then we can then integrate using that right. But over time, you can imagine these will be very native and. Integrations. I mean, today, we already have native integrations into Google searches, Google Maps, because these are common asks for us. But over time, this will be a lot of places where there's common APIs to get access to external or internal data that matters to our users. Internal data would be even things like. Imagine connectors into notion search, or glean search right? Because we want to grab all this enterprise context. External will be, of course, like the ones that we've just discussed the pitch book, the crunch pieces of the world, but also like a lot of like LinkedIn APIs and a bunch of APIs that get us like, let's say, for sales and marketing types of teams. But. Then, you know, for us, like it just boils down into which verticals are we serving today? And I think this maybe goes into the conversation the second part of your question, which is, what is a very specific kind of time today? Because over time, this will be every industry, many use cases per industry, but we have to start somewhere. And so. Where do we start, where we know there are dollars that are available for us, where there's good customers that we can solve meaningful problems today, but yeah, look often like customers when they're sort of inbound to us, right? They teach us about the problems that they have. And so you know, even though it doesn't exactly fit. Our current ICP, we had an inbound from a healthcare customer who's actually now starting to use refuel, and we haven't signed a BA with them yet, but like they're asking us to because they have a very specific kind of categorization problem that they haven't been able to solve on their own with just llms.
so you will have to purchase. The long term, we will probably have a ticket. You will have integrations into many of the common API sources. Today, you would have to go purchase the API, and you would have to just give us the curl command, and then we can then integrate using that right. But over time, you can imagine these will be very native and. Integrations. I mean, today, we already have native integrations into Google searches, Google Maps, because these are common asks for us. But over time, this will be a lot of places where there's common APIs to get access to external or internal data that matters to our users. Internal data would be even things like. Imagine connectors into notion search, or glean search right? Because we want to grab all this enterprise context. External will be, of course, like the ones that we've just discussed the pitch book, the crunch pieces of the world, but also like a lot of like LinkedIn APIs and a bunch of APIs that get us like, let's say, for sales and marketing types of teams. But. Then, you know, for us, like it just boils down into which verticals are we serving today? And I think this maybe goes into the conversation the second part of your question, which is, what is a very specific kind of time today? Because over time, this will be every industry, many use cases per industry, but we have to start somewhere. And so. Where do we start, where we know there are dollars that are available for us, where there's good customers that we can solve meaningful problems today, but yeah, look often like customers when they're sort of inbound to us, right? They teach us about the problems that they have. And so you know, even though it doesn't exactly fit. Our current ICP, we had an inbound from a healthcare customer who's actually now starting to use refuel, and we haven't signed a BA with them yet, but like they're asking us to because they have a very specific kind of categorization problem that they haven't been able to solve on their own with just llms.
so you will have to purchase. The long term, we will probably have a ticket. You will have integrations into many of the common API sources. Today, you would have to go purchase the API, and you would have to just give us the curl command, and then we can then integrate using that right. But over time, you can imagine these will be very native and. Integrations. I mean, today, we already have native integrations into Google searches, Google Maps, because these are common asks for us. But over time, this will be a lot of places where there's common APIs to get access to external or internal data that matters to our users. Internal data would be even things like. Imagine connectors into notion search, or glean search right? Because we want to grab all this enterprise context. External will be, of course, like the ones that we've just discussed the pitch book, the crunch pieces of the world, but also like a lot of like LinkedIn APIs and a bunch of APIs that get us like, let's say, for sales and marketing types of teams. But. Then, you know, for us, like it just boils down into which verticals are we serving today? And I think this maybe goes into the conversation the second part of your question, which is, what is a very specific kind of time today? Because over time, this will be every industry, many use cases per industry, but we have to start somewhere. And so. Where do we start, where we know there are dollars that are available for us, where there's good customers that we can solve meaningful problems today, but yeah, look often like customers when they're sort of inbound to us, right? They teach us about the problems that they have. And so you know, even though it doesn't exactly fit. Our current ICP, we had an inbound from a healthcare customer who's actually now starting to use refuel, and we haven't signed a BA with them yet, but like they're asking us to because they have a very specific kind of categorization problem that they haven't been able to solve on their own with just llms.
18:57You have a premium product.
You have a premium product.
You have a premium product.
You have a premium product.
S Speaker 219:00We don't today Tushar, we will early next year, probably.
We don't today Tushar, we will early next year, probably.
We don't today Tushar, we will early next year, probably.
We don't today Tushar, we will early next year, probably.
S Speaker 119:05How did this healthcare company get access to refuel?
How did this healthcare company get access to refuel?
How did this healthcare company get access to refuel?
How did this healthcare company get access to refuel?
S Speaker 219:12So they reached out to us, like from our website. I did a demo, and then over a couple of demos, couple of calls, they were ready to start using refuel so we didn't do any POC. Yeah, yes, yeah. I. Ah,
So they reached out to us, like from our website. I did a demo, and then over a couple of demos, couple of calls, they were ready to start using refuel so we didn't do any POC. Yeah, yes, yeah. I. Ah,
So they reached out to us, like from our website. I did a demo, and then over a couple of demos, couple of calls, they were ready to start using refuel so we didn't do any POC. Yeah, yes, yeah. I. Ah,
So they reached out to us, like from our website. I did a demo, and then over a couple of demos, couple of calls, they were ready to start using refuel so we didn't do any POC. Yeah, yes, yeah. I. Ah,
S Speaker 119:27and then, so in this particular, if you can talk about the use case in this particular, if you have nine minutes, and then let's schedule if, what's your availability for this afternoon?
and then, so in this particular, if you can talk about the use case in this particular, if you have nine minutes, and then let's schedule if, what's your availability for this afternoon?
and then, so in this particular, if you can talk about the use case in this particular, if you have nine minutes, and then let's schedule if, what's your availability for this afternoon?
and then, so in this particular, if you can talk about the use case in this particular, if you have nine minutes, and then let's schedule if, what's your availability for this afternoon?
19:40I think I could do 1pm okay, I
I think I could do 1pm okay, I
I think I could do 1pm okay, I
I think I could do 1pm okay, I
S Speaker 219:47might actually ask to head out five minutes early, because I have to actually
might actually ask to head out five minutes early, because I have to actually
might actually ask to head out five minutes early, because I have to actually
might actually ask to head out five minutes early, because I have to actually
S Speaker 119:54set up another. Session for us, maybe an hour at 1pm
set up another. Session for us, maybe an hour at 1pm
set up another. Session for us, maybe an hour at 1pm
set up another. Session for us, maybe an hour at 1pm
S Speaker 220:00if we want to do an hour. Could be is like evening possible? Yeah, we could do evening. For example, my last customer call ends at 606
if we want to do an hour. Could be is like evening possible? Yeah, we could do evening. For example, my last customer call ends at 606
if we want to do an hour. Could be is like evening possible? Yeah, we could do evening. For example, my last customer call ends at 606
if we want to do an hour. Could be is like evening possible? Yeah, we could do evening. For example, my last customer call ends at 606
20:11today I have dinner.
S Speaker 220:15I can do late night as well, like Okay, so, but this is more a question for the two of you,
I can do late night as well, like Okay, so, but this is more a question for the two of you,
I can do late night as well, like Okay, so, but this is more a question for the two of you,
I can do late night as well, like Okay, so, but this is more a question for the two of you,
20:20because I think I can do that too.
because I think I can do that too.
because I think I can do that too.
because I think I can do that too.
S Speaker 120:24Priyesh Works for me. Does 830 work for you? Yeah? It works.
Priyesh Works for me. Does 830 work for you? Yeah? It works.
Priyesh Works for me. Does 830 work for you? Yeah? It works.
Priyesh Works for me. Does 830 work for you? Yeah? It works.
20:31Yeah. Okay. Okay, so I'll
Yeah. Okay. Okay, so I'll
Yeah. Okay. Okay, so I'll
Yeah. Okay. Okay, so I'll
20:38send an invite for me. So since we have three minutes left,
send an invite for me. So since we have three minutes left,
send an invite for me. So since we have three minutes left,
send an invite for me. So since we have three minutes left,
S Speaker 120:41so So me finish that, which is that particular healthcare customer, and if it's take, if it takes longer than we can talk about that, if you can just actually, it would be great to walk through your entire stack if you can with a use case, yeah, which is pick a use case. What are all the things that you're doing for that particular. Customer, and then what's the interface that you serve that customer? The idea is that you abstract away all of those things, but then happen under the abstraction. What are all things that you're doing
so So me finish that, which is that particular healthcare customer, and if it's take, if it takes longer than we can talk about that, if you can just actually, it would be great to walk through your entire stack if you can with a use case, yeah, which is pick a use case. What are all the things that you're doing for that particular. Customer, and then what's the interface that you serve that customer? The idea is that you abstract away all of those things, but then happen under the abstraction. What are all things that you're doing
so So me finish that, which is that particular healthcare customer, and if it's take, if it takes longer than we can talk about that, if you can just actually, it would be great to walk through your entire stack if you can with a use case, yeah, which is pick a use case. What are all the things that you're doing for that particular. Customer, and then what's the interface that you serve that customer? The idea is that you abstract away all of those things, but then happen under the abstraction. What are all things that you're doing
so So me finish that, which is that particular healthcare customer, and if it's take, if it takes longer than we can talk about that, if you can just actually, it would be great to walk through your entire stack if you can with a use case, yeah, which is pick a use case. What are all the things that you're doing for that particular. Customer, and then what's the interface that you serve that customer? The idea is that you abstract away all of those things, but then happen under the abstraction. What are all things that you're doing
S Speaker 221:17for that particular so maybe the healthcare one is very easy. They've just started. They're building their first use case. But this problem probably resonate with might resonate quite a lot. They have clinical visits like notes, and they're trying to figure out what is the complexity of the case, because they can essentially like charge. Medicare, Medicaid, based on the complexity. And so they're trying to figure out what criteria that they can use to say this is low complexity, medium complexity, high complexity. Use case, the reason why refuel is actually important for them is because just using llms is not enough. They actually have to have an interface where it's again, it's multiple steps, because there are multiple pieces that contribute to this complexity. There's some information that they have to grab about, you know what actually matters from a Medicare, Medicaid use case that external and they have to come. Buy this information along with an interface for their clinician team, like clinical team internally, to give a give it some feedback. And so that's the thing that they're building out. So imagine, so it's a five step workflow that they're looking to build out in pre flow. There's many different things that contribute to complexity, and then there's an overall complexity score that they're building. And you can imagine this is like a very repeatable use case. Many people care about it. We just didn't focus on it because, you know, with a team of seven people, like, you know, doing HIPAA and, like, doing a bunch of these things, it's like just a lot of effort. But again, this is fully inbound, right? Like we, well, frankly, I ran into the, like, an engineer. Any lead at this company in person at an event, and then he wanted to see the demo, and then, yeah, looped us in. Okay,
for that particular so maybe the healthcare one is very easy. They've just started. They're building their first use case. But this problem probably resonate with might resonate quite a lot. They have clinical visits like notes, and they're trying to figure out what is the complexity of the case, because they can essentially like charge. Medicare, Medicaid, based on the complexity. And so they're trying to figure out what criteria that they can use to say this is low complexity, medium complexity, high complexity. Use case, the reason why refuel is actually important for them is because just using llms is not enough. They actually have to have an interface where it's again, it's multiple steps, because there are multiple pieces that contribute to this complexity. There's some information that they have to grab about, you know what actually matters from a Medicare, Medicaid use case that external and they have to come. Buy this information along with an interface for their clinician team, like clinical team internally, to give a give it some feedback. And so that's the thing that they're building out. So imagine, so it's a five step workflow that they're looking to build out in pre flow. There's many different things that contribute to complexity, and then there's an overall complexity score that they're building. And you can imagine this is like a very repeatable use case. Many people care about it. We just didn't focus on it because, you know, with a team of seven people, like, you know, doing HIPAA and, like, doing a bunch of these things, it's like just a lot of effort. But again, this is fully inbound, right? Like we, well, frankly, I ran into the, like, an engineer. Any lead at this company in person at an event, and then he wanted to see the demo, and then, yeah, looped us in. Okay,
for that particular so maybe the healthcare one is very easy. They've just started. They're building their first use case. But this problem probably resonate with might resonate quite a lot. They have clinical visits like notes, and they're trying to figure out what is the complexity of the case, because they can essentially like charge. Medicare, Medicaid, based on the complexity. And so they're trying to figure out what criteria that they can use to say this is low complexity, medium complexity, high complexity. Use case, the reason why refuel is actually important for them is because just using llms is not enough. They actually have to have an interface where it's again, it's multiple steps, because there are multiple pieces that contribute to this complexity. There's some information that they have to grab about, you know what actually matters from a Medicare, Medicaid use case that external and they have to come. Buy this information along with an interface for their clinician team, like clinical team internally, to give a give it some feedback. And so that's the thing that they're building out. So imagine, so it's a five step workflow that they're looking to build out in pre flow. There's many different things that contribute to complexity, and then there's an overall complexity score that they're building. And you can imagine this is like a very repeatable use case. Many people care about it. We just didn't focus on it because, you know, with a team of seven people, like, you know, doing HIPAA and, like, doing a bunch of these things, it's like just a lot of effort. But again, this is fully inbound, right? Like we, well, frankly, I ran into the, like, an engineer. Any lead at this company in person at an event, and then he wanted to see the demo, and then, yeah, looped us in. Okay,
for that particular so maybe the healthcare one is very easy. They've just started. They're building their first use case. But this problem probably resonate with might resonate quite a lot. They have clinical visits like notes, and they're trying to figure out what is the complexity of the case, because they can essentially like charge. Medicare, Medicaid, based on the complexity. And so they're trying to figure out what criteria that they can use to say this is low complexity, medium complexity, high complexity. Use case, the reason why refuel is actually important for them is because just using llms is not enough. They actually have to have an interface where it's again, it's multiple steps, because there are multiple pieces that contribute to this complexity. There's some information that they have to grab about, you know what actually matters from a Medicare, Medicaid use case that external and they have to come. Buy this information along with an interface for their clinician team, like clinical team internally, to give a give it some feedback. And so that's the thing that they're building out. So imagine, so it's a five step workflow that they're looking to build out in pre flow. There's many different things that contribute to complexity, and then there's an overall complexity score that they're building. And you can imagine this is like a very repeatable use case. Many people care about it. We just didn't focus on it because, you know, with a team of seven people, like, you know, doing HIPAA and, like, doing a bunch of these things, it's like just a lot of effort. But again, this is fully inbound, right? Like we, well, frankly, I ran into the, like, an engineer. Any lead at this company in person at an event, and then he wanted to see the demo, and then, yeah, looped us in. Okay,
22:46so that's pretty cool. Okay,
so that's pretty cool. Okay,
so that's pretty cool. Okay,
so that's pretty cool. Okay,
S Speaker 122:47that's interesting. So walk me through a few more use cases. I'll set up that. Let's set up that meeting. And then, actually, now that I think about a week, only half an hour, should be good enough for now
that's interesting. So walk me through a few more use cases. I'll set up that. Let's set up that meeting. And then, actually, now that I think about a week, only half an hour, should be good enough for now
that's interesting. So walk me through a few more use cases. I'll set up that. Let's set up that meeting. And then, actually, now that I think about a week, only half an hour, should be good enough for now
that's interesting. So walk me through a few more use cases. I'll set up that. Let's set up that meeting. And then, actually, now that I think about a week, only half an hour, should be good enough for now
23:01I can, yeah, we can do 830, or one,
I can, yeah, we can do 830, or one,
I can, yeah, we can do 830, or one,
I can, yeah, we can do 830, or one,
S Speaker 223:07both works for me. You should. I just. That time based on whatever works best. Thanks. Rishabh. Also,
both works for me. You should. I just. That time based on whatever works best. Thanks. Rishabh. Also,
both works for me. You should. I just. That time based on whatever works best. Thanks. Rishabh. Also,
both works for me. You should. I just. That time based on whatever works best. Thanks. Rishabh. Also,
23:17I want to set up like a pitch for our team.
I want to set up like a pitch for our team.
I want to set up like a pitch for our team.
I want to set up like a pitch for our team.
S Speaker 123:22Let me think through the schedule for when that'll work, and then I'll have Leilani and assistant send out.
Let me think through the schedule for when that'll work, and then I'll have Leilani and assistant send out.
Let me think through the schedule for when that'll work, and then I'll have Leilani and assistant send out.
Let me think through the schedule for when that'll work, and then I'll have Leilani and assistant send out.
S Speaker 223:31Does the team meet in person at all for those pitches? What would you prefer? That would
Does the team meet in person at all for those pitches? What would you prefer? That would
Does the team meet in person at all for those pitches? What would you prefer? That would
Does the team meet in person at all for those pitches? What would you prefer? That would
S Speaker 123:34be our team, as in split in San Diego and here? Okay, so when who runs the group? So let me see he was here this week. So. Let me say what, ideally, yes, we can do with, like, a large
be our team, as in split in San Diego and here? Okay, so when who runs the group? So let me see he was here this week. So. Let me say what, ideally, yes, we can do with, like, a large
be our team, as in split in San Diego and here? Okay, so when who runs the group? So let me see he was here this week. So. Let me say what, ideally, yes, we can do with, like, a large
be our team, as in split in San Diego and here? Okay, so when who runs the group? So let me see he was here this week. So. Let me say what, ideally, yes, we can do with, like, a large
23:49part of the team in person. Yeah,
part of the team in person. Yeah,
part of the team in person. Yeah,
part of the team in person. Yeah,
23:53that would be good, too. So let me figure that out. Okay,
that would be good, too. So let me figure that out. Okay,
that would be good, too. So let me figure that out. Okay,
that would be good, too. So let me figure that out. Okay,
S Speaker 223:55okay, I'm a big fan of IT person, and I'm happy to swing by the office. I don't think I can swing by the San Diego office anytime soon, but very often,
okay, I'm a big fan of IT person, and I'm happy to swing by the office. I don't think I can swing by the San Diego office anytime soon, but very often,
okay, I'm a big fan of IT person, and I'm happy to swing by the office. I don't think I can swing by the San Diego office anytime soon, but very often,
okay, I'm a big fan of IT person, and I'm happy to swing by the office. I don't think I can swing by the San Diego office anytime soon, but very often,
S Speaker 124:04so we can do it, maybe Santa Clara office, with a large number of people here, and then you can also,
so we can do it, maybe Santa Clara office, with a large number of people here, and then you can also,
so we can do it, maybe Santa Clara office, with a large number of people here, and then you can also,
so we can do it, maybe Santa Clara office, with a large number of people here, and then you can also,
24:14can you. Get that
S Speaker 224:17perfect cool I'll look forward to chatting more today. Thanks a lot both for the time it should
perfect cool I'll look forward to chatting more today. Thanks a lot both for the time it should
perfect cool I'll look forward to chatting more today. Thanks a lot both for the time it should
perfect cool I'll look forward to chatting more today. Thanks a lot both for the time it should