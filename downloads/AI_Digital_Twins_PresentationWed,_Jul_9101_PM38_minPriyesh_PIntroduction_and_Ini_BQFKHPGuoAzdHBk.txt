Meeting: AI Digital Twins Presentation
Wed, Jul 9
1:01 PM
38 min
Priyesh P
Introduction and Initial Greetings
URL: https://otter.ai/u/BQFKHPGuoAzdHBkJRLw9uDjVcNc
Downloaded: 2025-12-21T21:41:04.334382
Method: text_extraction
============================================================

0:01You go Hey, Hi, Michael, can you hear me? Yep.
You go Hey, Hi, Michael, can you hear me? Yep.
You go Hey, Hi, Michael, can you hear me? Yep.
You go Hey, Hi, Michael, can you hear me? Yep.
S Speaker 10:37Hey, Michael, how's it going? Okay? Great to be connected.
Hey, Michael, how's it going? Okay? Great to be connected.
Hey, Michael, how's it going? Okay? Great to be connected.
Hey, Michael, how's it going? Okay? Great to be connected.
0:42Sorry, perplexity.
S Speaker 10:44Comment, launch today. Oh, I didn't check that. What's the new product? About? What's the new update?
Comment, launch today. Oh, I didn't check that. What's the new product? About? What's the new update?
Comment, launch today. Oh, I didn't check that. What's the new product? About? What's the new update?
Comment, launch today. Oh, I didn't check that. What's the new product? About? What's the new update?
0:50Basically, it's a browser. Oh, right.
Basically, it's a browser. Oh, right.
Basically, it's a browser. Oh, right.
Basically, it's a browser. Oh, right.
0:54So it's kind of like operator,
So it's kind of like operator,
So it's kind of like operator,
So it's kind of like operator,
S Speaker 20:58so it's, it's interesting, because, like last week, what's it called? Warm wind dropped, yeah, system, and it's because I feel like the web browser entry point is a lot easier for consumers to stomach than replacing their operating system.
so it's, it's interesting, because, like last week, what's it called? Warm wind dropped, yeah, system, and it's because I feel like the web browser entry point is a lot easier for consumers to stomach than replacing their operating system.
so it's, it's interesting, because, like last week, what's it called? Warm wind dropped, yeah, system, and it's because I feel like the web browser entry point is a lot easier for consumers to stomach than replacing their operating system.
so it's, it's interesting, because, like last week, what's it called? Warm wind dropped, yeah, system, and it's because I feel like the web browser entry point is a lot easier for consumers to stomach than replacing their operating system.
S Speaker 11:17I know, I know it's going to be a race. Michael, we've been seeing quite a lot of companies trying to sort of get into computer use, mobile use and web browser use. I don't know how which one of these would win, but quite impressed with perplexity and their level of product velocity, I would say,
I know, I know it's going to be a race. Michael, we've been seeing quite a lot of companies trying to sort of get into computer use, mobile use and web browser use. I don't know how which one of these would win, but quite impressed with perplexity and their level of product velocity, I would say,
I know, I know it's going to be a race. Michael, we've been seeing quite a lot of companies trying to sort of get into computer use, mobile use and web browser use. I don't know how which one of these would win, but quite impressed with perplexity and their level of product velocity, I would say,
I know, I know it's going to be a race. Michael, we've been seeing quite a lot of companies trying to sort of get into computer use, mobile use and web browser use. I don't know how which one of these would win, but quite impressed with perplexity and their level of product velocity, I would say,
S Speaker 21:37Yeah, we're actually taking a slightly different track. So what's the most popular browser for us, for for locations,
Yeah, we're actually taking a slightly different track. So what's the most popular browser for us, for for locations,
Yeah, we're actually taking a slightly different track. So what's the most popular browser for us, for for locations,
Yeah, we're actually taking a slightly different track. So what's the most popular browser for us, for for locations,
1:48for locations as in as then, what exactly do you mean?
for locations as in as then, what exactly do you mean?
for locations as in as then, what exactly do you mean?
for locations as in as then, what exactly do you mean?
S Speaker 21:53Like places, Google Maps, yeah, yeah. But people don't think of it as a web browser, yeah, and so, but they'll install them on their phone anyway. And so I would love to see, like, the stats on, like, you know, where Chrome is and where where Google Maps is, because I feel like, you know, those are kind of like one of those things where it's a web browser, but people don't think of it as
Like places, Google Maps, yeah, yeah. But people don't think of it as a web browser, yeah, and so, but they'll install them on their phone anyway. And so I would love to see, like, the stats on, like, you know, where Chrome is and where where Google Maps is, because I feel like, you know, those are kind of like one of those things where it's a web browser, but people don't think of it as
Like places, Google Maps, yeah, yeah. But people don't think of it as a web browser, yeah, and so, but they'll install them on their phone anyway. And so I would love to see, like, the stats on, like, you know, where Chrome is and where where Google Maps is, because I feel like, you know, those are kind of like one of those things where it's a web browser, but people don't think of it as
Like places, Google Maps, yeah, yeah. But people don't think of it as a web browser, yeah, and so, but they'll install them on their phone anyway. And so I would love to see, like, the stats on, like, you know, where Chrome is and where where Google Maps is, because I feel like, you know, those are kind of like one of those things where it's a web browser, but people don't think of it as
S Speaker 12:21a web browser. Yeah, that's a pretty interesting thought. And actually, Google, if I'm not sure if you check, but Google launched a lot of natural language LLM features on Google Maps last week. I'm not sure if it is a broad rollout, but they are going that way, so it aligns with how you were thinking about them. Yeah,
a web browser. Yeah, that's a pretty interesting thought. And actually, Google, if I'm not sure if you check, but Google launched a lot of natural language LLM features on Google Maps last week. I'm not sure if it is a broad rollout, but they are going that way, so it aligns with how you were thinking about them. Yeah,
a web browser. Yeah, that's a pretty interesting thought. And actually, Google, if I'm not sure if you check, but Google launched a lot of natural language LLM features on Google Maps last week. I'm not sure if it is a broad rollout, but they are going that way, so it aligns with how you were thinking about them. Yeah,
a web browser. Yeah, that's a pretty interesting thought. And actually, Google, if I'm not sure if you check, but Google launched a lot of natural language LLM features on Google Maps last week. I'm not sure if it is a broad rollout, but they are going that way, so it aligns with how you were thinking about them. Yeah,
S Speaker 22:39we're taking a very similar approach to products. Yeah, oh,
we're taking a very similar approach to products. Yeah, oh,
we're taking a very similar approach to products. Yeah, oh,
we're taking a very similar approach to products. Yeah, oh,
2:43that's that's a great segue to enter into the conversation. Very smooth.
that's that's a great segue to enter into the conversation. Very smooth.
that's that's a great segue to enter into the conversation. Very smooth.
that's that's a great segue to enter into the conversation. Very smooth.
S Speaker 22:51So we just launched Curie shop, and we've been working with meta by dance to establish it, establish it as like, kind of what Google Maps was to the iPhone
So we just launched Curie shop, and we've been working with meta by dance to establish it, establish it as like, kind of what Google Maps was to the iPhone
So we just launched Curie shop, and we've been working with meta by dance to establish it, establish it as like, kind of what Google Maps was to the iPhone
So we just launched Curie shop, and we've been working with meta by dance to establish it, establish it as like, kind of what Google Maps was to the iPhone
3:02as yet another form of distribution for us.
as yet another form of distribution for us.
as yet another form of distribution for us.
as yet another form of distribution for us.
S Speaker 23:07But yeah, happy to kind of take a step back and do intros.
But yeah, happy to kind of take a step back and do intros.
But yeah, happy to kind of take a step back and do intros.
But yeah, happy to kind of take a step back and do intros.
S Speaker 25:07Yeah. So you see you mentioned like seed, have you invested as a lead in that space
Yeah. So you see you mentioned like seed, have you invested as a lead in that space
Yeah. So you see you mentioned like seed, have you invested as a lead in that space
Yeah. So you see you mentioned like seed, have you invested as a lead in that space
S Speaker 15:13before? So we do not lead. Most of our investments would be about 80% of our investments would be just a follow on check. We rarely lead rounds unless it's a highly strategical area for us. So I would say even here, we would be a follow on check.
before? So we do not lead. Most of our investments would be about 80% of our investments would be just a follow on check. We rarely lead rounds unless it's a highly strategical area for us. So I would say even here, we would be a follow on check.
before? So we do not lead. Most of our investments would be about 80% of our investments would be just a follow on check. We rarely lead rounds unless it's a highly strategical area for us. So I would say even here, we would be a follow on check.
before? So we do not lead. Most of our investments would be about 80% of our investments would be just a follow on check. We rarely lead rounds unless it's a highly strategical area for us. So I would say even here, we would be a follow on check.
S Speaker 25:32Okay, and which firms have you followed
Okay, and which firms have you followed
Okay, and which firms have you followed
Okay, and which firms have you followed
S Speaker 15:38almost all of the tier one funds. Our last investment was with the deal that I did was with Lux capital and general Catalyst. We have had almost all the tier one and recent Sequoia we have invested alongside them. We've invested alongside Venrock point 72
almost all of the tier one funds. Our last investment was with the deal that I did was with Lux capital and general Catalyst. We have had almost all the tier one and recent Sequoia we have invested alongside them. We've invested alongside Venrock point 72
almost all of the tier one funds. Our last investment was with the deal that I did was with Lux capital and general Catalyst. We have had almost all the tier one and recent Sequoia we have invested alongside them. We've invested alongside Venrock point 72
almost all of the tier one funds. Our last investment was with the deal that I did was with Lux capital and general Catalyst. We have had almost all the tier one and recent Sequoia we have invested alongside them. We've invested alongside Venrock point 72
5:57just thinking of all the recent investments we did,
just thinking of all the recent investments we did,
just thinking of all the recent investments we did,
just thinking of all the recent investments we did,
S Speaker 16:01some of the notable names maybe I can give you in AI is we in the foundation model layer. We have anthropic as our investment, hugging face in the tooling layer, scale AI, weights and biases, Cresta context. AI are some of our application level investments. Core weave in the silicon layer.
some of the notable names maybe I can give you in AI is we in the foundation model layer. We have anthropic as our investment, hugging face in the tooling layer, scale AI, weights and biases, Cresta context. AI are some of our application level investments. Core weave in the silicon layer.
some of the notable names maybe I can give you in AI is we in the foundation model layer. We have anthropic as our investment, hugging face in the tooling layer, scale AI, weights and biases, Cresta context. AI are some of our application level investments. Core weave in the silicon layer.
some of the notable names maybe I can give you in AI is we in the foundation model layer. We have anthropic as our investment, hugging face in the tooling layer, scale AI, weights and biases, Cresta context. AI are some of our application level investments. Core weave in the silicon layer.
S Speaker 26:28yeah, so happy to chat about Curie and what
yeah, so happy to chat about Curie and what
yeah, so happy to chat about Curie and what
yeah, so happy to chat about Curie and what
6:31we're working on. Absolutely would love to hear more.
we're working on. Absolutely would love to hear more.
we're working on. Absolutely would love to hear more.
we're working on. Absolutely would love to hear more.
6:38I guess, like a, you know, taking a step back,
I guess, like a, you know, taking a step back,
I guess, like a, you know, taking a step back,
I guess, like a, you know, taking a step back,
S Speaker 26:44just talking about the context of physical AI, you know, one of the problems that we been looking at is in the world of, like, AI hallucination. And I think this affects, like, nearly every device that Qualcomm sells into, right? Like, I feel like, if it's not addressed, then, you know, a lot of these models, you know, they work well under, you know, these nice commercials for comment. But I've been using perplexity and, and a lot of these tools for a while. And a lot of cases, they will completely make up things, and it requires a lot of human loop to basically double check to see whether things are right or wrong, and that puts a lot of tax on people, especially if they don't have a computer science degree. They haven't really figured that out. Know how to figure out what is false or true on their own, and so, so, yeah, we've sort of hit this like Blue Screen of Death era for AI or for AI hallucination. Every time that it happens, it erodes trust. You have to fall back to manual effort, and it could potentially cost you roughly 100,000 times more, and this directly affects Qualcomm's bottom line, because if, especially on edge, if computers are seen to be hallucinating, then that Basically caps the potential for these devices, and it would result in, like, lost, you know, not as many sales as you would normally would. So the way we kind of got into this is, you know, my co founder is ex Google Brain. I spent 15 years at Google, worked at Google X, TensorFlow, Everyday Robots, Google Shopping, you know, glass. It's basically like having, you know, a one of those valuable engineers that Mark Zuckerberg is always looking at as
just talking about the context of physical AI, you know, one of the problems that we been looking at is in the world of, like, AI hallucination. And I think this affects, like, nearly every device that Qualcomm sells into, right? Like, I feel like, if it's not addressed, then, you know, a lot of these models, you know, they work well under, you know, these nice commercials for comment. But I've been using perplexity and, and a lot of these tools for a while. And a lot of cases, they will completely make up things, and it requires a lot of human loop to basically double check to see whether things are right or wrong, and that puts a lot of tax on people, especially if they don't have a computer science degree. They haven't really figured that out. Know how to figure out what is false or true on their own, and so, so, yeah, we've sort of hit this like Blue Screen of Death era for AI or for AI hallucination. Every time that it happens, it erodes trust. You have to fall back to manual effort, and it could potentially cost you roughly 100,000 times more, and this directly affects Qualcomm's bottom line, because if, especially on edge, if computers are seen to be hallucinating, then that Basically caps the potential for these devices, and it would result in, like, lost, you know, not as many sales as you would normally would. So the way we kind of got into this is, you know, my co founder is ex Google Brain. I spent 15 years at Google, worked at Google X, TensorFlow, Everyday Robots, Google Shopping, you know, glass. It's basically like having, you know, a one of those valuable engineers that Mark Zuckerberg is always looking at as
just talking about the context of physical AI, you know, one of the problems that we been looking at is in the world of, like, AI hallucination. And I think this affects, like, nearly every device that Qualcomm sells into, right? Like, I feel like, if it's not addressed, then, you know, a lot of these models, you know, they work well under, you know, these nice commercials for comment. But I've been using perplexity and, and a lot of these tools for a while. And a lot of cases, they will completely make up things, and it requires a lot of human loop to basically double check to see whether things are right or wrong, and that puts a lot of tax on people, especially if they don't have a computer science degree. They haven't really figured that out. Know how to figure out what is false or true on their own, and so, so, yeah, we've sort of hit this like Blue Screen of Death era for AI or for AI hallucination. Every time that it happens, it erodes trust. You have to fall back to manual effort, and it could potentially cost you roughly 100,000 times more, and this directly affects Qualcomm's bottom line, because if, especially on edge, if computers are seen to be hallucinating, then that Basically caps the potential for these devices, and it would result in, like, lost, you know, not as many sales as you would normally would. So the way we kind of got into this is, you know, my co founder is ex Google Brain. I spent 15 years at Google, worked at Google X, TensorFlow, Everyday Robots, Google Shopping, you know, glass. It's basically like having, you know, a one of those valuable engineers that Mark Zuckerberg is always looking at as
just talking about the context of physical AI, you know, one of the problems that we been looking at is in the world of, like, AI hallucination. And I think this affects, like, nearly every device that Qualcomm sells into, right? Like, I feel like, if it's not addressed, then, you know, a lot of these models, you know, they work well under, you know, these nice commercials for comment. But I've been using perplexity and, and a lot of these tools for a while. And a lot of cases, they will completely make up things, and it requires a lot of human loop to basically double check to see whether things are right or wrong, and that puts a lot of tax on people, especially if they don't have a computer science degree. They haven't really figured that out. Know how to figure out what is false or true on their own, and so, so, yeah, we've sort of hit this like Blue Screen of Death era for AI or for AI hallucination. Every time that it happens, it erodes trust. You have to fall back to manual effort, and it could potentially cost you roughly 100,000 times more, and this directly affects Qualcomm's bottom line, because if, especially on edge, if computers are seen to be hallucinating, then that Basically caps the potential for these devices, and it would result in, like, lost, you know, not as many sales as you would normally would. So the way we kind of got into this is, you know, my co founder is ex Google Brain. I spent 15 years at Google, worked at Google X, TensorFlow, Everyday Robots, Google Shopping, you know, glass. It's basically like having, you know, a one of those valuable engineers that Mark Zuckerberg is always looking at as
8:54as as a potential investment, right? Like
as as a potential investment, right? Like
as as a potential investment, right? Like
as as a potential investment, right? Like
S Speaker 28:58and I came from Apple's platform Experience Team shipped Mac OS with the instead of the R D route with the entrepreneurial route. So raise 30 million across two companies, and then we were the first to basically bring natural language into code back in 2007 for mobile. So we were 21% of game uploads the iOS App Store. The product was called Game Salad, and internally, I was working on a version where you could take the instructions of chess or bow or baton and turn that into
and I came from Apple's platform Experience Team shipped Mac OS with the instead of the R D route with the entrepreneurial route. So raise 30 million across two companies, and then we were the first to basically bring natural language into code back in 2007 for mobile. So we were 21% of game uploads the iOS App Store. The product was called Game Salad, and internally, I was working on a version where you could take the instructions of chess or bow or baton and turn that into
and I came from Apple's platform Experience Team shipped Mac OS with the instead of the R D route with the entrepreneurial route. So raise 30 million across two companies, and then we were the first to basically bring natural language into code back in 2007 for mobile. So we were 21% of game uploads the iOS App Store. The product was called Game Salad, and internally, I was working on a version where you could take the instructions of chess or bow or baton and turn that into
and I came from Apple's platform Experience Team shipped Mac OS with the instead of the R D route with the entrepreneurial route. So raise 30 million across two companies, and then we were the first to basically bring natural language into code back in 2007 for mobile. So we were 21% of game uploads the iOS App Store. The product was called Game Salad, and internally, I was working on a version where you could take the instructions of chess or bow or baton and turn that into
9:39a game 10 years before opening i
a game 10 years before opening i
a game 10 years before opening i
a game 10 years before opening i
S Speaker 19:42You're from Apple, Android is from Google, but you're wearing a meta cap. How's that?
You're from Apple, Android is from Google, but you're wearing a meta cap. How's that?
You're from Apple, Android is from Google, but you're wearing a meta cap. How's that?
You're from Apple, Android is from Google, but you're wearing a meta cap. How's that?
10:01That's amazing. Tell me more about that.
That's amazing. Tell me more about that.
That's amazing. Tell me more about that.
That's amazing. Tell me more about that.
S Speaker 110:37and just One customer. So which customer? This is
and just One customer. So which customer? This is
and just One customer. So which customer? This is
and just One customer. So which customer? This is
11:54Like Android XR was represented.
Like Android XR was represented.
Like Android XR was represented.
Like Android XR was represented.
11:58Like bytedance was represented,
Like bytedance was represented,
Like bytedance was represented,
Like bytedance was represented,
S Speaker 212:02you know, meta Android, like, like, Apple vision Pro. So it was kind of like a who's who, where I had classmates pretty much working on every project and so, so, yeah, this, this was our kind of experience that was featured by Tim Cook last year for our work with stock X, which is the largest sneaker head marketplace or collectibles marketplace, and then, and then we just recently did announcement at awe,
you know, meta Android, like, like, Apple vision Pro. So it was kind of like a who's who, where I had classmates pretty much working on every project and so, so, yeah, this, this was our kind of experience that was featured by Tim Cook last year for our work with stock X, which is the largest sneaker head marketplace or collectibles marketplace, and then, and then we just recently did announcement at awe,
you know, meta Android, like, like, Apple vision Pro. So it was kind of like a who's who, where I had classmates pretty much working on every project and so, so, yeah, this, this was our kind of experience that was featured by Tim Cook last year for our work with stock X, which is the largest sneaker head marketplace or collectibles marketplace, and then, and then we just recently did announcement at awe,
you know, meta Android, like, like, Apple vision Pro. So it was kind of like a who's who, where I had classmates pretty much working on every project and so, so, yeah, this, this was our kind of experience that was featured by Tim Cook last year for our work with stock X, which is the largest sneaker head marketplace or collectibles marketplace, and then, and then we just recently did announcement at awe,
12:36for our work with by Chance,
for our work with by Chance,
for our work with by Chance,
for our work with by Chance,
S Speaker 212:41and they have like, 30 minutes of B roll that they just launched this week. So, so yeah, what we're working on is eliminating or mitigating hallucination in digital twins. So this is not language models. This is physical space and so a good keeping on the Google Maps analogy you wouldn't trust catch BT to give you turn bike interactions while driving right over Google Maps, yes, and the reason for that is that it doesn't have context, right, like, immediately, like When we ask, like, oh, how many outlets are in the Vatican? Like, it has no idea, and they'll ask you to upload photos. And so this is the core weakness of of language models, and this is why, like Mimi 10 and so many others are pushing for word models. But the problem with World models is the data set. So there is no image net for spatial 99% of training set are gaming data. So it's Space Marines and dragons. So it's basically garbage in, garbage out. Starting with a different data set is like starting a whole new company. And I think this is what, if you're a practitioner of AI, you understand bias, but if you're not, then you're like, oh, agents of the future, it's origin and and so, you know, what we're looking to do is, you know, for the same reasons why sensor data is considered like a higher form of evidence than hearsay in a court of law. Like, you know, photos are better than language because language can be intercepted, right? Like, just today, right?
and they have like, 30 minutes of B roll that they just launched this week. So, so yeah, what we're working on is eliminating or mitigating hallucination in digital twins. So this is not language models. This is physical space and so a good keeping on the Google Maps analogy you wouldn't trust catch BT to give you turn bike interactions while driving right over Google Maps, yes, and the reason for that is that it doesn't have context, right, like, immediately, like When we ask, like, oh, how many outlets are in the Vatican? Like, it has no idea, and they'll ask you to upload photos. And so this is the core weakness of of language models, and this is why, like Mimi 10 and so many others are pushing for word models. But the problem with World models is the data set. So there is no image net for spatial 99% of training set are gaming data. So it's Space Marines and dragons. So it's basically garbage in, garbage out. Starting with a different data set is like starting a whole new company. And I think this is what, if you're a practitioner of AI, you understand bias, but if you're not, then you're like, oh, agents of the future, it's origin and and so, you know, what we're looking to do is, you know, for the same reasons why sensor data is considered like a higher form of evidence than hearsay in a court of law. Like, you know, photos are better than language because language can be intercepted, right? Like, just today, right?
and they have like, 30 minutes of B roll that they just launched this week. So, so yeah, what we're working on is eliminating or mitigating hallucination in digital twins. So this is not language models. This is physical space and so a good keeping on the Google Maps analogy you wouldn't trust catch BT to give you turn bike interactions while driving right over Google Maps, yes, and the reason for that is that it doesn't have context, right, like, immediately, like When we ask, like, oh, how many outlets are in the Vatican? Like, it has no idea, and they'll ask you to upload photos. And so this is the core weakness of of language models, and this is why, like Mimi 10 and so many others are pushing for word models. But the problem with World models is the data set. So there is no image net for spatial 99% of training set are gaming data. So it's Space Marines and dragons. So it's basically garbage in, garbage out. Starting with a different data set is like starting a whole new company. And I think this is what, if you're a practitioner of AI, you understand bias, but if you're not, then you're like, oh, agents of the future, it's origin and and so, you know, what we're looking to do is, you know, for the same reasons why sensor data is considered like a higher form of evidence than hearsay in a court of law. Like, you know, photos are better than language because language can be intercepted, right? Like, just today, right?
and they have like, 30 minutes of B roll that they just launched this week. So, so yeah, what we're working on is eliminating or mitigating hallucination in digital twins. So this is not language models. This is physical space and so a good keeping on the Google Maps analogy you wouldn't trust catch BT to give you turn bike interactions while driving right over Google Maps, yes, and the reason for that is that it doesn't have context, right, like, immediately, like When we ask, like, oh, how many outlets are in the Vatican? Like, it has no idea, and they'll ask you to upload photos. And so this is the core weakness of of language models, and this is why, like Mimi 10 and so many others are pushing for word models. But the problem with World models is the data set. So there is no image net for spatial 99% of training set are gaming data. So it's Space Marines and dragons. So it's basically garbage in, garbage out. Starting with a different data set is like starting a whole new company. And I think this is what, if you're a practitioner of AI, you understand bias, but if you're not, then you're like, oh, agents of the future, it's origin and and so, you know, what we're looking to do is, you know, for the same reasons why sensor data is considered like a higher form of evidence than hearsay in a court of law. Like, you know, photos are better than language because language can be intercepted, right? Like, just today, right?
14:34You know, the CEO of
S Speaker 214:37X just left, and it's because their language on grok was pointing place, basically hallucinating, and so. So anything that is every everyone kind of questions the quality of Bucha Twitter data set and but if you, if you train directly off of sensor data, then you're much closer to a true answer than than not, right? So we're using deterministic efforts like math and physics to get to those predictable answers. And with that, we've built the largest data set of digital twins that are accurate in the world, and we have the fastest growing database. So we're currently digitizing about 300,000 products for stock x, which would easily give us and top Amazon's database. And in the quality of the data matters, right? Like, you know, we've, we've tested, we're pretty much benchmarking all of all of the latest three reconstruction models against against photos. The way they had ran is basically against other assets that either have been handmade or from scanned data. And the problem with that is that like well, if you just output your ground truth, then you get pretty much a similar answer. And so we have a much more rigorous way to determine which models are hallucinating and which are not. And so we have. We've housed all of this as Curie shop, which is and then we've also built not just a search engine, but
X just left, and it's because their language on grok was pointing place, basically hallucinating, and so. So anything that is every everyone kind of questions the quality of Bucha Twitter data set and but if you, if you train directly off of sensor data, then you're much closer to a true answer than than not, right? So we're using deterministic efforts like math and physics to get to those predictable answers. And with that, we've built the largest data set of digital twins that are accurate in the world, and we have the fastest growing database. So we're currently digitizing about 300,000 products for stock x, which would easily give us and top Amazon's database. And in the quality of the data matters, right? Like, you know, we've, we've tested, we're pretty much benchmarking all of all of the latest three reconstruction models against against photos. The way they had ran is basically against other assets that either have been handmade or from scanned data. And the problem with that is that like well, if you just output your ground truth, then you get pretty much a similar answer. And so we have a much more rigorous way to determine which models are hallucinating and which are not. And so we have. We've housed all of this as Curie shop, which is and then we've also built not just a search engine, but
X just left, and it's because their language on grok was pointing place, basically hallucinating, and so. So anything that is every everyone kind of questions the quality of Bucha Twitter data set and but if you, if you train directly off of sensor data, then you're much closer to a true answer than than not, right? So we're using deterministic efforts like math and physics to get to those predictable answers. And with that, we've built the largest data set of digital twins that are accurate in the world, and we have the fastest growing database. So we're currently digitizing about 300,000 products for stock x, which would easily give us and top Amazon's database. And in the quality of the data matters, right? Like, you know, we've, we've tested, we're pretty much benchmarking all of all of the latest three reconstruction models against against photos. The way they had ran is basically against other assets that either have been handmade or from scanned data. And the problem with that is that like well, if you just output your ground truth, then you get pretty much a similar answer. And so we have a much more rigorous way to determine which models are hallucinating and which are not. And so we have. We've housed all of this as Curie shop, which is and then we've also built not just a search engine, but
X just left, and it's because their language on grok was pointing place, basically hallucinating, and so. So anything that is every everyone kind of questions the quality of Bucha Twitter data set and but if you, if you train directly off of sensor data, then you're much closer to a true answer than than not, right? So we're using deterministic efforts like math and physics to get to those predictable answers. And with that, we've built the largest data set of digital twins that are accurate in the world, and we have the fastest growing database. So we're currently digitizing about 300,000 products for stock x, which would easily give us and top Amazon's database. And in the quality of the data matters, right? Like, you know, we've, we've tested, we're pretty much benchmarking all of all of the latest three reconstruction models against against photos. The way they had ran is basically against other assets that either have been handmade or from scanned data. And the problem with that is that like well, if you just output your ground truth, then you get pretty much a similar answer. And so we have a much more rigorous way to determine which models are hallucinating and which are not. And so we have. We've housed all of this as Curie shop, which is and then we've also built not just a search engine, but
16:14a language model. And
a language model. And
a language model. And
a language model. And
S Speaker 216:24a language model. We built a conversational system, right and and we've also built an MCP. And so instead of traditional search where, you know, you have to look at a million links and you know, AI gives you a similar answer, we've done the same thing for imagery set ahead to look at 100 different photos. Much, much of it's duplicated. Doesn't really give you a lot of context. We're AI generating twins of products, and this is probably the most rigorous form to be able to use, because people can directly identify products visually, right? So I think in the end of the day, we have a data set that is much better than you can get in warehouses by individual scans made people.
a language model. We built a conversational system, right and and we've also built an MCP. And so instead of traditional search where, you know, you have to look at a million links and you know, AI gives you a similar answer, we've done the same thing for imagery set ahead to look at 100 different photos. Much, much of it's duplicated. Doesn't really give you a lot of context. We're AI generating twins of products, and this is probably the most rigorous form to be able to use, because people can directly identify products visually, right? So I think in the end of the day, we have a data set that is much better than you can get in warehouses by individual scans made people.
a language model. We built a conversational system, right and and we've also built an MCP. And so instead of traditional search where, you know, you have to look at a million links and you know, AI gives you a similar answer, we've done the same thing for imagery set ahead to look at 100 different photos. Much, much of it's duplicated. Doesn't really give you a lot of context. We're AI generating twins of products, and this is probably the most rigorous form to be able to use, because people can directly identify products visually, right? So I think in the end of the day, we have a data set that is much better than you can get in warehouses by individual scans made people.
a language model. We built a conversational system, right and and we've also built an MCP. And so instead of traditional search where, you know, you have to look at a million links and you know, AI gives you a similar answer, we've done the same thing for imagery set ahead to look at 100 different photos. Much, much of it's duplicated. Doesn't really give you a lot of context. We're AI generating twins of products, and this is probably the most rigorous form to be able to use, because people can directly identify products visually, right? So I think in the end of the day, we have a data set that is much better than you can get in warehouses by individual scans made people.
17:16And it's always going to be more or less
And it's always going to be more or less
And it's always going to be more or less
And it's always going to be more or less
S Speaker 217:20the most realistic it can be based on what is this? What is the state of the art?
the most realistic it can be based on what is this? What is the state of the art?
the most realistic it can be based on what is this? What is the state of the art?
the most realistic it can be based on what is this? What is the state of the art?
S Speaker 117:25Right? Michael, a couple of questions here. So the digital twins certainly seem very realistic, like the outputs look amazing. Couple of questions. How much do you think the data set is transferable in terms of creating digital twins, or are you particularly focused? Let's say you have a large data set of sneakers from stock X, can you sort of replicate the same engine for a different kind of product, and can you replicate the same engine for a completely different industry, per se,
Right? Michael, a couple of questions here. So the digital twins certainly seem very realistic, like the outputs look amazing. Couple of questions. How much do you think the data set is transferable in terms of creating digital twins, or are you particularly focused? Let's say you have a large data set of sneakers from stock X, can you sort of replicate the same engine for a different kind of product, and can you replicate the same engine for a completely different industry, per se,
Right? Michael, a couple of questions here. So the digital twins certainly seem very realistic, like the outputs look amazing. Couple of questions. How much do you think the data set is transferable in terms of creating digital twins, or are you particularly focused? Let's say you have a large data set of sneakers from stock X, can you sort of replicate the same engine for a different kind of product, and can you replicate the same engine for a completely different industry, per se,
Right? Michael, a couple of questions here. So the digital twins certainly seem very realistic, like the outputs look amazing. Couple of questions. How much do you think the data set is transferable in terms of creating digital twins, or are you particularly focused? Let's say you have a large data set of sneakers from stock X, can you sort of replicate the same engine for a different kind of product, and can you replicate the same engine for a completely different industry, per se,
S Speaker 218:04yes and yes. So then the reason for that is that the technology we're using is completely agnostic. So it doesn't matter if you use it on robots or on on security cameras or on even even LiDAR, it is, effectively this computer vision is computer vision. It's, it's, it is independent of, you know, which, which hardware and vertical and because we're dealing with like, effectively light and shapes, as long as it exists in the physical world and light can bounce off of it,
yes and yes. So then the reason for that is that the technology we're using is completely agnostic. So it doesn't matter if you use it on robots or on on security cameras or on even even LiDAR, it is, effectively this computer vision is computer vision. It's, it's, it is independent of, you know, which, which hardware and vertical and because we're dealing with like, effectively light and shapes, as long as it exists in the physical world and light can bounce off of it,
yes and yes. So then the reason for that is that the technology we're using is completely agnostic. So it doesn't matter if you use it on robots or on on security cameras or on even even LiDAR, it is, effectively this computer vision is computer vision. It's, it's, it is independent of, you know, which, which hardware and vertical and because we're dealing with like, effectively light and shapes, as long as it exists in the physical world and light can bounce off of it,
yes and yes. So then the reason for that is that the technology we're using is completely agnostic. So it doesn't matter if you use it on robots or on on security cameras or on even even LiDAR, it is, effectively this computer vision is computer vision. It's, it's, it is independent of, you know, which, which hardware and vertical and because we're dealing with like, effectively light and shapes, as long as it exists in the physical world and light can bounce off of it,
18:45then it should work,
S Speaker 118:47right? And can you take me through a workflow of one of the clients working with you? Exactly, what do you supply? How do you create digital twins? What part of the workflows are owned by you? Things like that, yeah, 100%
right? And can you take me through a workflow of one of the clients working with you? Exactly, what do you supply? How do you create digital twins? What part of the workflows are owned by you? Things like that, yeah, 100%
right? And can you take me through a workflow of one of the clients working with you? Exactly, what do you supply? How do you create digital twins? What part of the workflows are owned by you? Things like that, yeah, 100%
right? And can you take me through a workflow of one of the clients working with you? Exactly, what do you supply? How do you create digital twins? What part of the workflows are owned by you? Things like that, yeah, 100%
S Speaker 218:59of the workflow is owned by us, and all the data is owned by us. So just kind of, kind of like Google Maps, on a percent of the data that's output on Google Maps that's generated from Google Street map to top down views are owned by Google. We're doing the same thing for our data set. So it's not Google is going around asking for permission from every architect in the world and saying, hey, you know, because you have, like, a sparsely populated map, like it just wouldn't
of the workflow is owned by us, and all the data is owned by us. So just kind of, kind of like Google Maps, on a percent of the data that's output on Google Maps that's generated from Google Street map to top down views are owned by Google. We're doing the same thing for our data set. So it's not Google is going around asking for permission from every architect in the world and saying, hey, you know, because you have, like, a sparsely populated map, like it just wouldn't
of the workflow is owned by us, and all the data is owned by us. So just kind of, kind of like Google Maps, on a percent of the data that's output on Google Maps that's generated from Google Street map to top down views are owned by Google. We're doing the same thing for our data set. So it's not Google is going around asking for permission from every architect in the world and saying, hey, you know, because you have, like, a sparsely populated map, like it just wouldn't
of the workflow is owned by us, and all the data is owned by us. So just kind of, kind of like Google Maps, on a percent of the data that's output on Google Maps that's generated from Google Street map to top down views are owned by Google. We're doing the same thing for our data set. So it's not Google is going around asking for permission from every architect in the world and saying, hey, you know, because you have, like, a sparsely populated map, like it just wouldn't
S Speaker 119:26work. Got it? Got it. And Michael, so why? Why? If would love to understand a little bit more about a technical architecture, but before that, why sort of keep yourself tied up in the entire product vertical? Why not go for a large world model, sort of simulation, robotics, foundation model, kind of thing. Why do something like a world slab?
work. Got it? Got it. And Michael, so why? Why? If would love to understand a little bit more about a technical architecture, but before that, why sort of keep yourself tied up in the entire product vertical? Why not go for a large world model, sort of simulation, robotics, foundation model, kind of thing. Why do something like a world slab?
work. Got it? Got it. And Michael, so why? Why? If would love to understand a little bit more about a technical architecture, but before that, why sort of keep yourself tied up in the entire product vertical? Why not go for a large world model, sort of simulation, robotics, foundation model, kind of thing. Why do something like a world slab?
work. Got it? Got it. And Michael, so why? Why? If would love to understand a little bit more about a technical architecture, but before that, why sort of keep yourself tied up in the entire product vertical? Why not go for a large world model, sort of simulation, robotics, foundation model, kind of thing. Why do something like a world slab?
19:55I guess the short answer is, I live in Seattle,
I guess the short answer is, I live in Seattle,
I guess the short answer is, I live in Seattle,
I guess the short answer is, I live in Seattle,
S Speaker 220:03you know, being in being in the bay, you have access to a multiplier of resources, and I think that being outside of the bay, then that kind of limits your ability to take on risk. And so we are basically cherry picking projects that we can launch to market a lot sooner as a forcing function. So quite evidence today, right? You have like Fei Fei Li. You have, you know, Ilia sutz For no product, right? You have the former CEO of OpenAI no product. You know, they have some team members. I don't even know what technology they have yet, but they probably like be half a decade away from monetization. And even then, world Labs is focusing on game data. And so the gulf between gaming data and physical data is actually quite wide. So so I think that by by being resourceful, focusing we've effectively taken on the strategy of geek seek where we can do a lot more and get to market a lot faster with limited resources, by basically as a forcing function of this limited resources, having to be very creative on and very opinionated on where we enter the market and so. So this is not like a hey, we're going to wave our hands, and ultimately, everything is going to be fixed type argument. This is a okay, we did our homework. We've talked to everybody. We know where the pain points are, investors. Sorry, a lot of the people who have invested have been ourselves. They've been able to do the due diligence, as opposed to, like, following the latest trends and and following the latest like, kind of TED speaker, um, and, and kind of trying to throw money at them and hoping, hoping that they will generate any type of return. I feel like, I don't know if that is like a satisfactory answer, but you know, you and I know that, like the people who build these projects don't represent the people who get funded,
you know, being in being in the bay, you have access to a multiplier of resources, and I think that being outside of the bay, then that kind of limits your ability to take on risk. And so we are basically cherry picking projects that we can launch to market a lot sooner as a forcing function. So quite evidence today, right? You have like Fei Fei Li. You have, you know, Ilia sutz For no product, right? You have the former CEO of OpenAI no product. You know, they have some team members. I don't even know what technology they have yet, but they probably like be half a decade away from monetization. And even then, world Labs is focusing on game data. And so the gulf between gaming data and physical data is actually quite wide. So so I think that by by being resourceful, focusing we've effectively taken on the strategy of geek seek where we can do a lot more and get to market a lot faster with limited resources, by basically as a forcing function of this limited resources, having to be very creative on and very opinionated on where we enter the market and so. So this is not like a hey, we're going to wave our hands, and ultimately, everything is going to be fixed type argument. This is a okay, we did our homework. We've talked to everybody. We know where the pain points are, investors. Sorry, a lot of the people who have invested have been ourselves. They've been able to do the due diligence, as opposed to, like, following the latest trends and and following the latest like, kind of TED speaker, um, and, and kind of trying to throw money at them and hoping, hoping that they will generate any type of return. I feel like, I don't know if that is like a satisfactory answer, but you know, you and I know that, like the people who build these projects don't represent the people who get funded,
you know, being in being in the bay, you have access to a multiplier of resources, and I think that being outside of the bay, then that kind of limits your ability to take on risk. And so we are basically cherry picking projects that we can launch to market a lot sooner as a forcing function. So quite evidence today, right? You have like Fei Fei Li. You have, you know, Ilia sutz For no product, right? You have the former CEO of OpenAI no product. You know, they have some team members. I don't even know what technology they have yet, but they probably like be half a decade away from monetization. And even then, world Labs is focusing on game data. And so the gulf between gaming data and physical data is actually quite wide. So so I think that by by being resourceful, focusing we've effectively taken on the strategy of geek seek where we can do a lot more and get to market a lot faster with limited resources, by basically as a forcing function of this limited resources, having to be very creative on and very opinionated on where we enter the market and so. So this is not like a hey, we're going to wave our hands, and ultimately, everything is going to be fixed type argument. This is a okay, we did our homework. We've talked to everybody. We know where the pain points are, investors. Sorry, a lot of the people who have invested have been ourselves. They've been able to do the due diligence, as opposed to, like, following the latest trends and and following the latest like, kind of TED speaker, um, and, and kind of trying to throw money at them and hoping, hoping that they will generate any type of return. I feel like, I don't know if that is like a satisfactory answer, but you know, you and I know that, like the people who build these projects don't represent the people who get funded,
you know, being in being in the bay, you have access to a multiplier of resources, and I think that being outside of the bay, then that kind of limits your ability to take on risk. And so we are basically cherry picking projects that we can launch to market a lot sooner as a forcing function. So quite evidence today, right? You have like Fei Fei Li. You have, you know, Ilia sutz For no product, right? You have the former CEO of OpenAI no product. You know, they have some team members. I don't even know what technology they have yet, but they probably like be half a decade away from monetization. And even then, world Labs is focusing on game data. And so the gulf between gaming data and physical data is actually quite wide. So so I think that by by being resourceful, focusing we've effectively taken on the strategy of geek seek where we can do a lot more and get to market a lot faster with limited resources, by basically as a forcing function of this limited resources, having to be very creative on and very opinionated on where we enter the market and so. So this is not like a hey, we're going to wave our hands, and ultimately, everything is going to be fixed type argument. This is a okay, we did our homework. We've talked to everybody. We know where the pain points are, investors. Sorry, a lot of the people who have invested have been ourselves. They've been able to do the due diligence, as opposed to, like, following the latest trends and and following the latest like, kind of TED speaker, um, and, and kind of trying to throw money at them and hoping, hoping that they will generate any type of return. I feel like, I don't know if that is like a satisfactory answer, but you know, you and I know that, like the people who build these projects don't represent the people who get funded,
S Speaker 122:19that's that's fair, Michael, I understand that in terms of the business model you've mentioned a few partnerships, how are you pricing the solution? How is the traction today?
that's that's fair, Michael, I understand that in terms of the business model you've mentioned a few partnerships, how are you pricing the solution? How is the traction today?
that's that's fair, Michael, I understand that in terms of the business model you've mentioned a few partnerships, how are you pricing the solution? How is the traction today?
that's that's fair, Michael, I understand that in terms of the business model you've mentioned a few partnerships, how are you pricing the solution? How is the traction today?
S Speaker 124:40Great and Michael, when, when you sort of say that you integrate the platform, on solid solution, on some of these platforms, to what depth of integration are you talking? You sort of take your UX onto the platform, would you just plug in the generated twins?
Great and Michael, when, when you sort of say that you integrate the platform, on solid solution, on some of these platforms, to what depth of integration are you talking? You sort of take your UX onto the platform, would you just plug in the generated twins?
Great and Michael, when, when you sort of say that you integrate the platform, on solid solution, on some of these platforms, to what depth of integration are you talking? You sort of take your UX onto the platform, would you just plug in the generated twins?
Great and Michael, when, when you sort of say that you integrate the platform, on solid solution, on some of these platforms, to what depth of integration are you talking? You sort of take your UX onto the platform, would you just plug in the generated twins?
S Speaker 225:01Yeah, yeah. So you know how, like Google Maps integrates with Uber door, dash, Yelp, Zillow,
Yeah, yeah. So you know how, like Google Maps integrates with Uber door, dash, Yelp, Zillow,
Yeah, yeah. So you know how, like Google Maps integrates with Uber door, dash, Yelp, Zillow,
Yeah, yeah. So you know how, like Google Maps integrates with Uber door, dash, Yelp, Zillow,
25:08like apartments.com,
S Speaker 225:12you know, like any, any type of location based information is served via component, yeah? So we're effectively
you know, like any, any type of location based information is served via component, yeah? So we're effectively
you know, like any, any type of location based information is served via component, yeah? So we're effectively
you know, like any, any type of location based information is served via component, yeah? So we're effectively
25:22augmenting anywhere where you see
augmenting anywhere where you see
augmenting anywhere where you see
augmenting anywhere where you see
S Speaker 125:28very interesting and Michael, so what's the traction like today?
very interesting and Michael, so what's the traction like today?
very interesting and Michael, so what's the traction like today?
very interesting and Michael, so what's the traction like today?
S Speaker 225:34So yeah, our biggest customer by far is with meta, and they take up pretty much most of our time, but we're starting to starting to get more and more business from bytedance, yeah. And so the latest conversations are about integrating directly with Tiktok shop. This would break basically. First would be to replace the galleries, so right now they show static photo. This would effectively replace it with an interactive view of each product. But then that leads us into a land and expand scenario where we can enable, you know, virtual panning shots, virtual unboxing, virtual hauls, like all the types of videos that are typically shown on a Tiktok video for talking about and then you can also do like kind of mirrors and try on so. And the reason why this is important is that this is data that people don't know. Most of this is according to sockets. Most of the sales of a product is at the drop at the drop, like basically at the at launch. So a lot of products are like Apple, it's a hit based business. Most of the sales are upfront or pre sales, right? Like this with the switch. And so the problem is that influencer has physical access to anything, and you have to wait six months embargo. So you're basically risking a leak six months before your launch to be able to coordinate this archaic method of distributing information. What can be done is that say, Hey, you pick a product, and the moment in which you want to announce it to the world is the moment in which you release it. Influencers and because this modernized system, like your your movie system, right? Movies are no longer, people no longer send reels of film over to you, so your, your cinema works, right? Yeah, it's all done digitally over fiber, so we can do the same thing for these products, where everyone can start reviewing it all at the same time. And if you wanted to make even make it even more realistic, you can do a generative pass to make it look like indistinguishable from your physical if it was taken from a physical camera,
So yeah, our biggest customer by far is with meta, and they take up pretty much most of our time, but we're starting to starting to get more and more business from bytedance, yeah. And so the latest conversations are about integrating directly with Tiktok shop. This would break basically. First would be to replace the galleries, so right now they show static photo. This would effectively replace it with an interactive view of each product. But then that leads us into a land and expand scenario where we can enable, you know, virtual panning shots, virtual unboxing, virtual hauls, like all the types of videos that are typically shown on a Tiktok video for talking about and then you can also do like kind of mirrors and try on so. And the reason why this is important is that this is data that people don't know. Most of this is according to sockets. Most of the sales of a product is at the drop at the drop, like basically at the at launch. So a lot of products are like Apple, it's a hit based business. Most of the sales are upfront or pre sales, right? Like this with the switch. And so the problem is that influencer has physical access to anything, and you have to wait six months embargo. So you're basically risking a leak six months before your launch to be able to coordinate this archaic method of distributing information. What can be done is that say, Hey, you pick a product, and the moment in which you want to announce it to the world is the moment in which you release it. Influencers and because this modernized system, like your your movie system, right? Movies are no longer, people no longer send reels of film over to you, so your, your cinema works, right? Yeah, it's all done digitally over fiber, so we can do the same thing for these products, where everyone can start reviewing it all at the same time. And if you wanted to make even make it even more realistic, you can do a generative pass to make it look like indistinguishable from your physical if it was taken from a physical camera,
So yeah, our biggest customer by far is with meta, and they take up pretty much most of our time, but we're starting to starting to get more and more business from bytedance, yeah. And so the latest conversations are about integrating directly with Tiktok shop. This would break basically. First would be to replace the galleries, so right now they show static photo. This would effectively replace it with an interactive view of each product. But then that leads us into a land and expand scenario where we can enable, you know, virtual panning shots, virtual unboxing, virtual hauls, like all the types of videos that are typically shown on a Tiktok video for talking about and then you can also do like kind of mirrors and try on so. And the reason why this is important is that this is data that people don't know. Most of this is according to sockets. Most of the sales of a product is at the drop at the drop, like basically at the at launch. So a lot of products are like Apple, it's a hit based business. Most of the sales are upfront or pre sales, right? Like this with the switch. And so the problem is that influencer has physical access to anything, and you have to wait six months embargo. So you're basically risking a leak six months before your launch to be able to coordinate this archaic method of distributing information. What can be done is that say, Hey, you pick a product, and the moment in which you want to announce it to the world is the moment in which you release it. Influencers and because this modernized system, like your your movie system, right? Movies are no longer, people no longer send reels of film over to you, so your, your cinema works, right? Yeah, it's all done digitally over fiber, so we can do the same thing for these products, where everyone can start reviewing it all at the same time. And if you wanted to make even make it even more realistic, you can do a generative pass to make it look like indistinguishable from your physical if it was taken from a physical camera,
So yeah, our biggest customer by far is with meta, and they take up pretty much most of our time, but we're starting to starting to get more and more business from bytedance, yeah. And so the latest conversations are about integrating directly with Tiktok shop. This would break basically. First would be to replace the galleries, so right now they show static photo. This would effectively replace it with an interactive view of each product. But then that leads us into a land and expand scenario where we can enable, you know, virtual panning shots, virtual unboxing, virtual hauls, like all the types of videos that are typically shown on a Tiktok video for talking about and then you can also do like kind of mirrors and try on so. And the reason why this is important is that this is data that people don't know. Most of this is according to sockets. Most of the sales of a product is at the drop at the drop, like basically at the at launch. So a lot of products are like Apple, it's a hit based business. Most of the sales are upfront or pre sales, right? Like this with the switch. And so the problem is that influencer has physical access to anything, and you have to wait six months embargo. So you're basically risking a leak six months before your launch to be able to coordinate this archaic method of distributing information. What can be done is that say, Hey, you pick a product, and the moment in which you want to announce it to the world is the moment in which you release it. Influencers and because this modernized system, like your your movie system, right? Movies are no longer, people no longer send reels of film over to you, so your, your cinema works, right? Yeah, it's all done digitally over fiber, so we can do the same thing for these products, where everyone can start reviewing it all at the same time. And if you wanted to make even make it even more realistic, you can do a generative pass to make it look like indistinguishable from your physical if it was taken from a physical camera,
28:36would say, for and we're still
would say, for and we're still
would say, for and we're still
would say, for and we're still
S Speaker 230:25innovation space is not done yet. It's not fully baked, right? So like trilinear splats, splats and or like trying to linear voxel rendering,
innovation space is not done yet. It's not fully baked, right? So like trilinear splats, splats and or like trying to linear voxel rendering,
innovation space is not done yet. It's not fully baked, right? So like trilinear splats, splats and or like trying to linear voxel rendering,
innovation space is not done yet. It's not fully baked, right? So like trilinear splats, splats and or like trying to linear voxel rendering,
30:37are taking off, and then you also have
are taking off, and then you also have
are taking off, and then you also have
are taking off, and then you also have
S Speaker 230:42splats. So I said there hasn't been, like, a fully solved system yet. We are tracking it, but like you definitely want to use whatever is the
splats. So I said there hasn't been, like, a fully solved system yet. We are tracking it, but like you definitely want to use whatever is the
splats. So I said there hasn't been, like, a fully solved system yet. We are tracking it, but like you definitely want to use whatever is the
splats. So I said there hasn't been, like, a fully solved system yet. We are tracking it, but like you definitely want to use whatever is the
30:54winner at the end of the day.
winner at the end of the day.
winner at the end of the day.
winner at the end of the day.
S Speaker 230:57I so if I don't know if that answer your answers your questions
I so if I don't know if that answer your answers your questions
I so if I don't know if that answer your answers your questions
I so if I don't know if that answer your answers your questions
S Speaker 231:08before? Yes, other three generative companies have raised roughly about 5 million, and we in the most recent raise by a three year construction company has been the 20 million phase. So ultimately it will be set by the fund. It will be set by the
before? Yes, other three generative companies have raised roughly about 5 million, and we in the most recent raise by a three year construction company has been the 20 million phase. So ultimately it will be set by the fund. It will be set by the
before? Yes, other three generative companies have raised roughly about 5 million, and we in the most recent raise by a three year construction company has been the 20 million phase. So ultimately it will be set by the fund. It will be set by the
before? Yes, other three generative companies have raised roughly about 5 million, and we in the most recent raise by a three year construction company has been the 20 million phase. So ultimately it will be set by the fund. It will be set by the
S Speaker 131:27Yeah, and it could be anywhere between five to 20. Is roughly what maybe you think this would based
Yeah, and it could be anywhere between five to 20. Is roughly what maybe you think this would based
Yeah, and it could be anywhere between five to 20. Is roughly what maybe you think this would based
Yeah, and it could be anywhere between five to 20. Is roughly what maybe you think this would based
S Speaker 231:33on, based on what has raised in the last
on, based on what has raised in the last
on, based on what has raised in the last
on, based on what has raised in the last
S Speaker 131:37two years. Got it, got it. And when did you start the company? Michael, and how many members are in the team I many
two years. Got it, got it. And when did you start the company? Michael, and how many members are in the team I many
two years. Got it, got it. And when did you start the company? Michael, and how many members are in the team I many
two years. Got it, got it. And when did you start the company? Michael, and how many members are in the team I many
S Speaker 231:43members are on the team? So there's five of us. So I'm starting the company right beginning of the pandemic. But during the pandemic, we pivoted from a system that can basically be a face ID for our products. Which do you know how face ID works?
members are on the team? So there's five of us. So I'm starting the company right beginning of the pandemic. But during the pandemic, we pivoted from a system that can basically be a face ID for our products. Which do you know how face ID works?
members are on the team? So there's five of us. So I'm starting the company right beginning of the pandemic. But during the pandemic, we pivoted from a system that can basically be a face ID for our products. Which do you know how face ID works?
members are on the team? So there's five of us. So I'm starting the company right beginning of the pandemic. But during the pandemic, we pivoted from a system that can basically be a face ID for our products. Which do you know how face ID works?
S Speaker 131:59Yeah. I mean, on top of it, maybe I do, yeah? So when
Yeah. I mean, on top of it, maybe I do, yeah? So when
Yeah. I mean, on top of it, maybe I do, yeah? So when
Yeah. I mean, on top of it, maybe I do, yeah? So when
S Speaker 232:03you first, when you first train it, you're building a high quality, free reconstruction of your face, yeah, so what we did is we actually pitched the apple Intelligence Team like right before the pandemic, and that's Imagine if you could face ID everything in the room, right? So yeah,
you first, when you first train it, you're building a high quality, free reconstruction of your face, yeah, so what we did is we actually pitched the apple Intelligence Team like right before the pandemic, and that's Imagine if you could face ID everything in the room, right? So yeah,
you first, when you first train it, you're building a high quality, free reconstruction of your face, yeah, so what we did is we actually pitched the apple Intelligence Team like right before the pandemic, and that's Imagine if you could face ID everything in the room, right? So yeah,
you first, when you first train it, you're building a high quality, free reconstruction of your face, yeah, so what we did is we actually pitched the apple Intelligence Team like right before the pandemic, and that's Imagine if you could face ID everything in the room, right? So yeah,
32:23let me pull up this video. This is kind
let me pull up this video. This is kind
let me pull up this video. This is kind
let me pull up this video. This is kind
S Speaker 232:29of where we got started. And the reason I didn't move forward is that you had to build a high quality 3d digital twin of everything in the world. We could prototype this because Apple releases a three different twin of everything that started over
of where we got started. And the reason I didn't move forward is that you had to build a high quality 3d digital twin of everything in the world. We could prototype this because Apple releases a three different twin of everything that started over
of where we got started. And the reason I didn't move forward is that you had to build a high quality 3d digital twin of everything in the world. We could prototype this because Apple releases a three different twin of everything that started over
of where we got started. And the reason I didn't move forward is that you had to build a high quality 3d digital twin of everything in the world. We could prototype this because Apple releases a three different twin of everything that started over
S Speaker 232:51again, that other thing that it sells, and then we were able to train a model that recognizes all the products in the
again, that other thing that it sells, and then we were able to train a model that recognizes all the products in the
again, that other thing that it sells, and then we were able to train a model that recognizes all the products in the
again, that other thing that it sells, and then we were able to train a model that recognizes all the products in the
S Speaker 233:04yeah. So now we solve that problem, and always come back to it is we basically split the product in half, and we now have the ability to recognize any shape or sort of build, reconstruct any shape from photos.
yeah. So now we solve that problem, and always come back to it is we basically split the product in half, and we now have the ability to recognize any shape or sort of build, reconstruct any shape from photos.
yeah. So now we solve that problem, and always come back to it is we basically split the product in half, and we now have the ability to recognize any shape or sort of build, reconstruct any shape from photos.
yeah. So now we solve that problem, and always come back to it is we basically split the product in half, and we now have the ability to recognize any shape or sort of build, reconstruct any shape from photos.
S Speaker 133:20Well, this has been interesting conversation. Michael also fits our thesis in the areas we like to look at. So I'd love to keep the conversation going. Would appreciate can send some more materials over for me to take a look. And then in this case, Michael, if we do proceed, it will be a follow on check. So keep me posted on how the round evolves and when you have a lead in sight, and we can continue some more discussions. I can loop in few more members of my team, and we can continue our technical
Well, this has been interesting conversation. Michael also fits our thesis in the areas we like to look at. So I'd love to keep the conversation going. Would appreciate can send some more materials over for me to take a look. And then in this case, Michael, if we do proceed, it will be a follow on check. So keep me posted on how the round evolves and when you have a lead in sight, and we can continue some more discussions. I can loop in few more members of my team, and we can continue our technical
Well, this has been interesting conversation. Michael also fits our thesis in the areas we like to look at. So I'd love to keep the conversation going. Would appreciate can send some more materials over for me to take a look. And then in this case, Michael, if we do proceed, it will be a follow on check. So keep me posted on how the round evolves and when you have a lead in sight, and we can continue some more discussions. I can loop in few more members of my team, and we can continue our technical
Well, this has been interesting conversation. Michael also fits our thesis in the areas we like to look at. So I'd love to keep the conversation going. Would appreciate can send some more materials over for me to take a look. And then in this case, Michael, if we do proceed, it will be a follow on check. So keep me posted on how the round evolves and when you have a lead in sight, and we can continue some more discussions. I can loop in few more members of my team, and we can continue our technical
33:57a meeting between your engineering team and my co founder?
a meeting between your engineering team and my co founder?
a meeting between your engineering team and my co founder?
a meeting between your engineering team and my co founder?
S Speaker 133:59I will do a little bit more research and get back to that. I'll also have to sort of identify who will be the right people inside at Qualcomm to have that conversation. So let me do a little bit more research. There. We have a business development person in the team who looks at both internal BD within Qualcomm and external BD, so and to find the right stakeholders at Qualcomm and then get that meeting going. Okay.
I will do a little bit more research and get back to that. I'll also have to sort of identify who will be the right people inside at Qualcomm to have that conversation. So let me do a little bit more research. There. We have a business development person in the team who looks at both internal BD within Qualcomm and external BD, so and to find the right stakeholders at Qualcomm and then get that meeting going. Okay.
I will do a little bit more research and get back to that. I'll also have to sort of identify who will be the right people inside at Qualcomm to have that conversation. So let me do a little bit more research. There. We have a business development person in the team who looks at both internal BD within Qualcomm and external BD, so and to find the right stakeholders at Qualcomm and then get that meeting going. Okay.
I will do a little bit more research and get back to that. I'll also have to sort of identify who will be the right people inside at Qualcomm to have that conversation. So let me do a little bit more research. There. We have a business development person in the team who looks at both internal BD within Qualcomm and external BD, so and to find the right stakeholders at Qualcomm and then get that meeting going. Okay.
34:25Are you familiar with
Are you familiar with
Are you familiar with
Are you familiar with
S Speaker 234:32to Paula? Yes, yes. I spoke to him yesterday. Okay.
to Paula? Yes, yes. I spoke to him yesterday. Okay.
to Paula? Yes, yes. I spoke to him yesterday. Okay.
to Paula? Yes, yes. I spoke to him yesterday. Okay.
34:39How did the conversation go?
How did the conversation go?
How did the conversation go?
How did the conversation go?