Meeting: Hydra Host Pitch
Mon, Aug 5, 2024
11:34 AM
39 min
Priyesh P
Investing in AI and deep tech with Qualc
URL: https://otter.ai/u/GQHv2QTEY0bOw494DCEG8yvMM-I
Downloaded: 2025-12-22T14:57:50.683481
Method: text_extraction
============================================================

S Speaker 10:01Leaving in person thing. So I'm driving away from my house right now.
Leaving in person thing. So I'm driving away from my house right now.
Leaving in person thing. So I'm driving away from my house right now.
Leaving in person thing. So I'm driving away from my house right now.
S Speaker 10:10Boulder. I used to live San Francisco. Okay, yeah, we got there for like 1212, years, and then I went to Boulder.
Boulder. I used to live San Francisco. Okay, yeah, we got there for like 1212, years, and then I went to Boulder.
Boulder. I used to live San Francisco. Okay, yeah, we got there for like 1212, years, and then I went to Boulder.
Boulder. I used to live San Francisco. Okay, yeah, we got there for like 1212, years, and then I went to Boulder.
S Speaker 10:21Yeah, yeah. Wanted to go to a place that was a lot less locked down, yeah. So, so the boulder was where I landed, and built the house on here on some land, and then start building houses for my friends. So, so we have a little commune going. Oh, nice.
Yeah, yeah. Wanted to go to a place that was a lot less locked down, yeah. So, so the boulder was where I landed, and built the house on here on some land, and then start building houses for my friends. So, so we have a little commune going. Oh, nice.
Yeah, yeah. Wanted to go to a place that was a lot less locked down, yeah. So, so the boulder was where I landed, and built the house on here on some land, and then start building houses for my friends. So, so we have a little commune going. Oh, nice.
Yeah, yeah. Wanted to go to a place that was a lot less locked down, yeah. So, so the boulder was where I landed, and built the house on here on some land, and then start building houses for my friends. So, so we have a little commune going. Oh, nice.
S Speaker 21:02one, wanted to just get chat with you, introduce us, and learn more about what you're up to. So maybe we can do, you know, I can do a quick round of, I mean, we can do interactions, and then tell you about Qualcomm ventures. And then
one, wanted to just get chat with you, introduce us, and learn more about what you're up to. So maybe we can do, you know, I can do a quick round of, I mean, we can do interactions, and then tell you about Qualcomm ventures. And then
one, wanted to just get chat with you, introduce us, and learn more about what you're up to. So maybe we can do, you know, I can do a quick round of, I mean, we can do interactions, and then tell you about Qualcomm ventures. And then
one, wanted to just get chat with you, introduce us, and learn more about what you're up to. So maybe we can do, you know, I can do a quick round of, I mean, we can do interactions, and then tell you about Qualcomm ventures. And then
S Speaker 21:29learn more about you as well. So you know. So my background is in engineering product.
learn more about you as well. So you know. So my background is in engineering product.
learn more about you as well. So you know. So my background is in engineering product.
learn more about you as well. So you know. So my background is in engineering product.
1:40Used to run a few businesses at Qualcomm and then
S Speaker 21:44at Qualcomm ventures. Over the last seven years, I've been investing in AI and
at Qualcomm ventures. Over the last seven years, I've been investing in AI and
at Qualcomm ventures. Over the last seven years, I've been investing in AI and
at Qualcomm ventures. Over the last seven years, I've been investing in AI and
S Speaker 21:52Qualcomm ventures. As you know, is the strategic investment on for Qualcomm. So we invest across areas that are strategically relevant to Qualcomm. So you know, this is everything from mobile to cloud to automotive to IoT and networking and voice music. That's our PCs. So I mean, our platform, we ship over a billion chips every year, and I'd like go into all of these
Qualcomm ventures. As you know, is the strategic investment on for Qualcomm. So we invest across areas that are strategically relevant to Qualcomm. So you know, this is everything from mobile to cloud to automotive to IoT and networking and voice music. That's our PCs. So I mean, our platform, we ship over a billion chips every year, and I'd like go into all of these
Qualcomm ventures. As you know, is the strategic investment on for Qualcomm. So we invest across areas that are strategically relevant to Qualcomm. So you know, this is everything from mobile to cloud to automotive to IoT and networking and voice music. That's our PCs. So I mean, our platform, we ship over a billion chips every year, and I'd like go into all of these
Qualcomm ventures. As you know, is the strategic investment on for Qualcomm. So we invest across areas that are strategically relevant to Qualcomm. So you know, this is everything from mobile to cloud to automotive to IoT and networking and voice music. That's our PCs. So I mean, our platform, we ship over a billion chips every year, and I'd like go into all of these
S Speaker 22:31And this is compute and connectivity both. So our investment mandate spans across and then even though, you know, we're a hardware company. But most of our investments, I would say, are mostly skewed towards software, because we do hardware well. We do some investments in hardware as
And this is compute and connectivity both. So our investment mandate spans across and then even though, you know, we're a hardware company. But most of our investments, I would say, are mostly skewed towards software, because we do hardware well. We do some investments in hardware as
And this is compute and connectivity both. So our investment mandate spans across and then even though, you know, we're a hardware company. But most of our investments, I would say, are mostly skewed towards software, because we do hardware well. We do some investments in hardware as
And this is compute and connectivity both. So our investment mandate spans across and then even though, you know, we're a hardware company. But most of our investments, I would say, are mostly skewed towards software, because we do hardware well. We do some investments in hardware as
S Speaker 22:54from a fund perspective, it's off the balance sheet. We invest one $50 million every year. And we stage agnostic for the most part. CDC tends to be our sweet spot, but we do other stages as well. And check sizes are anywhere from $2 million to 10 million depending on the ground. Yeah. Okay, yeah. Let me know if you have any other questions happy to answer. Okay, so,
from a fund perspective, it's off the balance sheet. We invest one $50 million every year. And we stage agnostic for the most part. CDC tends to be our sweet spot, but we do other stages as well. And check sizes are anywhere from $2 million to 10 million depending on the ground. Yeah. Okay, yeah. Let me know if you have any other questions happy to answer. Okay, so,
from a fund perspective, it's off the balance sheet. We invest one $50 million every year. And we stage agnostic for the most part. CDC tends to be our sweet spot, but we do other stages as well. And check sizes are anywhere from $2 million to 10 million depending on the ground. Yeah. Okay, yeah. Let me know if you have any other questions happy to answer. Okay, so,
from a fund perspective, it's off the balance sheet. We invest one $50 million every year. And we stage agnostic for the most part. CDC tends to be our sweet spot, but we do other stages as well. And check sizes are anywhere from $2 million to 10 million depending on the ground. Yeah. Okay, yeah. Let me know if you have any other questions happy to answer. Okay, so,
3:33yeah, so, so you just want me to go down, yeah.
S Speaker 13:37So, hard job about three years ago with the goal of building a new data center orchestration product that would basically build in modern infrastructure automation at the data center level, we had a conviction about three years ago that data centers were going to be most valuable commercial real estate in The world for like, 10 years. So we're definitely right on the target there with that hypothesis that we at first started doing CPU workloads, which is where we had iterate, is that we thought that okay, we can build a new orchestration product going from cloud to data centers, and we just start with CPU workloads and storage. Ends up that the technology was using was being used by GPUs. So we built out the product a little bit further after our second round. First round was led by teal, second rounds led by package files, and we decided to focus only on GPUs, although the technology does work with CPUs, but we had to do a bunch of other new things to support CPU workloads and to support interconnect, because, as y'all know, interconnect is a completely different network that we're designed with CPUs. So we did all that work. Then we launched the new product late last year, and that drove a lot of our growth. So fundamentally, our data centers, they use our software to basically get a turnkey solution that is rental, fabric, monetization, fabric, plus provisioning and automation. It's a turnkey solution works like Shopify Open Table. They actually comes in a hardware device. So to the OEMs, we are an OEM partner, so we're sort of like a bar to super micro Nvidia, but our bar, quote, unquote solution is fragile. We are a monetization solution. It comes in a machine and install the data center. Takes one hour to install. They plug it in, and it runs this automation process, pulls in all the views, as they would say, which would be servers, you know, like each 100 140 90 CPUs, storage servers, all into the dashboard. Then they can associate that with customers. They can use API to have people automatically buy. They can put a storefront on their own website. And as well, we drive demand, or our own top level funnel, as we have already all the demand together and send it out to, you know, basically all of our customers income, and can look at what we have available in our router network. So, so it works very similar to the model South bot. So we are the first horizontal solution in the space. We are. We don't own any infrastructure. The Data Center owns all of it, and we provide the common API layer to deliver rentals, to demand customers currently have deployments and to lower to death data centers that span from Thailand all the way to about to be a Saudi Arabia, so India, all around the world. And we are also a WD copper. We are the handful of both companies and selected in them Scorpion labs. And we are the only one that doesn't actually know its own temperature, because their software is that good, and it's, it is something that they assaults. They settled very much needed to answer this question of heterogeneous supply, and Nvidia, in us believe, depending on data centers, depending on the video, because we don't think a robot is actually going to happen as Nvidia does it this way. So so yeah, so that's what
So, hard job about three years ago with the goal of building a new data center orchestration product that would basically build in modern infrastructure automation at the data center level, we had a conviction about three years ago that data centers were going to be most valuable commercial real estate in The world for like, 10 years. So we're definitely right on the target there with that hypothesis that we at first started doing CPU workloads, which is where we had iterate, is that we thought that okay, we can build a new orchestration product going from cloud to data centers, and we just start with CPU workloads and storage. Ends up that the technology was using was being used by GPUs. So we built out the product a little bit further after our second round. First round was led by teal, second rounds led by package files, and we decided to focus only on GPUs, although the technology does work with CPUs, but we had to do a bunch of other new things to support CPU workloads and to support interconnect, because, as y'all know, interconnect is a completely different network that we're designed with CPUs. So we did all that work. Then we launched the new product late last year, and that drove a lot of our growth. So fundamentally, our data centers, they use our software to basically get a turnkey solution that is rental, fabric, monetization, fabric, plus provisioning and automation. It's a turnkey solution works like Shopify Open Table. They actually comes in a hardware device. So to the OEMs, we are an OEM partner, so we're sort of like a bar to super micro Nvidia, but our bar, quote, unquote solution is fragile. We are a monetization solution. It comes in a machine and install the data center. Takes one hour to install. They plug it in, and it runs this automation process, pulls in all the views, as they would say, which would be servers, you know, like each 100 140 90 CPUs, storage servers, all into the dashboard. Then they can associate that with customers. They can use API to have people automatically buy. They can put a storefront on their own website. And as well, we drive demand, or our own top level funnel, as we have already all the demand together and send it out to, you know, basically all of our customers income, and can look at what we have available in our router network. So, so it works very similar to the model South bot. So we are the first horizontal solution in the space. We are. We don't own any infrastructure. The Data Center owns all of it, and we provide the common API layer to deliver rentals, to demand customers currently have deployments and to lower to death data centers that span from Thailand all the way to about to be a Saudi Arabia, so India, all around the world. And we are also a WD copper. We are the handful of both companies and selected in them Scorpion labs. And we are the only one that doesn't actually know its own temperature, because their software is that good, and it's, it is something that they assaults. They settled very much needed to answer this question of heterogeneous supply, and Nvidia, in us believe, depending on data centers, depending on the video, because we don't think a robot is actually going to happen as Nvidia does it this way. So so yeah, so that's what
So, hard job about three years ago with the goal of building a new data center orchestration product that would basically build in modern infrastructure automation at the data center level, we had a conviction about three years ago that data centers were going to be most valuable commercial real estate in The world for like, 10 years. So we're definitely right on the target there with that hypothesis that we at first started doing CPU workloads, which is where we had iterate, is that we thought that okay, we can build a new orchestration product going from cloud to data centers, and we just start with CPU workloads and storage. Ends up that the technology was using was being used by GPUs. So we built out the product a little bit further after our second round. First round was led by teal, second rounds led by package files, and we decided to focus only on GPUs, although the technology does work with CPUs, but we had to do a bunch of other new things to support CPU workloads and to support interconnect, because, as y'all know, interconnect is a completely different network that we're designed with CPUs. So we did all that work. Then we launched the new product late last year, and that drove a lot of our growth. So fundamentally, our data centers, they use our software to basically get a turnkey solution that is rental, fabric, monetization, fabric, plus provisioning and automation. It's a turnkey solution works like Shopify Open Table. They actually comes in a hardware device. So to the OEMs, we are an OEM partner, so we're sort of like a bar to super micro Nvidia, but our bar, quote, unquote solution is fragile. We are a monetization solution. It comes in a machine and install the data center. Takes one hour to install. They plug it in, and it runs this automation process, pulls in all the views, as they would say, which would be servers, you know, like each 100 140 90 CPUs, storage servers, all into the dashboard. Then they can associate that with customers. They can use API to have people automatically buy. They can put a storefront on their own website. And as well, we drive demand, or our own top level funnel, as we have already all the demand together and send it out to, you know, basically all of our customers income, and can look at what we have available in our router network. So, so it works very similar to the model South bot. So we are the first horizontal solution in the space. We are. We don't own any infrastructure. The Data Center owns all of it, and we provide the common API layer to deliver rentals, to demand customers currently have deployments and to lower to death data centers that span from Thailand all the way to about to be a Saudi Arabia, so India, all around the world. And we are also a WD copper. We are the handful of both companies and selected in them Scorpion labs. And we are the only one that doesn't actually know its own temperature, because their software is that good, and it's, it is something that they assaults. They settled very much needed to answer this question of heterogeneous supply, and Nvidia, in us believe, depending on data centers, depending on the video, because we don't think a robot is actually going to happen as Nvidia does it this way. So so yeah, so that's what
So, hard job about three years ago with the goal of building a new data center orchestration product that would basically build in modern infrastructure automation at the data center level, we had a conviction about three years ago that data centers were going to be most valuable commercial real estate in The world for like, 10 years. So we're definitely right on the target there with that hypothesis that we at first started doing CPU workloads, which is where we had iterate, is that we thought that okay, we can build a new orchestration product going from cloud to data centers, and we just start with CPU workloads and storage. Ends up that the technology was using was being used by GPUs. So we built out the product a little bit further after our second round. First round was led by teal, second rounds led by package files, and we decided to focus only on GPUs, although the technology does work with CPUs, but we had to do a bunch of other new things to support CPU workloads and to support interconnect, because, as y'all know, interconnect is a completely different network that we're designed with CPUs. So we did all that work. Then we launched the new product late last year, and that drove a lot of our growth. So fundamentally, our data centers, they use our software to basically get a turnkey solution that is rental, fabric, monetization, fabric, plus provisioning and automation. It's a turnkey solution works like Shopify Open Table. They actually comes in a hardware device. So to the OEMs, we are an OEM partner, so we're sort of like a bar to super micro Nvidia, but our bar, quote, unquote solution is fragile. We are a monetization solution. It comes in a machine and install the data center. Takes one hour to install. They plug it in, and it runs this automation process, pulls in all the views, as they would say, which would be servers, you know, like each 100 140 90 CPUs, storage servers, all into the dashboard. Then they can associate that with customers. They can use API to have people automatically buy. They can put a storefront on their own website. And as well, we drive demand, or our own top level funnel, as we have already all the demand together and send it out to, you know, basically all of our customers income, and can look at what we have available in our router network. So, so it works very similar to the model South bot. So we are the first horizontal solution in the space. We are. We don't own any infrastructure. The Data Center owns all of it, and we provide the common API layer to deliver rentals, to demand customers currently have deployments and to lower to death data centers that span from Thailand all the way to about to be a Saudi Arabia, so India, all around the world. And we are also a WD copper. We are the handful of both companies and selected in them Scorpion labs. And we are the only one that doesn't actually know its own temperature, because their software is that good, and it's, it is something that they assaults. They settled very much needed to answer this question of heterogeneous supply, and Nvidia, in us believe, depending on data centers, depending on the video, because we don't think a robot is actually going to happen as Nvidia does it this way. So so yeah, so that's what
S Speaker 27:20we did. Thanks. Did you say you also sent a machine?
we did. Thanks. Did you say you also sent a machine?
we did. Thanks. Did you say you also sent a machine?
we did. Thanks. Did you say you also sent a machine?
S Speaker 17:25Yeah, we have, we have a little micro circle that gets sent to the data center to run the data center. So how does that,
Yeah, we have, we have a little micro circle that gets sent to the data center to run the data center. So how does that,
Yeah, we have, we have a little micro circle that gets sent to the data center to run the data center. So how does that,
Yeah, we have, we have a little micro circle that gets sent to the data center to run the data center. So how does that,
S Speaker 27:35something that you send to your customers. Why do you
something that you send to your customers. Why do you
something that you send to your customers. Why do you
something that you send to your customers. Why do you
S Speaker 17:40Because data centers don't know how to install software before you software itself. Oh,
Because data centers don't know how to install software before you software itself. Oh,
Because data centers don't know how to install software before you software itself. Oh,
Because data centers don't know how to install software before you software itself. Oh,
S Speaker 27:48instead, I guess the public and easy as possible. This is to reduce friction, I guess because otherwise they could install your software.
instead, I guess the public and easy as possible. This is to reduce friction, I guess because otherwise they could install your software.
instead, I guess the public and easy as possible. This is to reduce friction, I guess because otherwise they could install your software.
instead, I guess the public and easy as possible. This is to reduce friction, I guess because otherwise they could install your software.
S Speaker 18:00Yeah, we already tried that. Nerdy. Tried that for six months, and it's
Yeah, we already tried that. Nerdy. Tried that for six months, and it's
Yeah, we already tried that. Nerdy. Tried that for six months, and it's
Yeah, we already tried that. Nerdy. Tried that for six months, and it's
S Speaker 18:18control plane server. You see now there's, there's a lot of, a lot of the more advanced deployments of GPUs. They have these three CPU nodes. We were very early on that. We started doing that mid last year, because we saw that, like, one trying to, like, control layer on GPUs with all node was very complicated, and CPUs themselves are very complicated and very fragile. It's like, anti fragile, right? It's like, it's fragile in the lane of like a Ferrari, right? A Ferrari works amazing. When everything works, when it doesn't work, you have no idea what's going on, right? So it's exactly like that. So when you try to put all that stuff together the data center trying to figure that out, it was too complicated. So we're so excited to do was, like, very much apropos to the Silicon Valley show, where they said, just put it in a box and click your signature on it. That's literally what we did. And they just, boom, just start working, because it operates like an equipment lease, which they're very familiar with. So they're not software people, they're hardware people. So we started operating at like, equipment lease, which is what the SaaS SaaS fee is. The machine cost us, like, 900 bucks. It's like seven machines and and then, yeah, so they just pay monthly for it, like the police.
control plane server. You see now there's, there's a lot of, a lot of the more advanced deployments of GPUs. They have these three CPU nodes. We were very early on that. We started doing that mid last year, because we saw that, like, one trying to, like, control layer on GPUs with all node was very complicated, and CPUs themselves are very complicated and very fragile. It's like, anti fragile, right? It's like, it's fragile in the lane of like a Ferrari, right? A Ferrari works amazing. When everything works, when it doesn't work, you have no idea what's going on, right? So it's exactly like that. So when you try to put all that stuff together the data center trying to figure that out, it was too complicated. So we're so excited to do was, like, very much apropos to the Silicon Valley show, where they said, just put it in a box and click your signature on it. That's literally what we did. And they just, boom, just start working, because it operates like an equipment lease, which they're very familiar with. So they're not software people, they're hardware people. So we started operating at like, equipment lease, which is what the SaaS SaaS fee is. The machine cost us, like, 900 bucks. It's like seven machines and and then, yeah, so they just pay monthly for it, like the police.
control plane server. You see now there's, there's a lot of, a lot of the more advanced deployments of GPUs. They have these three CPU nodes. We were very early on that. We started doing that mid last year, because we saw that, like, one trying to, like, control layer on GPUs with all node was very complicated, and CPUs themselves are very complicated and very fragile. It's like, anti fragile, right? It's like, it's fragile in the lane of like a Ferrari, right? A Ferrari works amazing. When everything works, when it doesn't work, you have no idea what's going on, right? So it's exactly like that. So when you try to put all that stuff together the data center trying to figure that out, it was too complicated. So we're so excited to do was, like, very much apropos to the Silicon Valley show, where they said, just put it in a box and click your signature on it. That's literally what we did. And they just, boom, just start working, because it operates like an equipment lease, which they're very familiar with. So they're not software people, they're hardware people. So we started operating at like, equipment lease, which is what the SaaS SaaS fee is. The machine cost us, like, 900 bucks. It's like seven machines and and then, yeah, so they just pay monthly for it, like the police.
control plane server. You see now there's, there's a lot of, a lot of the more advanced deployments of GPUs. They have these three CPU nodes. We were very early on that. We started doing that mid last year, because we saw that, like, one trying to, like, control layer on GPUs with all node was very complicated, and CPUs themselves are very complicated and very fragile. It's like, anti fragile, right? It's like, it's fragile in the lane of like a Ferrari, right? A Ferrari works amazing. When everything works, when it doesn't work, you have no idea what's going on, right? So it's exactly like that. So when you try to put all that stuff together the data center trying to figure that out, it was too complicated. So we're so excited to do was, like, very much apropos to the Silicon Valley show, where they said, just put it in a box and click your signature on it. That's literally what we did. And they just, boom, just start working, because it operates like an equipment lease, which they're very familiar with. So they're not software people, they're hardware people. So we started operating at like, equipment lease, which is what the SaaS SaaS fee is. The machine cost us, like, 900 bucks. It's like seven machines and and then, yeah, so they just pay monthly for it, like the police.
S Speaker 29:25and then, and then the workloads are, I think you mentioned, the workloads are not necessarily just AI workloads, or are they?
and then, and then the workloads are, I think you mentioned, the workloads are not necessarily just AI workloads, or are they?
and then, and then the workloads are, I think you mentioned, the workloads are not necessarily just AI workloads, or are they?
and then, and then the workloads are, I think you mentioned, the workloads are not necessarily just AI workloads, or are they?
S Speaker 19:34No, it's everything under the sun, but like, 90% of the capacity is GPUs, but they, but that's where people are moving. It's sort of like, think of it this way. It's like that. When GPUs came out, right? They were built as a, as a modular component, computing component, right? So it comes itself, and it works by itself, right? This is designed for consumer application, right? And and so CPUs are not like that. It's like, it's like a it's like cake flower mix, right? Like CPUs need all this other stuff to work with GPUs. It's like sheet cakes are to come made by the store. And what happened is that data centers, I because they, you know, there's been a scarcity of data center builds the last two decades. It's just because hyperscalers are controlling everything so much. But when GPUs started really growing. Public Cloud has a network incompatibility with GPUs, specifically with Nvidia, and then data centers are buying it because they're like, well, there's no need. Oh, there's all this cloud stuff. It's not needed anymore. It's not it's relevant. It's up, like, you can use it for GPUs, but it's irrelevant, since it's not a requirement, right? And so people start leaving in massive drugs. And then that's when the use case starts really appearing, which is that data centers were being overloaded with GPU requests. But it can work with storage servers. It works with it works with every network switch, from Arista to meladox. It works with AMD servers. It works with AMD chips, Intel chips. It doesn't matter. It's just that GPUs became the thing. So now what our tools being used for is to combine, like all the apple the deployments of the data centers, like CPUs, storage servers, command like it's being used to control all those various things. So so that that's how we're different in the space is that when you see the top level doing is like shop, map and Dropbox, just our aggregator. We have a whole other product that is actually doing the data center automation that we plan on controlling the entire aspect of what works the data center. So everything from what do you use to build? What do you use to do? Let's say you have to do government reporting. Do you have to use students, which what type of CUDA version Do you want to use this type of storage issue? We want to control all that through our control plane. So that is a turnkey product to where data centers like, click a button, click, apply, click, button, runs its provisioning, delivers it out to all of the relevant servers. So that's like our vision. It's like, yeah, a data center automation,
No, it's everything under the sun, but like, 90% of the capacity is GPUs, but they, but that's where people are moving. It's sort of like, think of it this way. It's like that. When GPUs came out, right? They were built as a, as a modular component, computing component, right? So it comes itself, and it works by itself, right? This is designed for consumer application, right? And and so CPUs are not like that. It's like, it's like a it's like cake flower mix, right? Like CPUs need all this other stuff to work with GPUs. It's like sheet cakes are to come made by the store. And what happened is that data centers, I because they, you know, there's been a scarcity of data center builds the last two decades. It's just because hyperscalers are controlling everything so much. But when GPUs started really growing. Public Cloud has a network incompatibility with GPUs, specifically with Nvidia, and then data centers are buying it because they're like, well, there's no need. Oh, there's all this cloud stuff. It's not needed anymore. It's not it's relevant. It's up, like, you can use it for GPUs, but it's irrelevant, since it's not a requirement, right? And so people start leaving in massive drugs. And then that's when the use case starts really appearing, which is that data centers were being overloaded with GPU requests. But it can work with storage servers. It works with it works with every network switch, from Arista to meladox. It works with AMD servers. It works with AMD chips, Intel chips. It doesn't matter. It's just that GPUs became the thing. So now what our tools being used for is to combine, like all the apple the deployments of the data centers, like CPUs, storage servers, command like it's being used to control all those various things. So so that that's how we're different in the space is that when you see the top level doing is like shop, map and Dropbox, just our aggregator. We have a whole other product that is actually doing the data center automation that we plan on controlling the entire aspect of what works the data center. So everything from what do you use to build? What do you use to do? Let's say you have to do government reporting. Do you have to use students, which what type of CUDA version Do you want to use this type of storage issue? We want to control all that through our control plane. So that is a turnkey product to where data centers like, click a button, click, apply, click, button, runs its provisioning, delivers it out to all of the relevant servers. So that's like our vision. It's like, yeah, a data center automation,
No, it's everything under the sun, but like, 90% of the capacity is GPUs, but they, but that's where people are moving. It's sort of like, think of it this way. It's like that. When GPUs came out, right? They were built as a, as a modular component, computing component, right? So it comes itself, and it works by itself, right? This is designed for consumer application, right? And and so CPUs are not like that. It's like, it's like a it's like cake flower mix, right? Like CPUs need all this other stuff to work with GPUs. It's like sheet cakes are to come made by the store. And what happened is that data centers, I because they, you know, there's been a scarcity of data center builds the last two decades. It's just because hyperscalers are controlling everything so much. But when GPUs started really growing. Public Cloud has a network incompatibility with GPUs, specifically with Nvidia, and then data centers are buying it because they're like, well, there's no need. Oh, there's all this cloud stuff. It's not needed anymore. It's not it's relevant. It's up, like, you can use it for GPUs, but it's irrelevant, since it's not a requirement, right? And so people start leaving in massive drugs. And then that's when the use case starts really appearing, which is that data centers were being overloaded with GPU requests. But it can work with storage servers. It works with it works with every network switch, from Arista to meladox. It works with AMD servers. It works with AMD chips, Intel chips. It doesn't matter. It's just that GPUs became the thing. So now what our tools being used for is to combine, like all the apple the deployments of the data centers, like CPUs, storage servers, command like it's being used to control all those various things. So so that that's how we're different in the space is that when you see the top level doing is like shop, map and Dropbox, just our aggregator. We have a whole other product that is actually doing the data center automation that we plan on controlling the entire aspect of what works the data center. So everything from what do you use to build? What do you use to do? Let's say you have to do government reporting. Do you have to use students, which what type of CUDA version Do you want to use this type of storage issue? We want to control all that through our control plane. So that is a turnkey product to where data centers like, click a button, click, apply, click, button, runs its provisioning, delivers it out to all of the relevant servers. So that's like our vision. It's like, yeah, a data center automation,
No, it's everything under the sun, but like, 90% of the capacity is GPUs, but they, but that's where people are moving. It's sort of like, think of it this way. It's like that. When GPUs came out, right? They were built as a, as a modular component, computing component, right? So it comes itself, and it works by itself, right? This is designed for consumer application, right? And and so CPUs are not like that. It's like, it's like a it's like cake flower mix, right? Like CPUs need all this other stuff to work with GPUs. It's like sheet cakes are to come made by the store. And what happened is that data centers, I because they, you know, there's been a scarcity of data center builds the last two decades. It's just because hyperscalers are controlling everything so much. But when GPUs started really growing. Public Cloud has a network incompatibility with GPUs, specifically with Nvidia, and then data centers are buying it because they're like, well, there's no need. Oh, there's all this cloud stuff. It's not needed anymore. It's not it's relevant. It's up, like, you can use it for GPUs, but it's irrelevant, since it's not a requirement, right? And so people start leaving in massive drugs. And then that's when the use case starts really appearing, which is that data centers were being overloaded with GPU requests. But it can work with storage servers. It works with it works with every network switch, from Arista to meladox. It works with AMD servers. It works with AMD chips, Intel chips. It doesn't matter. It's just that GPUs became the thing. So now what our tools being used for is to combine, like all the apple the deployments of the data centers, like CPUs, storage servers, command like it's being used to control all those various things. So so that that's how we're different in the space is that when you see the top level doing is like shop, map and Dropbox, just our aggregator. We have a whole other product that is actually doing the data center automation that we plan on controlling the entire aspect of what works the data center. So everything from what do you use to build? What do you use to do? Let's say you have to do government reporting. Do you have to use students, which what type of CUDA version Do you want to use this type of storage issue? We want to control all that through our control plane. So that is a turnkey product to where data centers like, click a button, click, apply, click, button, runs its provisioning, delivers it out to all of the relevant servers. So that's like our vision. It's like, yeah, a data center automation,
S Speaker 212:03good and Aaron, one question which is,
S Speaker 112:53We operate actually at the kernel layer, so rescaler operates upon us. Rescaler is essentially like an open stack or with some Kubernetes components built into it, as far as we've seen on our deployments. And so we are running permission so they would run above us, so we actually run on the auto band management network. We're running the management network within the cluster, within the data center. So that's how we're different. Yeah. Okay, okay, and then,
We operate actually at the kernel layer, so rescaler operates upon us. Rescaler is essentially like an open stack or with some Kubernetes components built into it, as far as we've seen on our deployments. And so we are running permission so they would run above us, so we actually run on the auto band management network. We're running the management network within the cluster, within the data center. So that's how we're different. Yeah. Okay, okay, and then,
We operate actually at the kernel layer, so rescaler operates upon us. Rescaler is essentially like an open stack or with some Kubernetes components built into it, as far as we've seen on our deployments. And so we are running permission so they would run above us, so we actually run on the auto band management network. We're running the management network within the cluster, within the data center. So that's how we're different. Yeah. Okay, okay, and then,
We operate actually at the kernel layer, so rescaler operates upon us. Rescaler is essentially like an open stack or with some Kubernetes components built into it, as far as we've seen on our deployments. And so we are running permission so they would run above us, so we actually run on the auto band management network. We're running the management network within the cluster, within the data center. So that's how we're different. Yeah. Okay, okay, and then,
S Speaker 213:22and what about all these, you know, inference as a service companies, which is, which are focused primarily on AI inference and but, but they try to do that for AI workloads across, you know, primarily AI workloads, but across clouds, most of them
and what about all these, you know, inference as a service companies, which is, which are focused primarily on AI inference and but, but they try to do that for AI workloads across, you know, primarily AI workloads, but across clouds, most of them
and what about all these, you know, inference as a service companies, which is, which are focused primarily on AI inference and but, but they try to do that for AI workloads across, you know, primarily AI workloads, but across clouds, most of them
and what about all these, you know, inference as a service companies, which is, which are focused primarily on AI inference and but, but they try to do that for AI workloads across, you know, primarily AI workloads, but across clouds, most of them
S Speaker 213:54like companies like together, and companies like replicate, companies like Opto AI, so I'm talking about those types of companies.
like companies like together, and companies like replicate, companies like Opto AI, so I'm talking about those types of companies.
like companies like together, and companies like replicate, companies like Opto AI, so I'm talking about those types of companies.
like companies like together, and companies like replicate, companies like Opto AI, so I'm talking about those types of companies.
S Speaker 114:02Yeah, they don't, they don't do decent rotation. They have a virtualized product that runs like three layers. Boss,
Yeah, they don't, they don't do decent rotation. They have a virtualized product that runs like three layers. Boss,
Yeah, they don't, they don't do decent rotation. They have a virtualized product that runs like three layers. Boss,
Yeah, they don't, they don't do decent rotation. They have a virtualized product that runs like three layers. Boss,
S Speaker 214:09interesting. So, so the company that I'm talking about, are they your customers? Yeah. So like,
interesting. So, so the company that I'm talking about, are they your customers? Yeah. So like,
interesting. So, so the company that I'm talking about, are they your customers? Yeah. So like,
interesting. So, so the company that I'm talking about, are they your customers? Yeah. So like,
S Speaker 114:17together, as a customer, as a computer customer, lambda, lab thread, some stuff from us. Interesting ether all been like just Akash, all the sort of decentralized folks. They run from us because they don't do data center automation. They run a virtualized product, which is technically 121234, layers above us, so we run way down, like as in, we're installing CUDA, we're installing Wicca. We are determining what Ubuntu version right? That's what our software does. Do you and then you then, because once you do okay, get the provisioning right. Do a bruising process if you're promoting all this work. So you call into provisioning out of a management network. You then do the we actually do the reinstall, we do the reboot, we actually do the ypits, but that's our software that's doing that. Then you didn't pick the OS, so that's that layer. Then you didn't pick the driver version, which is that layer. Then you then decide, okay, am I going to put a VM on this? Am I going to Kubernetes it? Am I going to what am I going to do. Then you then decide, okay, now I've done that. Am I going to put it on a replicate and we're going to put it on together on that so we run way down below that, which is why we plan on commoditizing all those people above us, because we are actually the rails right now, the way Dennis, nor does it. It doesn't manually
together, as a customer, as a computer customer, lambda, lab thread, some stuff from us. Interesting ether all been like just Akash, all the sort of decentralized folks. They run from us because they don't do data center automation. They run a virtualized product, which is technically 121234, layers above us, so we run way down, like as in, we're installing CUDA, we're installing Wicca. We are determining what Ubuntu version right? That's what our software does. Do you and then you then, because once you do okay, get the provisioning right. Do a bruising process if you're promoting all this work. So you call into provisioning out of a management network. You then do the we actually do the reinstall, we do the reboot, we actually do the ypits, but that's our software that's doing that. Then you didn't pick the OS, so that's that layer. Then you didn't pick the driver version, which is that layer. Then you then decide, okay, am I going to put a VM on this? Am I going to Kubernetes it? Am I going to what am I going to do. Then you then decide, okay, now I've done that. Am I going to put it on a replicate and we're going to put it on together on that so we run way down below that, which is why we plan on commoditizing all those people above us, because we are actually the rails right now, the way Dennis, nor does it. It doesn't manually
together, as a customer, as a computer customer, lambda, lab thread, some stuff from us. Interesting ether all been like just Akash, all the sort of decentralized folks. They run from us because they don't do data center automation. They run a virtualized product, which is technically 121234, layers above us, so we run way down, like as in, we're installing CUDA, we're installing Wicca. We are determining what Ubuntu version right? That's what our software does. Do you and then you then, because once you do okay, get the provisioning right. Do a bruising process if you're promoting all this work. So you call into provisioning out of a management network. You then do the we actually do the reinstall, we do the reboot, we actually do the ypits, but that's our software that's doing that. Then you didn't pick the OS, so that's that layer. Then you didn't pick the driver version, which is that layer. Then you then decide, okay, am I going to put a VM on this? Am I going to Kubernetes it? Am I going to what am I going to do. Then you then decide, okay, now I've done that. Am I going to put it on a replicate and we're going to put it on together on that so we run way down below that, which is why we plan on commoditizing all those people above us, because we are actually the rails right now, the way Dennis, nor does it. It doesn't manually
together, as a customer, as a computer customer, lambda, lab thread, some stuff from us. Interesting ether all been like just Akash, all the sort of decentralized folks. They run from us because they don't do data center automation. They run a virtualized product, which is technically 121234, layers above us, so we run way down, like as in, we're installing CUDA, we're installing Wicca. We are determining what Ubuntu version right? That's what our software does. Do you and then you then, because once you do okay, get the provisioning right. Do a bruising process if you're promoting all this work. So you call into provisioning out of a management network. You then do the we actually do the reinstall, we do the reboot, we actually do the ypits, but that's our software that's doing that. Then you didn't pick the OS, so that's that layer. Then you didn't pick the driver version, which is that layer. Then you then decide, okay, am I going to put a VM on this? Am I going to Kubernetes it? Am I going to what am I going to do. Then you then decide, okay, now I've done that. Am I going to put it on a replicate and we're going to put it on together on that so we run way down below that, which is why we plan on commoditizing all those people above us, because we are actually the rails right now, the way Dennis, nor does it. It doesn't manually
S Speaker 215:44probably maybe not. Now, if you don't have access, which is, do you happen to have, like, a an architecture stack
probably maybe not. Now, if you don't have access, which is, do you happen to have, like, a an architecture stack
probably maybe not. Now, if you don't have access, which is, do you happen to have, like, a an architecture stack
probably maybe not. Now, if you don't have access, which is, do you happen to have, like, a an architecture stack
S Speaker 215:59or even, like, there's maybe two diagrams, which is, one is showing the stack, when, where does your software sit, and then the other one is typical workflow of somebody who's was trying to run, you know, workloads on a data center. Then who do they interact with? And where does your software fit in that picture because, because it sounds like you don't sell to the people who are running the workload, you sell to companies who then work with the customers. Is that, right?
or even, like, there's maybe two diagrams, which is, one is showing the stack, when, where does your software sit, and then the other one is typical workflow of somebody who's was trying to run, you know, workloads on a data center. Then who do they interact with? And where does your software fit in that picture because, because it sounds like you don't sell to the people who are running the workload, you sell to companies who then work with the customers. Is that, right?
or even, like, there's maybe two diagrams, which is, one is showing the stack, when, where does your software sit, and then the other one is typical workflow of somebody who's was trying to run, you know, workloads on a data center. Then who do they interact with? And where does your software fit in that picture because, because it sounds like you don't sell to the people who are running the workload, you sell to companies who then work with the customers. Is that, right?
or even, like, there's maybe two diagrams, which is, one is showing the stack, when, where does your software sit, and then the other one is typical workflow of somebody who's was trying to run, you know, workloads on a data center. Then who do they interact with? And where does your software fit in that picture because, because it sounds like you don't sell to the people who are running the workload, you sell to companies who then work with the customers. Is that, right?
S Speaker 116:34Well, we are like a supply driven product, right? So we think that this space is going to be a supply driven not necessarily like a marketplace, but just like, like Uber, right? Uber is a supply driven market. Right? Drivers is what drives the marketplace. Right? People of choosing where they go and where they ride. Same thing with the data centers. We sell a data set and then, and then people come based on our access to data centers. So that's, that's the difference, right?
Well, we are like a supply driven product, right? So we think that this space is going to be a supply driven not necessarily like a marketplace, but just like, like Uber, right? Uber is a supply driven market. Right? Drivers is what drives the marketplace. Right? People of choosing where they go and where they ride. Same thing with the data centers. We sell a data set and then, and then people come based on our access to data centers. So that's, that's the difference, right?
Well, we are like a supply driven product, right? So we think that this space is going to be a supply driven not necessarily like a marketplace, but just like, like Uber, right? Uber is a supply driven market. Right? Drivers is what drives the marketplace. Right? People of choosing where they go and where they ride. Same thing with the data centers. We sell a data set and then, and then people come based on our access to data centers. So that's, that's the difference, right?
Well, we are like a supply driven product, right? So we think that this space is going to be a supply driven not necessarily like a marketplace, but just like, like Uber, right? Uber is a supply driven market. Right? Drivers is what drives the marketplace. Right? People of choosing where they go and where they ride. Same thing with the data centers. We sell a data set and then, and then people come based on our access to data centers. So that's, that's the difference, right?
S Speaker 217:02So you sell to the data centers, but you also sell to the togethers of the world, or their partners, yeah,
So you sell to the data centers, but you also sell to the togethers of the world, or their partners, yeah,
So you sell to the data centers, but you also sell to the togethers of the world, or their partners, yeah,
So you sell to the data centers, but you also sell to the togethers of the world, or their partners, yeah,
S Speaker 117:08because we have, we have the, we have the common API across all these data centers, and they need, they need common API to access these data centers.
because we have, we have the, we have the common API across all these data centers, and they need, they need common API to access these data centers.
because we have, we have the, we have the common API across all these data centers, and they need, they need common API to access these data centers.
because we have, we have the, we have the common API across all these data centers, and they need, they need common API to access these data centers.
S Speaker 217:14So you do sell to together and replicate or,
S Speaker 117:18I mean, it's like, it's like, Does, does Uber sell to writers and sort of, but not really, right? Like, they sell to drivers, right? So that that's, that's 80% of their focus. So 20% is that they, you know, we have the demo or API and stuff like that, and then they can either go work the data center directly, or they can, you know, work with us. So, so those are the two different ways that we we work with people.
I mean, it's like, it's like, Does, does Uber sell to writers and sort of, but not really, right? Like, they sell to drivers, right? So that that's, that's 80% of their focus. So 20% is that they, you know, we have the demo or API and stuff like that, and then they can either go work the data center directly, or they can, you know, work with us. So, so those are the two different ways that we we work with people.
I mean, it's like, it's like, Does, does Uber sell to writers and sort of, but not really, right? Like, they sell to drivers, right? So that that's, that's 80% of their focus. So 20% is that they, you know, we have the demo or API and stuff like that, and then they can either go work the data center directly, or they can, you know, work with us. So, so those are the two different ways that we we work with people.
I mean, it's like, it's like, Does, does Uber sell to writers and sort of, but not really, right? Like, they sell to drivers, right? So that that's, that's 80% of their focus. So 20% is that they, you know, we have the demo or API and stuff like that, and then they can either go work the data center directly, or they can, you know, work with us. So, so those are the two different ways that we we work with people.
S Speaker 117:59I can see there's something that we've made, there's nothing that outlines when we'll obviously have, like, technical specs and product features, things like that. We can we have, but I see if there's something that describes it how you're thinking, which is, like, if I'm an AI company, which
I can see there's something that we've made, there's nothing that outlines when we'll obviously have, like, technical specs and product features, things like that. We can we have, but I see if there's something that describes it how you're thinking, which is, like, if I'm an AI company, which
I can see there's something that we've made, there's nothing that outlines when we'll obviously have, like, technical specs and product features, things like that. We can we have, but I see if there's something that describes it how you're thinking, which is, like, if I'm an AI company, which
I can see there's something that we've made, there's nothing that outlines when we'll obviously have, like, technical specs and product features, things like that. We can we have, but I see if there's something that describes it how you're thinking, which is, like, if I'm an AI company, which
S Speaker 218:18Yeah, that's right. And and I get it that you're not just focused on AI workloads, but I'm but since you refer and then one thing that you mentioned, you said, 90% of the capacity is is GPUs. Are you referring to 90% of the times your customers end up using the GPUs. Are you referring to more the fact that data center is comprised these days 90% of GPUs,
Yeah, that's right. And and I get it that you're not just focused on AI workloads, but I'm but since you refer and then one thing that you mentioned, you said, 90% of the capacity is is GPUs. Are you referring to 90% of the times your customers end up using the GPUs. Are you referring to more the fact that data center is comprised these days 90% of GPUs,
Yeah, that's right. And and I get it that you're not just focused on AI workloads, but I'm but since you refer and then one thing that you mentioned, you said, 90% of the capacity is is GPUs. Are you referring to 90% of the times your customers end up using the GPUs. Are you referring to more the fact that data center is comprised these days 90% of GPUs,
Yeah, that's right. And and I get it that you're not just focused on AI workloads, but I'm but since you refer and then one thing that you mentioned, you said, 90% of the capacity is is GPUs. Are you referring to 90% of the times your customers end up using the GPUs. Are you referring to more the fact that data center is comprised these days 90% of GPUs,
S Speaker 118:51as in, if you look at the number of cards and servers, the SKUs that are being managed in our software, it's GPUs. That's right.
as in, if you look at the number of cards and servers, the SKUs that are being managed in our software, it's GPUs. That's right.
as in, if you look at the number of cards and servers, the SKUs that are being managed in our software, it's GPUs. That's right.
as in, if you look at the number of cards and servers, the SKUs that are being managed in our software, it's GPUs. That's right.
S Speaker 218:59Okay, so it's more from your demand side, which is, that's what you've seen, okay? And it's GPUs. And then I'm assuming most of it is AI workload,
Okay, so it's more from your demand side, which is, that's what you've seen, okay? And it's GPUs. And then I'm assuming most of it is AI workload,
Okay, so it's more from your demand side, which is, that's what you've seen, okay? And it's GPUs. And then I'm assuming most of it is AI workload,
Okay, so it's more from your demand side, which is, that's what you've seen, okay? And it's GPUs. And then I'm assuming most of it is AI workload,
S Speaker 119:13yeah, AI inferencing by tuning, you know, drawing applications, running services, yeah, stuff like that. Okay? And
yeah, AI inferencing by tuning, you know, drawing applications, running services, yeah, stuff like that. Okay? And
yeah, AI inferencing by tuning, you know, drawing applications, running services, yeah, stuff like that. Okay? And
yeah, AI inferencing by tuning, you know, drawing applications, running services, yeah, stuff like that. Okay? And
S Speaker 219:22I'm curious to, like, you know, one of the things these days, what we're seeing with a lot of the AI infringing as a service businesses is that the gross margins end up becoming low for many of them, and then they're trending lower. Like, how are you able to are you able to get, what's your gross
I'm curious to, like, you know, one of the things these days, what we're seeing with a lot of the AI infringing as a service businesses is that the gross margins end up becoming low for many of them, and then they're trending lower. Like, how are you able to are you able to get, what's your gross
I'm curious to, like, you know, one of the things these days, what we're seeing with a lot of the AI infringing as a service businesses is that the gross margins end up becoming low for many of them, and then they're trending lower. Like, how are you able to are you able to get, what's your gross
I'm curious to, like, you know, one of the things these days, what we're seeing with a lot of the AI infringing as a service businesses is that the gross margins end up becoming low for many of them, and then they're trending lower. Like, how are you able to are you able to get, what's your gross
S Speaker 219:51the gain here is scale. Is that what how you're thinking, or you feel? Are
the gain here is scale. Is that what how you're thinking, or you feel? Are
the gain here is scale. Is that what how you're thinking, or you feel? Are
the gain here is scale. Is that what how you're thinking, or you feel? Are
19:56you thinking that you can increase the gross margins?
you thinking that you can increase the gross margins?
you thinking that you can increase the gross margins?
you thinking that you can increase the gross margins?
S Speaker 120:00We can't increase, increase goes margin, because all of those guys that you're mentioning, they don't run data centers. They don't work with data centers. We sell our software as a SAS feed. So we're, we're actually like an operational company with the data center. So the data center buys from us the hardware. We ship it to them with our machine, and we provide, we're testing everything from providing financing solutions, as in, they file on credit from Hydra, Hydra send them video gear to we're doing automation around like Wicca install, where Wicca would pay us for that. We're doing what's called Slurm automation, right? So our business model is different because they inferencing, like inference AI right there in from us. Like, don't give a shit about what happens to the data level. Like that they they're just taking in GPUs and trying to get the best price out. What we do is that we are the monetization fabric that actually runs the data zone. So, for example, one of our features rolling out this year is ability to co list across run pod and vast and all these guys, like, within the within, within a hydra VM, right? And so you install that product, then hydro listed for you across all these different places. So, so that's where our motivation is different, you know? And then the data center is going to pay us for that, for that feature, so that that's how it works, as a structurally different one. My goal is the data center and the data center making them, but everything AI is completely different. Goal in terms of what they're
We can't increase, increase goes margin, because all of those guys that you're mentioning, they don't run data centers. They don't work with data centers. We sell our software as a SAS feed. So we're, we're actually like an operational company with the data center. So the data center buys from us the hardware. We ship it to them with our machine, and we provide, we're testing everything from providing financing solutions, as in, they file on credit from Hydra, Hydra send them video gear to we're doing automation around like Wicca install, where Wicca would pay us for that. We're doing what's called Slurm automation, right? So our business model is different because they inferencing, like inference AI right there in from us. Like, don't give a shit about what happens to the data level. Like that they they're just taking in GPUs and trying to get the best price out. What we do is that we are the monetization fabric that actually runs the data zone. So, for example, one of our features rolling out this year is ability to co list across run pod and vast and all these guys, like, within the within, within a hydra VM, right? And so you install that product, then hydro listed for you across all these different places. So, so that's where our motivation is different, you know? And then the data center is going to pay us for that, for that feature, so that that's how it works, as a structurally different one. My goal is the data center and the data center making them, but everything AI is completely different. Goal in terms of what they're
We can't increase, increase goes margin, because all of those guys that you're mentioning, they don't run data centers. They don't work with data centers. We sell our software as a SAS feed. So we're, we're actually like an operational company with the data center. So the data center buys from us the hardware. We ship it to them with our machine, and we provide, we're testing everything from providing financing solutions, as in, they file on credit from Hydra, Hydra send them video gear to we're doing automation around like Wicca install, where Wicca would pay us for that. We're doing what's called Slurm automation, right? So our business model is different because they inferencing, like inference AI right there in from us. Like, don't give a shit about what happens to the data level. Like that they they're just taking in GPUs and trying to get the best price out. What we do is that we are the monetization fabric that actually runs the data zone. So, for example, one of our features rolling out this year is ability to co list across run pod and vast and all these guys, like, within the within, within a hydra VM, right? And so you install that product, then hydro listed for you across all these different places. So, so that's where our motivation is different, you know? And then the data center is going to pay us for that, for that feature, so that that's how it works, as a structurally different one. My goal is the data center and the data center making them, but everything AI is completely different. Goal in terms of what they're
We can't increase, increase goes margin, because all of those guys that you're mentioning, they don't run data centers. They don't work with data centers. We sell our software as a SAS feed. So we're, we're actually like an operational company with the data center. So the data center buys from us the hardware. We ship it to them with our machine, and we provide, we're testing everything from providing financing solutions, as in, they file on credit from Hydra, Hydra send them video gear to we're doing automation around like Wicca install, where Wicca would pay us for that. We're doing what's called Slurm automation, right? So our business model is different because they inferencing, like inference AI right there in from us. Like, don't give a shit about what happens to the data level. Like that they they're just taking in GPUs and trying to get the best price out. What we do is that we are the monetization fabric that actually runs the data zone. So, for example, one of our features rolling out this year is ability to co list across run pod and vast and all these guys, like, within the within, within a hydra VM, right? And so you install that product, then hydro listed for you across all these different places. So, so that's where our motivation is different, you know? And then the data center is going to pay us for that, for that feature, so that that's how it works, as a structurally different one. My goal is the data center and the data center making them, but everything AI is completely different. Goal in terms of what they're
S Speaker 221:30I get it. I think you're selling to the data centers so that they can
I get it. I think you're selling to the data centers so that they can
I get it. I think you're selling to the data centers so that they can
I get it. I think you're selling to the data centers so that they can
S Speaker 121:38and grow and grow their their footprint and grow their capacity, because we think we are, our vision is that that couple things are not in the market. One is that this is going to be a highly regionalized market. This is not going to be a roll up. One is that there's no need. There's no There's no pressure, actually, to use Cloud to do these things. The second is political factors people rank based on geopolitics and political relations like that is very, very clear in all of our customer behavior. And you hear that also in the video. The video saying sovereign, am so that so that, again, plays to our favor. The third is that if you look at what is going to be the ongoing constraint, a within the compute space. As you think about that capacity on the data center is going to be more triple the next, next to the end of this decade, like all that's going to be Greenfield space at which the most important person in that relationship is the data center. So when they are doing all this new capacity raw, they're going to need some fabric to run, whether or not they list it on fast or together, or even friends, or any of that stuff. Like, like, we don't really care. Like, that's not, that's not our motivation. Fact, I don't even really care if you buy the video you're done. My goal is, like, are you making the maximum amount of money data center, right, that you can so, so our relationship is, is much more, let's say, like, a like, a franchise model, right? That's how we're actually working. Then inference AI, which inference a sort of, like, it's like, it's like, saying, okay, like, we're like, Chick fil A, right? Or something like that. And everyone's AI is, like, run up, right? Like, that's, that's like, that's what everyone's AI is doing. Or these AI companies, right? They're higher level abstractions. They're not actually running the covid business with the data center. And the last point, which is how we're going to be fundamentally different than this separation space, is we think that the space is going to become increasingly oriented on demand. We, right now, are the only product in the world that gives on demand white label as a service, where you can list every on demand product you want via API or via website, put it on your data center website, and then people can go in there and check out what they call it, so that, that's how that, yeah, so that's how we're like, replicates never going to do that like, they're never going to give a software out to data centers to, like, whether or not they sell on replicate or something else, because replicate is a verticalized business, right? We are a horizontal business where we add these modular components similar to like franchise model, and it grows the value of the franchise, right? So, so that's how we're operating, as a complete
and grow and grow their their footprint and grow their capacity, because we think we are, our vision is that that couple things are not in the market. One is that this is going to be a highly regionalized market. This is not going to be a roll up. One is that there's no need. There's no There's no pressure, actually, to use Cloud to do these things. The second is political factors people rank based on geopolitics and political relations like that is very, very clear in all of our customer behavior. And you hear that also in the video. The video saying sovereign, am so that so that, again, plays to our favor. The third is that if you look at what is going to be the ongoing constraint, a within the compute space. As you think about that capacity on the data center is going to be more triple the next, next to the end of this decade, like all that's going to be Greenfield space at which the most important person in that relationship is the data center. So when they are doing all this new capacity raw, they're going to need some fabric to run, whether or not they list it on fast or together, or even friends, or any of that stuff. Like, like, we don't really care. Like, that's not, that's not our motivation. Fact, I don't even really care if you buy the video you're done. My goal is, like, are you making the maximum amount of money data center, right, that you can so, so our relationship is, is much more, let's say, like, a like, a franchise model, right? That's how we're actually working. Then inference AI, which inference a sort of, like, it's like, it's like, saying, okay, like, we're like, Chick fil A, right? Or something like that. And everyone's AI is, like, run up, right? Like, that's, that's like, that's what everyone's AI is doing. Or these AI companies, right? They're higher level abstractions. They're not actually running the covid business with the data center. And the last point, which is how we're going to be fundamentally different than this separation space, is we think that the space is going to become increasingly oriented on demand. We, right now, are the only product in the world that gives on demand white label as a service, where you can list every on demand product you want via API or via website, put it on your data center website, and then people can go in there and check out what they call it, so that, that's how that, yeah, so that's how we're like, replicates never going to do that like, they're never going to give a software out to data centers to, like, whether or not they sell on replicate or something else, because replicate is a verticalized business, right? We are a horizontal business where we add these modular components similar to like franchise model, and it grows the value of the franchise, right? So, so that's how we're operating, as a complete
and grow and grow their their footprint and grow their capacity, because we think we are, our vision is that that couple things are not in the market. One is that this is going to be a highly regionalized market. This is not going to be a roll up. One is that there's no need. There's no There's no pressure, actually, to use Cloud to do these things. The second is political factors people rank based on geopolitics and political relations like that is very, very clear in all of our customer behavior. And you hear that also in the video. The video saying sovereign, am so that so that, again, plays to our favor. The third is that if you look at what is going to be the ongoing constraint, a within the compute space. As you think about that capacity on the data center is going to be more triple the next, next to the end of this decade, like all that's going to be Greenfield space at which the most important person in that relationship is the data center. So when they are doing all this new capacity raw, they're going to need some fabric to run, whether or not they list it on fast or together, or even friends, or any of that stuff. Like, like, we don't really care. Like, that's not, that's not our motivation. Fact, I don't even really care if you buy the video you're done. My goal is, like, are you making the maximum amount of money data center, right, that you can so, so our relationship is, is much more, let's say, like, a like, a franchise model, right? That's how we're actually working. Then inference AI, which inference a sort of, like, it's like, it's like, saying, okay, like, we're like, Chick fil A, right? Or something like that. And everyone's AI is, like, run up, right? Like, that's, that's like, that's what everyone's AI is doing. Or these AI companies, right? They're higher level abstractions. They're not actually running the covid business with the data center. And the last point, which is how we're going to be fundamentally different than this separation space, is we think that the space is going to become increasingly oriented on demand. We, right now, are the only product in the world that gives on demand white label as a service, where you can list every on demand product you want via API or via website, put it on your data center website, and then people can go in there and check out what they call it, so that, that's how that, yeah, so that's how we're like, replicates never going to do that like, they're never going to give a software out to data centers to, like, whether or not they sell on replicate or something else, because replicate is a verticalized business, right? We are a horizontal business where we add these modular components similar to like franchise model, and it grows the value of the franchise, right? So, so that's how we're operating, as a complete
and grow and grow their their footprint and grow their capacity, because we think we are, our vision is that that couple things are not in the market. One is that this is going to be a highly regionalized market. This is not going to be a roll up. One is that there's no need. There's no There's no pressure, actually, to use Cloud to do these things. The second is political factors people rank based on geopolitics and political relations like that is very, very clear in all of our customer behavior. And you hear that also in the video. The video saying sovereign, am so that so that, again, plays to our favor. The third is that if you look at what is going to be the ongoing constraint, a within the compute space. As you think about that capacity on the data center is going to be more triple the next, next to the end of this decade, like all that's going to be Greenfield space at which the most important person in that relationship is the data center. So when they are doing all this new capacity raw, they're going to need some fabric to run, whether or not they list it on fast or together, or even friends, or any of that stuff. Like, like, we don't really care. Like, that's not, that's not our motivation. Fact, I don't even really care if you buy the video you're done. My goal is, like, are you making the maximum amount of money data center, right, that you can so, so our relationship is, is much more, let's say, like, a like, a franchise model, right? That's how we're actually working. Then inference AI, which inference a sort of, like, it's like, it's like, saying, okay, like, we're like, Chick fil A, right? Or something like that. And everyone's AI is, like, run up, right? Like, that's, that's like, that's what everyone's AI is doing. Or these AI companies, right? They're higher level abstractions. They're not actually running the covid business with the data center. And the last point, which is how we're going to be fundamentally different than this separation space, is we think that the space is going to become increasingly oriented on demand. We, right now, are the only product in the world that gives on demand white label as a service, where you can list every on demand product you want via API or via website, put it on your data center website, and then people can go in there and check out what they call it, so that, that's how that, yeah, so that's how we're like, replicates never going to do that like, they're never going to give a software out to data centers to, like, whether or not they sell on replicate or something else, because replicate is a verticalized business, right? We are a horizontal business where we add these modular components similar to like franchise model, and it grows the value of the franchise, right? So, so that's how we're operating, as a complete
S Speaker 224:18horizontal player, and probably a data center like so how many customers do you have today? We
horizontal player, and probably a data center like so how many customers do you have today? We
horizontal player, and probably a data center like so how many customers do you have today? We
horizontal player, and probably a data center like so how many customers do you have today? We
S Speaker 124:27have a little over two dozen data centers. And I think on demand side, it's like, I can't I think it's like 50 demand cost 50. You see, I think it's like 50 demand customers, 50 or seven, somewhere to 1575,
have a little over two dozen data centers. And I think on demand side, it's like, I can't I think it's like 50 demand cost 50. You see, I think it's like 50 demand customers, 50 or seven, somewhere to 1575,
have a little over two dozen data centers. And I think on demand side, it's like, I can't I think it's like 50 demand cost 50. You see, I think it's like 50 demand customers, 50 or seven, somewhere to 1575,
have a little over two dozen data centers. And I think on demand side, it's like, I can't I think it's like 50 demand cost 50. You see, I think it's like 50 demand customers, 50 or seven, somewhere to 1575,
S Speaker 224:37do you also sell to the demand customers? Or do you just sell to the data centers? And data centers sell to the demand customers for
do you also sell to the demand customers? Or do you just sell to the data centers? And data centers sell to the demand customers for
do you also sell to the demand customers? Or do you just sell to the data centers? And data centers sell to the demand customers for
do you also sell to the demand customers? Or do you just sell to the data centers? And data centers sell to the demand customers for
S Speaker 124:45you both, because the data center uses our monetization player, so we own the contract. It bills through us, like Shopify. Right when you buy through Shopify, it builds through Shopify. You have a legal agreement with Shopify to do that transaction so, we see all the customer data that appears.
you both, because the data center uses our monetization player, so we own the contract. It bills through us, like Shopify. Right when you buy through Shopify, it builds through Shopify. You have a legal agreement with Shopify to do that transaction so, we see all the customer data that appears.
you both, because the data center uses our monetization player, so we own the contract. It bills through us, like Shopify. Right when you buy through Shopify, it builds through Shopify. You have a legal agreement with Shopify to do that transaction so, we see all the customer data that appears.
you both, because the data center uses our monetization player, so we own the contract. It bills through us, like Shopify. Right when you buy through Shopify, it builds through Shopify. You have a legal agreement with Shopify to do that transaction so, we see all the customer data that appears.
S Speaker 225:16probably AI has been a big boost to the company. So in terms of revenue last year, and what are you planning to do this year?
probably AI has been a big boost to the company. So in terms of revenue last year, and what are you planning to do this year?
probably AI has been a big boost to the company. So in terms of revenue last year, and what are you planning to do this year?
probably AI has been a big boost to the company. So in terms of revenue last year, and what are you planning to do this year?
S Speaker 125:26Think last year, I think we annualized, was around 2 million in ARR, and then this year, we're on track for, like, probably 200 million.
Think last year, I think we annualized, was around 2 million in ARR, and then this year, we're on track for, like, probably 200 million.
Think last year, I think we annualized, was around 2 million in ARR, and then this year, we're on track for, like, probably 200 million.
Think last year, I think we annualized, was around 2 million in ARR, and then this year, we're on track for, like, probably 200 million.
S Speaker 125:40yeah, recurring, yeah, so that that's recurring, GMB is best way probably to categorize it, but
yeah, recurring, yeah, so that that's recurring, GMB is best way probably to categorize it, but
yeah, recurring, yeah, so that that's recurring, GMB is best way probably to categorize it, but
yeah, recurring, yeah, so that that's recurring, GMB is best way probably to categorize it, but
S Speaker 225:54what's the actual realized revenue for you?
S Speaker 126:00So it ranges, because most of our contracts are long term. So we have, I think the mean average of our contracts is like 12 months. So on the longer term stuff, we shoot for 5% take on the on demand stuff, we shoot for 12 and a half. So anything less than a month is around 12 and a half, and anything long terms around 5% so it's a blended mix of all that
So it ranges, because most of our contracts are long term. So we have, I think the mean average of our contracts is like 12 months. So on the longer term stuff, we shoot for 5% take on the on demand stuff, we shoot for 12 and a half. So anything less than a month is around 12 and a half, and anything long terms around 5% so it's a blended mix of all that
So it ranges, because most of our contracts are long term. So we have, I think the mean average of our contracts is like 12 months. So on the longer term stuff, we shoot for 5% take on the on demand stuff, we shoot for 12 and a half. So anything less than a month is around 12 and a half, and anything long terms around 5% so it's a blended mix of all that
So it ranges, because most of our contracts are long term. So we have, I think the mean average of our contracts is like 12 months. So on the longer term stuff, we shoot for 5% take on the on demand stuff, we shoot for 12 and a half. So anything less than a month is around 12 and a half, and anything long terms around 5% so it's a blended mix of all that
S Speaker 226:27But what do you so maybe either one would be with what revenue wise?
But what do you so maybe either one would be with what revenue wise?
But what do you so maybe either one would be with what revenue wise?
But what do you so maybe either one would be with what revenue wise?
26:33Where do you think you can be the lender this year?
Where do you think you can be the lender this year?
Where do you think you can be the lender this year?
Where do you think you can be the lender this year?
S Speaker 126:37I had to go look at the because, because we measure everything on the GMP side, we probably like, I don't know, yeah, it's gonna be somewhere in the you know, you multiply. Let's say, if you take a blend of 12 and a half and five, you take it probably 8% of that, something like that.
I had to go look at the because, because we measure everything on the GMP side, we probably like, I don't know, yeah, it's gonna be somewhere in the you know, you multiply. Let's say, if you take a blend of 12 and a half and five, you take it probably 8% of that, something like that.
I had to go look at the because, because we measure everything on the GMP side, we probably like, I don't know, yeah, it's gonna be somewhere in the you know, you multiply. Let's say, if you take a blend of 12 and a half and five, you take it probably 8% of that, something like that.
I had to go look at the because, because we measure everything on the GMP side, we probably like, I don't know, yeah, it's gonna be somewhere in the you know, you multiply. Let's say, if you take a blend of 12 and a half and five, you take it probably 8% of that, something like that.
S Speaker 227:14around 18 or $16 million in revenue this year after
around 18 or $16 million in revenue this year after
around 18 or $16 million in revenue this year after
around 18 or $16 million in revenue this year after
S Speaker 127:22your removal, so it'd be like, net, gross,
S Speaker 227:27gross, yeah. So that would be, that's what. And then year today, where are you today,
gross, yeah. So that would be, that's what. And then year today, where are you today,
gross, yeah. So that would be, that's what. And then year today, where are you today,
gross, yeah. So that would be, that's what. And then year today, where are you today,
S Speaker 227:38even if we can take the 8% again, right? So
S Speaker 127:44we, we've done, I think we've done around,
S Speaker 227:58so, so 40 or 50, so you're at around
S Speaker 128:06think that's about right. I mean, it was a ballpark on it. We haven't, yeah,
think that's about right. I mean, it was a ballpark on it. We haven't, yeah,
think that's about right. I mean, it was a ballpark on it. We haven't, yeah,
think that's about right. I mean, it was a ballpark on it. We haven't, yeah,
S Speaker 228:12okay, got it? Okay, that's good. Good traction. And then how big is the team? 18. That's good.
okay, got it? Okay, that's good. Good traction. And then how big is the team? 18. That's good.
okay, got it? Okay, that's good. Good traction. And then how big is the team? 18. That's good.
okay, got it? Okay, that's good. Good traction. And then how big is the team? 18. That's good.
S Speaker 228:29call and but we we can follow up. Let me discuss with our team as well. Would love to follow up? Would you do you have have, like, in sort of an architecture diagram somewhere that shows how where your software fits into this data center stack and how your customers are building on top of it.
call and but we we can follow up. Let me discuss with our team as well. Would love to follow up? Would you do you have have, like, in sort of an architecture diagram somewhere that shows how where your software fits into this data center stack and how your customers are building on top of it.
call and but we we can follow up. Let me discuss with our team as well. Would love to follow up? Would you do you have have, like, in sort of an architecture diagram somewhere that shows how where your software fits into this data center stack and how your customers are building on top of it.
call and but we we can follow up. Let me discuss with our team as well. Would love to follow up? Would you do you have have, like, in sort of an architecture diagram somewhere that shows how where your software fits into this data center stack and how your customers are building on top of it.
S Speaker 128:57If I don't have something, I can just make something a hero really fast that you have, okay, so that would
If I don't have something, I can just make something a hero really fast that you have, okay, so that would
If I don't have something, I can just make something a hero really fast that you have, okay, so that would
If I don't have something, I can just make something a hero really fast that you have, okay, so that would
S Speaker 229:04get our team to understand where this fits. Well. Funding wise,
get our team to understand where this fits. Well. Funding wise,
get our team to understand where this fits. Well. Funding wise,
get our team to understand where this fits. Well. Funding wise,
S Speaker 229:15Okay, so $12 million and then who are the key investors?
Okay, so $12 million and then who are the key investors?
Okay, so $12 million and then who are the key investors?
Okay, so $12 million and then who are the key investors?
S Speaker 129:25last round? Was they think just over 34 million
S Speaker 229:28posts? Okay, then this was last year.
S Speaker 129:32They would have been a little bit over that. I think it's like almost two years. Because right now we're, we are floating around profitability. We've been that way for about six months. So we, we've extended the runway, probably for a
They would have been a little bit over that. I think it's like almost two years. Because right now we're, we are floating around profitability. We've been that way for about six months. So we, we've extended the runway, probably for a
They would have been a little bit over that. I think it's like almost two years. Because right now we're, we are floating around profitability. We've been that way for about six months. So we, we've extended the runway, probably for a
They would have been a little bit over that. I think it's like almost two years. Because right now we're, we are floating around profitability. We've been that way for about six months. So we, we've extended the runway, probably for a
S Speaker 229:59So, and you're looking away. So this would be what series A or
So, and you're looking away. So this would be what series A or
So, and you're looking away. So this would be what series A or
So, and you're looking away. So this would be what series A or
S Speaker 130:03B. So Series A, we are looking to do about 25 million right now. We're looking at for, mostly for a lead. We already have all the other capital following. We do have close to term sheet, so two other firms. We also have an offer for inside around because we just closed our first ever billion dollar customer. It's approximately gonna be little over $1 billion and he's gonna pay mostly on front for his first order. So that's gonna give us a lot of capital. So we are gonna probably make a decision here soon about what we're going to do. We've been on this kind of roadshow for like, about three, four weeks, and we have like, eight firms that are, like, in various forms of, you know, data room or questions, and two, or probably two, have committed to some form of working through a term sheet. But, you know, our insiders because, you know, I informed them of the business progress, they because we landed this unicorn customers. We have, like, four we have customers. Two of them are active customers, and two of them are we'll see. And, and so they, you know, they knew that, like, the 10 figure guy was converted, so they offered us some insider stuff as well. So we have a couple options on the table. We're gonna figure out what we're gonna do in the next week or so. Okay,
B. So Series A, we are looking to do about 25 million right now. We're looking at for, mostly for a lead. We already have all the other capital following. We do have close to term sheet, so two other firms. We also have an offer for inside around because we just closed our first ever billion dollar customer. It's approximately gonna be little over $1 billion and he's gonna pay mostly on front for his first order. So that's gonna give us a lot of capital. So we are gonna probably make a decision here soon about what we're going to do. We've been on this kind of roadshow for like, about three, four weeks, and we have like, eight firms that are, like, in various forms of, you know, data room or questions, and two, or probably two, have committed to some form of working through a term sheet. But, you know, our insiders because, you know, I informed them of the business progress, they because we landed this unicorn customers. We have, like, four we have customers. Two of them are active customers, and two of them are we'll see. And, and so they, you know, they knew that, like, the 10 figure guy was converted, so they offered us some insider stuff as well. So we have a couple options on the table. We're gonna figure out what we're gonna do in the next week or so. Okay,
B. So Series A, we are looking to do about 25 million right now. We're looking at for, mostly for a lead. We already have all the other capital following. We do have close to term sheet, so two other firms. We also have an offer for inside around because we just closed our first ever billion dollar customer. It's approximately gonna be little over $1 billion and he's gonna pay mostly on front for his first order. So that's gonna give us a lot of capital. So we are gonna probably make a decision here soon about what we're going to do. We've been on this kind of roadshow for like, about three, four weeks, and we have like, eight firms that are, like, in various forms of, you know, data room or questions, and two, or probably two, have committed to some form of working through a term sheet. But, you know, our insiders because, you know, I informed them of the business progress, they because we landed this unicorn customers. We have, like, four we have customers. Two of them are active customers, and two of them are we'll see. And, and so they, you know, they knew that, like, the 10 figure guy was converted, so they offered us some insider stuff as well. So we have a couple options on the table. We're gonna figure out what we're gonna do in the next week or so. Okay,
B. So Series A, we are looking to do about 25 million right now. We're looking at for, mostly for a lead. We already have all the other capital following. We do have close to term sheet, so two other firms. We also have an offer for inside around because we just closed our first ever billion dollar customer. It's approximately gonna be little over $1 billion and he's gonna pay mostly on front for his first order. So that's gonna give us a lot of capital. So we are gonna probably make a decision here soon about what we're going to do. We've been on this kind of roadshow for like, about three, four weeks, and we have like, eight firms that are, like, in various forms of, you know, data room or questions, and two, or probably two, have committed to some form of working through a term sheet. But, you know, our insiders because, you know, I informed them of the business progress, they because we landed this unicorn customers. We have, like, four we have customers. Two of them are active customers, and two of them are we'll see. And, and so they, you know, they knew that, like, the 10 figure guy was converted, so they offered us some insider stuff as well. So we have a couple options on the table. We're gonna figure out what we're gonna do in the next week or so. Okay,
S Speaker 231:29I'm guessing. So you either have people already running, so see, we were corporate, so we won't be able to run fast and give you a term sheet in the timeframe that you expect. I'm guessing you're expecting a term sheet or few term sheets within the next week or two, and then you would want to make a decision in that timeframe. Is that right? Erin,
I'm guessing. So you either have people already running, so see, we were corporate, so we won't be able to run fast and give you a term sheet in the timeframe that you expect. I'm guessing you're expecting a term sheet or few term sheets within the next week or two, and then you would want to make a decision in that timeframe. Is that right? Erin,
I'm guessing. So you either have people already running, so see, we were corporate, so we won't be able to run fast and give you a term sheet in the timeframe that you expect. I'm guessing you're expecting a term sheet or few term sheets within the next week or two, and then you would want to make a decision in that timeframe. Is that right? Erin,
I'm guessing. So you either have people already running, so see, we were corporate, so we won't be able to run fast and give you a term sheet in the timeframe that you expect. I'm guessing you're expecting a term sheet or few term sheets within the next week or two, and then you would want to make a decision in that timeframe. Is that right? Erin,
S Speaker 131:58I mean the on the terms. I mean, we have not be all be transparent, like we haven't received the only offer received from insiders. So and with the capital plus from the customer, which is obviously non dilutive, it's great for them. You know, my insiders don't care about the really about the next round. They care about us making money and and so it's a very interesting kind of pool and play because, because we do make money, and we've already been able to create, like, you know, more than ten million of top line per cut for employee, right? And it's a really just working on gross margins. And we already have, like, a very clear plan for all that stuff. And because, you know, like, we shifted the business from, like, for the first two quarters, we were focusing only on top line, because top line drives installations right installations drive top line revenue. And it was this nice matrix. And then now we're moving towards the gross margins layer, and so we're seeing more and more improvement there already. And so, yeah, we're we would prefer to do the A because we have a couple banks that want to create our lending facility for this, which is another area we're going to get gross margin on, which is because essentially how I just, I know you have to go, but just kind of quickly, how the model sort of works is like, we don't spend money on marketing. Like, of course, we have a marketing person. We have one person that does marketing right, because you need to something right. But we don't really have a need for doing some form of like pay, right? Because how it works is we are a VAR we get var pricing right, which, I know you're welcome totally get that right, but bars right? So, yep, I don't sell for var price, because I make money when someone ranks. So I sell it basically at the exact price that the OEM gives it to me Id every single person that that DC is buying from, every single person, they then buy from us. We send it with our machine. Now we have the loot, right? So essentially, data centers come to us to buy hardware because we give it to the lowest cost in the whole market. Because I don't have to make money ever, right? I make money on the rental side. So that's actually how we're driving installations, is, I found a way to, like, commoditize someone else out of the of the procurement cycle, because Dell or computer center or trace a whoever, nutrix has to make money on that transaction. I don't have to make money on my transaction. And that's how we're we've done the motion right. So we're getting we want to do an A, because, again, a already have to do two or three over the banks that would give us essentially double the amount on the lending capacity side. And then then would offer these, like these, like lending facilities to our data center so they get more stuff. And so, so that's actually how we're driving acquisition, is I'm selling the hardware at dirt cheap pricing, because I don't have to make money on that and what. But what does that mean on the rental side, right? Therefore I can charge a higher margin on the rental front, right?
I mean the on the terms. I mean, we have not be all be transparent, like we haven't received the only offer received from insiders. So and with the capital plus from the customer, which is obviously non dilutive, it's great for them. You know, my insiders don't care about the really about the next round. They care about us making money and and so it's a very interesting kind of pool and play because, because we do make money, and we've already been able to create, like, you know, more than ten million of top line per cut for employee, right? And it's a really just working on gross margins. And we already have, like, a very clear plan for all that stuff. And because, you know, like, we shifted the business from, like, for the first two quarters, we were focusing only on top line, because top line drives installations right installations drive top line revenue. And it was this nice matrix. And then now we're moving towards the gross margins layer, and so we're seeing more and more improvement there already. And so, yeah, we're we would prefer to do the A because we have a couple banks that want to create our lending facility for this, which is another area we're going to get gross margin on, which is because essentially how I just, I know you have to go, but just kind of quickly, how the model sort of works is like, we don't spend money on marketing. Like, of course, we have a marketing person. We have one person that does marketing right, because you need to something right. But we don't really have a need for doing some form of like pay, right? Because how it works is we are a VAR we get var pricing right, which, I know you're welcome totally get that right, but bars right? So, yep, I don't sell for var price, because I make money when someone ranks. So I sell it basically at the exact price that the OEM gives it to me Id every single person that that DC is buying from, every single person, they then buy from us. We send it with our machine. Now we have the loot, right? So essentially, data centers come to us to buy hardware because we give it to the lowest cost in the whole market. Because I don't have to make money ever, right? I make money on the rental side. So that's actually how we're driving installations, is, I found a way to, like, commoditize someone else out of the of the procurement cycle, because Dell or computer center or trace a whoever, nutrix has to make money on that transaction. I don't have to make money on my transaction. And that's how we're we've done the motion right. So we're getting we want to do an A, because, again, a already have to do two or three over the banks that would give us essentially double the amount on the lending capacity side. And then then would offer these, like these, like lending facilities to our data center so they get more stuff. And so, so that's actually how we're driving acquisition, is I'm selling the hardware at dirt cheap pricing, because I don't have to make money on that and what. But what does that mean on the rental side, right? Therefore I can charge a higher margin on the rental front, right?
I mean the on the terms. I mean, we have not be all be transparent, like we haven't received the only offer received from insiders. So and with the capital plus from the customer, which is obviously non dilutive, it's great for them. You know, my insiders don't care about the really about the next round. They care about us making money and and so it's a very interesting kind of pool and play because, because we do make money, and we've already been able to create, like, you know, more than ten million of top line per cut for employee, right? And it's a really just working on gross margins. And we already have, like, a very clear plan for all that stuff. And because, you know, like, we shifted the business from, like, for the first two quarters, we were focusing only on top line, because top line drives installations right installations drive top line revenue. And it was this nice matrix. And then now we're moving towards the gross margins layer, and so we're seeing more and more improvement there already. And so, yeah, we're we would prefer to do the A because we have a couple banks that want to create our lending facility for this, which is another area we're going to get gross margin on, which is because essentially how I just, I know you have to go, but just kind of quickly, how the model sort of works is like, we don't spend money on marketing. Like, of course, we have a marketing person. We have one person that does marketing right, because you need to something right. But we don't really have a need for doing some form of like pay, right? Because how it works is we are a VAR we get var pricing right, which, I know you're welcome totally get that right, but bars right? So, yep, I don't sell for var price, because I make money when someone ranks. So I sell it basically at the exact price that the OEM gives it to me Id every single person that that DC is buying from, every single person, they then buy from us. We send it with our machine. Now we have the loot, right? So essentially, data centers come to us to buy hardware because we give it to the lowest cost in the whole market. Because I don't have to make money ever, right? I make money on the rental side. So that's actually how we're driving installations, is, I found a way to, like, commoditize someone else out of the of the procurement cycle, because Dell or computer center or trace a whoever, nutrix has to make money on that transaction. I don't have to make money on my transaction. And that's how we're we've done the motion right. So we're getting we want to do an A, because, again, a already have to do two or three over the banks that would give us essentially double the amount on the lending capacity side. And then then would offer these, like these, like lending facilities to our data center so they get more stuff. And so, so that's actually how we're driving acquisition, is I'm selling the hardware at dirt cheap pricing, because I don't have to make money on that and what. But what does that mean on the rental side, right? Therefore I can charge a higher margin on the rental front, right?
I mean the on the terms. I mean, we have not be all be transparent, like we haven't received the only offer received from insiders. So and with the capital plus from the customer, which is obviously non dilutive, it's great for them. You know, my insiders don't care about the really about the next round. They care about us making money and and so it's a very interesting kind of pool and play because, because we do make money, and we've already been able to create, like, you know, more than ten million of top line per cut for employee, right? And it's a really just working on gross margins. And we already have, like, a very clear plan for all that stuff. And because, you know, like, we shifted the business from, like, for the first two quarters, we were focusing only on top line, because top line drives installations right installations drive top line revenue. And it was this nice matrix. And then now we're moving towards the gross margins layer, and so we're seeing more and more improvement there already. And so, yeah, we're we would prefer to do the A because we have a couple banks that want to create our lending facility for this, which is another area we're going to get gross margin on, which is because essentially how I just, I know you have to go, but just kind of quickly, how the model sort of works is like, we don't spend money on marketing. Like, of course, we have a marketing person. We have one person that does marketing right, because you need to something right. But we don't really have a need for doing some form of like pay, right? Because how it works is we are a VAR we get var pricing right, which, I know you're welcome totally get that right, but bars right? So, yep, I don't sell for var price, because I make money when someone ranks. So I sell it basically at the exact price that the OEM gives it to me Id every single person that that DC is buying from, every single person, they then buy from us. We send it with our machine. Now we have the loot, right? So essentially, data centers come to us to buy hardware because we give it to the lowest cost in the whole market. Because I don't have to make money ever, right? I make money on the rental side. So that's actually how we're driving installations, is, I found a way to, like, commoditize someone else out of the of the procurement cycle, because Dell or computer center or trace a whoever, nutrix has to make money on that transaction. I don't have to make money on my transaction. And that's how we're we've done the motion right. So we're getting we want to do an A, because, again, a already have to do two or three over the banks that would give us essentially double the amount on the lending capacity side. And then then would offer these, like these, like lending facilities to our data center so they get more stuff. And so, so that's actually how we're driving acquisition, is I'm selling the hardware at dirt cheap pricing, because I don't have to make money on that and what. But what does that mean on the rental side, right? Therefore I can charge a higher margin on the rental front, right?
S Speaker 234:48So what I'm trying to understand is, is there even like for this round? Would you even consider us for this round, given that you already have an insider term sheet, and you have two potential leads. And then, since you don't have room for another besides a lead, so there's only a room for one lead, one external investor, and then for that external investor, you have two candidates that are running towards giving you a term sheet, I get it that you don't have one yet, but given our process, it's really long, I'm not going to be able to give you a term sheet even if it wanted to, within the next two to three weeks. So so I'm trying to understand if there's even room for us in this round.
So what I'm trying to understand is, is there even like for this round? Would you even consider us for this round, given that you already have an insider term sheet, and you have two potential leads. And then, since you don't have room for another besides a lead, so there's only a room for one lead, one external investor, and then for that external investor, you have two candidates that are running towards giving you a term sheet, I get it that you don't have one yet, but given our process, it's really long, I'm not going to be able to give you a term sheet even if it wanted to, within the next two to three weeks. So so I'm trying to understand if there's even room for us in this round.
So what I'm trying to understand is, is there even like for this round? Would you even consider us for this round, given that you already have an insider term sheet, and you have two potential leads. And then, since you don't have room for another besides a lead, so there's only a room for one lead, one external investor, and then for that external investor, you have two candidates that are running towards giving you a term sheet, I get it that you don't have one yet, but given our process, it's really long, I'm not going to be able to give you a term sheet even if it wanted to, within the next two to three weeks. So so I'm trying to understand if there's even room for us in this round.
So what I'm trying to understand is, is there even like for this round? Would you even consider us for this round, given that you already have an insider term sheet, and you have two potential leads. And then, since you don't have room for another besides a lead, so there's only a room for one lead, one external investor, and then for that external investor, you have two candidates that are running towards giving you a term sheet, I get it that you don't have one yet, but given our process, it's really long, I'm not going to be able to give you a term sheet even if it wanted to, within the next two to three weeks. So so I'm trying to understand if there's even room for us in this round.
S Speaker 135:40Yeah. I mean, that's fair. I mean, like, yeah, like, it's, it's a as a CEO. I mean, I'm sure you know from other CEOs, right? I get lots of words about term sheets, until I see it, it doesn't exist, right?
Yeah. I mean, that's fair. I mean, like, yeah, like, it's, it's a as a CEO. I mean, I'm sure you know from other CEOs, right? I get lots of words about term sheets, until I see it, it doesn't exist, right?
Yeah. I mean, that's fair. I mean, like, yeah, like, it's, it's a as a CEO. I mean, I'm sure you know from other CEOs, right? I get lots of words about term sheets, until I see it, it doesn't exist, right?
Yeah. I mean, that's fair. I mean, like, yeah, like, it's, it's a as a CEO. I mean, I'm sure you know from other CEOs, right? I get lots of words about term sheets, until I see it, it doesn't exist, right?
S Speaker 235:50So, but, but if you get that term sheet, then you don't have room for us. Is that, right?
So, but, but if you get that term sheet, then you don't have room for us. Is that, right?
So, but, but if you get that term sheet, then you don't have room for us. Is that, right?
So, but, but if you get that term sheet, then you don't have room for us. Is that, right?
S Speaker 135:57We have root for probably one strategic in the $25
S Speaker 236:03And the thing is, our room. So the reason I want to spend I want to figure out if we should both spend time together, and that's why I'm asking you these questions, which is, we would need at least a minimum of four to $5 million for us to be, uh, able to participate in the round is, given the constraints that you have with the round size, with one lead and with insider demand, would you think that would there could be a room for a strategic to get four to $5 million in the round?
And the thing is, our room. So the reason I want to spend I want to figure out if we should both spend time together, and that's why I'm asking you these questions, which is, we would need at least a minimum of four to $5 million for us to be, uh, able to participate in the round is, given the constraints that you have with the round size, with one lead and with insider demand, would you think that would there could be a room for a strategic to get four to $5 million in the round?
And the thing is, our room. So the reason I want to spend I want to figure out if we should both spend time together, and that's why I'm asking you these questions, which is, we would need at least a minimum of four to $5 million for us to be, uh, able to participate in the round is, given the constraints that you have with the round size, with one lead and with insider demand, would you think that would there could be a room for a strategic to get four to $5 million in the round?
And the thing is, our room. So the reason I want to spend I want to figure out if we should both spend time together, and that's why I'm asking you these questions, which is, we would need at least a minimum of four to $5 million for us to be, uh, able to participate in the round is, given the constraints that you have with the round size, with one lead and with insider demand, would you think that would there could be a room for a strategic to get four to $5 million in the round?
S Speaker 136:39Yeah, yeah. So, the lead is going to take 50, 50% sorry, and then pro rata rights is around. We don't do very little pro rata rights.
Yeah, yeah. So, the lead is going to take 50, 50% sorry, and then pro rata rights is around. We don't do very little pro rata rights.
Yeah, yeah. So, the lead is going to take 50, 50% sorry, and then pro rata rights is around. We don't do very little pro rata rights.
Yeah, yeah. So, the lead is going to take 50, 50% sorry, and then pro rata rights is around. We don't do very little pro rata rights.
S Speaker 136:56and then the rest would be we want to and it all be new. So we have some people that you know, and all those would just be everyone we've talked to that we they decided not to lead, or they don't lead. And so we, we have been talking to strategic like I've talked to Intel Capital, talking the video talk to like a data center investment company. So we are looking at a strategic because we think that we exist in this plane in the data center automation space that a lot of people want to play in, and we want to provide some some extra trajectory for us there, like you seen you're like a sure, like having a T or a B, C, give us a lead check is great, right? But having a strategic right outside of like our main strategic nowadays from space is the CEO of Sun Microsystems, Scott McNeil, right? He's a big investor, so obviously, that's some validation, right? And some of the GPU cloud companies are gonna do some small checks into the next round. But what we really want is somebody that's like, Oh, yes, they're an OEM. We would prefer, you know, I'm talking to video, of course, because the king, right, of course, the king, right. So, but we prefer someone who isn't like a, you know, like, oh, because, if anybody invests the amp, is gonna, like, not like us, right? So we prefer not that we refer to somebody who's, like, more neutral in the space, like a Cisco, right? Or, like, a, you know, something like that, like, okay, yeah, okay, which is more like yellow, right? Yeah,
and then the rest would be we want to and it all be new. So we have some people that you know, and all those would just be everyone we've talked to that we they decided not to lead, or they don't lead. And so we, we have been talking to strategic like I've talked to Intel Capital, talking the video talk to like a data center investment company. So we are looking at a strategic because we think that we exist in this plane in the data center automation space that a lot of people want to play in, and we want to provide some some extra trajectory for us there, like you seen you're like a sure, like having a T or a B, C, give us a lead check is great, right? But having a strategic right outside of like our main strategic nowadays from space is the CEO of Sun Microsystems, Scott McNeil, right? He's a big investor, so obviously, that's some validation, right? And some of the GPU cloud companies are gonna do some small checks into the next round. But what we really want is somebody that's like, Oh, yes, they're an OEM. We would prefer, you know, I'm talking to video, of course, because the king, right, of course, the king, right. So, but we prefer someone who isn't like a, you know, like, oh, because, if anybody invests the amp, is gonna, like, not like us, right? So we prefer not that we refer to somebody who's, like, more neutral in the space, like a Cisco, right? Or, like, a, you know, something like that, like, okay, yeah, okay, which is more like yellow, right? Yeah,
and then the rest would be we want to and it all be new. So we have some people that you know, and all those would just be everyone we've talked to that we they decided not to lead, or they don't lead. And so we, we have been talking to strategic like I've talked to Intel Capital, talking the video talk to like a data center investment company. So we are looking at a strategic because we think that we exist in this plane in the data center automation space that a lot of people want to play in, and we want to provide some some extra trajectory for us there, like you seen you're like a sure, like having a T or a B, C, give us a lead check is great, right? But having a strategic right outside of like our main strategic nowadays from space is the CEO of Sun Microsystems, Scott McNeil, right? He's a big investor, so obviously, that's some validation, right? And some of the GPU cloud companies are gonna do some small checks into the next round. But what we really want is somebody that's like, Oh, yes, they're an OEM. We would prefer, you know, I'm talking to video, of course, because the king, right, of course, the king, right. So, but we prefer someone who isn't like a, you know, like, oh, because, if anybody invests the amp, is gonna, like, not like us, right? So we prefer not that we refer to somebody who's, like, more neutral in the space, like a Cisco, right? Or, like, a, you know, something like that, like, okay, yeah, okay, which is more like yellow, right? Yeah,
and then the rest would be we want to and it all be new. So we have some people that you know, and all those would just be everyone we've talked to that we they decided not to lead, or they don't lead. And so we, we have been talking to strategic like I've talked to Intel Capital, talking the video talk to like a data center investment company. So we are looking at a strategic because we think that we exist in this plane in the data center automation space that a lot of people want to play in, and we want to provide some some extra trajectory for us there, like you seen you're like a sure, like having a T or a B, C, give us a lead check is great, right? But having a strategic right outside of like our main strategic nowadays from space is the CEO of Sun Microsystems, Scott McNeil, right? He's a big investor, so obviously, that's some validation, right? And some of the GPU cloud companies are gonna do some small checks into the next round. But what we really want is somebody that's like, Oh, yes, they're an OEM. We would prefer, you know, I'm talking to video, of course, because the king, right, of course, the king, right. So, but we prefer someone who isn't like a, you know, like, oh, because, if anybody invests the amp, is gonna, like, not like us, right? So we prefer not that we refer to somebody who's, like, more neutral in the space, like a Cisco, right? Or, like, a, you know, something like that, like, okay, yeah, okay, which is more like yellow, right? Yeah,
S Speaker 238:25yeah. We're more neutral here right now. We do want to go in, into the CPU space, hard as well, actually. But for the teams eventually, not yet, just yet.
yeah. We're more neutral here right now. We do want to go in, into the CPU space, hard as well, actually. But for the teams eventually, not yet, just yet.
yeah. We're more neutral here right now. We do want to go in, into the CPU space, hard as well, actually. But for the teams eventually, not yet, just yet.
yeah. We're more neutral here right now. We do want to go in, into the CPU space, hard as well, actually. But for the teams eventually, not yet, just yet.
S Speaker 238:44Do you have a pitch deck that you could send it to us? Oh, yeah, I
Do you have a pitch deck that you could send it to us? Oh, yeah, I
Do you have a pitch deck that you could send it to us? Oh, yeah, I
Do you have a pitch deck that you could send it to us? Oh, yeah, I
38:48thought you had it. Yeah, sure. I'm happy to Yeah,
S Speaker 238:51yeah. That would be great. Thanks, of course. Okay,
yeah. That would be great. Thanks, of course. Okay,
yeah. That would be great. Thanks, of course. Okay,
yeah. That would be great. Thanks, of course. Okay,
S Speaker 139:02Yeah? I sent him a technical outbreak, and I actually don't know what happened after that. So,
Yeah? I sent him a technical outbreak, and I actually don't know what happened after that. So,
Yeah? I sent him a technical outbreak, and I actually don't know what happened after that. So,
Yeah? I sent him a technical outbreak, and I actually don't know what happened after that. So,
S Speaker 239:10yeah, can you send that technical out brief to me as well? Yeah, happy to Yes. Okay, yeah, thanks. And so we will follow up, and I'll be back to you Sure. Okay, thank you. Yeah, thanks for your time. Okay, thank you.
yeah, can you send that technical out brief to me as well? Yeah, happy to Yes. Okay, yeah, thanks. And so we will follow up, and I'll be back to you Sure. Okay, thank you. Yeah, thanks for your time. Okay, thank you.
yeah, can you send that technical out brief to me as well? Yeah, happy to Yes. Okay, yeah, thanks. And so we will follow up, and I'll be back to you Sure. Okay, thank you. Yeah, thanks for your time. Okay, thank you.
yeah, can you send that technical out brief to me as well? Yeah, happy to Yes. Okay, yeah, thanks. And so we will follow up, and I'll be back to you Sure. Okay, thank you. Yeah, thanks for your time. Okay, thank you.