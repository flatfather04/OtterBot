Meeting: Refuel - Demo call
Tue, Nov 5, 2024
1:01 PM
33 min
Priyesh P
Enterprise Workflow Solutions and Posit
URL: https://otter.ai/u/2Yt_k5c-SQd2FCykQI0IuSAFmUw
Downloaded: 2025-12-22T13:52:26.383647
Method: text_extraction
============================================================

0:16I think he's short for Rishi. Oh, is he short for, I thought he was also Risha.
I think he's short for Rishi. Oh, is he short for, I thought he was also Risha.
I think he's short for Rishi. Oh, is he short for, I thought he was also Risha.
I think he's short for Rishi. Oh, is he short for, I thought he was also Risha.
S Speaker 10:34Yeah, because Rishi, like short enough from Priyesh. You know that like Priyesh is easy enough. I think it's only worth like shorting in progression, like your longest line and the name is actually as long as continue.
Yeah, because Rishi, like short enough from Priyesh. You know that like Priyesh is easy enough. I think it's only worth like shorting in progression, like your longest line and the name is actually as long as continue.
Yeah, because Rishi, like short enough from Priyesh. You know that like Priyesh is easy enough. I think it's only worth like shorting in progression, like your longest line and the name is actually as long as continue.
Yeah, because Rishi, like short enough from Priyesh. You know that like Priyesh is easy enough. I think it's only worth like shorting in progression, like your longest line and the name is actually as long as continue.
1:00Let's continue from where we left off, which
Let's continue from where we left off, which
Let's continue from where we left off, which
Let's continue from where we left off, which
1:07a few things. So one,
a few things. So one,
a few things. So one,
a few things. So one,
1:08let's walk through. The
let's walk through. The
let's walk through. The
let's walk through. The
1:22other thing, other things, also, we
other thing, other things, also, we
other thing, other things, also, we
other thing, other things, also, we
1:26would like address your positioning. But
would like address your positioning. But
would like address your positioning. But
would like address your positioning. But
S Speaker 21:28also some of the companies that you know like, there are many companies that are trying to solve enterprise, end to end enterprise work, whether it's
also some of the companies that you know like, there are many companies that are trying to solve enterprise, end to end enterprise work, whether it's
also some of the companies that you know like, there are many companies that are trying to solve enterprise, end to end enterprise work, whether it's
also some of the companies that you know like, there are many companies that are trying to solve enterprise, end to end enterprise work, whether it's
S Speaker 31:40like we discussed contextual like we discussed companies like contextual backgrounds and companies like much of these
like we discussed contextual like we discussed companies like contextual backgrounds and companies like much of these
like we discussed contextual like we discussed companies like contextual backgrounds and companies like much of these
like we discussed contextual like we discussed companies like contextual backgrounds and companies like much of these
1:55things, but then they're going And solving
things, but then they're going And solving
things, but then they're going And solving
things, but then they're going And solving
1:59end to end workflows for
end to end workflows for
end to end workflows for
end to end workflows for
S Speaker 22:02customers once you your positioning versus that? And then is your target customer, typically people who just want to build their workflow and occupation. You
customers once you your positioning versus that? And then is your target customer, typically people who just want to build their workflow and occupation. You
customers once you your positioning versus that? And then is your target customer, typically people who just want to build their workflow and occupation. You
customers once you your positioning versus that? And then is your target customer, typically people who just want to build their workflow and occupation. You
2:13know? What are you building? Are
know? What are you building? Are
know? What are you building? Are
know? What are you building? Are
2:14you doing that lab?
S Speaker 22:16I know you're providing endpoints. What are you doing going on that as
I know you're providing endpoints. What are you doing going on that as
I know you're providing endpoints. What are you doing going on that as
I know you're providing endpoints. What are you doing going on that as
S Speaker 12:22well? I Yeah, so maybe, I think there's maybe things in there, because contextual, and that's almost like very different companies. I think Tushar, as we talked about, like contextual like, I think for a lot of those types of companies that are building end user applications, right, because they're fine tuning rags like end user applications and co pilot it's like something that is like they have
well? I Yeah, so maybe, I think there's maybe things in there, because contextual, and that's almost like very different companies. I think Tushar, as we talked about, like contextual like, I think for a lot of those types of companies that are building end user applications, right, because they're fine tuning rags like end user applications and co pilot it's like something that is like they have
well? I Yeah, so maybe, I think there's maybe things in there, because contextual, and that's almost like very different companies. I think Tushar, as we talked about, like contextual like, I think for a lot of those types of companies that are building end user applications, right, because they're fine tuning rags like end user applications and co pilot it's like something that is like they have
well? I Yeah, so maybe, I think there's maybe things in there, because contextual, and that's almost like very different companies. I think Tushar, as we talked about, like contextual like, I think for a lot of those types of companies that are building end user applications, right, because they're fine tuning rags like end user applications and co pilot it's like something that is like they have
2:44to do all of this as well,
to do all of this as well,
to do all of this as well,
to do all of this as well,
S Speaker 12:47exactly for those customers. I think we will Bank, which is being partners, because they will not want to. Well, we'll see how this plays out, but it's unlikely that they will want to invest a lot of their core efforts. In terms of what does it take to clean structure, pre process data? Because the place where they would want to start out is look there is raw data that has been refined, that has been put back into a snow plate or into a vendor database, and it's now ready for, you know, all the applications that we're building that will make you build out. Because with applications, of course, you have to think about, okay, what is it means that, you know, user requirements, what are the types of queries they'll be asked with a bunch of work that needs to be done upstream of this green process data, whereas they will essentially want somebody to do this for them. This is going to be the case for contextual This is 100% going to be the case for companies like Databricks, because I might have mentioned this, but I know that, like data really trying to figure out how when they don't talk to their enterprise customers. I mean, imagine some semiconductor company, right? And that is just like they, they sit on, like, just massive, massive amounts of Qualcomm is also like semiconductor, but like I've heard from other customers, they've not they're just sitting on so much PDF data. They're sitting on so much data that there's like, message structure data, and those engineers don't have the skills to go and read that data. Database does not want to spend three months of like, their engineers building it out. So it's like a very much imaginative and of course, these are partnerships that will have to expend energy to go and build out, but this is how we will, sort of, like, stay that ecosystem and go, you know, actually go and, you know, have AI applications that are successfully deployed. That's
exactly for those customers. I think we will Bank, which is being partners, because they will not want to. Well, we'll see how this plays out, but it's unlikely that they will want to invest a lot of their core efforts. In terms of what does it take to clean structure, pre process data? Because the place where they would want to start out is look there is raw data that has been refined, that has been put back into a snow plate or into a vendor database, and it's now ready for, you know, all the applications that we're building that will make you build out. Because with applications, of course, you have to think about, okay, what is it means that, you know, user requirements, what are the types of queries they'll be asked with a bunch of work that needs to be done upstream of this green process data, whereas they will essentially want somebody to do this for them. This is going to be the case for contextual This is 100% going to be the case for companies like Databricks, because I might have mentioned this, but I know that, like data really trying to figure out how when they don't talk to their enterprise customers. I mean, imagine some semiconductor company, right? And that is just like they, they sit on, like, just massive, massive amounts of Qualcomm is also like semiconductor, but like I've heard from other customers, they've not they're just sitting on so much PDF data. They're sitting on so much data that there's like, message structure data, and those engineers don't have the skills to go and read that data. Database does not want to spend three months of like, their engineers building it out. So it's like a very much imaginative and of course, these are partnerships that will have to expend energy to go and build out, but this is how we will, sort of, like, stay that ecosystem and go, you know, actually go and, you know, have AI applications that are successfully deployed. That's
exactly for those customers. I think we will Bank, which is being partners, because they will not want to. Well, we'll see how this plays out, but it's unlikely that they will want to invest a lot of their core efforts. In terms of what does it take to clean structure, pre process data? Because the place where they would want to start out is look there is raw data that has been refined, that has been put back into a snow plate or into a vendor database, and it's now ready for, you know, all the applications that we're building that will make you build out. Because with applications, of course, you have to think about, okay, what is it means that, you know, user requirements, what are the types of queries they'll be asked with a bunch of work that needs to be done upstream of this green process data, whereas they will essentially want somebody to do this for them. This is going to be the case for contextual This is 100% going to be the case for companies like Databricks, because I might have mentioned this, but I know that, like data really trying to figure out how when they don't talk to their enterprise customers. I mean, imagine some semiconductor company, right? And that is just like they, they sit on, like, just massive, massive amounts of Qualcomm is also like semiconductor, but like I've heard from other customers, they've not they're just sitting on so much PDF data. They're sitting on so much data that there's like, message structure data, and those engineers don't have the skills to go and read that data. Database does not want to spend three months of like, their engineers building it out. So it's like a very much imaginative and of course, these are partnerships that will have to expend energy to go and build out, but this is how we will, sort of, like, stay that ecosystem and go, you know, actually go and, you know, have AI applications that are successfully deployed. That's
exactly for those customers. I think we will Bank, which is being partners, because they will not want to. Well, we'll see how this plays out, but it's unlikely that they will want to invest a lot of their core efforts. In terms of what does it take to clean structure, pre process data? Because the place where they would want to start out is look there is raw data that has been refined, that has been put back into a snow plate or into a vendor database, and it's now ready for, you know, all the applications that we're building that will make you build out. Because with applications, of course, you have to think about, okay, what is it means that, you know, user requirements, what are the types of queries they'll be asked with a bunch of work that needs to be done upstream of this green process data, whereas they will essentially want somebody to do this for them. This is going to be the case for contextual This is 100% going to be the case for companies like Databricks, because I might have mentioned this, but I know that, like data really trying to figure out how when they don't talk to their enterprise customers. I mean, imagine some semiconductor company, right? And that is just like they, they sit on, like, just massive, massive amounts of Qualcomm is also like semiconductor, but like I've heard from other customers, they've not they're just sitting on so much PDF data. They're sitting on so much data that there's like, message structure data, and those engineers don't have the skills to go and read that data. Database does not want to spend three months of like, their engineers building it out. So it's like a very much imaginative and of course, these are partnerships that will have to expend energy to go and build out, but this is how we will, sort of, like, stay that ecosystem and go, you know, actually go and, you know, have AI applications that are successfully deployed. That's
4:33how we that's exactly
how we that's exactly
how we that's exactly
how we that's exactly
4:37what I thought. But I was
what I thought. But I was
what I thought. But I was
what I thought. But I was
S Speaker 24:40just wanted to understand, because with your some of your customers who are using these models as end
just wanted to understand, because with your some of your customers who are using these models as end
just wanted to understand, because with your some of your customers who are using these models as end
just wanted to understand, because with your some of your customers who are using these models as end
4:49points, my guess is they're more Fielding, so
points, my guess is they're more Fielding, so
points, my guess is they're more Fielding, so
points, my guess is they're more Fielding, so
4:52the assumption is that they're going and
the assumption is that they're going and
the assumption is that they're going and
the assumption is that they're going and
4:56building these themselves
building these themselves
building these themselves
building these themselves
S Speaker 14:57exactly, exactly and the endpoints. I think the way, the best way to think about them is, it's not sort of used like it's not very rare, is it user facing endpoints? It's actually just data transformation, like endpoints, right? Just like data that is coming in, it needs to be processed. And often, like their data just needs to be processed. I'll give you an example. One of our customers, they have the user function I find right for their streaming system. So they have like this, like continuous batch of data that is being ingested, putting into NiFi. And they basically make calls from their NiFi into reflow to process and transform it along the way, because then downstream of that, like that data gets routed into database. That data gets updated to some applications, but they just want this data to be transformed along the way, along the journey, right? And so that's one of the ways they start using us. It's a very much like we think of it as like a stream, like data transformation, streaming, sort of like ERP microplu, three, that is coming in every day, processing that on a daily basis, but it's very core. Sort of transformation produces transform data that now gets consumed by some other software application, some other AI application. That's the predominant way sort of refill gets gets utilized.
exactly, exactly and the endpoints. I think the way, the best way to think about them is, it's not sort of used like it's not very rare, is it user facing endpoints? It's actually just data transformation, like endpoints, right? Just like data that is coming in, it needs to be processed. And often, like their data just needs to be processed. I'll give you an example. One of our customers, they have the user function I find right for their streaming system. So they have like this, like continuous batch of data that is being ingested, putting into NiFi. And they basically make calls from their NiFi into reflow to process and transform it along the way, because then downstream of that, like that data gets routed into database. That data gets updated to some applications, but they just want this data to be transformed along the way, along the journey, right? And so that's one of the ways they start using us. It's a very much like we think of it as like a stream, like data transformation, streaming, sort of like ERP microplu, three, that is coming in every day, processing that on a daily basis, but it's very core. Sort of transformation produces transform data that now gets consumed by some other software application, some other AI application. That's the predominant way sort of refill gets gets utilized.
exactly, exactly and the endpoints. I think the way, the best way to think about them is, it's not sort of used like it's not very rare, is it user facing endpoints? It's actually just data transformation, like endpoints, right? Just like data that is coming in, it needs to be processed. And often, like their data just needs to be processed. I'll give you an example. One of our customers, they have the user function I find right for their streaming system. So they have like this, like continuous batch of data that is being ingested, putting into NiFi. And they basically make calls from their NiFi into reflow to process and transform it along the way, because then downstream of that, like that data gets routed into database. That data gets updated to some applications, but they just want this data to be transformed along the way, along the journey, right? And so that's one of the ways they start using us. It's a very much like we think of it as like a stream, like data transformation, streaming, sort of like ERP microplu, three, that is coming in every day, processing that on a daily basis, but it's very core. Sort of transformation produces transform data that now gets consumed by some other software application, some other AI application. That's the predominant way sort of refill gets gets utilized.
exactly, exactly and the endpoints. I think the way, the best way to think about them is, it's not sort of used like it's not very rare, is it user facing endpoints? It's actually just data transformation, like endpoints, right? Just like data that is coming in, it needs to be processed. And often, like their data just needs to be processed. I'll give you an example. One of our customers, they have the user function I find right for their streaming system. So they have like this, like continuous batch of data that is being ingested, putting into NiFi. And they basically make calls from their NiFi into reflow to process and transform it along the way, because then downstream of that, like that data gets routed into database. That data gets updated to some applications, but they just want this data to be transformed along the way, along the journey, right? And so that's one of the ways they start using us. It's a very much like we think of it as like a stream, like data transformation, streaming, sort of like ERP microplu, three, that is coming in every day, processing that on a daily basis, but it's very core. Sort of transformation produces transform data that now gets consumed by some other software application, some other AI application. That's the predominant way sort of refill gets gets utilized.
S Speaker 26:22But you do have one end point for some
But you do have one end point for some
But you do have one end point for some
But you do have one end point for some
S Speaker 16:30yeah, but that train model is not one model, frankly, Tushar and maybe I can spin up the demo that shows that. But for example, with that mid desk use case, there's actually three or four LLM calls, there's multiple external products, because that is the whole complex combination. Yeah,
yeah, but that train model is not one model, frankly, Tushar and maybe I can spin up the demo that shows that. But for example, with that mid desk use case, there's actually three or four LLM calls, there's multiple external products, because that is the whole complex combination. Yeah,
yeah, but that train model is not one model, frankly, Tushar and maybe I can spin up the demo that shows that. But for example, with that mid desk use case, there's actually three or four LLM calls, there's multiple external products, because that is the whole complex combination. Yeah,
yeah, but that train model is not one model, frankly, Tushar and maybe I can spin up the demo that shows that. But for example, with that mid desk use case, there's actually three or four LLM calls, there's multiple external products, because that is the whole complex combination. Yeah,
6:47let's walk through that.
let's walk through that.
let's walk through that.
let's walk through that.
S Speaker 17:07Are you able to see this? Yes, okay, so this is the high level platform. This is like, where raw data, where transform data goes. But the thing that I'll actually walk you through is sort of like one of our customers, and how they build their specific kind of data information, which is this company called Windows series CBC, type of customer, serving hundreds of customers. They build a KYB business identity sort of platform. They build a product for industry classification, where all of the sort of businesses and the industry prioritization was happening have been so before, they have both paradigms. So they also have like you can imagine a big batch of like companies that they know that is sitting in their warehouse that they use from batch processing. And then in real time as well, they get requests. They get both of these kind of requests. And now this is the nice why, but let me actually walk you through how we will build this individual product. And so you can imagine the inputs to the system are like the name for business and address its website, and then they're trying to figure out and piece together a bunch of information. So step one would be, hey, I already have some separate data and snowflake. Let me just connect my snowflake, get that data into video, so I can now start configuring my specific categorization workflow in review. So step one would be go connect to a Step two would be building out this step by step workflow, which you can imagine. Often it's like a software engineer or data person that is doing it, sometimes even product managers or operations people are connected. So here's how they would build that workflow in review, which is, you know, you give it a name, you pick a starter model. So this could be aI models, could be a video model, whichever you pick your favorite. And then here's a five step workflow within right? So step one is just go to a Google search for the business, right? So, given the name of the business and its address, search on Google, fetch a bunch of information. Step two is go screen the website of this business. Okay, in their case, they actually have, like many other steps that are external and internal searches. But you can imagine you can do internal searches, external searches, all that and figure out what works. Step three is, here's my massive taxonomy of NAICS code, right? These are industry categorization codes. They've uploaded, like a massive taxonomy here, or pointed us to the back where, like taxonomy limits now, go to the stack categorization. Similarly, you know, here's the SDC categories, right? Here's my math attacks on me. Go to this categorization, and then finally, there's a risk category. And so they have some risk scores now, do this use category, right? That's kind of what they built. That's what the piece together. And then the outputs of this look like this, right? So which is already best data from? There's no big here. The outputs that we're seeing for every single input record that they had. And then you can do a few things, right? So now somebody on their team is going to be reviewing a handful of data points and then doing the thumbs up, thumbs up to give it feedback. So if it is correct, you just hit a proof. If it is incorrect, right, you just say, what is incorrect answer, writing explanation and say and then refuel, is like learning from all of that feedback, because they don't have to do anything in terms of prompt engineering, in terms of, you know, how do I curate and find videos and like, they don't care. Like, they don't mean they're not involved with that business at all. They're just giving us thumbs up, thumbs down, and refilates all that burden of, how do we improve the quality.
Are you able to see this? Yes, okay, so this is the high level platform. This is like, where raw data, where transform data goes. But the thing that I'll actually walk you through is sort of like one of our customers, and how they build their specific kind of data information, which is this company called Windows series CBC, type of customer, serving hundreds of customers. They build a KYB business identity sort of platform. They build a product for industry classification, where all of the sort of businesses and the industry prioritization was happening have been so before, they have both paradigms. So they also have like you can imagine a big batch of like companies that they know that is sitting in their warehouse that they use from batch processing. And then in real time as well, they get requests. They get both of these kind of requests. And now this is the nice why, but let me actually walk you through how we will build this individual product. And so you can imagine the inputs to the system are like the name for business and address its website, and then they're trying to figure out and piece together a bunch of information. So step one would be, hey, I already have some separate data and snowflake. Let me just connect my snowflake, get that data into video, so I can now start configuring my specific categorization workflow in review. So step one would be go connect to a Step two would be building out this step by step workflow, which you can imagine. Often it's like a software engineer or data person that is doing it, sometimes even product managers or operations people are connected. So here's how they would build that workflow in review, which is, you know, you give it a name, you pick a starter model. So this could be aI models, could be a video model, whichever you pick your favorite. And then here's a five step workflow within right? So step one is just go to a Google search for the business, right? So, given the name of the business and its address, search on Google, fetch a bunch of information. Step two is go screen the website of this business. Okay, in their case, they actually have, like many other steps that are external and internal searches. But you can imagine you can do internal searches, external searches, all that and figure out what works. Step three is, here's my massive taxonomy of NAICS code, right? These are industry categorization codes. They've uploaded, like a massive taxonomy here, or pointed us to the back where, like taxonomy limits now, go to the stack categorization. Similarly, you know, here's the SDC categories, right? Here's my math attacks on me. Go to this categorization, and then finally, there's a risk category. And so they have some risk scores now, do this use category, right? That's kind of what they built. That's what the piece together. And then the outputs of this look like this, right? So which is already best data from? There's no big here. The outputs that we're seeing for every single input record that they had. And then you can do a few things, right? So now somebody on their team is going to be reviewing a handful of data points and then doing the thumbs up, thumbs up to give it feedback. So if it is correct, you just hit a proof. If it is incorrect, right, you just say, what is incorrect answer, writing explanation and say and then refuel, is like learning from all of that feedback, because they don't have to do anything in terms of prompt engineering, in terms of, you know, how do I curate and find videos and like, they don't care. Like, they don't mean they're not involved with that business at all. They're just giving us thumbs up, thumbs down, and refilates all that burden of, how do we improve the quality.
Are you able to see this? Yes, okay, so this is the high level platform. This is like, where raw data, where transform data goes. But the thing that I'll actually walk you through is sort of like one of our customers, and how they build their specific kind of data information, which is this company called Windows series CBC, type of customer, serving hundreds of customers. They build a KYB business identity sort of platform. They build a product for industry classification, where all of the sort of businesses and the industry prioritization was happening have been so before, they have both paradigms. So they also have like you can imagine a big batch of like companies that they know that is sitting in their warehouse that they use from batch processing. And then in real time as well, they get requests. They get both of these kind of requests. And now this is the nice why, but let me actually walk you through how we will build this individual product. And so you can imagine the inputs to the system are like the name for business and address its website, and then they're trying to figure out and piece together a bunch of information. So step one would be, hey, I already have some separate data and snowflake. Let me just connect my snowflake, get that data into video, so I can now start configuring my specific categorization workflow in review. So step one would be go connect to a Step two would be building out this step by step workflow, which you can imagine. Often it's like a software engineer or data person that is doing it, sometimes even product managers or operations people are connected. So here's how they would build that workflow in review, which is, you know, you give it a name, you pick a starter model. So this could be aI models, could be a video model, whichever you pick your favorite. And then here's a five step workflow within right? So step one is just go to a Google search for the business, right? So, given the name of the business and its address, search on Google, fetch a bunch of information. Step two is go screen the website of this business. Okay, in their case, they actually have, like many other steps that are external and internal searches. But you can imagine you can do internal searches, external searches, all that and figure out what works. Step three is, here's my massive taxonomy of NAICS code, right? These are industry categorization codes. They've uploaded, like a massive taxonomy here, or pointed us to the back where, like taxonomy limits now, go to the stack categorization. Similarly, you know, here's the SDC categories, right? Here's my math attacks on me. Go to this categorization, and then finally, there's a risk category. And so they have some risk scores now, do this use category, right? That's kind of what they built. That's what the piece together. And then the outputs of this look like this, right? So which is already best data from? There's no big here. The outputs that we're seeing for every single input record that they had. And then you can do a few things, right? So now somebody on their team is going to be reviewing a handful of data points and then doing the thumbs up, thumbs up to give it feedback. So if it is correct, you just hit a proof. If it is incorrect, right, you just say, what is incorrect answer, writing explanation and say and then refuel, is like learning from all of that feedback, because they don't have to do anything in terms of prompt engineering, in terms of, you know, how do I curate and find videos and like, they don't care. Like, they don't mean they're not involved with that business at all. They're just giving us thumbs up, thumbs down, and refilates all that burden of, how do we improve the quality.
Are you able to see this? Yes, okay, so this is the high level platform. This is like, where raw data, where transform data goes. But the thing that I'll actually walk you through is sort of like one of our customers, and how they build their specific kind of data information, which is this company called Windows series CBC, type of customer, serving hundreds of customers. They build a KYB business identity sort of platform. They build a product for industry classification, where all of the sort of businesses and the industry prioritization was happening have been so before, they have both paradigms. So they also have like you can imagine a big batch of like companies that they know that is sitting in their warehouse that they use from batch processing. And then in real time as well, they get requests. They get both of these kind of requests. And now this is the nice why, but let me actually walk you through how we will build this individual product. And so you can imagine the inputs to the system are like the name for business and address its website, and then they're trying to figure out and piece together a bunch of information. So step one would be, hey, I already have some separate data and snowflake. Let me just connect my snowflake, get that data into video, so I can now start configuring my specific categorization workflow in review. So step one would be go connect to a Step two would be building out this step by step workflow, which you can imagine. Often it's like a software engineer or data person that is doing it, sometimes even product managers or operations people are connected. So here's how they would build that workflow in review, which is, you know, you give it a name, you pick a starter model. So this could be aI models, could be a video model, whichever you pick your favorite. And then here's a five step workflow within right? So step one is just go to a Google search for the business, right? So, given the name of the business and its address, search on Google, fetch a bunch of information. Step two is go screen the website of this business. Okay, in their case, they actually have, like many other steps that are external and internal searches. But you can imagine you can do internal searches, external searches, all that and figure out what works. Step three is, here's my massive taxonomy of NAICS code, right? These are industry categorization codes. They've uploaded, like a massive taxonomy here, or pointed us to the back where, like taxonomy limits now, go to the stack categorization. Similarly, you know, here's the SDC categories, right? Here's my math attacks on me. Go to this categorization, and then finally, there's a risk category. And so they have some risk scores now, do this use category, right? That's kind of what they built. That's what the piece together. And then the outputs of this look like this, right? So which is already best data from? There's no big here. The outputs that we're seeing for every single input record that they had. And then you can do a few things, right? So now somebody on their team is going to be reviewing a handful of data points and then doing the thumbs up, thumbs up to give it feedback. So if it is correct, you just hit a proof. If it is incorrect, right, you just say, what is incorrect answer, writing explanation and say and then refuel, is like learning from all of that feedback, because they don't have to do anything in terms of prompt engineering, in terms of, you know, how do I curate and find videos and like, they don't care. Like, they don't mean they're not involved with that business at all. They're just giving us thumbs up, thumbs down, and refilates all that burden of, how do we improve the quality.
10:41Where do they give them? Like, right here.
Where do they give them? Like, right here.
Where do they give them? Like, right here.
Where do they give them? Like, right here.
S Speaker 110:43Yeah, right here. So basically, this is like, for example, this is a proof, right? So then like, now approved by somebody, have to do, yeah, great question. So the answer is a little bit of, it depends on the complexity of the use case, but typically, when we onboard them for the first time. We give them something, and even in our documentation, we point them to like, how to think about this. But you can start with as few as, like, 50 examples. And the nice thing is, like, we have a very specific way of measuring quality, so there's a way to evaluate scores. So you can always just check what does the quality look like on a held out data set? So they'll always be able to see like, okay, we're at 70% today. Let me spend another hour. Okay? I got 80% so they make progress on their own. Okay? And now you can take this entire workflow and shrink this into a small model. So you can either say, hey, I want to use refuse 47 billion parameter model, or I want to use refusal 8 billion or 1.5 billion parameter of the model. And really, we tell them the choice is yours based on what agency you want, what throughput you want, right? And so you pick based on whatever that choice is. And then you know, again, you don't have to think about anything. Just hit Next if you will, find in a model. We'll do that data curation, find in the model, deploy the model, we'll take care of
Yeah, right here. So basically, this is like, for example, this is a proof, right? So then like, now approved by somebody, have to do, yeah, great question. So the answer is a little bit of, it depends on the complexity of the use case, but typically, when we onboard them for the first time. We give them something, and even in our documentation, we point them to like, how to think about this. But you can start with as few as, like, 50 examples. And the nice thing is, like, we have a very specific way of measuring quality, so there's a way to evaluate scores. So you can always just check what does the quality look like on a held out data set? So they'll always be able to see like, okay, we're at 70% today. Let me spend another hour. Okay? I got 80% so they make progress on their own. Okay? And now you can take this entire workflow and shrink this into a small model. So you can either say, hey, I want to use refuse 47 billion parameter model, or I want to use refusal 8 billion or 1.5 billion parameter of the model. And really, we tell them the choice is yours based on what agency you want, what throughput you want, right? And so you pick based on whatever that choice is. And then you know, again, you don't have to think about anything. Just hit Next if you will, find in a model. We'll do that data curation, find in the model, deploy the model, we'll take care of
Yeah, right here. So basically, this is like, for example, this is a proof, right? So then like, now approved by somebody, have to do, yeah, great question. So the answer is a little bit of, it depends on the complexity of the use case, but typically, when we onboard them for the first time. We give them something, and even in our documentation, we point them to like, how to think about this. But you can start with as few as, like, 50 examples. And the nice thing is, like, we have a very specific way of measuring quality, so there's a way to evaluate scores. So you can always just check what does the quality look like on a held out data set? So they'll always be able to see like, okay, we're at 70% today. Let me spend another hour. Okay? I got 80% so they make progress on their own. Okay? And now you can take this entire workflow and shrink this into a small model. So you can either say, hey, I want to use refuse 47 billion parameter model, or I want to use refusal 8 billion or 1.5 billion parameter of the model. And really, we tell them the choice is yours based on what agency you want, what throughput you want, right? And so you pick based on whatever that choice is. And then you know, again, you don't have to think about anything. Just hit Next if you will, find in a model. We'll do that data curation, find in the model, deploy the model, we'll take care of
Yeah, right here. So basically, this is like, for example, this is a proof, right? So then like, now approved by somebody, have to do, yeah, great question. So the answer is a little bit of, it depends on the complexity of the use case, but typically, when we onboard them for the first time. We give them something, and even in our documentation, we point them to like, how to think about this. But you can start with as few as, like, 50 examples. And the nice thing is, like, we have a very specific way of measuring quality, so there's a way to evaluate scores. So you can always just check what does the quality look like on a held out data set? So they'll always be able to see like, okay, we're at 70% today. Let me spend another hour. Okay? I got 80% so they make progress on their own. Okay? And now you can take this entire workflow and shrink this into a small model. So you can either say, hey, I want to use refuse 47 billion parameter model, or I want to use refusal 8 billion or 1.5 billion parameter of the model. And really, we tell them the choice is yours based on what agency you want, what throughput you want, right? And so you pick based on whatever that choice is. And then you know, again, you don't have to think about anything. Just hit Next if you will, find in a model. We'll do that data curation, find in the model, deploy the model, we'll take care of
S Speaker 211:59everything. The model that over here is for data curation,
everything. The model that over here is for data curation,
everything. The model that over here is for data curation,
everything. The model that over here is for data curation,
S Speaker 112:04right? Yeah, that's right. Interesting. And, you know, we had the conversation the morning to try, right? Like, there's no mention of curation anywhere, because we don't even want our customers to think about it. They don't want to think about it, right? No. Software engineers want to think about like, Okay, what is the composition of it, data set, because, like, that's not their job, right? Their job is like building the product, building the pipeline. Like, they're not trained to be a machine learning person, so they don't care. But of course, we can, because we have to deliver the outcome. The outcome is quality data that is how to be running as a pipeline that can run consistently, right? So we care about it. They don't on their database. And the final output of this becomes, look. You can either run this, so now this will, if it's connected to snowpay, you will run it on your entire data set. You can also schedule it on a daily basis, hourly basis, or you then deploy this. And when you deploy this, this entire workflow gets deployed as a single endpoint, right? This is what I was mentioning earlier. So now you just give it, you know, the input data, and we will follow all those steps, however many steps, to give you the answer, yeah, and then all the sort of data. Once this loads like there's not much data in here, but you get all the monitoring. You can even sort of programmatically fetch all of these monitoring so if you want to put that into like a dashboard, some people want to do that and with request logs available here, so you can continue to give it, comes up, comes down, and improve it on an ongoing basis.
right? Yeah, that's right. Interesting. And, you know, we had the conversation the morning to try, right? Like, there's no mention of curation anywhere, because we don't even want our customers to think about it. They don't want to think about it, right? No. Software engineers want to think about like, Okay, what is the composition of it, data set, because, like, that's not their job, right? Their job is like building the product, building the pipeline. Like, they're not trained to be a machine learning person, so they don't care. But of course, we can, because we have to deliver the outcome. The outcome is quality data that is how to be running as a pipeline that can run consistently, right? So we care about it. They don't on their database. And the final output of this becomes, look. You can either run this, so now this will, if it's connected to snowpay, you will run it on your entire data set. You can also schedule it on a daily basis, hourly basis, or you then deploy this. And when you deploy this, this entire workflow gets deployed as a single endpoint, right? This is what I was mentioning earlier. So now you just give it, you know, the input data, and we will follow all those steps, however many steps, to give you the answer, yeah, and then all the sort of data. Once this loads like there's not much data in here, but you get all the monitoring. You can even sort of programmatically fetch all of these monitoring so if you want to put that into like a dashboard, some people want to do that and with request logs available here, so you can continue to give it, comes up, comes down, and improve it on an ongoing basis.
right? Yeah, that's right. Interesting. And, you know, we had the conversation the morning to try, right? Like, there's no mention of curation anywhere, because we don't even want our customers to think about it. They don't want to think about it, right? No. Software engineers want to think about like, Okay, what is the composition of it, data set, because, like, that's not their job, right? Their job is like building the product, building the pipeline. Like, they're not trained to be a machine learning person, so they don't care. But of course, we can, because we have to deliver the outcome. The outcome is quality data that is how to be running as a pipeline that can run consistently, right? So we care about it. They don't on their database. And the final output of this becomes, look. You can either run this, so now this will, if it's connected to snowpay, you will run it on your entire data set. You can also schedule it on a daily basis, hourly basis, or you then deploy this. And when you deploy this, this entire workflow gets deployed as a single endpoint, right? This is what I was mentioning earlier. So now you just give it, you know, the input data, and we will follow all those steps, however many steps, to give you the answer, yeah, and then all the sort of data. Once this loads like there's not much data in here, but you get all the monitoring. You can even sort of programmatically fetch all of these monitoring so if you want to put that into like a dashboard, some people want to do that and with request logs available here, so you can continue to give it, comes up, comes down, and improve it on an ongoing basis.
right? Yeah, that's right. Interesting. And, you know, we had the conversation the morning to try, right? Like, there's no mention of curation anywhere, because we don't even want our customers to think about it. They don't want to think about it, right? No. Software engineers want to think about like, Okay, what is the composition of it, data set, because, like, that's not their job, right? Their job is like building the product, building the pipeline. Like, they're not trained to be a machine learning person, so they don't care. But of course, we can, because we have to deliver the outcome. The outcome is quality data that is how to be running as a pipeline that can run consistently, right? So we care about it. They don't on their database. And the final output of this becomes, look. You can either run this, so now this will, if it's connected to snowpay, you will run it on your entire data set. You can also schedule it on a daily basis, hourly basis, or you then deploy this. And when you deploy this, this entire workflow gets deployed as a single endpoint, right? This is what I was mentioning earlier. So now you just give it, you know, the input data, and we will follow all those steps, however many steps, to give you the answer, yeah, and then all the sort of data. Once this loads like there's not much data in here, but you get all the monitoring. You can even sort of programmatically fetch all of these monitoring so if you want to put that into like a dashboard, some people want to do that and with request logs available here, so you can continue to give it, comes up, comes down, and improve it on an ongoing basis.
S Speaker 214:42but that end point can also be plugged into another LLM Yes, yes.
but that end point can also be plugged into another LLM Yes, yes.
but that end point can also be plugged into another LLM Yes, yes.
but that end point can also be plugged into another LLM Yes, yes.
14:49So what's the split today like for these companies?
So what's the split today like for these companies?
So what's the split today like for these companies?
So what's the split today like for these companies?
S Speaker 214:52I'm curious, which is like this endpoint, where are they typically plugging in? Are they already plugging into their llms back pipelines? Or are whatever their legacy systems, which
I'm curious, which is like this endpoint, where are they typically plugging in? Are they already plugging into their llms back pipelines? Or are whatever their legacy systems, which
I'm curious, which is like this endpoint, where are they typically plugging in? Are they already plugging into their llms back pipelines? Or are whatever their legacy systems, which
I'm curious, which is like this endpoint, where are they typically plugging in? Are they already plugging into their llms back pipelines? Or are whatever their legacy systems, which
15:08they essentially execute? Yeah,
they essentially execute? Yeah,
they essentially execute? Yeah,
they essentially execute? Yeah,
S Speaker 115:14it's, it's a, it's roughly like, like 6040 split, which is 60% of it is like, you know, this is pipelines that are producing data that now gets stored somewhere and then gets processed later. And then 40% of it is like, you know, it's directly plugged into, like a software or AI application, where it's producing sort of data in real time for consumption by some service and so the funny thing is, like, sometimes we see both of them happen for the same workflow. And the biggest is that was a good one, because, you know, frankly, they have to sometimes do like pack fills, of like they're getting names of industries that they're collecting separately, and then they also get it in real time. So they have to sort of consume this in real time as well. So we end up seeing both using
it's, it's a, it's roughly like, like 6040 split, which is 60% of it is like, you know, this is pipelines that are producing data that now gets stored somewhere and then gets processed later. And then 40% of it is like, you know, it's directly plugged into, like a software or AI application, where it's producing sort of data in real time for consumption by some service and so the funny thing is, like, sometimes we see both of them happen for the same workflow. And the biggest is that was a good one, because, you know, frankly, they have to sometimes do like pack fills, of like they're getting names of industries that they're collecting separately, and then they also get it in real time. So they have to sort of consume this in real time as well. So we end up seeing both using
it's, it's a, it's roughly like, like 6040 split, which is 60% of it is like, you know, this is pipelines that are producing data that now gets stored somewhere and then gets processed later. And then 40% of it is like, you know, it's directly plugged into, like a software or AI application, where it's producing sort of data in real time for consumption by some service and so the funny thing is, like, sometimes we see both of them happen for the same workflow. And the biggest is that was a good one, because, you know, frankly, they have to sometimes do like pack fills, of like they're getting names of industries that they're collecting separately, and then they also get it in real time. So they have to sort of consume this in real time as well. So we end up seeing both using
it's, it's a, it's roughly like, like 6040 split, which is 60% of it is like, you know, this is pipelines that are producing data that now gets stored somewhere and then gets processed later. And then 40% of it is like, you know, it's directly plugged into, like a software or AI application, where it's producing sort of data in real time for consumption by some service and so the funny thing is, like, sometimes we see both of them happen for the same workflow. And the biggest is that was a good one, because, you know, frankly, they have to sometimes do like pack fills, of like they're getting names of industries that they're collecting separately, and then they also get it in real time. So they have to sort of consume this in real time as well. So we end up seeing both using
16:04this in cases where this gets
this in cases where this gets
this in cases where this gets
this in cases where this gets
S Speaker 216:08plugged into an LLM workflow. There, it's essentially over there, like the output is,
plugged into an LLM workflow. There, it's essentially over there, like the output is,
plugged into an LLM workflow. There, it's essentially over there, like the output is,
plugged into an LLM workflow. There, it's essentially over there, like the output is,
16:16like a JSON L so a JSON. L
like a JSON L so a JSON. L
like a JSON L so a JSON. L
like a JSON L so a JSON. L
S Speaker 116:24it's a JSON. If you call this endpoint right now, it will produce a JSON.
it's a JSON. If you call this endpoint right now, it will produce a JSON.
it's a JSON. If you call this endpoint right now, it will produce a JSON.
it's a JSON. If you call this endpoint right now, it will produce a JSON.
S Speaker 116:41get exactly one of the nice things is, like, we get, like, with our customers, like, typically, the journey, and it's a big like, it's like, the first use case that they want to go and sell. So we'll start building up the first use case, and then, predictively, within, like, sometimes, like, one month, sometimes it's three months, like, they'll get to a place where it's actually now running live in production, whether it's a production pipeline or it's a batch process. And then you see them like, you know, the knowledge sort of spreads within multiple teams. There's a second team that is already starting to expand within so we see that sort of like motion within those organizations, which is the first thing gets built. We often hear about it because, like, you know, they'll tell us, like, the first thing,
get exactly one of the nice things is, like, we get, like, with our customers, like, typically, the journey, and it's a big like, it's like, the first use case that they want to go and sell. So we'll start building up the first use case, and then, predictively, within, like, sometimes, like, one month, sometimes it's three months, like, they'll get to a place where it's actually now running live in production, whether it's a production pipeline or it's a batch process. And then you see them like, you know, the knowledge sort of spreads within multiple teams. There's a second team that is already starting to expand within so we see that sort of like motion within those organizations, which is the first thing gets built. We often hear about it because, like, you know, they'll tell us, like, the first thing,
get exactly one of the nice things is, like, we get, like, with our customers, like, typically, the journey, and it's a big like, it's like, the first use case that they want to go and sell. So we'll start building up the first use case, and then, predictively, within, like, sometimes, like, one month, sometimes it's three months, like, they'll get to a place where it's actually now running live in production, whether it's a production pipeline or it's a batch process. And then you see them like, you know, the knowledge sort of spreads within multiple teams. There's a second team that is already starting to expand within so we see that sort of like motion within those organizations, which is the first thing gets built. We often hear about it because, like, you know, they'll tell us, like, the first thing,
get exactly one of the nice things is, like, we get, like, with our customers, like, typically, the journey, and it's a big like, it's like, the first use case that they want to go and sell. So we'll start building up the first use case, and then, predictively, within, like, sometimes, like, one month, sometimes it's three months, like, they'll get to a place where it's actually now running live in production, whether it's a production pipeline or it's a batch process. And then you see them like, you know, the knowledge sort of spreads within multiple teams. There's a second team that is already starting to expand within so we see that sort of like motion within those organizations, which is the first thing gets built. We often hear about it because, like, you know, they'll tell us, like, the first thing,
17:21like, what's the journey again? Can you repeat?
like, what's the journey again? Can you repeat?
like, what's the journey again? Can you repeat?
like, what's the journey again? Can you repeat?
S Speaker 117:24So this, this product, right? Like this industry classification product from the test. It's one of multiple things that they now usually look for. And so they build the first one going to production. It's live. There's a second one they're already building. There's a third that they've already communicated to us, which is, hey, you need to bring down your latency. And we told them, Hey, we should use our smallest model that will bring up latency. And so we already telling them they're communicating, which is, here's, like the things that we are hoping to print out, because often, like for a lot of these organizations, the first time they taste sort of success right with with one of these other language cases going to production, like there's a level of trust that gets created that enables them to feel confident. They feel confident about doing the second thing, and the third thing with us,
So this, this product, right? Like this industry classification product from the test. It's one of multiple things that they now usually look for. And so they build the first one going to production. It's live. There's a second one they're already building. There's a third that they've already communicated to us, which is, hey, you need to bring down your latency. And we told them, Hey, we should use our smallest model that will bring up latency. And so we already telling them they're communicating, which is, here's, like the things that we are hoping to print out, because often, like for a lot of these organizations, the first time they taste sort of success right with with one of these other language cases going to production, like there's a level of trust that gets created that enables them to feel confident. They feel confident about doing the second thing, and the third thing with us,
So this, this product, right? Like this industry classification product from the test. It's one of multiple things that they now usually look for. And so they build the first one going to production. It's live. There's a second one they're already building. There's a third that they've already communicated to us, which is, hey, you need to bring down your latency. And we told them, Hey, we should use our smallest model that will bring up latency. And so we already telling them they're communicating, which is, here's, like the things that we are hoping to print out, because often, like for a lot of these organizations, the first time they taste sort of success right with with one of these other language cases going to production, like there's a level of trust that gets created that enables them to feel confident. They feel confident about doing the second thing, and the third thing with us,
So this, this product, right? Like this industry classification product from the test. It's one of multiple things that they now usually look for. And so they build the first one going to production. It's live. There's a second one they're already building. There's a third that they've already communicated to us, which is, hey, you need to bring down your latency. And we told them, Hey, we should use our smallest model that will bring up latency. And so we already telling them they're communicating, which is, here's, like the things that we are hoping to print out, because often, like for a lot of these organizations, the first time they taste sort of success right with with one of these other language cases going to production, like there's a level of trust that gets created that enables them to feel confident. They feel confident about doing the second thing, and the third thing with us,
18:11success is improved accuracy. It's
success is improved accuracy. It's
success is improved accuracy. It's
success is improved accuracy. It's
S Speaker 118:16improved accuracy in cases where there's a benchmark to compare it to and then, so in this case, they had a pre existing model where they saw an 85% rate against the previous model. And so then it was just so much better that it just got replaced with the version they were. In some cases it's actually completely net So, or the thing that they're measuring against is slightly different. So I'll tell you, like, what are the other things outside of the three things that they should because the fourth thing that they are looking to build out is they look, they're looking to automate some of their operations, so their operations is, like, inundated with, like, a bunch of requests their customers. And they are looking to integrate some review workflows so that, instead of things going to the operations team, can be handled automatically by one of the workflows. And so now it's going to be like, you know, the NH plus operations that is going to replace that, that workload. So now the comparison there isn't against like, a module. The comparison is, how much can we reduce our operations and because we can just automate that? Priyesh,
improved accuracy in cases where there's a benchmark to compare it to and then, so in this case, they had a pre existing model where they saw an 85% rate against the previous model. And so then it was just so much better that it just got replaced with the version they were. In some cases it's actually completely net So, or the thing that they're measuring against is slightly different. So I'll tell you, like, what are the other things outside of the three things that they should because the fourth thing that they are looking to build out is they look, they're looking to automate some of their operations, so their operations is, like, inundated with, like, a bunch of requests their customers. And they are looking to integrate some review workflows so that, instead of things going to the operations team, can be handled automatically by one of the workflows. And so now it's going to be like, you know, the NH plus operations that is going to replace that, that workload. So now the comparison there isn't against like, a module. The comparison is, how much can we reduce our operations and because we can just automate that? Priyesh,
improved accuracy in cases where there's a benchmark to compare it to and then, so in this case, they had a pre existing model where they saw an 85% rate against the previous model. And so then it was just so much better that it just got replaced with the version they were. In some cases it's actually completely net So, or the thing that they're measuring against is slightly different. So I'll tell you, like, what are the other things outside of the three things that they should because the fourth thing that they are looking to build out is they look, they're looking to automate some of their operations, so their operations is, like, inundated with, like, a bunch of requests their customers. And they are looking to integrate some review workflows so that, instead of things going to the operations team, can be handled automatically by one of the workflows. And so now it's going to be like, you know, the NH plus operations that is going to replace that, that workload. So now the comparison there isn't against like, a module. The comparison is, how much can we reduce our operations and because we can just automate that? Priyesh,
improved accuracy in cases where there's a benchmark to compare it to and then, so in this case, they had a pre existing model where they saw an 85% rate against the previous model. And so then it was just so much better that it just got replaced with the version they were. In some cases it's actually completely net So, or the thing that they're measuring against is slightly different. So I'll tell you, like, what are the other things outside of the three things that they should because the fourth thing that they are looking to build out is they look, they're looking to automate some of their operations, so their operations is, like, inundated with, like, a bunch of requests their customers. And they are looking to integrate some review workflows so that, instead of things going to the operations team, can be handled automatically by one of the workflows. And so now it's going to be like, you know, the NH plus operations that is going to replace that, that workload. So now the comparison there isn't against like, a module. The comparison is, how much can we reduce our operations and because we can just automate that? Priyesh,
S Speaker 119:49Yeah, I think some of the more complex ones that we've seen, I'm trying to think, which one do I remember that has the highest number of steps, frankly, because that, in some ways, like tells us that complexity. There's a view that we've seen where which requires processing PDFs, like processing PDFs and images, combining that data, and actually, even though this isn't fully built out yet, but one of the things that us, fact, is looking to build, I think it's going to be actually quite complex, because this is a workload that involves transactions and receipts and matching. And so you can imagine there's like a stream of like transactions that is coming in, there's receipts that are being uploaded by customers, and then there's like a matching process that needs to be built up. This is going to be fairly kind of involved, but that's going to be one of the more complex ones. Actually, like another interesting one that one of our customers uses. This is actually one of our customers is a technology company called Bird tie has, like, they're sort of like marketing, sort of solution for SMEs, where they process a lot of business reviews, they combine a lot of information about their customers data on the internet to basically suggest what that business would be doing better in terms of acquiring net new customers, one of the one of the workers they've built within actually uses information from reviews that they're processing they're all processing that with, already combines that with data on the doing searches for What are potential competitors, and almost producing a scorecard for where that particular company does better or worse than their competitor, and this ends up being like, you know, it's like six, seven steps, because there's some data classification, there's some extraction, there's some looking up entities on the internet and then finally producing a scripted output that is happening. But that is one of the sort of complex one therapies I
Yeah, I think some of the more complex ones that we've seen, I'm trying to think, which one do I remember that has the highest number of steps, frankly, because that, in some ways, like tells us that complexity. There's a view that we've seen where which requires processing PDFs, like processing PDFs and images, combining that data, and actually, even though this isn't fully built out yet, but one of the things that us, fact, is looking to build, I think it's going to be actually quite complex, because this is a workload that involves transactions and receipts and matching. And so you can imagine there's like a stream of like transactions that is coming in, there's receipts that are being uploaded by customers, and then there's like a matching process that needs to be built up. This is going to be fairly kind of involved, but that's going to be one of the more complex ones. Actually, like another interesting one that one of our customers uses. This is actually one of our customers is a technology company called Bird tie has, like, they're sort of like marketing, sort of solution for SMEs, where they process a lot of business reviews, they combine a lot of information about their customers data on the internet to basically suggest what that business would be doing better in terms of acquiring net new customers, one of the one of the workers they've built within actually uses information from reviews that they're processing they're all processing that with, already combines that with data on the doing searches for What are potential competitors, and almost producing a scorecard for where that particular company does better or worse than their competitor, and this ends up being like, you know, it's like six, seven steps, because there's some data classification, there's some extraction, there's some looking up entities on the internet and then finally producing a scripted output that is happening. But that is one of the sort of complex one therapies I
Yeah, I think some of the more complex ones that we've seen, I'm trying to think, which one do I remember that has the highest number of steps, frankly, because that, in some ways, like tells us that complexity. There's a view that we've seen where which requires processing PDFs, like processing PDFs and images, combining that data, and actually, even though this isn't fully built out yet, but one of the things that us, fact, is looking to build, I think it's going to be actually quite complex, because this is a workload that involves transactions and receipts and matching. And so you can imagine there's like a stream of like transactions that is coming in, there's receipts that are being uploaded by customers, and then there's like a matching process that needs to be built up. This is going to be fairly kind of involved, but that's going to be one of the more complex ones. Actually, like another interesting one that one of our customers uses. This is actually one of our customers is a technology company called Bird tie has, like, they're sort of like marketing, sort of solution for SMEs, where they process a lot of business reviews, they combine a lot of information about their customers data on the internet to basically suggest what that business would be doing better in terms of acquiring net new customers, one of the one of the workers they've built within actually uses information from reviews that they're processing they're all processing that with, already combines that with data on the doing searches for What are potential competitors, and almost producing a scorecard for where that particular company does better or worse than their competitor, and this ends up being like, you know, it's like six, seven steps, because there's some data classification, there's some extraction, there's some looking up entities on the internet and then finally producing a scripted output that is happening. But that is one of the sort of complex one therapies I
Yeah, I think some of the more complex ones that we've seen, I'm trying to think, which one do I remember that has the highest number of steps, frankly, because that, in some ways, like tells us that complexity. There's a view that we've seen where which requires processing PDFs, like processing PDFs and images, combining that data, and actually, even though this isn't fully built out yet, but one of the things that us, fact, is looking to build, I think it's going to be actually quite complex, because this is a workload that involves transactions and receipts and matching. And so you can imagine there's like a stream of like transactions that is coming in, there's receipts that are being uploaded by customers, and then there's like a matching process that needs to be built up. This is going to be fairly kind of involved, but that's going to be one of the more complex ones. Actually, like another interesting one that one of our customers uses. This is actually one of our customers is a technology company called Bird tie has, like, they're sort of like marketing, sort of solution for SMEs, where they process a lot of business reviews, they combine a lot of information about their customers data on the internet to basically suggest what that business would be doing better in terms of acquiring net new customers, one of the one of the workers they've built within actually uses information from reviews that they're processing they're all processing that with, already combines that with data on the doing searches for What are potential competitors, and almost producing a scorecard for where that particular company does better or worse than their competitor, and this ends up being like, you know, it's like six, seven steps, because there's some data classification, there's some extraction, there's some looking up entities on the internet and then finally producing a scripted output that is happening. But that is one of the sort of complex one therapies I
22:00can I can sort of remember at the moment. Yeah, moment,
can I can sort of remember at the moment. Yeah, moment,
can I can sort of remember at the moment. Yeah, moment,
can I can sort of remember at the moment. Yeah, moment,
S Speaker 422:04and one more follow up there. Rishabh, is it fair to say that the number of processes that you increase, would that linearly increase the amount of feedback that engineer has to give to the model?
and one more follow up there. Rishabh, is it fair to say that the number of processes that you increase, would that linearly increase the amount of feedback that engineer has to give to the model?
and one more follow up there. Rishabh, is it fair to say that the number of processes that you increase, would that linearly increase the amount of feedback that engineer has to give to the model?
and one more follow up there. Rishabh, is it fair to say that the number of processes that you increase, would that linearly increase the amount of feedback that engineer has to give to the model?
22:17Or does this hit a Plato somewhere
Or does this hit a Plato somewhere
Or does this hit a Plato somewhere
Or does this hit a Plato somewhere
S Speaker 122:20there's this probably, there's probably some relation. I'm not sure if it's like linear relation in terms of example, number of points of feedback, it more depends on the complexity of the product, because what ends up happening is certain steps in the workflow are actually like, quite trivial, like, it's just about doing the activity, and models are already good enough so they can do it at high levels of accuracy. But yeah, there's probably some correlation. It's not, it's not absolutely the one thing I will say is the four steps that are involved that actually has a strong correlation with customers thinking of us as replacing even costs, because those are the ones that are actually really hard for them to to automate with like, let's say just like ML model that is getting through, right? The more steps that is involved, the closer it is to like them. Thinking of this is like, Okay, this is actually similar to what a human will be doing, and we have a place for that. Do. And so by you
there's this probably, there's probably some relation. I'm not sure if it's like linear relation in terms of example, number of points of feedback, it more depends on the complexity of the product, because what ends up happening is certain steps in the workflow are actually like, quite trivial, like, it's just about doing the activity, and models are already good enough so they can do it at high levels of accuracy. But yeah, there's probably some correlation. It's not, it's not absolutely the one thing I will say is the four steps that are involved that actually has a strong correlation with customers thinking of us as replacing even costs, because those are the ones that are actually really hard for them to to automate with like, let's say just like ML model that is getting through, right? The more steps that is involved, the closer it is to like them. Thinking of this is like, Okay, this is actually similar to what a human will be doing, and we have a place for that. Do. And so by you
there's this probably, there's probably some relation. I'm not sure if it's like linear relation in terms of example, number of points of feedback, it more depends on the complexity of the product, because what ends up happening is certain steps in the workflow are actually like, quite trivial, like, it's just about doing the activity, and models are already good enough so they can do it at high levels of accuracy. But yeah, there's probably some correlation. It's not, it's not absolutely the one thing I will say is the four steps that are involved that actually has a strong correlation with customers thinking of us as replacing even costs, because those are the ones that are actually really hard for them to to automate with like, let's say just like ML model that is getting through, right? The more steps that is involved, the closer it is to like them. Thinking of this is like, Okay, this is actually similar to what a human will be doing, and we have a place for that. Do. And so by you
there's this probably, there's probably some relation. I'm not sure if it's like linear relation in terms of example, number of points of feedback, it more depends on the complexity of the product, because what ends up happening is certain steps in the workflow are actually like, quite trivial, like, it's just about doing the activity, and models are already good enough so they can do it at high levels of accuracy. But yeah, there's probably some correlation. It's not, it's not absolutely the one thing I will say is the four steps that are involved that actually has a strong correlation with customers thinking of us as replacing even costs, because those are the ones that are actually really hard for them to to automate with like, let's say just like ML model that is getting through, right? The more steps that is involved, the closer it is to like them. Thinking of this is like, Okay, this is actually similar to what a human will be doing, and we have a place for that. Do. And so by you
23:24processing. So one of the things that I was
processing. So one of the things that I was
processing. So one of the things that I was
processing. So one of the things that I was
S Speaker 323:30going to do contextual. So
going to do contextual. So
going to do contextual. So
going to do contextual. So
23:35we want to generate data
we want to generate data
we want to generate data
we want to generate data
S Speaker 223:38as well. Can you have a product that can serve I gave you, I think an example of document type is PDFs with images,
as well. Can you have a product that can serve I gave you, I think an example of document type is PDFs with images,
as well. Can you have a product that can serve I gave you, I think an example of document type is PDFs with images,
as well. Can you have a product that can serve I gave you, I think an example of document type is PDFs with images,
23:45charts, logs and nested tables. And
charts, logs and nested tables. And
charts, logs and nested tables. And
charts, logs and nested tables. And
23:49the idea is to curate
the idea is to curate
the idea is to curate
the idea is to curate
23:58data, you have a product that
data, you have a product that
data, you have a product that
data, you have a product that
S Speaker 124:05can work on that data, I think the way it would work is actually Bucha, probably very similar. And so one of the things that would probably happen is there will be
can work on that data, I think the way it would work is actually Bucha, probably very similar. And so one of the things that would probably happen is there will be
can work on that data, I think the way it would work is actually Bucha, probably very similar. And so one of the things that would probably happen is there will be
can work on that data, I think the way it would work is actually Bucha, probably very similar. And so one of the things that would probably happen is there will be
24:21there'll be a few.
S Speaker 124:30Like, you would essentially like, like, the way this would get set up is, like, one of the problems here would be, like, a link to a readable PDF. So we would have to be able to go and read that PDF, and then the way we're sort of extracting or structured data, like you would basically have to tell us, like, which are the fields that we're looking to extract, so whether it is charts, whether it is like specific business information, which is build out that workflow, which is what that final data like Final kind of rag application that needs to be built at these PDFs. What are the 510, 15 things will continue to extract and process for every single one of those PDFs. You would essentially go and build this out step by step. And then, of course, like for the models themselves, like a model that we could use is something that is multimodal, so that, like, we can sort of read the PDFs and sort of like both the image form, but also behind the scenes, we actually do the OCR complete the text along with the image, conserve increase within all the stacks that deliver sort of quality. But of course, like process
Like, you would essentially like, like, the way this would get set up is, like, one of the problems here would be, like, a link to a readable PDF. So we would have to be able to go and read that PDF, and then the way we're sort of extracting or structured data, like you would basically have to tell us, like, which are the fields that we're looking to extract, so whether it is charts, whether it is like specific business information, which is build out that workflow, which is what that final data like Final kind of rag application that needs to be built at these PDFs. What are the 510, 15 things will continue to extract and process for every single one of those PDFs. You would essentially go and build this out step by step. And then, of course, like for the models themselves, like a model that we could use is something that is multimodal, so that, like, we can sort of read the PDFs and sort of like both the image form, but also behind the scenes, we actually do the OCR complete the text along with the image, conserve increase within all the stacks that deliver sort of quality. But of course, like process
Like, you would essentially like, like, the way this would get set up is, like, one of the problems here would be, like, a link to a readable PDF. So we would have to be able to go and read that PDF, and then the way we're sort of extracting or structured data, like you would basically have to tell us, like, which are the fields that we're looking to extract, so whether it is charts, whether it is like specific business information, which is build out that workflow, which is what that final data like Final kind of rag application that needs to be built at these PDFs. What are the 510, 15 things will continue to extract and process for every single one of those PDFs. You would essentially go and build this out step by step. And then, of course, like for the models themselves, like a model that we could use is something that is multimodal, so that, like, we can sort of read the PDFs and sort of like both the image form, but also behind the scenes, we actually do the OCR complete the text along with the image, conserve increase within all the stacks that deliver sort of quality. But of course, like process
Like, you would essentially like, like, the way this would get set up is, like, one of the problems here would be, like, a link to a readable PDF. So we would have to be able to go and read that PDF, and then the way we're sort of extracting or structured data, like you would basically have to tell us, like, which are the fields that we're looking to extract, so whether it is charts, whether it is like specific business information, which is build out that workflow, which is what that final data like Final kind of rag application that needs to be built at these PDFs. What are the 510, 15 things will continue to extract and process for every single one of those PDFs. You would essentially go and build this out step by step. And then, of course, like for the models themselves, like a model that we could use is something that is multimodal, so that, like, we can sort of read the PDFs and sort of like both the image form, but also behind the scenes, we actually do the OCR complete the text along with the image, conserve increase within all the stacks that deliver sort of quality. But of course, like process
S Speaker 125:41yeah, and again. This just, you
yeah, and again. This just, you
yeah, and again. This just, you
yeah, and again. This just, you
S Speaker 225:45know, like, from one PDF to another, fields might not be predictable, you know, these are think about, these are like technology documents talking about different technology areas of that
know, like, from one PDF to another, fields might not be predictable, you know, these are think about, these are like technology documents talking about different technology areas of that
know, like, from one PDF to another, fields might not be predictable, you know, these are think about, these are like technology documents talking about different technology areas of that
know, like, from one PDF to another, fields might not be predictable, you know, these are think about, these are like technology documents talking about different technology areas of that
26:02shit. Yeah, it's of the chip, camera, audio,
shit. Yeah, it's of the chip, camera, audio,
shit. Yeah, it's of the chip, camera, audio,
shit. Yeah, it's of the chip, camera, audio,
S Speaker 226:07and then it's very hard to pick like fixed set of fields, yeah, each one
and then it's very hard to pick like fixed set of fields, yeah, each one
and then it's very hard to pick like fixed set of fields, yeah, each one
and then it's very hard to pick like fixed set of fields, yeah, each one
26:15goes. How does that work?
goes. How does that work?
goes. How does that work?
goes. How does that work?
S Speaker 126:19For that, it's actually you know, this is quite common to try. What ends up happening is, like, you'll see that there's a way to sort of have, like an extraction field where, essentially, you can tell us that there's a very large, let's say, Jigsaw schema of all the things that are possible that we might want to extract. And so you can wind us towards, like, you know, like maybe there are, you know, five things that are always there, 20 things that may or may not there. Just, if you give us an indignation of what that could look like, right then the combination of what we've built plus feedback from somebody on the team just doing something, it'll get you to the level of sort of quantity in that free process instead. Then, you know, after that, you just hit a button. Now, for every new sort of PDF that's going to get, it would be processing and successful. And then, sort of the goal of the because these are pipelines, right? So over time, like, maybe there's a net new type of PDF that will start showing up, right? And so when that happens, I will highlight that, which will be low confidence somebody can give additional feedback, fix it. It's
For that, it's actually you know, this is quite common to try. What ends up happening is, like, you'll see that there's a way to sort of have, like an extraction field where, essentially, you can tell us that there's a very large, let's say, Jigsaw schema of all the things that are possible that we might want to extract. And so you can wind us towards, like, you know, like maybe there are, you know, five things that are always there, 20 things that may or may not there. Just, if you give us an indignation of what that could look like, right then the combination of what we've built plus feedback from somebody on the team just doing something, it'll get you to the level of sort of quantity in that free process instead. Then, you know, after that, you just hit a button. Now, for every new sort of PDF that's going to get, it would be processing and successful. And then, sort of the goal of the because these are pipelines, right? So over time, like, maybe there's a net new type of PDF that will start showing up, right? And so when that happens, I will highlight that, which will be low confidence somebody can give additional feedback, fix it. It's
For that, it's actually you know, this is quite common to try. What ends up happening is, like, you'll see that there's a way to sort of have, like an extraction field where, essentially, you can tell us that there's a very large, let's say, Jigsaw schema of all the things that are possible that we might want to extract. And so you can wind us towards, like, you know, like maybe there are, you know, five things that are always there, 20 things that may or may not there. Just, if you give us an indignation of what that could look like, right then the combination of what we've built plus feedback from somebody on the team just doing something, it'll get you to the level of sort of quantity in that free process instead. Then, you know, after that, you just hit a button. Now, for every new sort of PDF that's going to get, it would be processing and successful. And then, sort of the goal of the because these are pipelines, right? So over time, like, maybe there's a net new type of PDF that will start showing up, right? And so when that happens, I will highlight that, which will be low confidence somebody can give additional feedback, fix it. It's
For that, it's actually you know, this is quite common to try. What ends up happening is, like, you'll see that there's a way to sort of have, like an extraction field where, essentially, you can tell us that there's a very large, let's say, Jigsaw schema of all the things that are possible that we might want to extract. And so you can wind us towards, like, you know, like maybe there are, you know, five things that are always there, 20 things that may or may not there. Just, if you give us an indignation of what that could look like, right then the combination of what we've built plus feedback from somebody on the team just doing something, it'll get you to the level of sort of quantity in that free process instead. Then, you know, after that, you just hit a button. Now, for every new sort of PDF that's going to get, it would be processing and successful. And then, sort of the goal of the because these are pipelines, right? So over time, like, maybe there's a net new type of PDF that will start showing up, right? And so when that happens, I will highlight that, which will be low confidence somebody can give additional feedback, fix it. It's
28:00you have, like, a contracted arr? You
you have, like, a contracted arr? You
you have, like, a contracted arr? You
you have, like, a contracted arr? You
S Speaker 228:04have, like, what's your contracted arr?
have, like, what's your contracted arr?
have, like, what's your contracted arr?
have, like, what's your contracted arr?
28:07Guess the difference between your contracted the way, I
Guess the difference between your contracted the way, I
Guess the difference between your contracted the way, I
Guess the difference between your contracted the way, I
S Speaker 128:11just want to make sure I understand exactly what you mean by contracted Arr, but essentially, like, the way our pricing works is it's two components, just like monthly platform. And then the second component is like more tied to the value that we deliver, which is like the amount of those transform. And of course, like the exact what we price, it is like based on tokens. So we end up getting these two half single pricing right. And so the AR number that we report is basically just look at like the combination of those two in every month times 12. Although one of the things that we're starting to do from our ARR companies, we're starting to remove things that we know are known, like I said, backfills that are going to be one time, because they'll show up in revenue. But we want to sort of like, be a little bit conservative in terms of our reporting, so not sort of like talk about that in a but generally, those are the two things that like matter revenue wise.
just want to make sure I understand exactly what you mean by contracted Arr, but essentially, like, the way our pricing works is it's two components, just like monthly platform. And then the second component is like more tied to the value that we deliver, which is like the amount of those transform. And of course, like the exact what we price, it is like based on tokens. So we end up getting these two half single pricing right. And so the AR number that we report is basically just look at like the combination of those two in every month times 12. Although one of the things that we're starting to do from our ARR companies, we're starting to remove things that we know are known, like I said, backfills that are going to be one time, because they'll show up in revenue. But we want to sort of like, be a little bit conservative in terms of our reporting, so not sort of like talk about that in a but generally, those are the two things that like matter revenue wise.
just want to make sure I understand exactly what you mean by contracted Arr, but essentially, like, the way our pricing works is it's two components, just like monthly platform. And then the second component is like more tied to the value that we deliver, which is like the amount of those transform. And of course, like the exact what we price, it is like based on tokens. So we end up getting these two half single pricing right. And so the AR number that we report is basically just look at like the combination of those two in every month times 12. Although one of the things that we're starting to do from our ARR companies, we're starting to remove things that we know are known, like I said, backfills that are going to be one time, because they'll show up in revenue. But we want to sort of like, be a little bit conservative in terms of our reporting, so not sort of like talk about that in a but generally, those are the two things that like matter revenue wise.
just want to make sure I understand exactly what you mean by contracted Arr, but essentially, like, the way our pricing works is it's two components, just like monthly platform. And then the second component is like more tied to the value that we deliver, which is like the amount of those transform. And of course, like the exact what we price, it is like based on tokens. So we end up getting these two half single pricing right. And so the AR number that we report is basically just look at like the combination of those two in every month times 12. Although one of the things that we're starting to do from our ARR companies, we're starting to remove things that we know are known, like I said, backfills that are going to be one time, because they'll show up in revenue. But we want to sort of like, be a little bit conservative in terms of our reporting, so not sort of like talk about that in a but generally, those are the two things that like matter revenue wise.
S Speaker 229:07Are you not signing contracts with customers such that you know for the next year? Are you not
Are you not signing contracts with customers such that you know for the next year? Are you not
Are you not signing contracts with customers such that you know for the next year? Are you not
Are you not signing contracts with customers such that you know for the next year? Are you not
29:18signing that contract yet?
signing that contract yet?
signing that contract yet?
signing that contract yet?
S Speaker 129:22No, not yet, you know. And to show like, you know, this is something that we will likely graduate to. But the reason, the specific reason why we don't do it today is often we are the first time customers end up seeing something that works successfully with llms, and when they are not sure if it's going to work, right. It's very hard for them to project out, like, what is a like, contracted amount that would make sense to them, right? If this was something like, Hey, you're spending x amount of open AI, let's just like, replace that with something else. Okay, there's like, a calculation that is easy. But look, this is a profession, more about sort of, you know, maturity, friendly of some of these customers, for some of the largest ones. We do make this end, but it is not the common sort of mode of operation. So, for example, our largest customer, which is when they did abusive, first proved out the value. So that's 150k contract. And so that basically has both platform and sort of like that, like volume up to a certain amount, right? That's,
No, not yet, you know. And to show like, you know, this is something that we will likely graduate to. But the reason, the specific reason why we don't do it today is often we are the first time customers end up seeing something that works successfully with llms, and when they are not sure if it's going to work, right. It's very hard for them to project out, like, what is a like, contracted amount that would make sense to them, right? If this was something like, Hey, you're spending x amount of open AI, let's just like, replace that with something else. Okay, there's like, a calculation that is easy. But look, this is a profession, more about sort of, you know, maturity, friendly of some of these customers, for some of the largest ones. We do make this end, but it is not the common sort of mode of operation. So, for example, our largest customer, which is when they did abusive, first proved out the value. So that's 150k contract. And so that basically has both platform and sort of like that, like volume up to a certain amount, right? That's,
No, not yet, you know. And to show like, you know, this is something that we will likely graduate to. But the reason, the specific reason why we don't do it today is often we are the first time customers end up seeing something that works successfully with llms, and when they are not sure if it's going to work, right. It's very hard for them to project out, like, what is a like, contracted amount that would make sense to them, right? If this was something like, Hey, you're spending x amount of open AI, let's just like, replace that with something else. Okay, there's like, a calculation that is easy. But look, this is a profession, more about sort of, you know, maturity, friendly of some of these customers, for some of the largest ones. We do make this end, but it is not the common sort of mode of operation. So, for example, our largest customer, which is when they did abusive, first proved out the value. So that's 150k contract. And so that basically has both platform and sort of like that, like volume up to a certain amount, right? That's,
No, not yet, you know. And to show like, you know, this is something that we will likely graduate to. But the reason, the specific reason why we don't do it today is often we are the first time customers end up seeing something that works successfully with llms, and when they are not sure if it's going to work, right. It's very hard for them to project out, like, what is a like, contracted amount that would make sense to them, right? If this was something like, Hey, you're spending x amount of open AI, let's just like, replace that with something else. Okay, there's like, a calculation that is easy. But look, this is a profession, more about sort of, you know, maturity, friendly of some of these customers, for some of the largest ones. We do make this end, but it is not the common sort of mode of operation. So, for example, our largest customer, which is when they did abusive, first proved out the value. So that's 150k contract. And so that basically has both platform and sort of like that, like volume up to a certain amount, right? That's,
30:25that's contract.
30:29So the contract,
30:31most of the others today, are not
most of the others today, are not
most of the others today, are not
most of the others today, are not
S Speaker 130:35contractors, yeah, so it's combination of monthly subscription and then usage, but your AR, arr right now is how you calculate the it's the the monthly sort of platform fee, plus the sort of usage that happened within that month and the dollar spent there. So just take that immediately. Times by tomorrow. That's
contractors, yeah, so it's combination of monthly subscription and then usage, but your AR, arr right now is how you calculate the it's the the monthly sort of platform fee, plus the sort of usage that happened within that month and the dollar spent there. So just take that immediately. Times by tomorrow. That's
contractors, yeah, so it's combination of monthly subscription and then usage, but your AR, arr right now is how you calculate the it's the the monthly sort of platform fee, plus the sort of usage that happened within that month and the dollar spent there. So just take that immediately. Times by tomorrow. That's
contractors, yeah, so it's combination of monthly subscription and then usage, but your AR, arr right now is how you calculate the it's the the monthly sort of platform fee, plus the sort of usage that happened within that month and the dollar spent there. So just take that immediately. Times by tomorrow. That's
31:00not recurring per se, like, that's
not recurring per se, like, that's
not recurring per se, like, that's
not recurring per se, like, that's
31:07more revenue run rate than
more revenue run rate than
more revenue run rate than
more revenue run rate than
31:09recurring revenue. So it's,
recurring revenue. So it's,
recurring revenue. So it's,
recurring revenue. So it's,
31:12it's the run rate, yeah,
it's the run rate, yeah,
it's the run rate, yeah,
it's the run rate, yeah,
S Speaker 131:16I'd be curious, what do you think? But you know, it's one of those where, because some of it is, like, actually quite stable, right? And it's actually just like,
I'd be curious, what do you think? But you know, it's one of those where, because some of it is, like, actually quite stable, right? And it's actually just like,
I'd be curious, what do you think? But you know, it's one of those where, because some of it is, like, actually quite stable, right? And it's actually just like,
I'd be curious, what do you think? But you know, it's one of those where, because some of it is, like, actually quite stable, right? And it's actually just like,
S Speaker 231:25Yeah, at some point you have to, I think what you have to get these contracts, yeah, today, this is more run record, and
Yeah, at some point you have to, I think what you have to get these contracts, yeah, today, this is more run record, and
Yeah, at some point you have to, I think what you have to get these contracts, yeah, today, this is more run record, and
Yeah, at some point you have to, I think what you have to get these contracts, yeah, today, this is more run record, and
31:41it's healthy. It's a pretty healthy run rate
it's healthy. It's a pretty healthy run rate
it's healthy. It's a pretty healthy run rate
it's healthy. It's a pretty healthy run rate
S Speaker 231:45at which you're growing. But at one point you have to start getting converting, because you want predictability in your next quarter. And in order, the only
at which you're growing. But at one point you have to start getting converting, because you want predictability in your next quarter. And in order, the only
at which you're growing. But at one point you have to start getting converting, because you want predictability in your next quarter. And in order, the only
at which you're growing. But at one point you have to start getting converting, because you want predictability in your next quarter. And in order, the only
31:56way to get predictability is to build in
way to get predictability is to build in
way to get predictability is to build in
way to get predictability is to build in
32:03I agree, yeah, yeah.
S Speaker 132:06100% agree to try it. You know, you can imagine, like, the time when it comes for some of these renewals, right, there's going to be sort of like, important for us to do things, I wouldn't even say fix. It's just like an evolution, right, for our sort of prices. Well, I Well,
100% agree to try it. You know, you can imagine, like, the time when it comes for some of these renewals, right, there's going to be sort of like, important for us to do things, I wouldn't even say fix. It's just like an evolution, right, for our sort of prices. Well, I Well,
100% agree to try it. You know, you can imagine, like, the time when it comes for some of these renewals, right, there's going to be sort of like, important for us to do things, I wouldn't even say fix. It's just like an evolution, right, for our sort of prices. Well, I Well,
100% agree to try it. You know, you can imagine, like, the time when it comes for some of these renewals, right, there's going to be sort of like, important for us to do things, I wouldn't even say fix. It's just like an evolution, right, for our sort of prices. Well, I Well,
S Speaker 232:23okay, I guess they will just be happy paying from pay as you go, but, but you want to start talking
okay, I guess they will just be happy paying from pay as you go, but, but you want to start talking
okay, I guess they will just be happy paying from pay as you go, but, but you want to start talking
okay, I guess they will just be happy paying from pay as you go, but, but you want to start talking
32:41And so. So, from a pipeline, customer pipeline standpoint, how
And so. So, from a pipeline, customer pipeline standpoint, how
And so. So, from a pipeline, customer pipeline standpoint, how
And so. So, from a pipeline, customer pipeline standpoint, how
S Speaker 232:44are you building your pipeline, and which customers are you talking to, and where are they? How
are you building your pipeline, and which customers are you talking to, and where are they? How
are you building your pipeline, and which customers are you talking to, and where are they? How
are you building your pipeline, and which customers are you talking to, and where are they? How
32:51do you filter? Did
32:54you have to go? I do actually, okay,
you have to go? I do actually, okay,
you have to go? I do actually, okay,
you have to go? I do actually, okay,
S Speaker 233:00if you have a spreadsheet or something pipeline, you can send that over, and then let us take a look, and then we can get back.
if you have a spreadsheet or something pipeline, you can send that over, and then let us take a look, and then we can get back.
if you have a spreadsheet or something pipeline, you can send that over, and then let us take a look, and then we can get back.
if you have a spreadsheet or something pipeline, you can send that over, and then let us take a look, and then we can get back.
33:17Okay, thank you.
S Speaker 133:20Awesome. In terms of other kind of mix of so often, aside from
Awesome. In terms of other kind of mix of so often, aside from
Awesome. In terms of other kind of mix of so often, aside from
Awesome. In terms of other kind of mix of so often, aside from
33:26sending that over, are we still? I'll continue
sending that over, are we still? I'll continue
sending that over, are we still? I'll continue
sending that over, are we still? I'll continue
S Speaker 233:28to follow up, and I want to set up that meeting, but I have to talk to you some on the timing. I have
to follow up, and I want to set up that meeting, but I have to talk to you some on the timing. I have
to follow up, and I want to set up that meeting, but I have to talk to you some on the timing. I have
to follow up, and I want to set up that meeting, but I have to talk to you some on the timing. I have
33:35to figure out when people are traveling and everything,
to figure out when people are traveling and everything,
to figure out when people are traveling and everything,
to figure out when people are traveling and everything,
33:40so I'll have more visibility. But tomorrow, Thank
so I'll have more visibility. But tomorrow, Thank
so I'll have more visibility. But tomorrow, Thank
so I'll have more visibility. But tomorrow, Thank
33:42you so much, go to.