Meeting: OpenTeams
Mon, Oct 27
3:16 PM
42 min
Priyesh P
Introduction and Initial Greetings
0:06
Overview of Q
URL: https://otter.ai/u/B4aJOGH6fQfmbmxjbNPRXGQ_KRQ
Downloaded: 2025-12-21T19:50:39.233489
Method: text_extraction
============================================================

S Speaker 10:06Priyesh, how are you? Hey, Austin. Hey, Jose, great to meet you both. I'm doing great. Where are you calling in from?
Priyesh, how are you? Hey, Austin. Hey, Jose, great to meet you both. I'm doing great. Where are you calling in from?
Priyesh, how are you? Hey, Austin. Hey, Jose, great to meet you both. I'm doing great. Where are you calling in from?
Priyesh, how are you? Hey, Austin. Hey, Jose, great to meet you both. I'm doing great. Where are you calling in from?
0:16Austin, Texas. Oh,
S Speaker 10:18wow. So I have one more member of my team, Deepak, who is a partner at Qualcomm ventures, to join in. He should be coming in anyway, any minute, but, but that's all, yeah, looking forward to the call. So we got the initial intro deck. We have gone through that. We have an initial understanding of what you guys are trying to do, at least the vision, but would love to sort of dive deeper into the product and some of the work that you're doing with some of the corporates that you mentioned,
wow. So I have one more member of my team, Deepak, who is a partner at Qualcomm ventures, to join in. He should be coming in anyway, any minute, but, but that's all, yeah, looking forward to the call. So we got the initial intro deck. We have gone through that. We have an initial understanding of what you guys are trying to do, at least the vision, but would love to sort of dive deeper into the product and some of the work that you're doing with some of the corporates that you mentioned,
wow. So I have one more member of my team, Deepak, who is a partner at Qualcomm ventures, to join in. He should be coming in anyway, any minute, but, but that's all, yeah, looking forward to the call. So we got the initial intro deck. We have gone through that. We have an initial understanding of what you guys are trying to do, at least the vision, but would love to sort of dive deeper into the product and some of the work that you're doing with some of the corporates that you mentioned,
wow. So I have one more member of my team, Deepak, who is a partner at Qualcomm ventures, to join in. He should be coming in anyway, any minute, but, but that's all, yeah, looking forward to the call. So we got the initial intro deck. We have gone through that. We have an initial understanding of what you guys are trying to do, at least the vision, but would love to sort of dive deeper into the product and some of the work that you're doing with some of the corporates that you mentioned,
S Speaker 20:43Priyesh, I got to be very clear, though you said trying to do that's the wrong thing. This is happening, whether you like it or Yeah, we have the support of Microsoft, IBM, Nvidia, Dell, yes, AMD, Intel. So most of the time you talk to companies, yeah, you know you're talking to people who are trying to do something, right? That's not us. We're not trying to do something. Hey, how's it going?
Priyesh, I got to be very clear, though you said trying to do that's the wrong thing. This is happening, whether you like it or Yeah, we have the support of Microsoft, IBM, Nvidia, Dell, yes, AMD, Intel. So most of the time you talk to companies, yeah, you know you're talking to people who are trying to do something, right? That's not us. We're not trying to do something. Hey, how's it going?
Priyesh, I got to be very clear, though you said trying to do that's the wrong thing. This is happening, whether you like it or Yeah, we have the support of Microsoft, IBM, Nvidia, Dell, yes, AMD, Intel. So most of the time you talk to companies, yeah, you know you're talking to people who are trying to do something, right? That's not us. We're not trying to do something. Hey, how's it going?
Priyesh, I got to be very clear, though you said trying to do that's the wrong thing. This is happening, whether you like it or Yeah, we have the support of Microsoft, IBM, Nvidia, Dell, yes, AMD, Intel. So most of the time you talk to companies, yeah, you know you're talking to people who are trying to do something, right? That's not us. We're not trying to do something. Hey, how's it going?
1:08Hey, doing good. How are you doing excellent?
Hey, doing good. How are you doing excellent?
Hey, doing good. How are you doing excellent?
Hey, doing good. How are you doing excellent?
S Speaker 21:12We are doing excellent. Yeah, yeah. We're not trying to do something. We are doing something. All
We are doing excellent. Yeah, yeah. We're not trying to do something. We are doing something. All
We are doing excellent. Yeah, yeah. We're not trying to do something. We are doing something. All
We are doing excellent. Yeah, yeah. We're not trying to do something. We are doing something. All
1:18right, I stand corrected.
right, I stand corrected.
right, I stand corrected.
right, I stand corrected.
1:23to do. We love to understand what you're
to do. We love to understand what you're
to do. We love to understand what you're
to do. We love to understand what you're
S Speaker 11:27trying to do. Yeah, no, I think before that, did you guys connect? Before it's the first call? Is the first call, really quickly. Yes. What role do you play at Qualcomm? Exactly. No, I was, I was exactly gonna do that, right? Which is since the first time. I'll start with introducing, have you talked to Qualcomm or the ventures team before at Qualcomm, or first time? Right? So of course, I'm assuming you know of Qualcomm, but we are part of the ventures, ventures team within Qualcomm, as the name suggests, we have the strategic investment run. And interestingly, this is our 25th year of doing investment, right? So we've seen cycles. We are stage agnostic, so we do anywhere from only to growth stage in terms of focus areas. Of course, we are strategic to Qualcomm, so we are answerable to some of the core focus areas that Qualcomm has, which is anywhere from mobile and connectivity to automotive and IoT. But if you can see AI is cutting through all these markets and more, right? So we have a focus on, you know, the AI adoption within enterprises and how to enable that, both closed source and open source. So we invested in anthropic hugging face and bunch of other open source communities. We just recently invested in a company called poky that does open source agent orchestration, right? So, and coming from that point of view, right? We've spent some time on, how can you reduce friction for enterprises to adopt open source tools, right? Open source is catching up, and that's why I like I coming in from what I can see, you know, publicly available, it seems like an interesting value prop, so we'd love to learn more. Specifically coming to us, I am. I've been part of the ventures team for six plus years. I'm a director your lead investments in infrastructure, dev tools and cyber security. So this is right in the wheelhouse and and, yeah. So happy to answer any questions I might have missed. In terms of ticket size, Joseph, we invest anywhere from one to $12 million with sweet spot being seven to eight, and series A and B is where we try to, it's like our, you know, stage where we play. Now, it's all getting blurry, you know, series A's are being, you know, it's weird. It's weird, right? So forget about all of that. What we what we look for is maybe some early validation with customers, enterprise customers, early traction. And maybe you're transitioning from founder led sales to, you know, more
trying to do. Yeah, no, I think before that, did you guys connect? Before it's the first call? Is the first call, really quickly. Yes. What role do you play at Qualcomm? Exactly. No, I was, I was exactly gonna do that, right? Which is since the first time. I'll start with introducing, have you talked to Qualcomm or the ventures team before at Qualcomm, or first time? Right? So of course, I'm assuming you know of Qualcomm, but we are part of the ventures, ventures team within Qualcomm, as the name suggests, we have the strategic investment run. And interestingly, this is our 25th year of doing investment, right? So we've seen cycles. We are stage agnostic, so we do anywhere from only to growth stage in terms of focus areas. Of course, we are strategic to Qualcomm, so we are answerable to some of the core focus areas that Qualcomm has, which is anywhere from mobile and connectivity to automotive and IoT. But if you can see AI is cutting through all these markets and more, right? So we have a focus on, you know, the AI adoption within enterprises and how to enable that, both closed source and open source. So we invested in anthropic hugging face and bunch of other open source communities. We just recently invested in a company called poky that does open source agent orchestration, right? So, and coming from that point of view, right? We've spent some time on, how can you reduce friction for enterprises to adopt open source tools, right? Open source is catching up, and that's why I like I coming in from what I can see, you know, publicly available, it seems like an interesting value prop, so we'd love to learn more. Specifically coming to us, I am. I've been part of the ventures team for six plus years. I'm a director your lead investments in infrastructure, dev tools and cyber security. So this is right in the wheelhouse and and, yeah. So happy to answer any questions I might have missed. In terms of ticket size, Joseph, we invest anywhere from one to $12 million with sweet spot being seven to eight, and series A and B is where we try to, it's like our, you know, stage where we play. Now, it's all getting blurry, you know, series A's are being, you know, it's weird. It's weird, right? So forget about all of that. What we what we look for is maybe some early validation with customers, enterprise customers, early traction. And maybe you're transitioning from founder led sales to, you know, more
trying to do. Yeah, no, I think before that, did you guys connect? Before it's the first call? Is the first call, really quickly. Yes. What role do you play at Qualcomm? Exactly. No, I was, I was exactly gonna do that, right? Which is since the first time. I'll start with introducing, have you talked to Qualcomm or the ventures team before at Qualcomm, or first time? Right? So of course, I'm assuming you know of Qualcomm, but we are part of the ventures, ventures team within Qualcomm, as the name suggests, we have the strategic investment run. And interestingly, this is our 25th year of doing investment, right? So we've seen cycles. We are stage agnostic, so we do anywhere from only to growth stage in terms of focus areas. Of course, we are strategic to Qualcomm, so we are answerable to some of the core focus areas that Qualcomm has, which is anywhere from mobile and connectivity to automotive and IoT. But if you can see AI is cutting through all these markets and more, right? So we have a focus on, you know, the AI adoption within enterprises and how to enable that, both closed source and open source. So we invested in anthropic hugging face and bunch of other open source communities. We just recently invested in a company called poky that does open source agent orchestration, right? So, and coming from that point of view, right? We've spent some time on, how can you reduce friction for enterprises to adopt open source tools, right? Open source is catching up, and that's why I like I coming in from what I can see, you know, publicly available, it seems like an interesting value prop, so we'd love to learn more. Specifically coming to us, I am. I've been part of the ventures team for six plus years. I'm a director your lead investments in infrastructure, dev tools and cyber security. So this is right in the wheelhouse and and, yeah. So happy to answer any questions I might have missed. In terms of ticket size, Joseph, we invest anywhere from one to $12 million with sweet spot being seven to eight, and series A and B is where we try to, it's like our, you know, stage where we play. Now, it's all getting blurry, you know, series A's are being, you know, it's weird. It's weird, right? So forget about all of that. What we what we look for is maybe some early validation with customers, enterprise customers, early traction. And maybe you're transitioning from founder led sales to, you know, more
trying to do. Yeah, no, I think before that, did you guys connect? Before it's the first call? Is the first call, really quickly. Yes. What role do you play at Qualcomm? Exactly. No, I was, I was exactly gonna do that, right? Which is since the first time. I'll start with introducing, have you talked to Qualcomm or the ventures team before at Qualcomm, or first time? Right? So of course, I'm assuming you know of Qualcomm, but we are part of the ventures, ventures team within Qualcomm, as the name suggests, we have the strategic investment run. And interestingly, this is our 25th year of doing investment, right? So we've seen cycles. We are stage agnostic, so we do anywhere from only to growth stage in terms of focus areas. Of course, we are strategic to Qualcomm, so we are answerable to some of the core focus areas that Qualcomm has, which is anywhere from mobile and connectivity to automotive and IoT. But if you can see AI is cutting through all these markets and more, right? So we have a focus on, you know, the AI adoption within enterprises and how to enable that, both closed source and open source. So we invested in anthropic hugging face and bunch of other open source communities. We just recently invested in a company called poky that does open source agent orchestration, right? So, and coming from that point of view, right? We've spent some time on, how can you reduce friction for enterprises to adopt open source tools, right? Open source is catching up, and that's why I like I coming in from what I can see, you know, publicly available, it seems like an interesting value prop, so we'd love to learn more. Specifically coming to us, I am. I've been part of the ventures team for six plus years. I'm a director your lead investments in infrastructure, dev tools and cyber security. So this is right in the wheelhouse and and, yeah. So happy to answer any questions I might have missed. In terms of ticket size, Joseph, we invest anywhere from one to $12 million with sweet spot being seven to eight, and series A and B is where we try to, it's like our, you know, stage where we play. Now, it's all getting blurry, you know, series A's are being, you know, it's weird. It's weird, right? So forget about all of that. What we what we look for is maybe some early validation with customers, enterprise customers, early traction. And maybe you're transitioning from founder led sales to, you know, more
S Speaker 24:03functioning from founder led sales to a sales you
functioning from founder led sales to a sales you
functioning from founder led sales to a sales you
functioning from founder led sales to a sales you
4:07taking words from my yes
taking words from my yes
taking words from my yes
taking words from my yes
S Speaker 24:10over the past year we put that sales team in place. Yeah, we have to grow it. And we got, we need, we need, we need gas for the tank.
over the past year we put that sales team in place. Yeah, we have to grow it. And we got, we need, we need, we need gas for the tank.
over the past year we put that sales team in place. Yeah, we have to grow it. And we got, we need, we need, we need gas for the tank.
over the past year we put that sales team in place. Yeah, we have to grow it. And we got, we need, we need, we need gas for the tank.
S Speaker 24:31First off, do you know who Travis olivan is our founder?
First off, do you know who Travis olivan is our founder?
First off, do you know who Travis olivan is our founder?
First off, do you know who Travis olivan is our founder?
S Speaker 14:34Yes, of course, we did some background. But if you if you were to articulate, yeah, I mean,
Yes, of course, we did some background. But if you if you were to articulate, yeah, I mean,
Yes, of course, we did some background. But if you if you were to articulate, yeah, I mean,
Yes, of course, we did some background. But if you if you were to articulate, yeah, I mean,
4:41I like to explain to people,
I like to explain to people,
I like to explain to people,
I like to explain to people,
S Speaker 16:23Are you familiar with Navarre? Yeah, number, I did look it up. I wasn't familiar with it before.
Are you familiar with Navarre? Yeah, number, I did look it up. I wasn't familiar with it before.
Are you familiar with Navarre? Yeah, number, I did look it up. I wasn't familiar with it before.
Are you familiar with Navarre? Yeah, number, I did look it up. I wasn't familiar with it before.
S Speaker 26:27Most people know it, because it's been re skinned by a company called Palantir, okay? And they call it boundary, okay, okay, so Palantir boundaries. Navarre, I see and, and, and the thing that makes us mad is people who drive taxi, AI taxis, people that they're the car manufacturer.
Most people know it, because it's been re skinned by a company called Palantir, okay? And they call it boundary, okay, okay, so Palantir boundaries. Navarre, I see and, and, and the thing that makes us mad is people who drive taxi, AI taxis, people that they're the car manufacturer.
Most people know it, because it's been re skinned by a company called Palantir, okay? And they call it boundary, okay, okay, so Palantir boundaries. Navarre, I see and, and, and the thing that makes us mad is people who drive taxi, AI taxis, people that they're the car manufacturer.
Most people know it, because it's been re skinned by a company called Palantir, okay? And they call it boundary, okay, okay, so Palantir boundaries. Navarre, I see and, and, and the thing that makes us mad is people who drive taxi, AI taxis, people that they're the car manufacturer.
S Speaker 16:50Yeah, they're not the car manufacturer. They're not the car manufacturer, of course. Yeah. Okay, yeah. And, you know,
Yeah, they're not the car manufacturer. They're not the car manufacturer, of course. Yeah. Okay, yeah. And, you know,
Yeah, they're not the car manufacturer. They're not the car manufacturer, of course. Yeah. Okay, yeah. And, you know,
Yeah, they're not the car manufacturer. They're not the car manufacturer, of course. Yeah. Okay, yeah. And, you know,
S Speaker 26:55if I tell you the story of every industrial revolution in history, yeah, it sounds something like this. Priyesh, a guy who has a water wheel, creates a loom, an automatic loom machine to make cloth. Yeah, by bringing in engineers who can manage complex machines and gear ratios to automate the process of making cloth, and those machines have to be built by and maintained by an engineer. Yeah, if you forward 20 years later, the machines are simplified to the point that we have to have child labor laws, because you have four year olds operating those machines, and they're getting sucked into them. Yep, okay, yeah. And that's every every industrial revolution. So when compute first came out, I don't know if you remember or I've ever heard of Wang Unisys, Craig Unisys, yeah, like, and they couldn't imagine a world where you didn't have a team of engineers working around a core, yeah. It was a hub and spoke system that you'd connect to, yeah. And then no one saw Wintel. And Wintel came, it was like, boom. Now using a computer is so easy. Everyone can do it on your desktop, yeah? And you don't need to know how to orchestrate your hard drive, monitors, drivers, none of that crap. Yeah, it just does it automatically and it's easy to use. Well, Priyesh, this is no different. We built the first generation of tools. We know them very well, right? Everything Palantir is reselling with board deployed engineers and orchestrating for their clients. We know those products, okay, yep, we're, we just announced last week at pytorch that we are evolving navari. Over the next year, navari will now orchestrate everything, and it will be an operating system for AI. We're and I can give you more technical details if you want it, yeah, but there's going to be a new numerical, open source compiler, and so we resolve all the runtime issues between all the different permutations of hardware that are out there. Yeah, so Nvidia, CUDA will no longer give them an advantage. Everybody with a library in our system can run pytorch natively or whatever else they want. Yeah, because we build all those things that we make them all running native, right, right? And we're going to make it so easy that a caveman can do it. Priyesh, your kid is going to be able to buy code, whatever app they want, on top of their data. And you know, it's going to be a demo app. At first, over the time, it'll get better that you'll be able to actually build your own apps if you're a subject matter expert, on top of your data stack, just by like chat GPT style prompt. Okay, now there's gonna be two interfaces in navari. Next one is the Jupyter style interface that the data science the pie data people love. The other is just like a GPT style natural language interface. You can talk to it, you can type, we don't care, okay, yeah, but the code can write itself now. And so what I'm trying to tell you Priyesh Is the second generation of AI infrastructure tools are here. Yeah, we are building it. We're already demoing it with three clients, and we are already working with AMD, Intel, Nvidia, Microsoft, IBM. I can't remember who else to make sure that all the libraries support it. It's going to be an environment neutral platform. Yeah, these companies are putting serious resources into this to make sure that their hardware and software all orchestrate correctly under novari. And we're going to move to a world where anybody anywhere can create and build on their own, AI or themselves at home from the comfort of their office. And it will all your data and all your AI will decide within your walled garden, sovereign AI, sovereign data for everyone. We will do for AI, what Windows did for the PC. We will do for AI what Linux did or Unix, and we will do for AI what someone has needed to do for 20 years since Travis first released. Not high,
if I tell you the story of every industrial revolution in history, yeah, it sounds something like this. Priyesh, a guy who has a water wheel, creates a loom, an automatic loom machine to make cloth. Yeah, by bringing in engineers who can manage complex machines and gear ratios to automate the process of making cloth, and those machines have to be built by and maintained by an engineer. Yeah, if you forward 20 years later, the machines are simplified to the point that we have to have child labor laws, because you have four year olds operating those machines, and they're getting sucked into them. Yep, okay, yeah. And that's every every industrial revolution. So when compute first came out, I don't know if you remember or I've ever heard of Wang Unisys, Craig Unisys, yeah, like, and they couldn't imagine a world where you didn't have a team of engineers working around a core, yeah. It was a hub and spoke system that you'd connect to, yeah. And then no one saw Wintel. And Wintel came, it was like, boom. Now using a computer is so easy. Everyone can do it on your desktop, yeah? And you don't need to know how to orchestrate your hard drive, monitors, drivers, none of that crap. Yeah, it just does it automatically and it's easy to use. Well, Priyesh, this is no different. We built the first generation of tools. We know them very well, right? Everything Palantir is reselling with board deployed engineers and orchestrating for their clients. We know those products, okay, yep, we're, we just announced last week at pytorch that we are evolving navari. Over the next year, navari will now orchestrate everything, and it will be an operating system for AI. We're and I can give you more technical details if you want it, yeah, but there's going to be a new numerical, open source compiler, and so we resolve all the runtime issues between all the different permutations of hardware that are out there. Yeah, so Nvidia, CUDA will no longer give them an advantage. Everybody with a library in our system can run pytorch natively or whatever else they want. Yeah, because we build all those things that we make them all running native, right, right? And we're going to make it so easy that a caveman can do it. Priyesh, your kid is going to be able to buy code, whatever app they want, on top of their data. And you know, it's going to be a demo app. At first, over the time, it'll get better that you'll be able to actually build your own apps if you're a subject matter expert, on top of your data stack, just by like chat GPT style prompt. Okay, now there's gonna be two interfaces in navari. Next one is the Jupyter style interface that the data science the pie data people love. The other is just like a GPT style natural language interface. You can talk to it, you can type, we don't care, okay, yeah, but the code can write itself now. And so what I'm trying to tell you Priyesh Is the second generation of AI infrastructure tools are here. Yeah, we are building it. We're already demoing it with three clients, and we are already working with AMD, Intel, Nvidia, Microsoft, IBM. I can't remember who else to make sure that all the libraries support it. It's going to be an environment neutral platform. Yeah, these companies are putting serious resources into this to make sure that their hardware and software all orchestrate correctly under novari. And we're going to move to a world where anybody anywhere can create and build on their own, AI or themselves at home from the comfort of their office. And it will all your data and all your AI will decide within your walled garden, sovereign AI, sovereign data for everyone. We will do for AI, what Windows did for the PC. We will do for AI what Linux did or Unix, and we will do for AI what someone has needed to do for 20 years since Travis first released. Not high,
if I tell you the story of every industrial revolution in history, yeah, it sounds something like this. Priyesh, a guy who has a water wheel, creates a loom, an automatic loom machine to make cloth. Yeah, by bringing in engineers who can manage complex machines and gear ratios to automate the process of making cloth, and those machines have to be built by and maintained by an engineer. Yeah, if you forward 20 years later, the machines are simplified to the point that we have to have child labor laws, because you have four year olds operating those machines, and they're getting sucked into them. Yep, okay, yeah. And that's every every industrial revolution. So when compute first came out, I don't know if you remember or I've ever heard of Wang Unisys, Craig Unisys, yeah, like, and they couldn't imagine a world where you didn't have a team of engineers working around a core, yeah. It was a hub and spoke system that you'd connect to, yeah. And then no one saw Wintel. And Wintel came, it was like, boom. Now using a computer is so easy. Everyone can do it on your desktop, yeah? And you don't need to know how to orchestrate your hard drive, monitors, drivers, none of that crap. Yeah, it just does it automatically and it's easy to use. Well, Priyesh, this is no different. We built the first generation of tools. We know them very well, right? Everything Palantir is reselling with board deployed engineers and orchestrating for their clients. We know those products, okay, yep, we're, we just announced last week at pytorch that we are evolving navari. Over the next year, navari will now orchestrate everything, and it will be an operating system for AI. We're and I can give you more technical details if you want it, yeah, but there's going to be a new numerical, open source compiler, and so we resolve all the runtime issues between all the different permutations of hardware that are out there. Yeah, so Nvidia, CUDA will no longer give them an advantage. Everybody with a library in our system can run pytorch natively or whatever else they want. Yeah, because we build all those things that we make them all running native, right, right? And we're going to make it so easy that a caveman can do it. Priyesh, your kid is going to be able to buy code, whatever app they want, on top of their data. And you know, it's going to be a demo app. At first, over the time, it'll get better that you'll be able to actually build your own apps if you're a subject matter expert, on top of your data stack, just by like chat GPT style prompt. Okay, now there's gonna be two interfaces in navari. Next one is the Jupyter style interface that the data science the pie data people love. The other is just like a GPT style natural language interface. You can talk to it, you can type, we don't care, okay, yeah, but the code can write itself now. And so what I'm trying to tell you Priyesh Is the second generation of AI infrastructure tools are here. Yeah, we are building it. We're already demoing it with three clients, and we are already working with AMD, Intel, Nvidia, Microsoft, IBM. I can't remember who else to make sure that all the libraries support it. It's going to be an environment neutral platform. Yeah, these companies are putting serious resources into this to make sure that their hardware and software all orchestrate correctly under novari. And we're going to move to a world where anybody anywhere can create and build on their own, AI or themselves at home from the comfort of their office. And it will all your data and all your AI will decide within your walled garden, sovereign AI, sovereign data for everyone. We will do for AI, what Windows did for the PC. We will do for AI what Linux did or Unix, and we will do for AI what someone has needed to do for 20 years since Travis first released. Not high,
if I tell you the story of every industrial revolution in history, yeah, it sounds something like this. Priyesh, a guy who has a water wheel, creates a loom, an automatic loom machine to make cloth. Yeah, by bringing in engineers who can manage complex machines and gear ratios to automate the process of making cloth, and those machines have to be built by and maintained by an engineer. Yeah, if you forward 20 years later, the machines are simplified to the point that we have to have child labor laws, because you have four year olds operating those machines, and they're getting sucked into them. Yep, okay, yeah. And that's every every industrial revolution. So when compute first came out, I don't know if you remember or I've ever heard of Wang Unisys, Craig Unisys, yeah, like, and they couldn't imagine a world where you didn't have a team of engineers working around a core, yeah. It was a hub and spoke system that you'd connect to, yeah. And then no one saw Wintel. And Wintel came, it was like, boom. Now using a computer is so easy. Everyone can do it on your desktop, yeah? And you don't need to know how to orchestrate your hard drive, monitors, drivers, none of that crap. Yeah, it just does it automatically and it's easy to use. Well, Priyesh, this is no different. We built the first generation of tools. We know them very well, right? Everything Palantir is reselling with board deployed engineers and orchestrating for their clients. We know those products, okay, yep, we're, we just announced last week at pytorch that we are evolving navari. Over the next year, navari will now orchestrate everything, and it will be an operating system for AI. We're and I can give you more technical details if you want it, yeah, but there's going to be a new numerical, open source compiler, and so we resolve all the runtime issues between all the different permutations of hardware that are out there. Yeah, so Nvidia, CUDA will no longer give them an advantage. Everybody with a library in our system can run pytorch natively or whatever else they want. Yeah, because we build all those things that we make them all running native, right, right? And we're going to make it so easy that a caveman can do it. Priyesh, your kid is going to be able to buy code, whatever app they want, on top of their data. And you know, it's going to be a demo app. At first, over the time, it'll get better that you'll be able to actually build your own apps if you're a subject matter expert, on top of your data stack, just by like chat GPT style prompt. Okay, now there's gonna be two interfaces in navari. Next one is the Jupyter style interface that the data science the pie data people love. The other is just like a GPT style natural language interface. You can talk to it, you can type, we don't care, okay, yeah, but the code can write itself now. And so what I'm trying to tell you Priyesh Is the second generation of AI infrastructure tools are here. Yeah, we are building it. We're already demoing it with three clients, and we are already working with AMD, Intel, Nvidia, Microsoft, IBM. I can't remember who else to make sure that all the libraries support it. It's going to be an environment neutral platform. Yeah, these companies are putting serious resources into this to make sure that their hardware and software all orchestrate correctly under novari. And we're going to move to a world where anybody anywhere can create and build on their own, AI or themselves at home from the comfort of their office. And it will all your data and all your AI will decide within your walled garden, sovereign AI, sovereign data for everyone. We will do for AI, what Windows did for the PC. We will do for AI what Linux did or Unix, and we will do for AI what someone has needed to do for 20 years since Travis first released. Not high,
S Speaker 110:50right, right? No. So that's a, that's a very impressive vision. And there's a, you know, there's, it's not just a vision, no, no, no, but you wanted to. You want to get that thinking about it. No, no, but it's not yet. It's not yet. It's not like priyeshious son is building it today. That's the vision part. He doesn't even have production version by this time next year. Got it, got it, got it. No. So the way I was going with this was, there are multiple steps to building your own AI, right? So maybe, maybe unpacking that a little bit from data preparation, data cleansing, data collection to, you know, maybe figuring out the right model, you know, then being able to have an iterative loop to actually make sure that, you know, it's accurate, not hallucinating. Like, what I'm trying to get to is, what does nebari do from a company
right, right? No. So that's a, that's a very impressive vision. And there's a, you know, there's, it's not just a vision, no, no, no, but you wanted to. You want to get that thinking about it. No, no, but it's not yet. It's not yet. It's not like priyeshious son is building it today. That's the vision part. He doesn't even have production version by this time next year. Got it, got it, got it. No. So the way I was going with this was, there are multiple steps to building your own AI, right? So maybe, maybe unpacking that a little bit from data preparation, data cleansing, data collection to, you know, maybe figuring out the right model, you know, then being able to have an iterative loop to actually make sure that, you know, it's accurate, not hallucinating. Like, what I'm trying to get to is, what does nebari do from a company
right, right? No. So that's a, that's a very impressive vision. And there's a, you know, there's, it's not just a vision, no, no, no, but you wanted to. You want to get that thinking about it. No, no, but it's not yet. It's not yet. It's not like priyeshious son is building it today. That's the vision part. He doesn't even have production version by this time next year. Got it, got it, got it. No. So the way I was going with this was, there are multiple steps to building your own AI, right? So maybe, maybe unpacking that a little bit from data preparation, data cleansing, data collection to, you know, maybe figuring out the right model, you know, then being able to have an iterative loop to actually make sure that, you know, it's accurate, not hallucinating. Like, what I'm trying to get to is, what does nebari do from a company
right, right? No. So that's a, that's a very impressive vision. And there's a, you know, there's, it's not just a vision, no, no, no, but you wanted to. You want to get that thinking about it. No, no, but it's not yet. It's not yet. It's not like priyeshious son is building it today. That's the vision part. He doesn't even have production version by this time next year. Got it, got it, got it. No. So the way I was going with this was, there are multiple steps to building your own AI, right? So maybe, maybe unpacking that a little bit from data preparation, data cleansing, data collection to, you know, maybe figuring out the right model, you know, then being able to have an iterative loop to actually make sure that, you know, it's accurate, not hallucinating. Like, what I'm trying to get to is, what does nebari do from a company
S Speaker 211:45is data orchestration. So it doesn't matter who is your data provider, Azure, yeah, Amazon, local, yeah, right. Nabari doesn't care. So nabari basically makes it so you can plug and play any AI tool on top of your data stack. Regardless of what's underneath the top of the data stack, however crazy it gets under the hood of that car, it doesn't matter. Got it? You just navari just orchestrates all of it for you. Now we're elevating nevari To also orchestrate your hardware, yeah, okay, and to add a GPT style prompt, we're adding an app marketplace so that, if you want, you could, like you, anyone, could build the apps on top of it, but you could be basically buying and selling apps in that marketplace. We're also creating a data marketplace so data providers can sell data to anybody through there, and we're taking the cut of both, yeah, yeah.
is data orchestration. So it doesn't matter who is your data provider, Azure, yeah, Amazon, local, yeah, right. Nabari doesn't care. So nabari basically makes it so you can plug and play any AI tool on top of your data stack. Regardless of what's underneath the top of the data stack, however crazy it gets under the hood of that car, it doesn't matter. Got it? You just navari just orchestrates all of it for you. Now we're elevating nevari To also orchestrate your hardware, yeah, okay, and to add a GPT style prompt, we're adding an app marketplace so that, if you want, you could, like you, anyone, could build the apps on top of it, but you could be basically buying and selling apps in that marketplace. We're also creating a data marketplace so data providers can sell data to anybody through there, and we're taking the cut of both, yeah, yeah.
is data orchestration. So it doesn't matter who is your data provider, Azure, yeah, Amazon, local, yeah, right. Nabari doesn't care. So nabari basically makes it so you can plug and play any AI tool on top of your data stack. Regardless of what's underneath the top of the data stack, however crazy it gets under the hood of that car, it doesn't matter. Got it? You just navari just orchestrates all of it for you. Now we're elevating nevari To also orchestrate your hardware, yeah, okay, and to add a GPT style prompt, we're adding an app marketplace so that, if you want, you could, like you, anyone, could build the apps on top of it, but you could be basically buying and selling apps in that marketplace. We're also creating a data marketplace so data providers can sell data to anybody through there, and we're taking the cut of both, yeah, yeah.
is data orchestration. So it doesn't matter who is your data provider, Azure, yeah, Amazon, local, yeah, right. Nabari doesn't care. So nabari basically makes it so you can plug and play any AI tool on top of your data stack. Regardless of what's underneath the top of the data stack, however crazy it gets under the hood of that car, it doesn't matter. Got it? You just navari just orchestrates all of it for you. Now we're elevating nevari To also orchestrate your hardware, yeah, okay, and to add a GPT style prompt, we're adding an app marketplace so that, if you want, you could, like you, anyone, could build the apps on top of it, but you could be basically buying and selling apps in that marketplace. We're also creating a data marketplace so data providers can sell data to anybody through there, and we're taking the cut of both, yeah, yeah.
S Speaker 112:37And that's, and that's a, that's an adjacency, right? Which is you have a marketplaces where you can have people selling their data or selling their
And that's, and that's a, that's an adjacency, right? Which is you have a marketplaces where you can have people selling their data or selling their
And that's, and that's a, that's an adjacency, right? Which is you have a marketplaces where you can have people selling their data or selling their
And that's, and that's a, that's an adjacency, right? Which is you have a marketplaces where you can have people selling their data or selling their
S Speaker 212:46model. The long run though, Priyesh, that becomes the core, yeah, people would be by coding and building on this themselves, yeah, and they'll be buying more and more apps. People will be competitive. So an app has to be better than what your team can develop. Small companies will rely more on the App Store. Big companies will be doing their own thing. That's kind of how I think this will at least happen initially. But as the AI gets better at doing progression quality, right, eventually, I think, I think, you know, only the most competitive apps will be able to do that. The data science can be money in the long run, right? And I mean, and that, I mean, we're doing this.
model. The long run though, Priyesh, that becomes the core, yeah, people would be by coding and building on this themselves, yeah, and they'll be buying more and more apps. People will be competitive. So an app has to be better than what your team can develop. Small companies will rely more on the App Store. Big companies will be doing their own thing. That's kind of how I think this will at least happen initially. But as the AI gets better at doing progression quality, right, eventually, I think, I think, you know, only the most competitive apps will be able to do that. The data science can be money in the long run, right? And I mean, and that, I mean, we're doing this.
model. The long run though, Priyesh, that becomes the core, yeah, people would be by coding and building on this themselves, yeah, and they'll be buying more and more apps. People will be competitive. So an app has to be better than what your team can develop. Small companies will rely more on the App Store. Big companies will be doing their own thing. That's kind of how I think this will at least happen initially. But as the AI gets better at doing progression quality, right, eventually, I think, I think, you know, only the most competitive apps will be able to do that. The data science can be money in the long run, right? And I mean, and that, I mean, we're doing this.
model. The long run though, Priyesh, that becomes the core, yeah, people would be by coding and building on this themselves, yeah, and they'll be buying more and more apps. People will be competitive. So an app has to be better than what your team can develop. Small companies will rely more on the App Store. Big companies will be doing their own thing. That's kind of how I think this will at least happen initially. But as the AI gets better at doing progression quality, right, eventually, I think, I think, you know, only the most competitive apps will be able to do that. The data science can be money in the long run, right? And I mean, and that, I mean, we're doing this.
S Speaker 113:23And so maybe, can we talk about the demo and what you're actually, what's the core product there, versus, you know, there might be some hand holding required for these demos deployments. Can we maybe talk about Take, take a project, and, yeah,
And so maybe, can we talk about the demo and what you're actually, what's the core product there, versus, you know, there might be some hand holding required for these demos deployments. Can we maybe talk about Take, take a project, and, yeah,
And so maybe, can we talk about the demo and what you're actually, what's the core product there, versus, you know, there might be some hand holding required for these demos deployments. Can we maybe talk about Take, take a project, and, yeah,
And so maybe, can we talk about the demo and what you're actually, what's the core product there, versus, you know, there might be some hand holding required for these demos deployments. Can we maybe talk about Take, take a project, and, yeah,
S Speaker 213:37it's actually shockingly easy to deploy. So navarian is current form. He deployed at JP Morgan, Chase. It was our longest deployment. The installation took three hours.
it's actually shockingly easy to deploy. So navarian is current form. He deployed at JP Morgan, Chase. It was our longest deployment. The installation took three hours.
it's actually shockingly easy to deploy. So navarian is current form. He deployed at JP Morgan, Chase. It was our longest deployment. The installation took three hours.
it's actually shockingly easy to deploy. So navarian is current form. He deployed at JP Morgan, Chase. It was our longest deployment. The installation took three hours.
S Speaker 113:47But what? What they using? What were they using it? What was the initial pain point? What were they using it for? What? What caused
But what? What they using? What were they using it? What was the initial pain point? What were they using it for? What? What caused
But what? What they using? What were they using it? What was the initial pain point? What were they using it for? What? What caused
But what? What they using? What were they using it? What was the initial pain point? What were they using it for? What? What caused
S Speaker 213:53them to Are you familiar with a JP Morgan, Athena. JP Morgan, Athena. Athena. Athena.
them to Are you familiar with a JP Morgan, Athena. JP Morgan, Athena. Athena. Athena.
them to Are you familiar with a JP Morgan, Athena. JP Morgan, Athena. Athena. Athena.
them to Are you familiar with a JP Morgan, Athena. JP Morgan, Athena. Athena. Athena.
S Speaker 214:00Athena is their global risk management platform that handles their derivatives, all their derivatives trading. Okay, we built that. The bar is the back end behind it, okay? And it integrates with their private bank. It integrates with all these different data centers, okay, all right, okay, right. And so you're right, the hand holding that we have to do actually isn't technical, yeah, the handling that we have to do is the training. You can do this. And, yeah, exactly. It's training the IT team, so that they understand the interface. Like, here's where you connect and pick, you know, you can pick which provider you want for, you know, for any, any layer, right? If you're creating a genetic AI work, how to do it for the person?
Athena is their global risk management platform that handles their derivatives, all their derivatives trading. Okay, we built that. The bar is the back end behind it, okay? And it integrates with their private bank. It integrates with all these different data centers, okay, all right, okay, right. And so you're right, the hand holding that we have to do actually isn't technical, yeah, the handling that we have to do is the training. You can do this. And, yeah, exactly. It's training the IT team, so that they understand the interface. Like, here's where you connect and pick, you know, you can pick which provider you want for, you know, for any, any layer, right? If you're creating a genetic AI work, how to do it for the person?
Athena is their global risk management platform that handles their derivatives, all their derivatives trading. Okay, we built that. The bar is the back end behind it, okay? And it integrates with their private bank. It integrates with all these different data centers, okay, all right, okay, right. And so you're right, the hand holding that we have to do actually isn't technical, yeah, the handling that we have to do is the training. You can do this. And, yeah, exactly. It's training the IT team, so that they understand the interface. Like, here's where you connect and pick, you know, you can pick which provider you want for, you know, for any, any layer, right? If you're creating a genetic AI work, how to do it for the person?
Athena is their global risk management platform that handles their derivatives, all their derivatives trading. Okay, we built that. The bar is the back end behind it, okay? And it integrates with their private bank. It integrates with all these different data centers, okay, all right, okay, right. And so you're right, the hand holding that we have to do actually isn't technical, yeah, the handling that we have to do is the training. You can do this. And, yeah, exactly. It's training the IT team, so that they understand the interface. Like, here's where you connect and pick, you know, you can pick which provider you want for, you know, for any, any layer, right? If you're creating a genetic AI work, how to do it for the person?
S Speaker 114:41Yeah, but before the training, right? So maybe taking step by step, because I'm trying to unpack the product a little bit to for my understanding is, so let's say JP Morgan Athena is using nibari for its risk management back end. Let's assume, right, so, and nebari is a data orchestrator
Yeah, but before the training, right? So maybe taking step by step, because I'm trying to unpack the product a little bit to for my understanding is, so let's say JP Morgan Athena is using nibari for its risk management back end. Let's assume, right, so, and nebari is a data orchestrator
Yeah, but before the training, right? So maybe taking step by step, because I'm trying to unpack the product a little bit to for my understanding is, so let's say JP Morgan Athena is using nibari for its risk management back end. Let's assume, right, so, and nebari is a data orchestrator
Yeah, but before the training, right? So maybe taking step by step, because I'm trying to unpack the product a little bit to for my understanding is, so let's say JP Morgan Athena is using nibari for its risk management back end. Let's assume, right, so, and nebari is a data orchestrator
S Speaker 214:59today, today? Yes, all AI operating system next
today, today? Yes, all AI operating system next
today, today? Yes, all AI operating system next
today, today? Yes, all AI operating system next
S Speaker 115:03year? Yes, yes, yes. So I'm talking about today. Today they are using nibari as a data orchestrator, and this might not necessarily be for an AI app, right? It's
year? Yes, yes, yes. So I'm talking about today. Today they are using nibari as a data orchestrator, and this might not necessarily be for an AI app, right? It's
year? Yes, yes, yes. So I'm talking about today. Today they are using nibari as a data orchestrator, and this might not necessarily be for an AI app, right? It's
year? Yes, yes, yes. So I'm talking about today. Today they are using nibari as a data orchestrator, and this might not necessarily be for an AI app, right? It's
S Speaker 215:12built for AI, and so it's built for and the Department of Defense uses it for AI also. And so basically, you deploy it across, right? And then you can start building models. It has a Jupiter, like style interface today, yeah. And you can go in and start building you could connect it to hugging face if you wanted. And you could do stuff. You could download, you know, something from thinking machines or an open source model, and create it and do something on the stack. Palantir, actually, that's what they're doing with navari today, right? So they basically install navari, and they run scikit learn, and they run pytorch on it for training on everybody's data. Got it? So it's already doing that today. It's just, it's just that it requires, yeah, a lot more for the orchestration between compute and everything else,
built for AI, and so it's built for and the Department of Defense uses it for AI also. And so basically, you deploy it across, right? And then you can start building models. It has a Jupiter, like style interface today, yeah. And you can go in and start building you could connect it to hugging face if you wanted. And you could do stuff. You could download, you know, something from thinking machines or an open source model, and create it and do something on the stack. Palantir, actually, that's what they're doing with navari today, right? So they basically install navari, and they run scikit learn, and they run pytorch on it for training on everybody's data. Got it? So it's already doing that today. It's just, it's just that it requires, yeah, a lot more for the orchestration between compute and everything else,
built for AI, and so it's built for and the Department of Defense uses it for AI also. And so basically, you deploy it across, right? And then you can start building models. It has a Jupiter, like style interface today, yeah. And you can go in and start building you could connect it to hugging face if you wanted. And you could do stuff. You could download, you know, something from thinking machines or an open source model, and create it and do something on the stack. Palantir, actually, that's what they're doing with navari today, right? So they basically install navari, and they run scikit learn, and they run pytorch on it for training on everybody's data. Got it? So it's already doing that today. It's just, it's just that it requires, yeah, a lot more for the orchestration between compute and everything else,
built for AI, and so it's built for and the Department of Defense uses it for AI also. And so basically, you deploy it across, right? And then you can start building models. It has a Jupiter, like style interface today, yeah. And you can go in and start building you could connect it to hugging face if you wanted. And you could do stuff. You could download, you know, something from thinking machines or an open source model, and create it and do something on the stack. Palantir, actually, that's what they're doing with navari today, right? So they basically install navari, and they run scikit learn, and they run pytorch on it for training on everybody's data. Got it? So it's already doing that today. It's just, it's just that it requires, yeah, a lot more for the orchestration between compute and everything else,
S Speaker 115:57and which is what you're building as part of this, what's
and which is what you're building as part of this, what's
and which is what you're building as part of this, what's
and which is what you're building as part of this, what's
S Speaker 216:00good, correct? And that's what we're already demoing with people will be available the whole world next year.
good, correct? And that's what we're already demoing with people will be available the whole world next year.
good, correct? And that's what we're already demoing with people will be available the whole world next year.
good, correct? And that's what we're already demoing with people will be available the whole world next year.
S Speaker 116:05Very interesting. And how are you guys charging it for the customers? Is it charged by the compute that's required? Is it per application or you consumption basic
Very interesting. And how are you guys charging it for the customers? Is it charged by the compute that's required? Is it per application or you consumption basic
Very interesting. And how are you guys charging it for the customers? Is it charged by the compute that's required? Is it per application or you consumption basic
Very interesting. And how are you guys charging it for the customers? Is it charged by the compute that's required? Is it per application or you consumption basic
S Speaker 216:17compute? You pay for compute directly from the compute providers? Yeah, whether that be Amazon, Oracle Red Hat, we don't care. We buy your computer,
compute? You pay for compute directly from the compute providers? Yeah, whether that be Amazon, Oracle Red Hat, we don't care. We buy your computer,
compute? You pay for compute directly from the compute providers? Yeah, whether that be Amazon, Oracle Red Hat, we don't care. We buy your computer,
compute? You pay for compute directly from the compute providers? Yeah, whether that be Amazon, Oracle Red Hat, we don't care. We buy your computer,
16:26yeah, yeah, okay, yeah.
yeah, yeah, okay, yeah.
yeah, yeah, okay, yeah.
yeah, yeah, okay, yeah.
S Speaker 216:28But the way we make money is we charge for the installation, yep, and then we charge for the maintenance, because you have to have this maintained. Even Palantir has been paying us for maintenance for their
But the way we make money is we charge for the installation, yep, and then we charge for the maintenance, because you have to have this maintained. Even Palantir has been paying us for maintenance for their
But the way we make money is we charge for the installation, yep, and then we charge for the maintenance, because you have to have this maintained. Even Palantir has been paying us for maintenance for their
But the way we make money is we charge for the installation, yep, and then we charge for the maintenance, because you have to have this maintained. Even Palantir has been paying us for maintenance for their
S Speaker 216:47you. This one, this one is a little bit more complex though. Priyesh, how many people do you think on Earth really understand what's happening at the core? Yeah, of course. TensorFlow,
you. This one, this one is a little bit more complex though. Priyesh, how many people do you think on Earth really understand what's happening at the core? Yeah, of course. TensorFlow,
you. This one, this one is a little bit more complex though. Priyesh, how many people do you think on Earth really understand what's happening at the core? Yeah, of course. TensorFlow,
you. This one, this one is a little bit more complex though. Priyesh, how many people do you think on Earth really understand what's happening at the core? Yeah, of course. TensorFlow,
16:56yeah, yeah, that's your guess. You want to get 10,000
yeah, yeah, that's your guess. You want to get 10,000
yeah, yeah, that's your guess. You want to get 10,000
yeah, yeah, that's your guess. You want to get 10,000
17:05I wish it was that good. I'd be able to hire more.
I wish it was that good. I'd be able to hire more.
I wish it was that good. I'd be able to hire more.
I wish it was that good. I'd be able to hire more.
17:10It's about 200 people. Okay, okay,
It's about 200 people. Okay, okay,
It's about 200 people. Okay, okay,
It's about 200 people. Okay, okay,
S Speaker 217:13yeah, and a third of them work for me. Third of them work for meta, and a third of them work for Google. And then there's a few outliers. I said you there's a few more maintainers here and there that, like, you know, Microsoft has four right, right, open, AI has two right. Anthropic has one right, right, got it, got it, yeah, but, and so, I mean, the thing about what we're doing here is that, you know, we're distributing that, know how, in a software platform that's easy to use, yeah, but it does require maintenance. And I tell people say, Well, can't anyone maintain this? It's like, well, if they could, customer, okay, yeah, like, Apple couldn't figure out how to do this on their own, yeah? So they just finally hired us. Very interesting, right? Okay, Apple, with all their resources, their resources. Yeah, so it's not I mean you've looked at how they struggle with AI Yeah.
yeah, and a third of them work for me. Third of them work for meta, and a third of them work for Google. And then there's a few outliers. I said you there's a few more maintainers here and there that, like, you know, Microsoft has four right, right, open, AI has two right. Anthropic has one right, right, got it, got it, yeah, but, and so, I mean, the thing about what we're doing here is that, you know, we're distributing that, know how, in a software platform that's easy to use, yeah, but it does require maintenance. And I tell people say, Well, can't anyone maintain this? It's like, well, if they could, customer, okay, yeah, like, Apple couldn't figure out how to do this on their own, yeah? So they just finally hired us. Very interesting, right? Okay, Apple, with all their resources, their resources. Yeah, so it's not I mean you've looked at how they struggle with AI Yeah.
yeah, and a third of them work for me. Third of them work for meta, and a third of them work for Google. And then there's a few outliers. I said you there's a few more maintainers here and there that, like, you know, Microsoft has four right, right, open, AI has two right. Anthropic has one right, right, got it, got it, yeah, but, and so, I mean, the thing about what we're doing here is that, you know, we're distributing that, know how, in a software platform that's easy to use, yeah, but it does require maintenance. And I tell people say, Well, can't anyone maintain this? It's like, well, if they could, customer, okay, yeah, like, Apple couldn't figure out how to do this on their own, yeah? So they just finally hired us. Very interesting, right? Okay, Apple, with all their resources, their resources. Yeah, so it's not I mean you've looked at how they struggle with AI Yeah.
yeah, and a third of them work for me. Third of them work for meta, and a third of them work for Google. And then there's a few outliers. I said you there's a few more maintainers here and there that, like, you know, Microsoft has four right, right, open, AI has two right. Anthropic has one right, right, got it, got it, yeah, but, and so, I mean, the thing about what we're doing here is that, you know, we're distributing that, know how, in a software platform that's easy to use, yeah, but it does require maintenance. And I tell people say, Well, can't anyone maintain this? It's like, well, if they could, customer, okay, yeah, like, Apple couldn't figure out how to do this on their own, yeah? So they just finally hired us. Very interesting, right? Okay, Apple, with all their resources, their resources. Yeah, so it's not I mean you've looked at how they struggle with AI Yeah.
S Speaker 218:17enterprises, yeah and so on the maintenance side you know we can get in and talk about how that works. yeah yeah.
enterprises, yeah and so on the maintenance side you know we can get in and talk about how that works. yeah yeah.
enterprises, yeah and so on the maintenance side you know we can get in and talk about how that works. yeah yeah.
enterprises, yeah and so on the maintenance side you know we can get in and talk about how that works. yeah yeah.
S Speaker 218:32Right, yeah, basically, they get some delays on track, and then we make sure that the license is always up to
Right, yeah, basically, they get some delays on track, and then we make sure that the license is always up to
Right, yeah, basically, they get some delays on track, and then we make sure that the license is always up to
Right, yeah, basically, they get some delays on track, and then we make sure that the license is always up to
S Speaker 118:36date, of course, yeah. And I work and how much, how much model is Anaconda, Yeah, same model as MongoDB, or any, any of these, open source you got it, yeah. And how much are, like, how much revenue, or, you know, support revenue do you have today? Today?
date, of course, yeah. And I work and how much, how much model is Anaconda, Yeah, same model as MongoDB, or any, any of these, open source you got it, yeah. And how much are, like, how much revenue, or, you know, support revenue do you have today? Today?
date, of course, yeah. And I work and how much, how much model is Anaconda, Yeah, same model as MongoDB, or any, any of these, open source you got it, yeah. And how much are, like, how much revenue, or, you know, support revenue do you have today? Today?
date, of course, yeah. And I work and how much, how much model is Anaconda, Yeah, same model as MongoDB, or any, any of these, open source you got it, yeah. And how much are, like, how much revenue, or, you know, support revenue do you have today? Today?
S Speaker 218:52I mean, most of our revenue comes from us supporting people who are using open source, and us doing the back end that maintenance. We get a 50% margin when we install. We get a 75% margin to maintain. Yeah, got it.
I mean, most of our revenue comes from us supporting people who are using open source, and us doing the back end that maintenance. We get a 50% margin when we install. We get a 75% margin to maintain. Yeah, got it.
I mean, most of our revenue comes from us supporting people who are using open source, and us doing the back end that maintenance. We get a 50% margin when we install. We get a 75% margin to maintain. Yeah, got it.
I mean, most of our revenue comes from us supporting people who are using open source, and us doing the back end that maintenance. We get a 50% margin when we install. We get a 75% margin to maintain. Yeah, got it.
S Speaker 119:05Got it. And how much is it from the Yeah, how much is it from the open source community that you have in terms of revenue?
Got it. And how much is it from the Yeah, how much is it from the open source community that you have in terms of revenue?
Got it. And how much is it from the Yeah, how much is it from the open source community that you have in terms of revenue?
Got it. And how much is it from the Yeah, how much is it from the open source community that you have in terms of revenue?
S Speaker 219:15I don't follow how much is from the open source community? Yeah,
I don't follow how much is from the open source community? Yeah,
I don't follow how much is from the open source community? Yeah,
I don't follow how much is from the open source community? Yeah,
S Speaker 119:19you mentioned that it's mostly from, you know, the users who are paying you for installation.
you mentioned that it's mostly from, you know, the users who are paying you for installation.
you mentioned that it's mostly from, you know, the users who are paying you for installation.
you mentioned that it's mostly from, you know, the users who are paying you for installation.
S Speaker 219:24Our users, the people who pay us, yeah? Our meta
Our users, the people who pay us, yeah? Our meta
Our users, the people who pay us, yeah? Our meta
Our users, the people who pay us, yeah? Our meta
S Speaker 119:27AWS, yeah. So how much is it today? As of today, how much is your revenue?
AWS, yeah. So how much is it today? As of today, how much is your revenue?
AWS, yeah. So how much is it today? As of today, how much is your revenue?
AWS, yeah. So how much is it today? As of today, how much is your revenue?
S Speaker 219:32Our trailing 12 month is 15,000,001 five. Got it. What we're doing today is not scalable. That's why we're switching to this model. There aren't enough core pytorch developers and Jax development. There's aren't enough core developers to be able to do this, right? You know how long it takes to become one of those people?
Our trailing 12 month is 15,000,001 five. Got it. What we're doing today is not scalable. That's why we're switching to this model. There aren't enough core pytorch developers and Jax development. There's aren't enough core developers to be able to do this, right? You know how long it takes to become one of those people?
Our trailing 12 month is 15,000,001 five. Got it. What we're doing today is not scalable. That's why we're switching to this model. There aren't enough core pytorch developers and Jax development. There's aren't enough core developers to be able to do this, right? You know how long it takes to become one of those people?
Our trailing 12 month is 15,000,001 five. Got it. What we're doing today is not scalable. That's why we're switching to this model. There aren't enough core pytorch developers and Jax development. There's aren't enough core developers to be able to do this, right? You know how long it takes to become one of those people?
S Speaker 119:50Oh, I mean, I can imagine if you're saying it's only 200 Yeah, yeah,
Oh, I mean, I can imagine if you're saying it's only 200 Yeah, yeah,
Oh, I mean, I can imagine if you're saying it's only 200 Yeah, yeah,
Oh, I mean, I can imagine if you're saying it's only 200 Yeah, yeah,
S Speaker 219:5420 people, yeah, yeah, our best estimate is 20 years after you get your PhD. Oh, wow. Okay, so if you have a PhD in like, computational mathematics, yeah, or, like statistics, or something, yeah, or computer science with a statistical emphasis, but 20 more years of training, you can get to the point where they'll let you touch the tensors Got it, got it. And so Ain't nobody just going to come and start doing this, right? Interesting. That's my biggest challenge is, how do I rationalize that expertise across the earth?
20 people, yeah, yeah, our best estimate is 20 years after you get your PhD. Oh, wow. Okay, so if you have a PhD in like, computational mathematics, yeah, or, like statistics, or something, yeah, or computer science with a statistical emphasis, but 20 more years of training, you can get to the point where they'll let you touch the tensors Got it, got it. And so Ain't nobody just going to come and start doing this, right? Interesting. That's my biggest challenge is, how do I rationalize that expertise across the earth?
20 people, yeah, yeah, our best estimate is 20 years after you get your PhD. Oh, wow. Okay, so if you have a PhD in like, computational mathematics, yeah, or, like statistics, or something, yeah, or computer science with a statistical emphasis, but 20 more years of training, you can get to the point where they'll let you touch the tensors Got it, got it. And so Ain't nobody just going to come and start doing this, right? Interesting. That's my biggest challenge is, how do I rationalize that expertise across the earth?
20 people, yeah, yeah, our best estimate is 20 years after you get your PhD. Oh, wow. Okay, so if you have a PhD in like, computational mathematics, yeah, or, like statistics, or something, yeah, or computer science with a statistical emphasis, but 20 more years of training, you can get to the point where they'll let you touch the tensors Got it, got it. And so Ain't nobody just going to come and start doing this, right? Interesting. That's my biggest challenge is, how do I rationalize that expertise across the earth?
S Speaker 120:23That's exactly everybody, but everybody needs it. So the supply is concerned. Really needs it, okay? Interesting.
That's exactly everybody, but everybody needs it. So the supply is concerned. Really needs it, okay? Interesting.
That's exactly everybody, but everybody needs it. So the supply is concerned. Really needs it, okay? Interesting.
That's exactly everybody, but everybody needs it. So the supply is concerned. Really needs it, okay? Interesting.
S Speaker 220:29And metas. Meta is not going to do it. Google is not going to do it, right? We're going to do it interesting. And we're the only people who can be trusted to do it for everyone equally,
And metas. Meta is not going to do it. Google is not going to do it, right? We're going to do it interesting. And we're the only people who can be trusted to do it for everyone equally,
And metas. Meta is not going to do it. Google is not going to do it, right? We're going to do it interesting. And we're the only people who can be trusted to do it for everyone equally,
And metas. Meta is not going to do it. Google is not going to do it, right? We're going to do it interesting. And we're the only people who can be trusted to do it for everyone equally,
S Speaker 120:38got it. Got it. And who do you see as like? Your like? Do you? Is there any alternative solution that right now? Right now it's only brute force, or they customize something Well, I mean,
got it. Got it. And who do you see as like? Your like? Do you? Is there any alternative solution that right now? Right now it's only brute force, or they customize something Well, I mean,
got it. Got it. And who do you see as like? Your like? Do you? Is there any alternative solution that right now? Right now it's only brute force, or they customize something Well, I mean,
got it. Got it. And who do you see as like? Your like? Do you? Is there any alternative solution that right now? Right now it's only brute force, or they customize something Well, I mean,
S Speaker 220:51the problem right now is that it's so hard to drive the car you have to hire a taxi driver, yeah. But we're producing Waymo, yeah, you don't need a cab driver anymore. Got it? It's gonna be Waymo, why would you pay for a cab driver? That's really expensive. Just Waymo, yeah.
the problem right now is that it's so hard to drive the car you have to hire a taxi driver, yeah. But we're producing Waymo, yeah, you don't need a cab driver anymore. Got it? It's gonna be Waymo, why would you pay for a cab driver? That's really expensive. Just Waymo, yeah.
the problem right now is that it's so hard to drive the car you have to hire a taxi driver, yeah. But we're producing Waymo, yeah, you don't need a cab driver anymore. Got it? It's gonna be Waymo, why would you pay for a cab driver? That's really expensive. Just Waymo, yeah.
the problem right now is that it's so hard to drive the car you have to hire a taxi driver, yeah. But we're producing Waymo, yeah, you don't need a cab driver anymore. Got it? It's gonna be Waymo, why would you pay for a cab driver? That's really expensive. Just Waymo, yeah.
S Speaker 121:06And maybe, can we unpack the features of the Waymo in the cab driver? So maybe, yeah, like, what is the way what are the features of way more can we talk about?
And maybe, can we unpack the features of the Waymo in the cab driver? So maybe, yeah, like, what is the way what are the features of way more can we talk about?
And maybe, can we unpack the features of the Waymo in the cab driver? So maybe, yeah, like, what is the way what are the features of way more can we talk about?
And maybe, can we unpack the features of the Waymo in the cab driver? So maybe, yeah, like, what is the way what are the features of way more can we talk about?
S Speaker 221:15I'm going to tell you that the more technical you want to get, we really need Travis on this call. Hold on. I'm going to get to Travis. Because if you want to go deep in the stack, yeah, let's get the OG, yeah,
I'm going to tell you that the more technical you want to get, we really need Travis on this call. Hold on. I'm going to get to Travis. Because if you want to go deep in the stack, yeah, let's get the OG, yeah,
I'm going to tell you that the more technical you want to get, we really need Travis on this call. Hold on. I'm going to get to Travis. Because if you want to go deep in the stack, yeah, let's get the OG, yeah,
I'm going to tell you that the more technical you want to get, we really need Travis on this call. Hold on. I'm going to get to Travis. Because if you want to go deep in the stack, yeah, let's get the OG, yeah,
S Speaker 221:44Yeah, well, you can and you should. Yeah. I it,
Yeah, well, you can and you should. Yeah. I it,
Yeah, well, you can and you should. Yeah. I it,
Yeah, well, you can and you should. Yeah. I it,
S Speaker 122:00because I think the deck was eating and showing us that's fine. I mean, the deck was also a bit light on, you know, the features, so I would just love to understand it a little more. Yeah, I think we
because I think the deck was eating and showing us that's fine. I mean, the deck was also a bit light on, you know, the features, so I would just love to understand it a little more. Yeah, I think we
because I think the deck was eating and showing us that's fine. I mean, the deck was also a bit light on, you know, the features, so I would just love to understand it a little more. Yeah, I think we
because I think the deck was eating and showing us that's fine. I mean, the deck was also a bit light on, you know, the features, so I would just love to understand it a little more. Yeah, I think we
22:16you might be on mute. I don't know.
you might be on mute. I don't know.
you might be on mute. I don't know.
you might be on mute. I don't know.
S Speaker 222:18I am. Austin, can you send them the presentation from pytorch? Yes. I don't think we have both of your email addresses. We might just have one. Yeah, so
I am. Austin, can you send them the presentation from pytorch? Yes. I don't think we have both of your email addresses. We might just have one. Yeah, so
I am. Austin, can you send them the presentation from pytorch? Yes. I don't think we have both of your email addresses. We might just have one. Yeah, so
I am. Austin, can you send them the presentation from pytorch? Yes. I don't think we have both of your email addresses. We might just have one. Yeah, so
22:28I'll loop deep again. Send an email and you can reply to that.
I'll loop deep again. Send an email and you can reply to that.
I'll loop deep again. Send an email and you can reply to that.
I'll loop deep again. Send an email and you can reply to that.
22:31Okay, yeah, you're protective of your email. I know.
Okay, yeah, you're protective of your email. I know.
Okay, yeah, you're protective of your email. I know.
Okay, yeah, you're protective of your email. I know.
22:50contact, yeah, when
S Speaker 222:52you're handing out like you think you're handing out money. Yeah, my typical a ID budget one year was two $50 million a year, and then they upped it to a billion dollars a year. Wow, oh my gosh, all the blues. Thought they were my friends.
you're handing out like you think you're handing out money. Yeah, my typical a ID budget one year was two $50 million a year, and then they upped it to a billion dollars a year. Wow, oh my gosh, all the blues. Thought they were my friends.
you're handing out like you think you're handing out money. Yeah, my typical a ID budget one year was two $50 million a year, and then they upped it to a billion dollars a year. Wow, oh my gosh, all the blues. Thought they were my friends.
you're handing out like you think you're handing out money. Yeah, my typical a ID budget one year was two $50 million a year, and then they upped it to a billion dollars a year. Wow, oh my gosh, all the blues. Thought they were my friends.
S Speaker 123:06Travis is like, somewhere walking. Hey, Travis, how are you?
Travis is like, somewhere walking. Hey, Travis, how are you?
Travis is like, somewhere walking. Hey, Travis, how are you?
Travis is like, somewhere walking. Hey, Travis, how are you?
S Speaker 323:14When you're good. So we're going to do this quickly.
When you're good. So we're going to do this quickly.
When you're good. So we're going to do this quickly.
When you're good. So we're going to do this quickly.
S Speaker 223:21Travis, they want to get a beef on how Qualcomm would benefit from working with us on Navarre.
Travis, they want to get a beef on how Qualcomm would benefit from working with us on Navarre.
Travis, they want to get a beef on how Qualcomm would benefit from working with us on Navarre.
Travis, they want to get a beef on how Qualcomm would benefit from working with us on Navarre.
23:27Great. Yeah, we are. We are part of the technical as you can Yeah,
Great. Yeah, we are. We are part of the technical as you can Yeah,
Great. Yeah, we are. We are part of the technical as you can Yeah,
Great. Yeah, we are. We are part of the technical as you can Yeah,
23:32we are part of the ventures team
we are part of the ventures team
we are part of the ventures team
we are part of the ventures team
S Speaker 123:35Travis and trying to understand the nibari value prop a little better. So specifically
Travis and trying to understand the nibari value prop a little better. So specifically
Travis and trying to understand the nibari value prop a little better. So specifically
Travis and trying to understand the nibari value prop a little better. So specifically
23:41for Qualcomm, yeah,
S Speaker 323:43so nibari is creating a mechanism for delivery of AI solutions across hardware and platforms for multiple customers. So I know Qualcomm. I did some interaction with Qualcomm when I worked with Cyprus. Yeah, this past year, yeah. If you interact with those guys
so nibari is creating a mechanism for delivery of AI solutions across hardware and platforms for multiple customers. So I know Qualcomm. I did some interaction with Qualcomm when I worked with Cyprus. Yeah, this past year, yeah. If you interact with those guys
so nibari is creating a mechanism for delivery of AI solutions across hardware and platforms for multiple customers. So I know Qualcomm. I did some interaction with Qualcomm when I worked with Cyprus. Yeah, this past year, yeah. If you interact with those guys
so nibari is creating a mechanism for delivery of AI solutions across hardware and platforms for multiple customers. So I know Qualcomm. I did some interaction with Qualcomm when I worked with Cyprus. Yeah, this past year, yeah. If you interact with those guys
S Speaker 124:01at all, it would be no of them, but they haven't interacted as much. But yeah, go ahead. Yeah. So so they
at all, it would be no of them, but they haven't interacted as much. But yeah, go ahead. Yeah. So so they
at all, it would be no of them, but they haven't interacted as much. But yeah, go ahead. Yeah. So so they
at all, it would be no of them, but they haven't interacted as much. But yeah, go ahead. Yeah. So so they
25:02we were got it. So in terms of
we were got it. So in terms of
we were got it. So in terms of
we were got it. So in terms of
S Speaker 325:05the compiler, is the compiler? Okay? Yeah, it's a compiler. It's a compiler infrastructure, as opposed to a single compiler with modular and,
the compiler, is the compiler? Okay? Yeah, it's a compiler. It's a compiler infrastructure, as opposed to a single compiler with modular and,
the compiler, is the compiler? Okay? Yeah, it's a compiler. It's a compiler infrastructure, as opposed to a single compiler with modular and,
the compiler, is the compiler? Okay? Yeah, it's a compiler. It's a compiler infrastructure, as opposed to a single compiler with modular and,
S Speaker 325:15So I wrote a project called Numba, yeah, 12 years ago. Okay, so I started the project Numba, I don't know you are with the my background,
So I wrote a project called Numba, yeah, 12 years ago. Okay, so I started the project Numba, I don't know you are with the my background,
So I wrote a project called Numba, yeah, 12 years ago. Okay, so I started the project Numba, I don't know you are with the my background,
So I wrote a project called Numba, yeah, 12 years ago. Okay, so I started the project Numba, I don't know you are with the my background,
S Speaker 125:25okay, yeah, no, of course, of course, I Yeah, yeah.
okay, yeah, no, of course, of course, I Yeah, yeah.
okay, yeah, no, of course, of course, I Yeah, yeah.
okay, yeah, no, of course, of course, I Yeah, yeah.
S Speaker 125:53okay, and a reference compiler, okay. So that's the second thing. So one, one of the questions I have, Travis on the replication of environments, how do you see Nix coming along? Because Nix is also trying to it's another open source, right? Two decades old. Nix
okay, and a reference compiler, okay. So that's the second thing. So one, one of the questions I have, Travis on the replication of environments, how do you see Nix coming along? Because Nix is also trying to it's another open source, right? Two decades old. Nix
okay, and a reference compiler, okay. So that's the second thing. So one, one of the questions I have, Travis on the replication of environments, how do you see Nix coming along? Because Nix is also trying to it's another open source, right? Two decades old. Nix
okay, and a reference compiler, okay. So that's the second thing. So one, one of the questions I have, Travis on the replication of environments, how do you see Nix coming along? Because Nix is also trying to it's another open source, right? Two decades old. Nix
S Speaker 326:10is great. Actually, I like the approach they take. They're just, honestly, they're just Linux only, yeah, right. And so we, we take the ideas of that, yeah, you make them available on any, any platform, any of us got it. Did this with conda, but didn't take the final step, right, actually, to really reify environments. Got it. Got it. But the cross platform nature, I've learned a lot from next, yeah,
is great. Actually, I like the approach they take. They're just, honestly, they're just Linux only, yeah, right. And so we, we take the ideas of that, yeah, you make them available on any, any platform, any of us got it. Did this with conda, but didn't take the final step, right, actually, to really reify environments. Got it. Got it. But the cross platform nature, I've learned a lot from next, yeah,
is great. Actually, I like the approach they take. They're just, honestly, they're just Linux only, yeah, right. And so we, we take the ideas of that, yeah, you make them available on any, any platform, any of us got it. Did this with conda, but didn't take the final step, right, actually, to really reify environments. Got it. Got it. But the cross platform nature, I've learned a lot from next, yeah,
is great. Actually, I like the approach they take. They're just, honestly, they're just Linux only, yeah, right. And so we, we take the ideas of that, yeah, you make them available on any, any platform, any of us got it. Did this with conda, but didn't take the final step, right, actually, to really reify environments. Got it. Got it. But the cross platform nature, I've learned a lot from next, yeah,
S Speaker 126:32Nix is again. I mean, I'm talking to this company called flocks, that's trying to commercialize Nix as well, right?
Nix is again. I mean, I'm talking to this company called flocks, that's trying to commercialize Nix as well, right?
Nix is again. I mean, I'm talking to this company called flocks, that's trying to commercialize Nix as well, right?
Nix is again. I mean, I'm talking to this company called flocks, that's trying to commercialize Nix as well, right?
S Speaker 327:59yep, yep. In fact, I would say if Qualcomm, you know, comes in, yeah, we should maybe that a priority to make it super easy to go from center to Qualcomm, right, right. And that's, I know some a little bit about that, because I explored that because I explored that when I was talking about site graph, right? Ai hub you have, there's
yep, yep. In fact, I would say if Qualcomm, you know, comes in, yeah, we should maybe that a priority to make it super easy to go from center to Qualcomm, right, right. And that's, I know some a little bit about that, because I explored that because I explored that when I was talking about site graph, right? Ai hub you have, there's
yep, yep. In fact, I would say if Qualcomm, you know, comes in, yeah, we should maybe that a priority to make it super easy to go from center to Qualcomm, right, right. And that's, I know some a little bit about that, because I explored that because I explored that when I was talking about site graph, right? Ai hub you have, there's
yep, yep. In fact, I would say if Qualcomm, you know, comes in, yeah, we should maybe that a priority to make it super easy to go from center to Qualcomm, right, right. And that's, I know some a little bit about that, because I explored that because I explored that when I was talking about site graph, right? Ai hub you have, there's
S Speaker 128:17a, yeah, yeah, no, that's super interesting. So that's on the environment side, on the compiler side. There are multiple of these compilers claiming that we can do compilation on any device, right, on any on any so how do you how do you stand out? Is the combination? Standing out? Is the ecosystem standing out?
a, yeah, yeah, no, that's super interesting. So that's on the environment side, on the compiler side. There are multiple of these compilers claiming that we can do compilation on any device, right, on any on any so how do you how do you stand out? Is the combination? Standing out? Is the ecosystem standing out?
a, yeah, yeah, no, that's super interesting. So that's on the environment side, on the compiler side. There are multiple of these compilers claiming that we can do compilation on any device, right, on any on any so how do you how do you stand out? Is the combination? Standing out? Is the ecosystem standing out?
a, yeah, yeah, no, that's super interesting. So that's on the environment side, on the compiler side. There are multiple of these compilers claiming that we can do compilation on any device, right, on any on any so how do you how do you stand out? Is the combination? Standing out? Is the ecosystem standing out?