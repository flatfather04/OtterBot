Meeting: Note
Wed, Sep 4, 2024
2:01 PM
30 min
Priyesh P
Introduction and Initial Connections
0:12
Marie's Bac
URL: https://otter.ai/u/LpRFKhqyrf9onpE8IlxHRjl6qpc
Downloaded: 2025-12-22T14:40:44.866996
Method: text_extraction
============================================================

0:12Hey, Hi, Marie, can you hear me? Yes, I can. I can't I can. There we go.
Hey, Hi, Marie, can you hear me? Yes, I can. I can't I can. There we go.
Hey, Hi, Marie, can you hear me? Yes, I can. I can't I can. There we go.
Hey, Hi, Marie, can you hear me? Yes, I can. I can't I can. There we go.
0:23I'm based out of sand Mateo, so I'm in the Bay Area. Great, yeah, I'm in palato.
I'm based out of sand Mateo, so I'm in the Bay Area. Great, yeah, I'm in palato.
I'm based out of sand Mateo, so I'm in the Bay Area. Great, yeah, I'm in palato.
I'm based out of sand Mateo, so I'm in the Bay Area. Great, yeah, I'm in palato.
6:11Okay, and so it's for the agents, and then you're
S Speaker 16:14llms. Are there some other things that you really want? Are you really like targeting llms? Yes, we have investments in a couple of so we have investment in anthropic we have investment in scale AI, we have investment in weights and biases, which is an ML ops company. So as a team, we feel, unless it's a very, I would say, orthogonal approach to a new LLM, completely different architecture. We feel we have done a lot of LLM investments. So foundational models, from that perspective, is more or less saturated for us. We do come across every now and then new architectures for foundational models, taste state space models is something that we evaluated early this year. We are looking at a few companies which have different approaches to building that foundational model architecture. So that is interesting. But as far as like, I'd say, llms go, and if they are directly competing with some of these big players, it's probably past us.
llms. Are there some other things that you really want? Are you really like targeting llms? Yes, we have investments in a couple of so we have investment in anthropic we have investment in scale AI, we have investment in weights and biases, which is an ML ops company. So as a team, we feel, unless it's a very, I would say, orthogonal approach to a new LLM, completely different architecture. We feel we have done a lot of LLM investments. So foundational models, from that perspective, is more or less saturated for us. We do come across every now and then new architectures for foundational models, taste state space models is something that we evaluated early this year. We are looking at a few companies which have different approaches to building that foundational model architecture. So that is interesting. But as far as like, I'd say, llms go, and if they are directly competing with some of these big players, it's probably past us.
llms. Are there some other things that you really want? Are you really like targeting llms? Yes, we have investments in a couple of so we have investment in anthropic we have investment in scale AI, we have investment in weights and biases, which is an ML ops company. So as a team, we feel, unless it's a very, I would say, orthogonal approach to a new LLM, completely different architecture. We feel we have done a lot of LLM investments. So foundational models, from that perspective, is more or less saturated for us. We do come across every now and then new architectures for foundational models, taste state space models is something that we evaluated early this year. We are looking at a few companies which have different approaches to building that foundational model architecture. So that is interesting. But as far as like, I'd say, llms go, and if they are directly competing with some of these big players, it's probably past us.
llms. Are there some other things that you really want? Are you really like targeting llms? Yes, we have investments in a couple of so we have investment in anthropic we have investment in scale AI, we have investment in weights and biases, which is an ML ops company. So as a team, we feel, unless it's a very, I would say, orthogonal approach to a new LLM, completely different architecture. We feel we have done a lot of LLM investments. So foundational models, from that perspective, is more or less saturated for us. We do come across every now and then new architectures for foundational models, taste state space models is something that we evaluated early this year. We are looking at a few companies which have different approaches to building that foundational model architecture. So that is interesting. But as far as like, I'd say, llms go, and if they are directly competing with some of these big players, it's probably past us.
S Speaker 17:22So why do you extend LLM group? I believe LLM is not really like, I'm not just really looking at it from a perspective of deal flow, if, if that means sense. I am currently in a deep tech fund, and everything that we evaluate has have like the tech mode, the long standing tech differentiation is one of the key factors that we look into our investments. So looking to work with like minded people, people who have experience in this space, probably a few researchers trying to understand the technology a little bit better, a little bit in depth, that that's what my motive was behind this. Okay, great. Okay, great. Thank you for giving me that, that broader perspective and let me, let me talk you through some of the stuff that I'm doing. Some of it's kind of obvious. Some of it, maybe less so. So I learned my calendar events that will do for my events. So, funnily enough, I have a company that weighs $8 million they they just asked me to run so, so every week I have a bunch of events. So I started out every month, so I was in a VC fund, and then building a fund. So that's, I kind of understand that VC model, yeah. So startups want to be VC. So every Monday in Palo Alto, I do VC. Me startup. Okay, and then this is interesting to you. On Fridays, there's a CTO deep tech event every Friday at the same place, yeah, researchers often from Stanford, so that could be of interest to you, right, right? I've actually been to one of these events, CTO research, AI CTO researchers, and was a pretty interesting event, I guess, personally, from sort of also looking at some of these events to get deal flow, it gets a little bit confusing to really make sure that you meet the right people amongst those big set of people out there in network. So it's kind of a wild hunt in that way. So I felt, while it's a great experience to really meet some new people, understand a few new thoughts and how people are thinking about it, it's not as focused, if you will. And then every month or so, I do a these events, so you have to have a million dollars to get into the event. From a founder's perspective, you have to have raised a million dollars, is what you mean. Yes, okay, got it. Clears the bar, as far as, like, cutting out a lot of the startups who are just, you know, like, they're Thunderball, yeah, like, and then actually, there's a, there's a startup that I'm working with is paying me to grow a series, and they actually just asked me to launch an AI agent series.
So why do you extend LLM group? I believe LLM is not really like, I'm not just really looking at it from a perspective of deal flow, if, if that means sense. I am currently in a deep tech fund, and everything that we evaluate has have like the tech mode, the long standing tech differentiation is one of the key factors that we look into our investments. So looking to work with like minded people, people who have experience in this space, probably a few researchers trying to understand the technology a little bit better, a little bit in depth, that that's what my motive was behind this. Okay, great. Okay, great. Thank you for giving me that, that broader perspective and let me, let me talk you through some of the stuff that I'm doing. Some of it's kind of obvious. Some of it, maybe less so. So I learned my calendar events that will do for my events. So, funnily enough, I have a company that weighs $8 million they they just asked me to run so, so every week I have a bunch of events. So I started out every month, so I was in a VC fund, and then building a fund. So that's, I kind of understand that VC model, yeah. So startups want to be VC. So every Monday in Palo Alto, I do VC. Me startup. Okay, and then this is interesting to you. On Fridays, there's a CTO deep tech event every Friday at the same place, yeah, researchers often from Stanford, so that could be of interest to you, right, right? I've actually been to one of these events, CTO research, AI CTO researchers, and was a pretty interesting event, I guess, personally, from sort of also looking at some of these events to get deal flow, it gets a little bit confusing to really make sure that you meet the right people amongst those big set of people out there in network. So it's kind of a wild hunt in that way. So I felt, while it's a great experience to really meet some new people, understand a few new thoughts and how people are thinking about it, it's not as focused, if you will. And then every month or so, I do a these events, so you have to have a million dollars to get into the event. From a founder's perspective, you have to have raised a million dollars, is what you mean. Yes, okay, got it. Clears the bar, as far as, like, cutting out a lot of the startups who are just, you know, like, they're Thunderball, yeah, like, and then actually, there's a, there's a startup that I'm working with is paying me to grow a series, and they actually just asked me to launch an AI agent series.
So why do you extend LLM group? I believe LLM is not really like, I'm not just really looking at it from a perspective of deal flow, if, if that means sense. I am currently in a deep tech fund, and everything that we evaluate has have like the tech mode, the long standing tech differentiation is one of the key factors that we look into our investments. So looking to work with like minded people, people who have experience in this space, probably a few researchers trying to understand the technology a little bit better, a little bit in depth, that that's what my motive was behind this. Okay, great. Okay, great. Thank you for giving me that, that broader perspective and let me, let me talk you through some of the stuff that I'm doing. Some of it's kind of obvious. Some of it, maybe less so. So I learned my calendar events that will do for my events. So, funnily enough, I have a company that weighs $8 million they they just asked me to run so, so every week I have a bunch of events. So I started out every month, so I was in a VC fund, and then building a fund. So that's, I kind of understand that VC model, yeah. So startups want to be VC. So every Monday in Palo Alto, I do VC. Me startup. Okay, and then this is interesting to you. On Fridays, there's a CTO deep tech event every Friday at the same place, yeah, researchers often from Stanford, so that could be of interest to you, right, right? I've actually been to one of these events, CTO research, AI CTO researchers, and was a pretty interesting event, I guess, personally, from sort of also looking at some of these events to get deal flow, it gets a little bit confusing to really make sure that you meet the right people amongst those big set of people out there in network. So it's kind of a wild hunt in that way. So I felt, while it's a great experience to really meet some new people, understand a few new thoughts and how people are thinking about it, it's not as focused, if you will. And then every month or so, I do a these events, so you have to have a million dollars to get into the event. From a founder's perspective, you have to have raised a million dollars, is what you mean. Yes, okay, got it. Clears the bar, as far as, like, cutting out a lot of the startups who are just, you know, like, they're Thunderball, yeah, like, and then actually, there's a, there's a startup that I'm working with is paying me to grow a series, and they actually just asked me to launch an AI agent series.
So why do you extend LLM group? I believe LLM is not really like, I'm not just really looking at it from a perspective of deal flow, if, if that means sense. I am currently in a deep tech fund, and everything that we evaluate has have like the tech mode, the long standing tech differentiation is one of the key factors that we look into our investments. So looking to work with like minded people, people who have experience in this space, probably a few researchers trying to understand the technology a little bit better, a little bit in depth, that that's what my motive was behind this. Okay, great. Okay, great. Thank you for giving me that, that broader perspective and let me, let me talk you through some of the stuff that I'm doing. Some of it's kind of obvious. Some of it, maybe less so. So I learned my calendar events that will do for my events. So, funnily enough, I have a company that weighs $8 million they they just asked me to run so, so every week I have a bunch of events. So I started out every month, so I was in a VC fund, and then building a fund. So that's, I kind of understand that VC model, yeah. So startups want to be VC. So every Monday in Palo Alto, I do VC. Me startup. Okay, and then this is interesting to you. On Fridays, there's a CTO deep tech event every Friday at the same place, yeah, researchers often from Stanford, so that could be of interest to you, right, right? I've actually been to one of these events, CTO research, AI CTO researchers, and was a pretty interesting event, I guess, personally, from sort of also looking at some of these events to get deal flow, it gets a little bit confusing to really make sure that you meet the right people amongst those big set of people out there in network. So it's kind of a wild hunt in that way. So I felt, while it's a great experience to really meet some new people, understand a few new thoughts and how people are thinking about it, it's not as focused, if you will. And then every month or so, I do a these events, so you have to have a million dollars to get into the event. From a founder's perspective, you have to have raised a million dollars, is what you mean. Yes, okay, got it. Clears the bar, as far as, like, cutting out a lot of the startups who are just, you know, like, they're Thunderball, yeah, like, and then actually, there's a, there's a startup that I'm working with is paying me to grow a series, and they actually just asked me to launch an AI agent series.
S Speaker 110:32happen weekly in Palo Alto? So if you wonder about agents in Palo Alto, that'll be that this is a family office event. This is a dinner at the rosewood with a startup in the medical space. You've got a medical hardware thing. This is for later stage founders. This is that. And then now I started this, my third one, which is, this is a start to raise $4 million so I'm I'm not only going broad, I'm gonna go deep. And then I plan to also launch a series just for l just for kind of LL, that people right? The other thing that I do, apart from just this event series, is I've been running a series of different mastermind groups, okay, on different topics, so and so for the LLM group, I have a lady shraddha. She is, she is Amazon, running a kind of LLM project. There a guy called Max, who's actually back and forth to Poland, who is on the red team of anthropic and was on the red team of of open AI, I've got a guy called Harold who teaches at Stanford. He's going to bring a bunch of Stanford LLM people, Ash, ash from inside partners. I haven't personally interfaced with them. No, they're a billion dollar fund. He's interested in being part of it. And so what I want to do is create both a series of just events about llms, as well as much smaller, 1020, person collective of people who are who do, like a regular cadence of that core group of people, meaning to to talk about what's happening in the LLM space. And so Max, for example, not just is. Max is working on his own. He's working on his own LLM in this sort of storytelling space. And then some people, maybe they're not, maybe they're not building their labs, but they're taking open source llms And kind of retooling those. Yeah. So we really much more core architecture people. Then, then, then the other agent is basically, yeah, yeah, that makes sense.
happen weekly in Palo Alto? So if you wonder about agents in Palo Alto, that'll be that this is a family office event. This is a dinner at the rosewood with a startup in the medical space. You've got a medical hardware thing. This is for later stage founders. This is that. And then now I started this, my third one, which is, this is a start to raise $4 million so I'm I'm not only going broad, I'm gonna go deep. And then I plan to also launch a series just for l just for kind of LL, that people right? The other thing that I do, apart from just this event series, is I've been running a series of different mastermind groups, okay, on different topics, so and so for the LLM group, I have a lady shraddha. She is, she is Amazon, running a kind of LLM project. There a guy called Max, who's actually back and forth to Poland, who is on the red team of anthropic and was on the red team of of open AI, I've got a guy called Harold who teaches at Stanford. He's going to bring a bunch of Stanford LLM people, Ash, ash from inside partners. I haven't personally interfaced with them. No, they're a billion dollar fund. He's interested in being part of it. And so what I want to do is create both a series of just events about llms, as well as much smaller, 1020, person collective of people who are who do, like a regular cadence of that core group of people, meaning to to talk about what's happening in the LLM space. And so Max, for example, not just is. Max is working on his own. He's working on his own LLM in this sort of storytelling space. And then some people, maybe they're not, maybe they're not building their labs, but they're taking open source llms And kind of retooling those. Yeah. So we really much more core architecture people. Then, then, then the other agent is basically, yeah, yeah, that makes sense.
happen weekly in Palo Alto? So if you wonder about agents in Palo Alto, that'll be that this is a family office event. This is a dinner at the rosewood with a startup in the medical space. You've got a medical hardware thing. This is for later stage founders. This is that. And then now I started this, my third one, which is, this is a start to raise $4 million so I'm I'm not only going broad, I'm gonna go deep. And then I plan to also launch a series just for l just for kind of LL, that people right? The other thing that I do, apart from just this event series, is I've been running a series of different mastermind groups, okay, on different topics, so and so for the LLM group, I have a lady shraddha. She is, she is Amazon, running a kind of LLM project. There a guy called Max, who's actually back and forth to Poland, who is on the red team of anthropic and was on the red team of of open AI, I've got a guy called Harold who teaches at Stanford. He's going to bring a bunch of Stanford LLM people, Ash, ash from inside partners. I haven't personally interfaced with them. No, they're a billion dollar fund. He's interested in being part of it. And so what I want to do is create both a series of just events about llms, as well as much smaller, 1020, person collective of people who are who do, like a regular cadence of that core group of people, meaning to to talk about what's happening in the LLM space. And so Max, for example, not just is. Max is working on his own. He's working on his own LLM in this sort of storytelling space. And then some people, maybe they're not, maybe they're not building their labs, but they're taking open source llms And kind of retooling those. Yeah. So we really much more core architecture people. Then, then, then the other agent is basically, yeah, yeah, that makes sense.
happen weekly in Palo Alto? So if you wonder about agents in Palo Alto, that'll be that this is a family office event. This is a dinner at the rosewood with a startup in the medical space. You've got a medical hardware thing. This is for later stage founders. This is that. And then now I started this, my third one, which is, this is a start to raise $4 million so I'm I'm not only going broad, I'm gonna go deep. And then I plan to also launch a series just for l just for kind of LL, that people right? The other thing that I do, apart from just this event series, is I've been running a series of different mastermind groups, okay, on different topics, so and so for the LLM group, I have a lady shraddha. She is, she is Amazon, running a kind of LLM project. There a guy called Max, who's actually back and forth to Poland, who is on the red team of anthropic and was on the red team of of open AI, I've got a guy called Harold who teaches at Stanford. He's going to bring a bunch of Stanford LLM people, Ash, ash from inside partners. I haven't personally interfaced with them. No, they're a billion dollar fund. He's interested in being part of it. And so what I want to do is create both a series of just events about llms, as well as much smaller, 1020, person collective of people who are who do, like a regular cadence of that core group of people, meaning to to talk about what's happening in the LLM space. And so Max, for example, not just is. Max is working on his own. He's working on his own LLM in this sort of storytelling space. And then some people, maybe they're not, maybe they're not building their labs, but they're taking open source llms And kind of retooling those. Yeah. So we really much more core architecture people. Then, then, then the other agent is basically, yeah, yeah, that makes sense.
13:11So that's, that's what I'm trying to do with the with the group and, well, me, I mean, I do some deal sourcing for some funds.
So that's, that's what I'm trying to do with the with the group and, well, me, I mean, I do some deal sourcing for some funds.
So that's, that's what I'm trying to do with the with the group and, well, me, I mean, I do some deal sourcing for some funds.
So that's, that's what I'm trying to do with the with the group and, well, me, I mean, I do some deal sourcing for some funds.
S Speaker 123:08and they are running a mini LLM on the phone, which listens to a conversation, and then it pulls from prompts for activities, and then they they pass that to a big LLM outside. I've now seen multiple of those, yeah, but I definitely, I definitely see that. But phones will be 10 times more powerful, so phones will be able to run decent, small llms, yeah, and that core corruption should very much be in that space. Absolutely,
and they are running a mini LLM on the phone, which listens to a conversation, and then it pulls from prompts for activities, and then they they pass that to a big LLM outside. I've now seen multiple of those, yeah, but I definitely, I definitely see that. But phones will be 10 times more powerful, so phones will be able to run decent, small llms, yeah, and that core corruption should very much be in that space. Absolutely,
and they are running a mini LLM on the phone, which listens to a conversation, and then it pulls from prompts for activities, and then they they pass that to a big LLM outside. I've now seen multiple of those, yeah, but I definitely, I definitely see that. But phones will be 10 times more powerful, so phones will be able to run decent, small llms, yeah, and that core corruption should very much be in that space. Absolutely,
and they are running a mini LLM on the phone, which listens to a conversation, and then it pulls from prompts for activities, and then they they pass that to a big LLM outside. I've now seen multiple of those, yeah, but I definitely, I definitely see that. But phones will be 10 times more powerful, so phones will be able to run decent, small llms, yeah, and that core corruption should very much be in that space. Absolutely,
23:39we are trying to for sure. Yeah, like, how would you describe those, those agents? What?
we are trying to for sure. Yeah, like, how would you describe those, those agents? What?
we are trying to for sure. Yeah, like, how would you describe those, those agents? What?
we are trying to for sure. Yeah, like, how would you describe those, those agents? What?
S Speaker 123:58What do you mean by that? I am sorry I didn't get your question exactly. It's almost like agents running on running like it's almost like an event for agents running on many, many LMS, right? So we so Qualcomm has an initiative called the AI hub, wherein we work with a lot of open service models and try to optimize them for edge deployments. Our latest snap dragon processors, which go on the flagship Samsung phones. They are also able to run a lot of these mini llms, mini image generating models, diffusion based models on device. And that's how Samsung has powered a lot bunch of features in there. And then we recently launched our AI PCs with Microsoft and a few other with Dell and a few other OEMs. So in that space, we have optimized the GPUs that the Snapdragon GPUs that go into these PCs to run a lot of llms on space. I would say for a lot of these companies, models are getting compressed. For sure, there is a strong internal effort to make sure that the bigger llms could be compressed, the parameters could be shortened down so that they sort of work with more or less the same level of accuracy, but significantly less compute and power. Power is a factor that we significantly track. But So we do see this happening quite a lot, and some of the new architectures which are coming for llms, like the state space model is something which really piqued our interest. There's a company called cartesia which is working on it, Stanford guys, they've raised a pretty big round recently, and their models are significantly smaller than the large language models currently, and we that is where we feel some of these new architectures could really unlock a lot of value. I
What do you mean by that? I am sorry I didn't get your question exactly. It's almost like agents running on running like it's almost like an event for agents running on many, many LMS, right? So we so Qualcomm has an initiative called the AI hub, wherein we work with a lot of open service models and try to optimize them for edge deployments. Our latest snap dragon processors, which go on the flagship Samsung phones. They are also able to run a lot of these mini llms, mini image generating models, diffusion based models on device. And that's how Samsung has powered a lot bunch of features in there. And then we recently launched our AI PCs with Microsoft and a few other with Dell and a few other OEMs. So in that space, we have optimized the GPUs that the Snapdragon GPUs that go into these PCs to run a lot of llms on space. I would say for a lot of these companies, models are getting compressed. For sure, there is a strong internal effort to make sure that the bigger llms could be compressed, the parameters could be shortened down so that they sort of work with more or less the same level of accuracy, but significantly less compute and power. Power is a factor that we significantly track. But So we do see this happening quite a lot, and some of the new architectures which are coming for llms, like the state space model is something which really piqued our interest. There's a company called cartesia which is working on it, Stanford guys, they've raised a pretty big round recently, and their models are significantly smaller than the large language models currently, and we that is where we feel some of these new architectures could really unlock a lot of value. I
What do you mean by that? I am sorry I didn't get your question exactly. It's almost like agents running on running like it's almost like an event for agents running on many, many LMS, right? So we so Qualcomm has an initiative called the AI hub, wherein we work with a lot of open service models and try to optimize them for edge deployments. Our latest snap dragon processors, which go on the flagship Samsung phones. They are also able to run a lot of these mini llms, mini image generating models, diffusion based models on device. And that's how Samsung has powered a lot bunch of features in there. And then we recently launched our AI PCs with Microsoft and a few other with Dell and a few other OEMs. So in that space, we have optimized the GPUs that the Snapdragon GPUs that go into these PCs to run a lot of llms on space. I would say for a lot of these companies, models are getting compressed. For sure, there is a strong internal effort to make sure that the bigger llms could be compressed, the parameters could be shortened down so that they sort of work with more or less the same level of accuracy, but significantly less compute and power. Power is a factor that we significantly track. But So we do see this happening quite a lot, and some of the new architectures which are coming for llms, like the state space model is something which really piqued our interest. There's a company called cartesia which is working on it, Stanford guys, they've raised a pretty big round recently, and their models are significantly smaller than the large language models currently, and we that is where we feel some of these new architectures could really unlock a lot of value. I
What do you mean by that? I am sorry I didn't get your question exactly. It's almost like agents running on running like it's almost like an event for agents running on many, many LMS, right? So we so Qualcomm has an initiative called the AI hub, wherein we work with a lot of open service models and try to optimize them for edge deployments. Our latest snap dragon processors, which go on the flagship Samsung phones. They are also able to run a lot of these mini llms, mini image generating models, diffusion based models on device. And that's how Samsung has powered a lot bunch of features in there. And then we recently launched our AI PCs with Microsoft and a few other with Dell and a few other OEMs. So in that space, we have optimized the GPUs that the Snapdragon GPUs that go into these PCs to run a lot of llms on space. I would say for a lot of these companies, models are getting compressed. For sure, there is a strong internal effort to make sure that the bigger llms could be compressed, the parameters could be shortened down so that they sort of work with more or less the same level of accuracy, but significantly less compute and power. Power is a factor that we significantly track. But So we do see this happening quite a lot, and some of the new architectures which are coming for llms, like the state space model is something which really piqued our interest. There's a company called cartesia which is working on it, Stanford guys, they've raised a pretty big round recently, and their models are significantly smaller than the large language models currently, and we that is where we feel some of these new architectures could really unlock a lot of value. I
S Speaker 130:15Absolutely. Marie, thanks a lot for the time. Okay, see you again. Bye.
Absolutely. Marie, thanks a lot for the time. Okay, see you again. Bye.
Absolutely. Marie, thanks a lot for the time. Okay, see you again. Bye.
Absolutely. Marie, thanks a lot for the time. Okay, see you again. Bye.