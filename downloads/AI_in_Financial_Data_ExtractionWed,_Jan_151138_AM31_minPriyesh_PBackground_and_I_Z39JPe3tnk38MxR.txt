Meeting: AI in Financial Data Extraction
Wed, Jan 15
11:38 AM
31 min
Priyesh P
Background and Initial Introdu
URL: https://otter.ai/u/Z39JPe3tnk38MxR9wqvaUo2FpUM
Downloaded: 2025-12-22T13:28:12.050811
Method: text_extraction
============================================================

S Speaker 10:00Go ahead, would love to hear a little bit about your background and then what you're trying to build. So,
Go ahead, would love to hear a little bit about your background and then what you're trying to build. So,
Go ahead, would love to hear a little bit about your background and then what you're trying to build. So,
Go ahead, would love to hear a little bit about your background and then what you're trying to build. So,
S Speaker 20:06yeah, my name is graduated from IIT Kharagpur in 2027, to competitive programming and internships Singapore based wealth management, firmware. I got financial from software after graduating high frequency from as a trading systems engineer, where I was building technology.
yeah, my name is graduated from IIT Kharagpur in 2027, to competitive programming and internships Singapore based wealth management, firmware. I got financial from software after graduating high frequency from as a trading systems engineer, where I was building technology.
yeah, my name is graduated from IIT Kharagpur in 2027, to competitive programming and internships Singapore based wealth management, firmware. I got financial from software after graduating high frequency from as a trading systems engineer, where I was building technology.
yeah, my name is graduated from IIT Kharagpur in 2027, to competitive programming and internships Singapore based wealth management, firmware. I got financial from software after graduating high frequency from as a trading systems engineer, where I was building technology.
S Speaker 20:38I was also at the asset based AI startup founding engineer solutions for Fortune 500 companies like Disney, PayPal, gold in charge. I got to see how AI is applied. You know, across enterprises. Around that time, I started having discussions with introduce themselves. Yeah, we started discussing, and we felt that, you know, pi for finance is something where we have some experience and strong age match. And that is when things, you know, started taking off. And then we met entrepreneur. First we were in the COVID backlog, and we built our company over there. We got funded by them, and now we have, you know, just looking forward to take it ahead, you know, from there. So maybe Adnan can quickly introduce myself.
I was also at the asset based AI startup founding engineer solutions for Fortune 500 companies like Disney, PayPal, gold in charge. I got to see how AI is applied. You know, across enterprises. Around that time, I started having discussions with introduce themselves. Yeah, we started discussing, and we felt that, you know, pi for finance is something where we have some experience and strong age match. And that is when things, you know, started taking off. And then we met entrepreneur. First we were in the COVID backlog, and we built our company over there. We got funded by them, and now we have, you know, just looking forward to take it ahead, you know, from there. So maybe Adnan can quickly introduce myself.
I was also at the asset based AI startup founding engineer solutions for Fortune 500 companies like Disney, PayPal, gold in charge. I got to see how AI is applied. You know, across enterprises. Around that time, I started having discussions with introduce themselves. Yeah, we started discussing, and we felt that, you know, pi for finance is something where we have some experience and strong age match. And that is when things, you know, started taking off. And then we met entrepreneur. First we were in the COVID backlog, and we built our company over there. We got funded by them, and now we have, you know, just looking forward to take it ahead, you know, from there. So maybe Adnan can quickly introduce myself.
I was also at the asset based AI startup founding engineer solutions for Fortune 500 companies like Disney, PayPal, gold in charge. I got to see how AI is applied. You know, across enterprises. Around that time, I started having discussions with introduce themselves. Yeah, we started discussing, and we felt that, you know, pi for finance is something where we have some experience and strong age match. And that is when things, you know, started taking off. And then we met entrepreneur. First we were in the COVID backlog, and we built our company over there. We got funded by them, and now we have, you know, just looking forward to take it ahead, you know, from there. So maybe Adnan can quickly introduce myself.
S Speaker 31:32So I'm Adnan. I graduated in 23 and then I was aI researcher at the decoder at MIT. For around seven months, I was working at the intersection of Gen AI and finance and and then moving forward, I joined Mercedes Benz R and D for another for five months, then decided to drop out and pursue entrepreneurship.
So I'm Adnan. I graduated in 23 and then I was aI researcher at the decoder at MIT. For around seven months, I was working at the intersection of Gen AI and finance and and then moving forward, I joined Mercedes Benz R and D for another for five months, then decided to drop out and pursue entrepreneurship.
So I'm Adnan. I graduated in 23 and then I was aI researcher at the decoder at MIT. For around seven months, I was working at the intersection of Gen AI and finance and and then moving forward, I joined Mercedes Benz R and D for another for five months, then decided to drop out and pursue entrepreneurship.
So I'm Adnan. I graduated in 23 and then I was aI researcher at the decoder at MIT. For around seven months, I was working at the intersection of Gen AI and finance and and then moving forward, I joined Mercedes Benz R and D for another for five months, then decided to drop out and pursue entrepreneurship.
2:04Absolutely, that sounds amazing. Thanks, guys.
Absolutely, that sounds amazing. Thanks, guys.
Absolutely, that sounds amazing. Thanks, guys.
Absolutely, that sounds amazing. Thanks, guys.
S Speaker 12:11So yeah, we can, we can jump on the company discussion. Yeah,
So yeah, we can, we can jump on the company discussion. Yeah,
So yeah, we can, we can jump on the company discussion. Yeah,
So yeah, we can, we can jump on the company discussion. Yeah,
S Speaker 22:16yeah. So we are building AI agents for unstructured financial data. While working at the trading firm, as well as internal wealth management firm, I got to see that, you know this, firms have huge volumes of unstructured data, which generally is blocked away as PDS, PPTs, images, you know, and it's very hard to util utilize that in decision making and building, you know, business work does not type of that. So, you know, three years ago, it was almost impossible, like people used to use LLP based techniques or custom, you know, past solutions, to build something on top of it. You know, now when elements came, it becomes slightly easier to, you know, sort of manipulate these unstructured documents. But if you see it's still not widely practiced like people. People say you try to build that based solutions on top of it and try to leverage unstructured documents in decision making or in workflow. But most it fails most of the times, particularly for a sector like finance, where accuracy and reliability is of utmost importance. You know, there you can't have wrong numbers because that it is you are literally dealing with capital, yes. So I have seen how sensitive that is, you know, to tell us like there is absolutely no and no margin for error over there. So any of these solutions which people try, you know, are able to print them now using elements for extraction, inherent, you know, inaccuracy inside it. And all of this is because the first step, which is extraction, basically the data layer that is broken. People are trying to build applications on top of the data, but then in order to be able to build those applications, you need to be able to extract metrics accurately from these documents like this. Data is not slipping in some relational database so that you can build APIs or applications on top of it, the data is being locked away as PDFs, PPTs. There are numbers in those PDFs which you need to extract and use. So we are sort of on this data layer. We are trying to extract this matrix and make it available for the elements, basically. So we are making this unstructured data ready to be leveraged in building workflows or being used in decision making. And this has huge ROI for the for this financial firms, because, especially in trading forms, the leverage that you have because of any insight, you know that that's huge, that we can literally make millions by leveraging that insight, and that insight is mostly locked away, you know, in this huge volume of unstructured data that this financial form should be replying. You know, SSC file means statement that a form is releasing. So this is what we are trying to solve at this point of time.
yeah. So we are building AI agents for unstructured financial data. While working at the trading firm, as well as internal wealth management firm, I got to see that, you know this, firms have huge volumes of unstructured data, which generally is blocked away as PDS, PPTs, images, you know, and it's very hard to util utilize that in decision making and building, you know, business work does not type of that. So, you know, three years ago, it was almost impossible, like people used to use LLP based techniques or custom, you know, past solutions, to build something on top of it. You know, now when elements came, it becomes slightly easier to, you know, sort of manipulate these unstructured documents. But if you see it's still not widely practiced like people. People say you try to build that based solutions on top of it and try to leverage unstructured documents in decision making or in workflow. But most it fails most of the times, particularly for a sector like finance, where accuracy and reliability is of utmost importance. You know, there you can't have wrong numbers because that it is you are literally dealing with capital, yes. So I have seen how sensitive that is, you know, to tell us like there is absolutely no and no margin for error over there. So any of these solutions which people try, you know, are able to print them now using elements for extraction, inherent, you know, inaccuracy inside it. And all of this is because the first step, which is extraction, basically the data layer that is broken. People are trying to build applications on top of the data, but then in order to be able to build those applications, you need to be able to extract metrics accurately from these documents like this. Data is not slipping in some relational database so that you can build APIs or applications on top of it, the data is being locked away as PDFs, PPTs. There are numbers in those PDFs which you need to extract and use. So we are sort of on this data layer. We are trying to extract this matrix and make it available for the elements, basically. So we are making this unstructured data ready to be leveraged in building workflows or being used in decision making. And this has huge ROI for the for this financial firms, because, especially in trading forms, the leverage that you have because of any insight, you know that that's huge, that we can literally make millions by leveraging that insight, and that insight is mostly locked away, you know, in this huge volume of unstructured data that this financial form should be replying. You know, SSC file means statement that a form is releasing. So this is what we are trying to solve at this point of time.
yeah. So we are building AI agents for unstructured financial data. While working at the trading firm, as well as internal wealth management firm, I got to see that, you know this, firms have huge volumes of unstructured data, which generally is blocked away as PDS, PPTs, images, you know, and it's very hard to util utilize that in decision making and building, you know, business work does not type of that. So, you know, three years ago, it was almost impossible, like people used to use LLP based techniques or custom, you know, past solutions, to build something on top of it. You know, now when elements came, it becomes slightly easier to, you know, sort of manipulate these unstructured documents. But if you see it's still not widely practiced like people. People say you try to build that based solutions on top of it and try to leverage unstructured documents in decision making or in workflow. But most it fails most of the times, particularly for a sector like finance, where accuracy and reliability is of utmost importance. You know, there you can't have wrong numbers because that it is you are literally dealing with capital, yes. So I have seen how sensitive that is, you know, to tell us like there is absolutely no and no margin for error over there. So any of these solutions which people try, you know, are able to print them now using elements for extraction, inherent, you know, inaccuracy inside it. And all of this is because the first step, which is extraction, basically the data layer that is broken. People are trying to build applications on top of the data, but then in order to be able to build those applications, you need to be able to extract metrics accurately from these documents like this. Data is not slipping in some relational database so that you can build APIs or applications on top of it, the data is being locked away as PDFs, PPTs. There are numbers in those PDFs which you need to extract and use. So we are sort of on this data layer. We are trying to extract this matrix and make it available for the elements, basically. So we are making this unstructured data ready to be leveraged in building workflows or being used in decision making. And this has huge ROI for the for this financial firms, because, especially in trading forms, the leverage that you have because of any insight, you know that that's huge, that we can literally make millions by leveraging that insight, and that insight is mostly locked away, you know, in this huge volume of unstructured data that this financial form should be replying. You know, SSC file means statement that a form is releasing. So this is what we are trying to solve at this point of time.
yeah. So we are building AI agents for unstructured financial data. While working at the trading firm, as well as internal wealth management firm, I got to see that, you know this, firms have huge volumes of unstructured data, which generally is blocked away as PDS, PPTs, images, you know, and it's very hard to util utilize that in decision making and building, you know, business work does not type of that. So, you know, three years ago, it was almost impossible, like people used to use LLP based techniques or custom, you know, past solutions, to build something on top of it. You know, now when elements came, it becomes slightly easier to, you know, sort of manipulate these unstructured documents. But if you see it's still not widely practiced like people. People say you try to build that based solutions on top of it and try to leverage unstructured documents in decision making or in workflow. But most it fails most of the times, particularly for a sector like finance, where accuracy and reliability is of utmost importance. You know, there you can't have wrong numbers because that it is you are literally dealing with capital, yes. So I have seen how sensitive that is, you know, to tell us like there is absolutely no and no margin for error over there. So any of these solutions which people try, you know, are able to print them now using elements for extraction, inherent, you know, inaccuracy inside it. And all of this is because the first step, which is extraction, basically the data layer that is broken. People are trying to build applications on top of the data, but then in order to be able to build those applications, you need to be able to extract metrics accurately from these documents like this. Data is not slipping in some relational database so that you can build APIs or applications on top of it, the data is being locked away as PDFs, PPTs. There are numbers in those PDFs which you need to extract and use. So we are sort of on this data layer. We are trying to extract this matrix and make it available for the elements, basically. So we are making this unstructured data ready to be leveraged in building workflows or being used in decision making. And this has huge ROI for the for this financial firms, because, especially in trading forms, the leverage that you have because of any insight, you know that that's huge, that we can literally make millions by leveraging that insight, and that insight is mostly locked away, you know, in this huge volume of unstructured data that this financial form should be replying. You know, SSC file means statement that a form is releasing. So this is what we are trying to solve at this point of time.
S Speaker 15:22That's, that's very interesting, Aman, but I understand the value proposition. I've also met a lot of companies building LLM based solutions in the financial industry. And certainly there's a lot of value to be captured. There is the, probably one of the most hottest industries in terms of adoption of AI as well financial and financial services and healthcare probably lead the adoption at this moment. I understand that, but I have also come across a lot of companies who are trying to do what you are trying to predict. So how do you like is there a positioning advantage you have. Do you see things differently? What? How are you thinking about that? Yeah, so
That's, that's very interesting, Aman, but I understand the value proposition. I've also met a lot of companies building LLM based solutions in the financial industry. And certainly there's a lot of value to be captured. There is the, probably one of the most hottest industries in terms of adoption of AI as well financial and financial services and healthcare probably lead the adoption at this moment. I understand that, but I have also come across a lot of companies who are trying to do what you are trying to predict. So how do you like is there a positioning advantage you have. Do you see things differently? What? How are you thinking about that? Yeah, so
That's, that's very interesting, Aman, but I understand the value proposition. I've also met a lot of companies building LLM based solutions in the financial industry. And certainly there's a lot of value to be captured. There is the, probably one of the most hottest industries in terms of adoption of AI as well financial and financial services and healthcare probably lead the adoption at this moment. I understand that, but I have also come across a lot of companies who are trying to do what you are trying to predict. So how do you like is there a positioning advantage you have. Do you see things differently? What? How are you thinking about that? Yeah, so
That's, that's very interesting, Aman, but I understand the value proposition. I've also met a lot of companies building LLM based solutions in the financial industry. And certainly there's a lot of value to be captured. There is the, probably one of the most hottest industries in terms of adoption of AI as well financial and financial services and healthcare probably lead the adoption at this moment. I understand that, but I have also come across a lot of companies who are trying to do what you are trying to predict. So how do you like is there a positioning advantage you have. Do you see things differently? What? How are you thinking about that? Yeah, so
S Speaker 18:24makes sense someone. And in fact, if you actually do crack the data layer problem, you don't really need to get into the application layer, because there will be a lot of competition there. People will be winning on workflows, stickiness, and a lot of other things, and you can just benefit as a derivative of that industry. But again, what I feel is I have seen companies in the space where, let's say, if we call this a broader data parsing industry, refuel, does this? Snorkel, does this, and is there a benefit that you are specifically creating a data parsing technology for financial services and how in you mentioned accuracy. But is accuracy really a deciding factor in this market? Do you think you will be better at more accurate than the other players and like, what's the tech advantage that you're thinking of?
makes sense someone. And in fact, if you actually do crack the data layer problem, you don't really need to get into the application layer, because there will be a lot of competition there. People will be winning on workflows, stickiness, and a lot of other things, and you can just benefit as a derivative of that industry. But again, what I feel is I have seen companies in the space where, let's say, if we call this a broader data parsing industry, refuel, does this? Snorkel, does this, and is there a benefit that you are specifically creating a data parsing technology for financial services and how in you mentioned accuracy. But is accuracy really a deciding factor in this market? Do you think you will be better at more accurate than the other players and like, what's the tech advantage that you're thinking of?
makes sense someone. And in fact, if you actually do crack the data layer problem, you don't really need to get into the application layer, because there will be a lot of competition there. People will be winning on workflows, stickiness, and a lot of other things, and you can just benefit as a derivative of that industry. But again, what I feel is I have seen companies in the space where, let's say, if we call this a broader data parsing industry, refuel, does this? Snorkel, does this, and is there a benefit that you are specifically creating a data parsing technology for financial services and how in you mentioned accuracy. But is accuracy really a deciding factor in this market? Do you think you will be better at more accurate than the other players and like, what's the tech advantage that you're thinking of?
makes sense someone. And in fact, if you actually do crack the data layer problem, you don't really need to get into the application layer, because there will be a lot of competition there. People will be winning on workflows, stickiness, and a lot of other things, and you can just benefit as a derivative of that industry. But again, what I feel is I have seen companies in the space where, let's say, if we call this a broader data parsing industry, refuel, does this? Snorkel, does this, and is there a benefit that you are specifically creating a data parsing technology for financial services and how in you mentioned accuracy. But is accuracy really a deciding factor in this market? Do you think you will be better at more accurate than the other players and like, what's the tech advantage that you're thinking of?
S Speaker 29:16Yes here, accuracy is of utmost importance, because suppose you have revenue as 11, $11.1 billion say, for example, you are the private equity firm is evaluating a deal. The revenue is, say, for example, just making a video, $11.1 billion if you use an LLM to extract from it, it might end up perceiving that $11.1 billion as 11 power $1 billion the kind of mistakes that llms do because they are not good with numbers. You know, for example, a very popular newspaper used to think that 11.1
Yes here, accuracy is of utmost importance, because suppose you have revenue as 11, $11.1 billion say, for example, you are the private equity firm is evaluating a deal. The revenue is, say, for example, just making a video, $11.1 billion if you use an LLM to extract from it, it might end up perceiving that $11.1 billion as 11 power $1 billion the kind of mistakes that llms do because they are not good with numbers. You know, for example, a very popular newspaper used to think that 11.1
Yes here, accuracy is of utmost importance, because suppose you have revenue as 11, $11.1 billion say, for example, you are the private equity firm is evaluating a deal. The revenue is, say, for example, just making a video, $11.1 billion if you use an LLM to extract from it, it might end up perceiving that $11.1 billion as 11 power $1 billion the kind of mistakes that llms do because they are not good with numbers. You know, for example, a very popular newspaper used to think that 11.1
Yes here, accuracy is of utmost importance, because suppose you have revenue as 11, $11.1 billion say, for example, you are the private equity firm is evaluating a deal. The revenue is, say, for example, just making a video, $11.1 billion if you use an LLM to extract from it, it might end up perceiving that $11.1 billion as 11 power $1 billion the kind of mistakes that llms do because they are not good with numbers. You know, for example, a very popular newspaper used to think that 11.1
9:56is, I think smaller than 999,
is, I think smaller than 999,
is, I think smaller than 999,
is, I think smaller than 999,
10:00percent. Yeah, I've seen, seen those pictures, yes,
percent. Yeah, I've seen, seen those pictures, yes,
percent. Yeah, I've seen, seen those pictures, yes,
percent. Yeah, I've seen, seen those pictures, yes,
S Speaker 210:04exactly, and that that is not a random error that it makes, that is very valid, because if you drill down their large language models, they are not made for mathematical, you know, comparisons and all of that. So specifically, in finance, the margin for error is almost negligible, like if they if suppose they're using an LLM based, you know, agent to evaluate a dB, and suppose that LLM extracted in the 100 and $11 billion from that PDF, instead of 11.11 the the verdict that it is going to throw that a we are going to exist in forward versus no, we are, you know, dropping it here. So that is going to be widely different, you know. So here the margin. And if you, if you try to see what impact falls at, I mean, no accuracy can have, especially on the hedge funds, it is even much more like in hedge funds, you are literally trading using machine, which I have built trading systems, you know. So I know there, if you don't have it, even if you have slight error over there, you won't even get an opportunity to identify that. In private equity firms, things much slow. You can always stop at it, but in hedge funds, machines are making trades, and if the machines are seeing accurate numbers, the trades that they are going to make is also going to be incorrect. And once you have placed a false trade, there is no way going back, you know, like it's just, you might have your stop loss in place, but if that is just going to wipe out the amount of capital that we have allocated for that trading strategy, so that is why, in finance, accuracy is of utmost importance, accuracy and reliability. So what do I mean by that, like, if things go wrong, they need to explain. I mean, it is their fiduciary responsibility to be able to explain why they did took that decision for that need. They need to bring that to the source of truth. Now, source of truth is generally the findings that you know this companies present, like the SSC findings that the companies find that is considered the source of truth. So they need to place that to where did they get this number and why they make the trading decision. So it needs to be accurate and it's to be it needs to come from a reliable source. So these two are the things that they index on. Now, coming to there are, there are a lot of data passing solutions, but here just the OCR based parsing or regex passing won't make a cut. First and foremost, they are not very accurate. They might be useful in scenarios where the the error margin can be, you know, it's slightly higher. Basically, the downsides are not as intense as you know, saying finance in those kind of setups, you can rely on a parser or any other solution here, you need to be more sophisticated. The other thing is that you can't. I mean, people see it as an extraction problem. They feel like you take your bunch of PDFs, you just need to extract numbers from it, right? And that is like you will find most of the solutions out there. They are horizontal, but people and they try to use it, okay? You can use it in healthcare, you can use it in finance, you can use it in E commerce. But having worked in financial firms and with financial data, we feel like it's not just an extraction problem. It's more of a extraction combined with a context problem. And by context I mean that your extraction engine needs to understand what it has been asked to extract in finance. You know, finances are very is very scattered, like, it's very disparate, you know, like, you have different kinds of equities, different kind of you know, it's very basically fragmented, you know. And for example, estimate can mean simple moving average or separately managed accounts based on the context, you know. So unless and until the extraction engine understands the context, it is not going to provide the correct number, like, for example, if the PDF has simple moving average as well as separately managed accounts in the same, you know, PDF, and I ask it to say, you know, Hey, what is the SME? So if it is a trading firm. They, for them, SMA is simple, moving average. That is how they operate, whereas, if it's some other same, macro based trading form for them, sma generally be a force to separately manage accounts or something. So unless and until this context is built in, like this reasoning is built in, inside the extraction engine, it is not going to, you know, pro correct numbers. Another example is equity and equities, you know, both of these stocks are similar, but then the entire difference is in finance. So you need to embed a reasoning layer inside the extraction engine that you are building. And, yeah, that is what we are trying to solve. We are and we are doing this by, you know, building vision language models, which are not just data extractors, but they also have a reasoning layer built inside it, which is domain specific. And that is why we are not saying that we are building extraction solution for horizontal extraction solution. That is why we are specific, because we know that it is going to be accurate only when it knows the context. And you can't feed the entire or the context of the you know, world into it. It has to be a certain domain. So, yeah, that is how it's different from any traditional, you know, extraction. That's
exactly, and that that is not a random error that it makes, that is very valid, because if you drill down their large language models, they are not made for mathematical, you know, comparisons and all of that. So specifically, in finance, the margin for error is almost negligible, like if they if suppose they're using an LLM based, you know, agent to evaluate a dB, and suppose that LLM extracted in the 100 and $11 billion from that PDF, instead of 11.11 the the verdict that it is going to throw that a we are going to exist in forward versus no, we are, you know, dropping it here. So that is going to be widely different, you know. So here the margin. And if you, if you try to see what impact falls at, I mean, no accuracy can have, especially on the hedge funds, it is even much more like in hedge funds, you are literally trading using machine, which I have built trading systems, you know. So I know there, if you don't have it, even if you have slight error over there, you won't even get an opportunity to identify that. In private equity firms, things much slow. You can always stop at it, but in hedge funds, machines are making trades, and if the machines are seeing accurate numbers, the trades that they are going to make is also going to be incorrect. And once you have placed a false trade, there is no way going back, you know, like it's just, you might have your stop loss in place, but if that is just going to wipe out the amount of capital that we have allocated for that trading strategy, so that is why, in finance, accuracy is of utmost importance, accuracy and reliability. So what do I mean by that, like, if things go wrong, they need to explain. I mean, it is their fiduciary responsibility to be able to explain why they did took that decision for that need. They need to bring that to the source of truth. Now, source of truth is generally the findings that you know this companies present, like the SSC findings that the companies find that is considered the source of truth. So they need to place that to where did they get this number and why they make the trading decision. So it needs to be accurate and it's to be it needs to come from a reliable source. So these two are the things that they index on. Now, coming to there are, there are a lot of data passing solutions, but here just the OCR based parsing or regex passing won't make a cut. First and foremost, they are not very accurate. They might be useful in scenarios where the the error margin can be, you know, it's slightly higher. Basically, the downsides are not as intense as you know, saying finance in those kind of setups, you can rely on a parser or any other solution here, you need to be more sophisticated. The other thing is that you can't. I mean, people see it as an extraction problem. They feel like you take your bunch of PDFs, you just need to extract numbers from it, right? And that is like you will find most of the solutions out there. They are horizontal, but people and they try to use it, okay? You can use it in healthcare, you can use it in finance, you can use it in E commerce. But having worked in financial firms and with financial data, we feel like it's not just an extraction problem. It's more of a extraction combined with a context problem. And by context I mean that your extraction engine needs to understand what it has been asked to extract in finance. You know, finances are very is very scattered, like, it's very disparate, you know, like, you have different kinds of equities, different kind of you know, it's very basically fragmented, you know. And for example, estimate can mean simple moving average or separately managed accounts based on the context, you know. So unless and until the extraction engine understands the context, it is not going to provide the correct number, like, for example, if the PDF has simple moving average as well as separately managed accounts in the same, you know, PDF, and I ask it to say, you know, Hey, what is the SME? So if it is a trading firm. They, for them, SMA is simple, moving average. That is how they operate, whereas, if it's some other same, macro based trading form for them, sma generally be a force to separately manage accounts or something. So unless and until this context is built in, like this reasoning is built in, inside the extraction engine, it is not going to, you know, pro correct numbers. Another example is equity and equities, you know, both of these stocks are similar, but then the entire difference is in finance. So you need to embed a reasoning layer inside the extraction engine that you are building. And, yeah, that is what we are trying to solve. We are and we are doing this by, you know, building vision language models, which are not just data extractors, but they also have a reasoning layer built inside it, which is domain specific. And that is why we are not saying that we are building extraction solution for horizontal extraction solution. That is why we are specific, because we know that it is going to be accurate only when it knows the context. And you can't feed the entire or the context of the you know, world into it. It has to be a certain domain. So, yeah, that is how it's different from any traditional, you know, extraction. That's
exactly, and that that is not a random error that it makes, that is very valid, because if you drill down their large language models, they are not made for mathematical, you know, comparisons and all of that. So specifically, in finance, the margin for error is almost negligible, like if they if suppose they're using an LLM based, you know, agent to evaluate a dB, and suppose that LLM extracted in the 100 and $11 billion from that PDF, instead of 11.11 the the verdict that it is going to throw that a we are going to exist in forward versus no, we are, you know, dropping it here. So that is going to be widely different, you know. So here the margin. And if you, if you try to see what impact falls at, I mean, no accuracy can have, especially on the hedge funds, it is even much more like in hedge funds, you are literally trading using machine, which I have built trading systems, you know. So I know there, if you don't have it, even if you have slight error over there, you won't even get an opportunity to identify that. In private equity firms, things much slow. You can always stop at it, but in hedge funds, machines are making trades, and if the machines are seeing accurate numbers, the trades that they are going to make is also going to be incorrect. And once you have placed a false trade, there is no way going back, you know, like it's just, you might have your stop loss in place, but if that is just going to wipe out the amount of capital that we have allocated for that trading strategy, so that is why, in finance, accuracy is of utmost importance, accuracy and reliability. So what do I mean by that, like, if things go wrong, they need to explain. I mean, it is their fiduciary responsibility to be able to explain why they did took that decision for that need. They need to bring that to the source of truth. Now, source of truth is generally the findings that you know this companies present, like the SSC findings that the companies find that is considered the source of truth. So they need to place that to where did they get this number and why they make the trading decision. So it needs to be accurate and it's to be it needs to come from a reliable source. So these two are the things that they index on. Now, coming to there are, there are a lot of data passing solutions, but here just the OCR based parsing or regex passing won't make a cut. First and foremost, they are not very accurate. They might be useful in scenarios where the the error margin can be, you know, it's slightly higher. Basically, the downsides are not as intense as you know, saying finance in those kind of setups, you can rely on a parser or any other solution here, you need to be more sophisticated. The other thing is that you can't. I mean, people see it as an extraction problem. They feel like you take your bunch of PDFs, you just need to extract numbers from it, right? And that is like you will find most of the solutions out there. They are horizontal, but people and they try to use it, okay? You can use it in healthcare, you can use it in finance, you can use it in E commerce. But having worked in financial firms and with financial data, we feel like it's not just an extraction problem. It's more of a extraction combined with a context problem. And by context I mean that your extraction engine needs to understand what it has been asked to extract in finance. You know, finances are very is very scattered, like, it's very disparate, you know, like, you have different kinds of equities, different kind of you know, it's very basically fragmented, you know. And for example, estimate can mean simple moving average or separately managed accounts based on the context, you know. So unless and until the extraction engine understands the context, it is not going to provide the correct number, like, for example, if the PDF has simple moving average as well as separately managed accounts in the same, you know, PDF, and I ask it to say, you know, Hey, what is the SME? So if it is a trading firm. They, for them, SMA is simple, moving average. That is how they operate, whereas, if it's some other same, macro based trading form for them, sma generally be a force to separately manage accounts or something. So unless and until this context is built in, like this reasoning is built in, inside the extraction engine, it is not going to, you know, pro correct numbers. Another example is equity and equities, you know, both of these stocks are similar, but then the entire difference is in finance. So you need to embed a reasoning layer inside the extraction engine that you are building. And, yeah, that is what we are trying to solve. We are and we are doing this by, you know, building vision language models, which are not just data extractors, but they also have a reasoning layer built inside it, which is domain specific. And that is why we are not saying that we are building extraction solution for horizontal extraction solution. That is why we are specific, because we know that it is going to be accurate only when it knows the context. And you can't feed the entire or the context of the you know, world into it. It has to be a certain domain. So, yeah, that is how it's different from any traditional, you know, extraction. That's
exactly, and that that is not a random error that it makes, that is very valid, because if you drill down their large language models, they are not made for mathematical, you know, comparisons and all of that. So specifically, in finance, the margin for error is almost negligible, like if they if suppose they're using an LLM based, you know, agent to evaluate a dB, and suppose that LLM extracted in the 100 and $11 billion from that PDF, instead of 11.11 the the verdict that it is going to throw that a we are going to exist in forward versus no, we are, you know, dropping it here. So that is going to be widely different, you know. So here the margin. And if you, if you try to see what impact falls at, I mean, no accuracy can have, especially on the hedge funds, it is even much more like in hedge funds, you are literally trading using machine, which I have built trading systems, you know. So I know there, if you don't have it, even if you have slight error over there, you won't even get an opportunity to identify that. In private equity firms, things much slow. You can always stop at it, but in hedge funds, machines are making trades, and if the machines are seeing accurate numbers, the trades that they are going to make is also going to be incorrect. And once you have placed a false trade, there is no way going back, you know, like it's just, you might have your stop loss in place, but if that is just going to wipe out the amount of capital that we have allocated for that trading strategy, so that is why, in finance, accuracy is of utmost importance, accuracy and reliability. So what do I mean by that, like, if things go wrong, they need to explain. I mean, it is their fiduciary responsibility to be able to explain why they did took that decision for that need. They need to bring that to the source of truth. Now, source of truth is generally the findings that you know this companies present, like the SSC findings that the companies find that is considered the source of truth. So they need to place that to where did they get this number and why they make the trading decision. So it needs to be accurate and it's to be it needs to come from a reliable source. So these two are the things that they index on. Now, coming to there are, there are a lot of data passing solutions, but here just the OCR based parsing or regex passing won't make a cut. First and foremost, they are not very accurate. They might be useful in scenarios where the the error margin can be, you know, it's slightly higher. Basically, the downsides are not as intense as you know, saying finance in those kind of setups, you can rely on a parser or any other solution here, you need to be more sophisticated. The other thing is that you can't. I mean, people see it as an extraction problem. They feel like you take your bunch of PDFs, you just need to extract numbers from it, right? And that is like you will find most of the solutions out there. They are horizontal, but people and they try to use it, okay? You can use it in healthcare, you can use it in finance, you can use it in E commerce. But having worked in financial firms and with financial data, we feel like it's not just an extraction problem. It's more of a extraction combined with a context problem. And by context I mean that your extraction engine needs to understand what it has been asked to extract in finance. You know, finances are very is very scattered, like, it's very disparate, you know, like, you have different kinds of equities, different kind of you know, it's very basically fragmented, you know. And for example, estimate can mean simple moving average or separately managed accounts based on the context, you know. So unless and until the extraction engine understands the context, it is not going to provide the correct number, like, for example, if the PDF has simple moving average as well as separately managed accounts in the same, you know, PDF, and I ask it to say, you know, Hey, what is the SME? So if it is a trading firm. They, for them, SMA is simple, moving average. That is how they operate, whereas, if it's some other same, macro based trading form for them, sma generally be a force to separately manage accounts or something. So unless and until this context is built in, like this reasoning is built in, inside the extraction engine, it is not going to, you know, pro correct numbers. Another example is equity and equities, you know, both of these stocks are similar, but then the entire difference is in finance. So you need to embed a reasoning layer inside the extraction engine that you are building. And, yeah, that is what we are trying to solve. We are and we are doing this by, you know, building vision language models, which are not just data extractors, but they also have a reasoning layer built inside it, which is domain specific. And that is why we are not saying that we are building extraction solution for horizontal extraction solution. That is why we are specific, because we know that it is going to be accurate only when it knows the context. And you can't feed the entire or the context of the you know, world into it. It has to be a certain domain. So, yeah, that is how it's different from any traditional, you know, extraction. That's
S Speaker 315:58why it performs only on drag benchmarks, like 10k like, there is a Uber 10k benchmark. So most of the comparators, they're, like, capped at 85% accuracy. So so like, they are all of them, right? And also one very critical differentiator is that all these competitors like unstructured reducto, they are OC like wrappers around OCI services, like they use test react, or they can use table transformers. So there are multiple such, like Azure is there? So they'll, they'll basically built a wrapper, adapted so and the OCRs, which are like very age old technologies, they it's kind of lossy as well as it's high latency, because they're using multiple services. And for like the clients or the design partners, which we have, for example, Barclays, so for them, like low latency is a very critical factor for them, especially when they are analyzing lot of documents during the trading sessions. So so there we differentiate with our proprietary BLMs. And BLMs has been around for like, around a year, and since we are very early into this and in the API space, like, if you have Early Edge, like, it will compound, because you engage with design partners, they give you edge cases, so you are already ahead of others. So yeah, timing is great. And you're like, we have a strong thesis around this. Yeah, that
why it performs only on drag benchmarks, like 10k like, there is a Uber 10k benchmark. So most of the comparators, they're, like, capped at 85% accuracy. So so like, they are all of them, right? And also one very critical differentiator is that all these competitors like unstructured reducto, they are OC like wrappers around OCI services, like they use test react, or they can use table transformers. So there are multiple such, like Azure is there? So they'll, they'll basically built a wrapper, adapted so and the OCRs, which are like very age old technologies, they it's kind of lossy as well as it's high latency, because they're using multiple services. And for like the clients or the design partners, which we have, for example, Barclays, so for them, like low latency is a very critical factor for them, especially when they are analyzing lot of documents during the trading sessions. So so there we differentiate with our proprietary BLMs. And BLMs has been around for like, around a year, and since we are very early into this and in the API space, like, if you have Early Edge, like, it will compound, because you engage with design partners, they give you edge cases, so you are already ahead of others. So yeah, timing is great. And you're like, we have a strong thesis around this. Yeah, that
why it performs only on drag benchmarks, like 10k like, there is a Uber 10k benchmark. So most of the comparators, they're, like, capped at 85% accuracy. So so like, they are all of them, right? And also one very critical differentiator is that all these competitors like unstructured reducto, they are OC like wrappers around OCI services, like they use test react, or they can use table transformers. So there are multiple such, like Azure is there? So they'll, they'll basically built a wrapper, adapted so and the OCRs, which are like very age old technologies, they it's kind of lossy as well as it's high latency, because they're using multiple services. And for like the clients or the design partners, which we have, for example, Barclays, so for them, like low latency is a very critical factor for them, especially when they are analyzing lot of documents during the trading sessions. So so there we differentiate with our proprietary BLMs. And BLMs has been around for like, around a year, and since we are very early into this and in the API space, like, if you have Early Edge, like, it will compound, because you engage with design partners, they give you edge cases, so you are already ahead of others. So yeah, timing is great. And you're like, we have a strong thesis around this. Yeah, that
why it performs only on drag benchmarks, like 10k like, there is a Uber 10k benchmark. So most of the comparators, they're, like, capped at 85% accuracy. So so like, they are all of them, right? And also one very critical differentiator is that all these competitors like unstructured reducto, they are OC like wrappers around OCI services, like they use test react, or they can use table transformers. So there are multiple such, like Azure is there? So they'll, they'll basically built a wrapper, adapted so and the OCRs, which are like very age old technologies, they it's kind of lossy as well as it's high latency, because they're using multiple services. And for like the clients or the design partners, which we have, for example, Barclays, so for them, like low latency is a very critical factor for them, especially when they are analyzing lot of documents during the trading sessions. So so there we differentiate with our proprietary BLMs. And BLMs has been around for like, around a year, and since we are very early into this and in the API space, like, if you have Early Edge, like, it will compound, because you engage with design partners, they give you edge cases, so you are already ahead of others. So yeah, timing is great. And you're like, we have a strong thesis around this. Yeah, that
18:17Yeah, so we, I mean,
S Speaker 218:22the architecture, I mean the solution that is unstructured or reductive, that they generally rely on OCR. Like they try to make OCR more accurate, they try to make OCR low latency. But you have to understand that it was starting from OCR as the base technology. Yeah, it is going to have a feeling, you know,
the architecture, I mean the solution that is unstructured or reductive, that they generally rely on OCR. Like they try to make OCR more accurate, they try to make OCR low latency. But you have to understand that it was starting from OCR as the base technology. Yeah, it is going to have a feeling, you know,
the architecture, I mean the solution that is unstructured or reductive, that they generally rely on OCR. Like they try to make OCR more accurate, they try to make OCR low latency. But you have to understand that it was starting from OCR as the base technology. Yeah, it is going to have a feeling, you know,
the architecture, I mean the solution that is unstructured or reductive, that they generally rely on OCR. Like they try to make OCR more accurate, they try to make OCR low latency. But you have to understand that it was starting from OCR as the base technology. Yeah, it is going to have a feeling, you know,
S Speaker 118:40yes, you wouldn't have the reasoning layer like you mentioned, yes, exactly,
yes, you wouldn't have the reasoning layer like you mentioned, yes, exactly,
yes, you wouldn't have the reasoning layer like you mentioned, yes, exactly,
yes, you wouldn't have the reasoning layer like you mentioned, yes, exactly,
S Speaker 218:44even we started with OCR, we tried to, you know, make it more accurate, more relevant. But then, I mean, has this understanding, like he was working on it from earlier as well, that it is going to have a feeling. So we just, in fact, we just open source that, like whatever we build, it was accurate, it was latency was also good, but we realized that this is not going to sustain in the long run. And then we started working on the BLM. We are not using any open source model. We started almost from scratch the further training data, advanced leverage. You know, we SSC filings. You know, they have SSC basically has all these company files available. Yes, we leverage training data or using that. And currently we also have RT, you know, so none, along with other, you know, other team members, you know, they are trying to just,
even we started with OCR, we tried to, you know, make it more accurate, more relevant. But then, I mean, has this understanding, like he was working on it from earlier as well, that it is going to have a feeling. So we just, in fact, we just open source that, like whatever we build, it was accurate, it was latency was also good, but we realized that this is not going to sustain in the long run. And then we started working on the BLM. We are not using any open source model. We started almost from scratch the further training data, advanced leverage. You know, we SSC filings. You know, they have SSC basically has all these company files available. Yes, we leverage training data or using that. And currently we also have RT, you know, so none, along with other, you know, other team members, you know, they are trying to just,
even we started with OCR, we tried to, you know, make it more accurate, more relevant. But then, I mean, has this understanding, like he was working on it from earlier as well, that it is going to have a feeling. So we just, in fact, we just open source that, like whatever we build, it was accurate, it was latency was also good, but we realized that this is not going to sustain in the long run. And then we started working on the BLM. We are not using any open source model. We started almost from scratch the further training data, advanced leverage. You know, we SSC filings. You know, they have SSC basically has all these company files available. Yes, we leverage training data or using that. And currently we also have RT, you know, so none, along with other, you know, other team members, you know, they are trying to just,
even we started with OCR, we tried to, you know, make it more accurate, more relevant. But then, I mean, has this understanding, like he was working on it from earlier as well, that it is going to have a feeling. So we just, in fact, we just open source that, like whatever we build, it was accurate, it was latency was also good, but we realized that this is not going to sustain in the long run. And then we started working on the BLM. We are not using any open source model. We started almost from scratch the further training data, advanced leverage. You know, we SSC filings. You know, they have SSC basically has all these company files available. Yes, we leverage training data or using that. And currently we also have RT, you know, so none, along with other, you know, other team members, you know, they are trying to just,
S Speaker 319:41and also we have innovation at the architecture level in the VLF. So basically, you might have heard about cold Bali or something. I have not, sorry, so it's, it's one of like a primitive experiment with vlms for document extraction. But what it like fails at is it can just give you page, page level retrieval So, but that that is not enough. We need to be able to retrieve blocks of information which is relevant to any query. So we have been able to achieve that block level retrieval using heat maps. So, like heat maps as a pre processing technique. So, so using heat maps, you are able to figure out and basically divide the whole page into segments and then pass it on to the VLM, and that's how it's able to do block level retrieval.
and also we have innovation at the architecture level in the VLF. So basically, you might have heard about cold Bali or something. I have not, sorry, so it's, it's one of like a primitive experiment with vlms for document extraction. But what it like fails at is it can just give you page, page level retrieval So, but that that is not enough. We need to be able to retrieve blocks of information which is relevant to any query. So we have been able to achieve that block level retrieval using heat maps. So, like heat maps as a pre processing technique. So, so using heat maps, you are able to figure out and basically divide the whole page into segments and then pass it on to the VLM, and that's how it's able to do block level retrieval.
and also we have innovation at the architecture level in the VLF. So basically, you might have heard about cold Bali or something. I have not, sorry, so it's, it's one of like a primitive experiment with vlms for document extraction. But what it like fails at is it can just give you page, page level retrieval So, but that that is not enough. We need to be able to retrieve blocks of information which is relevant to any query. So we have been able to achieve that block level retrieval using heat maps. So, like heat maps as a pre processing technique. So, so using heat maps, you are able to figure out and basically divide the whole page into segments and then pass it on to the VLM, and that's how it's able to do block level retrieval.
and also we have innovation at the architecture level in the VLF. So basically, you might have heard about cold Bali or something. I have not, sorry, so it's, it's one of like a primitive experiment with vlms for document extraction. But what it like fails at is it can just give you page, page level retrieval So, but that that is not enough. We need to be able to retrieve blocks of information which is relevant to any query. So we have been able to achieve that block level retrieval using heat maps. So, like heat maps as a pre processing technique. So, so using heat maps, you are able to figure out and basically divide the whole page into segments and then pass it on to the VLM, and that's how it's able to do block level retrieval.
S Speaker 320:58So basically, heat map has been a workaround the layout segmentation model. So initially, in OCR based solution, what happens is they use YOLO or something like that, to basically find out where the table is or the text is so but right now, because there is already a reasoning layer within the VLM, we don't need to like segment that all we need to do is figure out where the textual information is. So for that, heat maps are much faster compared to layout segmentation models. So we are using that as part of our pre processing like technique. So we pass it through the like function, and then it segments out the chunks of text from it, and then it creates embeddings of like a multimode embedding of each block. And then it does, like a similarity search between the block of information and the query. And that's how it's able to retrieve at the block.
So basically, heat map has been a workaround the layout segmentation model. So initially, in OCR based solution, what happens is they use YOLO or something like that, to basically find out where the table is or the text is so but right now, because there is already a reasoning layer within the VLM, we don't need to like segment that all we need to do is figure out where the textual information is. So for that, heat maps are much faster compared to layout segmentation models. So we are using that as part of our pre processing like technique. So we pass it through the like function, and then it segments out the chunks of text from it, and then it creates embeddings of like a multimode embedding of each block. And then it does, like a similarity search between the block of information and the query. And that's how it's able to retrieve at the block.
So basically, heat map has been a workaround the layout segmentation model. So initially, in OCR based solution, what happens is they use YOLO or something like that, to basically find out where the table is or the text is so but right now, because there is already a reasoning layer within the VLM, we don't need to like segment that all we need to do is figure out where the textual information is. So for that, heat maps are much faster compared to layout segmentation models. So we are using that as part of our pre processing like technique. So we pass it through the like function, and then it segments out the chunks of text from it, and then it creates embeddings of like a multimode embedding of each block. And then it does, like a similarity search between the block of information and the query. And that's how it's able to retrieve at the block.
So basically, heat map has been a workaround the layout segmentation model. So initially, in OCR based solution, what happens is they use YOLO or something like that, to basically find out where the table is or the text is so but right now, because there is already a reasoning layer within the VLM, we don't need to like segment that all we need to do is figure out where the textual information is. So for that, heat maps are much faster compared to layout segmentation models. So we are using that as part of our pre processing like technique. So we pass it through the like function, and then it segments out the chunks of text from it, and then it creates embeddings of like a multimode embedding of each block. And then it does, like a similarity search between the block of information and the query. And that's how it's able to retrieve at the block.
S Speaker 222:35Yeah. So currently, we are working with six design partners. Four of them are in us, one in Europe, one in India. Initially we started with India, but soon we realized that, you know, like for a technology like in us, restricted our attention. But since we were working with so there is this financial firm in India, yeah. So initially we were working with them. So we continue the engagement. Because, you know, like, there were a good design partners, like they were giving us feedbacks, and they were using it. So they from India. They are design partners in us. We are working with four pumps, one of which is Barclays. We are working with their ein Pons team. So Barclays, ein pawn team sits in New York, and they try to get AI technologies for all the business units of Barclays across the world. And we are working with them regarding benchmark. They asked us for a benchmarking because they were explaining evaluating other solutions, yes, construction. So at that time, we did the benchmarking, and I think we have the benchmarks we can send. Send a white paper around that to you, and yeah, so we are working with the same design partners, three of them. So for the past one month, we focused on building a production grade, like close to production grade model. What we shipped initially was more of like, so that they can play around with it, like we provided them limited credit, so that they can test and give us feedback. For the past one month, we are mostly focused on sort of product, you know, converting that into production grade. We have that already. I mean, I think last week this is strapped it up. So now, from those six design partners, we had really strong intent, and they will be converting to paid five minutes in the coming weeks. So this is the funnel right now. Since now, we are at a certain stage with the technology, like obviously working on it slowly. Now we are sort of looking to sort of increase the funnel further, specifically in us.
Yeah. So currently, we are working with six design partners. Four of them are in us, one in Europe, one in India. Initially we started with India, but soon we realized that, you know, like for a technology like in us, restricted our attention. But since we were working with so there is this financial firm in India, yeah. So initially we were working with them. So we continue the engagement. Because, you know, like, there were a good design partners, like they were giving us feedbacks, and they were using it. So they from India. They are design partners in us. We are working with four pumps, one of which is Barclays. We are working with their ein Pons team. So Barclays, ein pawn team sits in New York, and they try to get AI technologies for all the business units of Barclays across the world. And we are working with them regarding benchmark. They asked us for a benchmarking because they were explaining evaluating other solutions, yes, construction. So at that time, we did the benchmarking, and I think we have the benchmarks we can send. Send a white paper around that to you, and yeah, so we are working with the same design partners, three of them. So for the past one month, we focused on building a production grade, like close to production grade model. What we shipped initially was more of like, so that they can play around with it, like we provided them limited credit, so that they can test and give us feedback. For the past one month, we are mostly focused on sort of product, you know, converting that into production grade. We have that already. I mean, I think last week this is strapped it up. So now, from those six design partners, we had really strong intent, and they will be converting to paid five minutes in the coming weeks. So this is the funnel right now. Since now, we are at a certain stage with the technology, like obviously working on it slowly. Now we are sort of looking to sort of increase the funnel further, specifically in us.
Yeah. So currently, we are working with six design partners. Four of them are in us, one in Europe, one in India. Initially we started with India, but soon we realized that, you know, like for a technology like in us, restricted our attention. But since we were working with so there is this financial firm in India, yeah. So initially we were working with them. So we continue the engagement. Because, you know, like, there were a good design partners, like they were giving us feedbacks, and they were using it. So they from India. They are design partners in us. We are working with four pumps, one of which is Barclays. We are working with their ein Pons team. So Barclays, ein pawn team sits in New York, and they try to get AI technologies for all the business units of Barclays across the world. And we are working with them regarding benchmark. They asked us for a benchmarking because they were explaining evaluating other solutions, yes, construction. So at that time, we did the benchmarking, and I think we have the benchmarks we can send. Send a white paper around that to you, and yeah, so we are working with the same design partners, three of them. So for the past one month, we focused on building a production grade, like close to production grade model. What we shipped initially was more of like, so that they can play around with it, like we provided them limited credit, so that they can test and give us feedback. For the past one month, we are mostly focused on sort of product, you know, converting that into production grade. We have that already. I mean, I think last week this is strapped it up. So now, from those six design partners, we had really strong intent, and they will be converting to paid five minutes in the coming weeks. So this is the funnel right now. Since now, we are at a certain stage with the technology, like obviously working on it slowly. Now we are sort of looking to sort of increase the funnel further, specifically in us.
Yeah. So currently, we are working with six design partners. Four of them are in us, one in Europe, one in India. Initially we started with India, but soon we realized that, you know, like for a technology like in us, restricted our attention. But since we were working with so there is this financial firm in India, yeah. So initially we were working with them. So we continue the engagement. Because, you know, like, there were a good design partners, like they were giving us feedbacks, and they were using it. So they from India. They are design partners in us. We are working with four pumps, one of which is Barclays. We are working with their ein Pons team. So Barclays, ein pawn team sits in New York, and they try to get AI technologies for all the business units of Barclays across the world. And we are working with them regarding benchmark. They asked us for a benchmarking because they were explaining evaluating other solutions, yes, construction. So at that time, we did the benchmarking, and I think we have the benchmarks we can send. Send a white paper around that to you, and yeah, so we are working with the same design partners, three of them. So for the past one month, we focused on building a production grade, like close to production grade model. What we shipped initially was more of like, so that they can play around with it, like we provided them limited credit, so that they can test and give us feedback. For the past one month, we are mostly focused on sort of product, you know, converting that into production grade. We have that already. I mean, I think last week this is strapped it up. So now, from those six design partners, we had really strong intent, and they will be converting to paid five minutes in the coming weeks. So this is the funnel right now. Since now, we are at a certain stage with the technology, like obviously working on it slowly. Now we are sort of looking to sort of increase the funnel further, specifically in us.
S Speaker 124:47That makes sense, guys, have you? Have you registered the company in us? Yes,
That makes sense, guys, have you? Have you registered the company in us? Yes,
That makes sense, guys, have you? Have you registered the company in us? Yes,
That makes sense, guys, have you? Have you registered the company in us? Yes,
24:51and a private limited
and a private limited
and a private limited
and a private limited
24:53in India as well.
S Speaker 124:55Okay, and so the parent company? Is that in us or Okay, perfect, perfect. That sounds interesting. Guys. How much have you raised so far? And do you plan to raise anytime soon?
Okay, and so the parent company? Is that in us or Okay, perfect, perfect. That sounds interesting. Guys. How much have you raised so far? And do you plan to raise anytime soon?
Okay, and so the parent company? Is that in us or Okay, perfect, perfect. That sounds interesting. Guys. How much have you raised so far? And do you plan to raise anytime soon?
Okay, and so the parent company? Is that in us or Okay, perfect, perfect. That sounds interesting. Guys. How much have you raised so far? And do you plan to raise anytime soon?
S Speaker 225:18raised $50,000 from year entrepreneur first, we are moving to SF for the next two to three months. We are just going to, you know, do more customer discovery us. And then we intend to raise starting. We intend to start our, you know, seed raise model from April or, you know, middle so EF has a demo day. So we will be giving that demo day, and that is when we are intending to kick start our fundraise. And the next two, three months will give us the opportunity to just whatever we have built to take the more customers, and then we intend to start the fundraising.
raised $50,000 from year entrepreneur first, we are moving to SF for the next two to three months. We are just going to, you know, do more customer discovery us. And then we intend to raise starting. We intend to start our, you know, seed raise model from April or, you know, middle so EF has a demo day. So we will be giving that demo day, and that is when we are intending to kick start our fundraise. And the next two, three months will give us the opportunity to just whatever we have built to take the more customers, and then we intend to start the fundraising.
raised $50,000 from year entrepreneur first, we are moving to SF for the next two to three months. We are just going to, you know, do more customer discovery us. And then we intend to raise starting. We intend to start our, you know, seed raise model from April or, you know, middle so EF has a demo day. So we will be giving that demo day, and that is when we are intending to kick start our fundraise. And the next two, three months will give us the opportunity to just whatever we have built to take the more customers, and then we intend to start the fundraising.
raised $50,000 from year entrepreneur first, we are moving to SF for the next two to three months. We are just going to, you know, do more customer discovery us. And then we intend to raise starting. We intend to start our, you know, seed raise model from April or, you know, middle so EF has a demo day. So we will be giving that demo day, and that is when we are intending to kick start our fundraise. And the next two, three months will give us the opportunity to just whatever we have built to take the more customers, and then we intend to start the fundraising.
S Speaker 126:00Very interesting. One question coming back, I just thought of it. So from the design partners, what is the intent that you're getting? Is is accuracy really the differentiating factor here? Or is it the latency, the quick latency that you guys offer? Is that really working for them?
Very interesting. One question coming back, I just thought of it. So from the design partners, what is the intent that you're getting? Is is accuracy really the differentiating factor here? Or is it the latency, the quick latency that you guys offer? Is that really working for them?
Very interesting. One question coming back, I just thought of it. So from the design partners, what is the intent that you're getting? Is is accuracy really the differentiating factor here? Or is it the latency, the quick latency that you guys offer? Is that really working for them?
Very interesting. One question coming back, I just thought of it. So from the design partners, what is the intent that you're getting? Is is accuracy really the differentiating factor here? Or is it the latency, the quick latency that you guys offer? Is that really working for them?
S Speaker 126:54because how dynamic is the data that you're analyzing? Like does? Does the data? Do they only look at SEC filings which is once a quarter at best? Or do they look at something which is very dynamically changing, and you have to sort of pass that data every now and then?
because how dynamic is the data that you're analyzing? Like does? Does the data? Do they only look at SEC filings which is once a quarter at best? Or do they look at something which is very dynamically changing, and you have to sort of pass that data every now and then?
because how dynamic is the data that you're analyzing? Like does? Does the data? Do they only look at SEC filings which is once a quarter at best? Or do they look at something which is very dynamically changing, and you have to sort of pass that data every now and then?
because how dynamic is the data that you're analyzing? Like does? Does the data? Do they only look at SEC filings which is once a quarter at best? Or do they look at something which is very dynamically changing, and you have to sort of pass that data every now and then?
S Speaker 227:13Yes. So not just in SSC filings. They look through quarterly or annual reports. Apart from that, they look through any sort of data regarding the firm, out really, any material, organic data that is regarding the firm that is out there in the public, whether it's coming from news outlets or whether it's coming from whatever you the whatever the request the company is publishing, or any sell side report meaning that is publishing regarding that company. They look through all of these while trying to make a trading decision. So it's very dynamic data. Also,
Yes. So not just in SSC filings. They look through quarterly or annual reports. Apart from that, they look through any sort of data regarding the firm, out really, any material, organic data that is regarding the firm that is out there in the public, whether it's coming from news outlets or whether it's coming from whatever you the whatever the request the company is publishing, or any sell side report meaning that is publishing regarding that company. They look through all of these while trying to make a trading decision. So it's very dynamic data. Also,
Yes. So not just in SSC filings. They look through quarterly or annual reports. Apart from that, they look through any sort of data regarding the firm, out really, any material, organic data that is regarding the firm that is out there in the public, whether it's coming from news outlets or whether it's coming from whatever you the whatever the request the company is publishing, or any sell side report meaning that is publishing regarding that company. They look through all of these while trying to make a trading decision. So it's very dynamic data. Also,
Yes. So not just in SSC filings. They look through quarterly or annual reports. Apart from that, they look through any sort of data regarding the firm, out really, any material, organic data that is regarding the firm that is out there in the public, whether it's coming from news outlets or whether it's coming from whatever you the whatever the request the company is publishing, or any sell side report meaning that is publishing regarding that company. They look through all of these while trying to make a trading decision. So it's very dynamic data. Also,
27:51they have internal data which is quite dynamic,
they have internal data which is quite dynamic,
they have internal data which is quite dynamic,
they have internal data which is quite dynamic,
27:55yes, so they keep collecting their own data as well.
yes, so they keep collecting their own data as well.
yes, so they keep collecting their own data as well.
yes, so they keep collecting their own data as well.
27:58Got it regarding,
S Speaker 128:01yeah, that makes sense. And for some of these design partners, your job ends from collecting data from their unstructured data sources. Or do you are also sort of planning to build insights layer on top of that, of on top of the data that you collect extract?
yeah, that makes sense. And for some of these design partners, your job ends from collecting data from their unstructured data sources. Or do you are also sort of planning to build insights layer on top of that, of on top of the data that you collect extract?
yeah, that makes sense. And for some of these design partners, your job ends from collecting data from their unstructured data sources. Or do you are also sort of planning to build insights layer on top of that, of on top of the data that you collect extract?
yeah, that makes sense. And for some of these design partners, your job ends from collecting data from their unstructured data sources. Or do you are also sort of planning to build insights layer on top of that, of on top of the data that you collect extract?
S Speaker 228:20Yeah, so in the initiative, like in the first phase, we are just focusing on accurate extraction, like enabling accurate extraction, yeah? But as soon as, as soon as we are able to nail this, this is also giving us a put into the door, you know, like, yeah, using this door at Barclays at piramal and similarly, at other code forms. Once we have nailed this, the obvious next step would be to get into the reasoning layer, basically the workflows like we can start pitching them something like, you know, reasoning on top of the data that they have extracted, maybe a workflow for them. So that is the obvious next step. But before reaching there, we want to sort of name this first, like the extraction part, and from pitching perspective, like it's easier for them to adopt as well, because they it's just a small part of their already payment workflows. So we are not disrupting too many things we are just putting in at one place, so that makes it easier for them to also and once we have made that, then we will just tell the next five to the next player.
Yeah, so in the initiative, like in the first phase, we are just focusing on accurate extraction, like enabling accurate extraction, yeah? But as soon as, as soon as we are able to nail this, this is also giving us a put into the door, you know, like, yeah, using this door at Barclays at piramal and similarly, at other code forms. Once we have nailed this, the obvious next step would be to get into the reasoning layer, basically the workflows like we can start pitching them something like, you know, reasoning on top of the data that they have extracted, maybe a workflow for them. So that is the obvious next step. But before reaching there, we want to sort of name this first, like the extraction part, and from pitching perspective, like it's easier for them to adopt as well, because they it's just a small part of their already payment workflows. So we are not disrupting too many things we are just putting in at one place, so that makes it easier for them to also and once we have made that, then we will just tell the next five to the next player.
Yeah, so in the initiative, like in the first phase, we are just focusing on accurate extraction, like enabling accurate extraction, yeah? But as soon as, as soon as we are able to nail this, this is also giving us a put into the door, you know, like, yeah, using this door at Barclays at piramal and similarly, at other code forms. Once we have nailed this, the obvious next step would be to get into the reasoning layer, basically the workflows like we can start pitching them something like, you know, reasoning on top of the data that they have extracted, maybe a workflow for them. So that is the obvious next step. But before reaching there, we want to sort of name this first, like the extraction part, and from pitching perspective, like it's easier for them to adopt as well, because they it's just a small part of their already payment workflows. So we are not disrupting too many things we are just putting in at one place, so that makes it easier for them to also and once we have made that, then we will just tell the next five to the next player.
Yeah, so in the initiative, like in the first phase, we are just focusing on accurate extraction, like enabling accurate extraction, yeah? But as soon as, as soon as we are able to nail this, this is also giving us a put into the door, you know, like, yeah, using this door at Barclays at piramal and similarly, at other code forms. Once we have nailed this, the obvious next step would be to get into the reasoning layer, basically the workflows like we can start pitching them something like, you know, reasoning on top of the data that they have extracted, maybe a workflow for them. So that is the obvious next step. But before reaching there, we want to sort of name this first, like the extraction part, and from pitching perspective, like it's easier for them to adopt as well, because they it's just a small part of their already payment workflows. So we are not disrupting too many things we are just putting in at one place, so that makes it easier for them to also and once we have made that, then we will just tell the next five to the next player.
S Speaker 230:19Yeah, sure. Would love to, I think at will be there in a week or something, so he can definitely catch up. And, yeah, so we don't have a formal cristae, like, the kind of, you know, but we have, you know, like, because we have too many, many people itself. So we just prepared something, yeah, I will turn that over to you, along with some white papers and some technical details so that we can have a photo, you know, understand
Yeah, sure. Would love to, I think at will be there in a week or something, so he can definitely catch up. And, yeah, so we don't have a formal cristae, like, the kind of, you know, but we have, you know, like, because we have too many, many people itself. So we just prepared something, yeah, I will turn that over to you, along with some white papers and some technical details so that we can have a photo, you know, understand
Yeah, sure. Would love to, I think at will be there in a week or something, so he can definitely catch up. And, yeah, so we don't have a formal cristae, like, the kind of, you know, but we have, you know, like, because we have too many, many people itself. So we just prepared something, yeah, I will turn that over to you, along with some white papers and some technical details so that we can have a photo, you know, understand
Yeah, sure. Would love to, I think at will be there in a week or something, so he can definitely catch up. And, yeah, so we don't have a formal cristae, like, the kind of, you know, but we have, you know, like, because we have too many, many people itself. So we just prepared something, yeah, I will turn that over to you, along with some white papers and some technical details so that we can have a photo, you know, understand
S Speaker 231:01definitely need, you know, like, people who can, sort of, you know, provide us more intros or something like that. So, yeah, we'll definitely reach out, for
definitely need, you know, like, people who can, sort of, you know, provide us more intros or something like that. So, yeah, we'll definitely reach out, for
definitely need, you know, like, people who can, sort of, you know, provide us more intros or something like that. So, yeah, we'll definitely reach out, for
definitely need, you know, like, people who can, sort of, you know, provide us more intros or something like that. So, yeah, we'll definitely reach out, for
S Speaker 131:10sure, guys, this is, this is very interesting. Like, you guys graduated from IIT last year, and you're going on an ambitious project that's amazing. I I didn't mention this. I am a graduate from IIT Madras and I graduated in 2018 so it's been I moved to the US probably three years from now, but always great to meet more IIT founders, once
sure, guys, this is, this is very interesting. Like, you guys graduated from IIT last year, and you're going on an ambitious project that's amazing. I I didn't mention this. I am a graduate from IIT Madras and I graduated in 2018 so it's been I moved to the US probably three years from now, but always great to meet more IIT founders, once
sure, guys, this is, this is very interesting. Like, you guys graduated from IIT last year, and you're going on an ambitious project that's amazing. I I didn't mention this. I am a graduate from IIT Madras and I graduated in 2018 so it's been I moved to the US probably three years from now, but always great to meet more IIT founders, once
sure, guys, this is, this is very interesting. Like, you guys graduated from IIT last year, and you're going on an ambitious project that's amazing. I I didn't mention this. I am a graduate from IIT Madras and I graduated in 2018 so it's been I moved to the US probably three years from now, but always great to meet more IIT founders, once
31:35we are there for sure. Guys, thanks a lot for your time.
we are there for sure. Guys, thanks a lot for your time.
we are there for sure. Guys, thanks a lot for your time.
we are there for sure. Guys, thanks a lot for your time.
31:41Likewise, yeah, I'll see you again bye guys.
Likewise, yeah, I'll see you again bye guys.
Likewise, yeah, I'll see you again bye guys.
Likewise, yeah, I'll see you again bye guys.