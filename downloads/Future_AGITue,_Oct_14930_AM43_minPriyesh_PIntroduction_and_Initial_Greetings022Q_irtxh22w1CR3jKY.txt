Meeting: Future AGI
Tue, Oct 14
9:30 AM
43 min
Priyesh P
Introduction and Initial Greetings
0:22
Qualcomm Ven
URL: https://otter.ai/u/irtxh22w1CR3jKY-6TJzFNQWdOw
Downloaded: 2025-12-21T20:05:09.997543
Method: text_extraction
============================================================

0:22Allah, Oh, Thank I I So I Hello, hi, hello,
Allah, Oh, Thank I I So I Hello, hi, hello,
Allah, Oh, Thank I I So I Hello, hi, hello,
Allah, Oh, Thank I I So I Hello, hi, hello,
5:43hey, hi, Charu, can you hear
hey, hi, Charu, can you hear
hey, hi, Charu, can you hear
hey, hi, Charu, can you hear
5:46me? Yes, Priyesh,
5:50think my previous call got extended. And no worries, I'm
think my previous call got extended. And no worries, I'm
think my previous call got extended. And no worries, I'm
think my previous call got extended. And no worries, I'm
S Speaker 15:54so sorry about this. No worries, no worries. I understand that always happens. So totally fine.
so sorry about this. No worries, no worries. I understand that always happens. So totally fine.
so sorry about this. No worries, no worries. I understand that always happens. So totally fine.
so sorry about this. No worries, no worries. I understand that always happens. So totally fine.
6:00Thank you so much. How have
Thank you so much. How have
Thank you so much. How have
Thank you so much. How have
S Speaker 16:02things been? Charu, I remember we bumped into each other at an event probably a year back, and then you have raised a seed. I see on the website. It seems like you have pivoted slightly. Would so would love to understand how have things been?
things been? Charu, I remember we bumped into each other at an event probably a year back, and then you have raised a seed. I see on the website. It seems like you have pivoted slightly. Would so would love to understand how have things been?
things been? Charu, I remember we bumped into each other at an event probably a year back, and then you have raised a seed. I see on the website. It seems like you have pivoted slightly. Would so would love to understand how have things been?
things been? Charu, I remember we bumped into each other at an event probably a year back, and then you have raised a seed. I see on the website. It seems like you have pivoted slightly. Would so would love to understand how have things been?
S Speaker 26:19Oh, it's their great page. Obviously, we did end up raising our
Oh, it's their great page. Obviously, we did end up raising our
Oh, it's their great page. Obviously, we did end up raising our
Oh, it's their great page. Obviously, we did end up raising our
6:28priyeshed around 1.6 million
priyeshed around 1.6 million
priyeshed around 1.6 million
priyeshed around 1.6 million
S Speaker 26:29from powerhouse ventures, and it's no leper ventures, a couple of angels. And then we built the product. We set up the team development center in India, commercialized earlier this year. Now we have three enterprise customers and couple of in fact, 10 more pilots, enterprise pilots that are starting and getting initiated with annual contractor structure.
from powerhouse ventures, and it's no leper ventures, a couple of angels. And then we built the product. We set up the team development center in India, commercialized earlier this year. Now we have three enterprise customers and couple of in fact, 10 more pilots, enterprise pilots that are starting and getting initiated with annual contractor structure.
from powerhouse ventures, and it's no leper ventures, a couple of angels. And then we built the product. We set up the team development center in India, commercialized earlier this year. Now we have three enterprise customers and couple of in fact, 10 more pilots, enterprise pilots that are starting and getting initiated with annual contractor structure.
from powerhouse ventures, and it's no leper ventures, a couple of angels. And then we built the product. We set up the team development center in India, commercialized earlier this year. Now we have three enterprise customers and couple of in fact, 10 more pilots, enterprise pilots that are starting and getting initiated with annual contractor structure.
S Speaker 27:47Sure, sure page. But I wanted to understand just Qualcomm ventures, invested series stage. What is your thesis in AI tooling? Already have you invested in any AI companies? What is happening?
Sure, sure page. But I wanted to understand just Qualcomm ventures, invested series stage. What is your thesis in AI tooling? Already have you invested in any AI companies? What is happening?
Sure, sure page. But I wanted to understand just Qualcomm ventures, invested series stage. What is your thesis in AI tooling? Already have you invested in any AI companies? What is happening?
Sure, sure page. But I wanted to understand just Qualcomm ventures, invested series stage. What is your thesis in AI tooling? Already have you invested in any AI companies? What is happening?
S Speaker 210:44Oh, great. Understood, if you have invested in weights and biases, then you would know the AI tooling space pretty
Oh, great. Understood, if you have invested in weights and biases, then you would know the AI tooling space pretty
Oh, great. Understood, if you have invested in weights and biases, then you would know the AI tooling space pretty
Oh, great. Understood, if you have invested in weights and biases, then you would know the AI tooling space pretty
S Speaker 110:51well. Yeah, it wasn't like, I would say, a very big exit for us, but it was a good investment. We got to see the entire space evolve through that they have also sort of expanded quite a lot on their product offering since we invested. So, yes, yes.
well. Yeah, it wasn't like, I would say, a very big exit for us, but it was a good investment. We got to see the entire space evolve through that they have also sort of expanded quite a lot on their product offering since we invested. So, yes, yes.
well. Yeah, it wasn't like, I would say, a very big exit for us, but it was a good investment. We got to see the entire space evolve through that they have also sort of expanded quite a lot on their product offering since we invested. So, yes, yes.
well. Yeah, it wasn't like, I would say, a very big exit for us, but it was a good investment. We got to see the entire space evolve through that they have also sort of expanded quite a lot on their product offering since we invested. So, yes, yes.
S Speaker 211:06Understood, understood. So you do stage investments like which are a little pre revenue, or even very little revenue just POCs going on, yes.
Understood, understood. So you do stage investments like which are a little pre revenue, or even very little revenue just POCs going on, yes.
Understood, understood. So you do stage investments like which are a little pre revenue, or even very little revenue just POCs going on, yes.
Understood, understood. So you do stage investments like which are a little pre revenue, or even very little revenue just POCs going on, yes.
S Speaker 111:18So we have done that selectively. Charu, I wouldn't say, like, that's not a sweet spot. A sweet spot would be series A with a check size of, say, five to $7 million but, but we have done seeds, especially in, say, very highly technical teams building a very differentiated product. So in that case, yes, we have done seeds as well
So we have done that selectively. Charu, I wouldn't say, like, that's not a sweet spot. A sweet spot would be series A with a check size of, say, five to $7 million but, but we have done seeds, especially in, say, very highly technical teams building a very differentiated product. So in that case, yes, we have done seeds as well
So we have done that selectively. Charu, I wouldn't say, like, that's not a sweet spot. A sweet spot would be series A with a check size of, say, five to $7 million but, but we have done seeds, especially in, say, very highly technical teams building a very differentiated product. So in that case, yes, we have done seeds as well
So we have done that selectively. Charu, I wouldn't say, like, that's not a sweet spot. A sweet spot would be series A with a check size of, say, five to $7 million but, but we have done seeds, especially in, say, very highly technical teams building a very differentiated product. So in that case, yes, we have done seeds as well
S Speaker 211:44got there, and if I may ask, what's your background? Is it like more technical or
got there, and if I may ask, what's your background? Is it like more technical or
got there, and if I may ask, what's your background? Is it like more technical or
got there, and if I may ask, what's your background? Is it like more technical or
S Speaker 111:48I am? I'm not as technical, but I am investing in tech, in highly technical, deep tech companies. Recently, I am originally from India. I did my undergrad there. I graduated from IIT Madras in 2018 and then work with early stage startups in India, pivoted to us. I've been about I came to us four years back, and I've been involved in venture for the last three years, one and a half years at Qualcomm ventures, did six investments. So that was a great experience, I would say, all in AI. So I'm particularly focused on AI infra and applications. And then prior to that, had spent some time with Menlo Ventures and some time with Morpheus ventures in LA
I am? I'm not as technical, but I am investing in tech, in highly technical, deep tech companies. Recently, I am originally from India. I did my undergrad there. I graduated from IIT Madras in 2018 and then work with early stage startups in India, pivoted to us. I've been about I came to us four years back, and I've been involved in venture for the last three years, one and a half years at Qualcomm ventures, did six investments. So that was a great experience, I would say, all in AI. So I'm particularly focused on AI infra and applications. And then prior to that, had spent some time with Menlo Ventures and some time with Morpheus ventures in LA
I am? I'm not as technical, but I am investing in tech, in highly technical, deep tech companies. Recently, I am originally from India. I did my undergrad there. I graduated from IIT Madras in 2018 and then work with early stage startups in India, pivoted to us. I've been about I came to us four years back, and I've been involved in venture for the last three years, one and a half years at Qualcomm ventures, did six investments. So that was a great experience, I would say, all in AI. So I'm particularly focused on AI infra and applications. And then prior to that, had spent some time with Menlo Ventures and some time with Morpheus ventures in LA
I am? I'm not as technical, but I am investing in tech, in highly technical, deep tech companies. Recently, I am originally from India. I did my undergrad there. I graduated from IIT Madras in 2018 and then work with early stage startups in India, pivoted to us. I've been about I came to us four years back, and I've been involved in venture for the last three years, one and a half years at Qualcomm ventures, did six investments. So that was a great experience, I would say, all in AI. So I'm particularly focused on AI infra and applications. And then prior to that, had spent some time with Menlo Ventures and some time with Morpheus ventures in LA
12:29understood that's amazing.
understood that's amazing.
understood that's amazing.
understood that's amazing.
12:33Star studied, resume,
Star studied, resume,
Star studied, resume,
Star studied, resume,
S Speaker 112:34no, it's, I would say, just the right timing for things. I got into the mix when things were just starting to boil. So the just the right timing, definitely.
no, it's, I would say, just the right timing for things. I got into the mix when things were just starting to boil. So the just the right timing, definitely.
no, it's, I would say, just the right timing for things. I got into the mix when things were just starting to boil. So the just the right timing, definitely.
no, it's, I would say, just the right timing for things. I got into the mix when things were just starting to boil. So the just the right timing, definitely.
S Speaker 212:46Thank you so much, Priyesh for answering my questions
Thank you so much, Priyesh for answering my questions
Thank you so much, Priyesh for answering my questions
Thank you so much, Priyesh for answering my questions
12:49Absolutely yes. Let
S Speaker 212:52me introduce myself and my tech co founder, Nikhil, I think he could not join. There
me introduce myself and my tech co founder, Nikhil, I think he could not join. There
me introduce myself and my tech co founder, Nikhil, I think he could not join. There
me introduce myself and my tech co founder, Nikhil, I think he could not join. There
12:57was some client firefighting going on, and
was some client firefighting going on, and
was some client firefighting going on, and
was some client firefighting going on, and
13:33where is it? Yes, yeah.
where is it? Yes, yeah.
where is it? Yes, yeah.
where is it? Yes, yeah.
S Speaker 213:3716 years experience person like nit Bhopal, and then IIM Lucknow did engineering for some time, then jumped into the category building goals, Bank of America, and then startups. I was very early employee for healthcart and big prostate in their first year. So work very closely with their founders, and
16 years experience person like nit Bhopal, and then IIM Lucknow did engineering for some time, then jumped into the category building goals, Bank of America, and then startups. I was very early employee for healthcart and big prostate in their first year. So work very closely with their founders, and
16 years experience person like nit Bhopal, and then IIM Lucknow did engineering for some time, then jumped into the category building goals, Bank of America, and then startups. I was very early employee for healthcart and big prostate in their first year. So work very closely with their founders, and
16 years experience person like nit Bhopal, and then IIM Lucknow did engineering for some time, then jumped into the category building goals, Bank of America, and then startups. I was very early employee for healthcart and big prostate in their first year. So work very closely with their founders, and
14:01they both got acquired by Tata, and
they both got acquired by Tata, and
they both got acquired by Tata, and
they both got acquired by Tata, and
S Speaker 214:05they're doing pretty well, quite successful. Then I was the first employee of metlife.com it's an E pharmacy, and as its business head, I grew from zero 200 million revenue in three years. So pretty intense growth. And after that couple of more zero to ones, 10s and more recently, I was with by juice, which is an edtech. They were acquiring a lot of companies across the global us here and there, I was leading their global strategy for acquisition and their founders office and set up their complete product research and customer inciting engine in house with a team of 50 across the globe, across geographies, to ensure that they are building products which are in line with the customer expectations, and we are doing the right thing.
they're doing pretty well, quite successful. Then I was the first employee of metlife.com it's an E pharmacy, and as its business head, I grew from zero 200 million revenue in three years. So pretty intense growth. And after that couple of more zero to ones, 10s and more recently, I was with by juice, which is an edtech. They were acquiring a lot of companies across the global us here and there, I was leading their global strategy for acquisition and their founders office and set up their complete product research and customer inciting engine in house with a team of 50 across the globe, across geographies, to ensure that they are building products which are in line with the customer expectations, and we are doing the right thing.
they're doing pretty well, quite successful. Then I was the first employee of metlife.com it's an E pharmacy, and as its business head, I grew from zero 200 million revenue in three years. So pretty intense growth. And after that couple of more zero to ones, 10s and more recently, I was with by juice, which is an edtech. They were acquiring a lot of companies across the global us here and there, I was leading their global strategy for acquisition and their founders office and set up their complete product research and customer inciting engine in house with a team of 50 across the globe, across geographies, to ensure that they are building products which are in line with the customer expectations, and we are doing the right thing.
they're doing pretty well, quite successful. Then I was the first employee of metlife.com it's an E pharmacy, and as its business head, I grew from zero 200 million revenue in three years. So pretty intense growth. And after that couple of more zero to ones, 10s and more recently, I was with by juice, which is an edtech. They were acquiring a lot of companies across the global us here and there, I was leading their global strategy for acquisition and their founders office and set up their complete product research and customer inciting engine in house with a team of 50 across the globe, across geographies, to ensure that they are building products which are in line with the customer expectations, and we are doing the right thing.
15:01So I met Nikhil five years back
So I met Nikhil five years back
So I met Nikhil five years back
So I met Nikhil five years back
15:05and started Priyesh agi
and started Priyesh agi
and started Priyesh agi
and started Priyesh agi
S Speaker 118:44That's, that's amazing, Charu, and congrats on all the success so far. It's, it's been like a very short journey, but you guys have had a lot of milestones already. I'd love to understand how the product looks like. What are say? What's the tip of the spare use case that enterprises are adopting today. How do some of these enterprises that you are already supplying to? What are the use cases for them, and how are they using it? Yeah, definitely.
That's, that's amazing, Charu, and congrats on all the success so far. It's, it's been like a very short journey, but you guys have had a lot of milestones already. I'd love to understand how the product looks like. What are say? What's the tip of the spare use case that enterprises are adopting today. How do some of these enterprises that you are already supplying to? What are the use cases for them, and how are they using it? Yeah, definitely.
That's, that's amazing, Charu, and congrats on all the success so far. It's, it's been like a very short journey, but you guys have had a lot of milestones already. I'd love to understand how the product looks like. What are say? What's the tip of the spare use case that enterprises are adopting today. How do some of these enterprises that you are already supplying to? What are the use cases for them, and how are they using it? Yeah, definitely.
That's, that's amazing, Charu, and congrats on all the success so far. It's, it's been like a very short journey, but you guys have had a lot of milestones already. I'd love to understand how the product looks like. What are say? What's the tip of the spare use case that enterprises are adopting today. How do some of these enterprises that you are already supplying to? What are the use cases for them, and how are they using it? Yeah, definitely.
19:21You can see my screen, yes.
You can see my screen, yes.
You can see my screen, yes.
You can see my screen, yes.
S Speaker 219:24Okay, so this part you already know, the big elements don't solve the enterprise use cases unless they are hyper customized.
Okay, so this part you already know, the big elements don't solve the enterprise use cases unless they are hyper customized.
Okay, so this part you already know, the big elements don't solve the enterprise use cases unless they are hyper customized.
Okay, so this part you already know, the big elements don't solve the enterprise use cases unless they are hyper customized.
S Speaker 219:37famous MIT report that says 95% enterprise are failing, yes, and when we talk to enterprises, we realize what is going wrong? Their AI development is totally messed up. Even the big ones, they are monitoring blankly, just system metrics, not the actual qualitative metrics, and that is why it's a business disaster. And the 5% enterprises, what they are doing right is they are customizing the big llms or AIs to their use case, and iterating very fast and giving it the full context context in memory, are the new buzzwords that have come after this report. And the reason is the big LLM does not have the context of the smaller enterprise use case. That is what we are solving. So going from left side to right side, from agent development to getting the business value out of it, so many intermittent steps have to be solved. They are non negotiable. You have to solve infra. You have to evaluate you have to
famous MIT report that says 95% enterprise are failing, yes, and when we talk to enterprises, we realize what is going wrong? Their AI development is totally messed up. Even the big ones, they are monitoring blankly, just system metrics, not the actual qualitative metrics, and that is why it's a business disaster. And the 5% enterprises, what they are doing right is they are customizing the big llms or AIs to their use case, and iterating very fast and giving it the full context context in memory, are the new buzzwords that have come after this report. And the reason is the big LLM does not have the context of the smaller enterprise use case. That is what we are solving. So going from left side to right side, from agent development to getting the business value out of it, so many intermittent steps have to be solved. They are non negotiable. You have to solve infra. You have to evaluate you have to
famous MIT report that says 95% enterprise are failing, yes, and when we talk to enterprises, we realize what is going wrong? Their AI development is totally messed up. Even the big ones, they are monitoring blankly, just system metrics, not the actual qualitative metrics, and that is why it's a business disaster. And the 5% enterprises, what they are doing right is they are customizing the big llms or AIs to their use case, and iterating very fast and giving it the full context context in memory, are the new buzzwords that have come after this report. And the reason is the big LLM does not have the context of the smaller enterprise use case. That is what we are solving. So going from left side to right side, from agent development to getting the business value out of it, so many intermittent steps have to be solved. They are non negotiable. You have to solve infra. You have to evaluate you have to
famous MIT report that says 95% enterprise are failing, yes, and when we talk to enterprises, we realize what is going wrong? Their AI development is totally messed up. Even the big ones, they are monitoring blankly, just system metrics, not the actual qualitative metrics, and that is why it's a business disaster. And the 5% enterprises, what they are doing right is they are customizing the big llms or AIs to their use case, and iterating very fast and giving it the full context context in memory, are the new buzzwords that have come after this report. And the reason is the big LLM does not have the context of the smaller enterprise use case. That is what we are solving. So going from left side to right side, from agent development to getting the business value out of it, so many intermittent steps have to be solved. They are non negotiable. You have to solve infra. You have to evaluate you have to
S Speaker 220:43synthetic data, simulate your users, how they will behave in production without all the edge cases. In production, you have to do observability, like monitoring even the qualitative answers, and keep on optimizing. And then there has to be a guardrail security there as well. And the final step is analyzing the users. Like, how are users interacting with the LLM? Everything might be grammatically correct, and it's still wrong, that sort of thing. Today, all of this is being done with humans. There are some point solutions. I would say there is something only for observability. For example, data dog has come up with LLM with solvability. There is something for evaluation,
synthetic data, simulate your users, how they will behave in production without all the edge cases. In production, you have to do observability, like monitoring even the qualitative answers, and keep on optimizing. And then there has to be a guardrail security there as well. And the final step is analyzing the users. Like, how are users interacting with the LLM? Everything might be grammatically correct, and it's still wrong, that sort of thing. Today, all of this is being done with humans. There are some point solutions. I would say there is something only for observability. For example, data dog has come up with LLM with solvability. There is something for evaluation,
synthetic data, simulate your users, how they will behave in production without all the edge cases. In production, you have to do observability, like monitoring even the qualitative answers, and keep on optimizing. And then there has to be a guardrail security there as well. And the final step is analyzing the users. Like, how are users interacting with the LLM? Everything might be grammatically correct, and it's still wrong, that sort of thing. Today, all of this is being done with humans. There are some point solutions. I would say there is something only for observability. For example, data dog has come up with LLM with solvability. There is something for evaluation,
synthetic data, simulate your users, how they will behave in production without all the edge cases. In production, you have to do observability, like monitoring even the qualitative answers, and keep on optimizing. And then there has to be a guardrail security there as well. And the final step is analyzing the users. Like, how are users interacting with the LLM? Everything might be grammatically correct, and it's still wrong, that sort of thing. Today, all of this is being done with humans. There are some point solutions. I would say there is something only for observability. For example, data dog has come up with LLM with solvability. There is something for evaluation,
21:28but these are not complete LLM tools.
but these are not complete LLM tools.
but these are not complete LLM tools.
but these are not complete LLM tools.
S Speaker 221:32It's not solving the problem. And why I can say that with confidence is because lot of enterprises already using, say, Datadog observability or length views or arise, all of these are now shifting to us after looking at our solution, because the ultimate problem of AI reliability in production, it's actually unsolved. That is why it looks a little cluttered space. But frankly, it is not because nobody's solving the ultimate problem. It is still unsolved, so there will be more players, unless the enterprise problem is actually getting solved.
It's not solving the problem. And why I can say that with confidence is because lot of enterprises already using, say, Datadog observability or length views or arise, all of these are now shifting to us after looking at our solution, because the ultimate problem of AI reliability in production, it's actually unsolved. That is why it looks a little cluttered space. But frankly, it is not because nobody's solving the ultimate problem. It is still unsolved, so there will be more players, unless the enterprise problem is actually getting solved.
It's not solving the problem. And why I can say that with confidence is because lot of enterprises already using, say, Datadog observability or length views or arise, all of these are now shifting to us after looking at our solution, because the ultimate problem of AI reliability in production, it's actually unsolved. That is why it looks a little cluttered space. But frankly, it is not because nobody's solving the ultimate problem. It is still unsolved, so there will be more players, unless the enterprise problem is actually getting solved.
It's not solving the problem. And why I can say that with confidence is because lot of enterprises already using, say, Datadog observability or length views or arise, all of these are now shifting to us after looking at our solution, because the ultimate problem of AI reliability in production, it's actually unsolved. That is why it looks a little cluttered space. But frankly, it is not because nobody's solving the ultimate problem. It is still unsolved, so there will be more players, unless the enterprise problem is actually getting solved.
22:20I'll take a pause here. Do you want to ask
I'll take a pause here. Do you want to ask
I'll take a pause here. Do you want to ask
I'll take a pause here. Do you want to ask
S Speaker 122:21anything? I think I understand this, this part. Well, Charu, maybe when you explain product, I would love to understand the differentiation between future AGI versus the likes of Galileo, fiddler, encrypt, these, these companies.
anything? I think I understand this, this part. Well, Charu, maybe when you explain product, I would love to understand the differentiation between future AGI versus the likes of Galileo, fiddler, encrypt, these, these companies.
anything? I think I understand this, this part. Well, Charu, maybe when you explain product, I would love to understand the differentiation between future AGI versus the likes of Galileo, fiddler, encrypt, these, these companies.
anything? I think I understand this, this part. Well, Charu, maybe when you explain product, I would love to understand the differentiation between future AGI versus the likes of Galileo, fiddler, encrypt, these, these companies.
S Speaker 222:40Yeah, all right, I think the main differentiation lies in our approach. So we provide capabilities to simulate faster and evaluate better, like even a smarter evaluation, the zero conflict evals, auto AI, error tracking, these are not present with any of them, and autonomous simulations are not present with any of the market chaos. There are few point solution, only for voice AI, for simulations, but not for other agents, and Agent optimizer is not present. So this, this is the differentiation these. None of these capabilities are there with them. And why they are not there is because they are solving different problems. They are only solving observability. They are not solving the ultimate hallucinations. And why we are able to do this better than all of the market solutions is because we have fine tuned our own doing models. I think only Galileo and PETRONAS AI are the ones who have their fine tuned their own models at this stage, two weeks back, two weeks that we have published our research paper in which we have proved that the models that we have fine tuned our algorithms, they perform much, much better than Gemini 2.5 Pro, which is mostly the LLM as a judge model that many others use, which is the strongest model out there. So this is the USP that we have, and we have made it context aware. We have put all the connectors and all the feedback. So this is where the major differentiation lies with the existing any other solution that claims that they are evaluation solution, or they are observability solution, and because we have fine tuned our own models, we are we can deal with all the modalities. For example, audio, we can evaluate natively audio, instead of transcribing it, and that is why we can evaluate the tool and the emotional aspects right.
Yeah, all right, I think the main differentiation lies in our approach. So we provide capabilities to simulate faster and evaluate better, like even a smarter evaluation, the zero conflict evals, auto AI, error tracking, these are not present with any of them, and autonomous simulations are not present with any of the market chaos. There are few point solution, only for voice AI, for simulations, but not for other agents, and Agent optimizer is not present. So this, this is the differentiation these. None of these capabilities are there with them. And why they are not there is because they are solving different problems. They are only solving observability. They are not solving the ultimate hallucinations. And why we are able to do this better than all of the market solutions is because we have fine tuned our own doing models. I think only Galileo and PETRONAS AI are the ones who have their fine tuned their own models at this stage, two weeks back, two weeks that we have published our research paper in which we have proved that the models that we have fine tuned our algorithms, they perform much, much better than Gemini 2.5 Pro, which is mostly the LLM as a judge model that many others use, which is the strongest model out there. So this is the USP that we have, and we have made it context aware. We have put all the connectors and all the feedback. So this is where the major differentiation lies with the existing any other solution that claims that they are evaluation solution, or they are observability solution, and because we have fine tuned our own models, we are we can deal with all the modalities. For example, audio, we can evaluate natively audio, instead of transcribing it, and that is why we can evaluate the tool and the emotional aspects right.
Yeah, all right, I think the main differentiation lies in our approach. So we provide capabilities to simulate faster and evaluate better, like even a smarter evaluation, the zero conflict evals, auto AI, error tracking, these are not present with any of them, and autonomous simulations are not present with any of the market chaos. There are few point solution, only for voice AI, for simulations, but not for other agents, and Agent optimizer is not present. So this, this is the differentiation these. None of these capabilities are there with them. And why they are not there is because they are solving different problems. They are only solving observability. They are not solving the ultimate hallucinations. And why we are able to do this better than all of the market solutions is because we have fine tuned our own doing models. I think only Galileo and PETRONAS AI are the ones who have their fine tuned their own models at this stage, two weeks back, two weeks that we have published our research paper in which we have proved that the models that we have fine tuned our algorithms, they perform much, much better than Gemini 2.5 Pro, which is mostly the LLM as a judge model that many others use, which is the strongest model out there. So this is the USP that we have, and we have made it context aware. We have put all the connectors and all the feedback. So this is where the major differentiation lies with the existing any other solution that claims that they are evaluation solution, or they are observability solution, and because we have fine tuned our own models, we are we can deal with all the modalities. For example, audio, we can evaluate natively audio, instead of transcribing it, and that is why we can evaluate the tool and the emotional aspects right.
Yeah, all right, I think the main differentiation lies in our approach. So we provide capabilities to simulate faster and evaluate better, like even a smarter evaluation, the zero conflict evals, auto AI, error tracking, these are not present with any of them, and autonomous simulations are not present with any of the market chaos. There are few point solution, only for voice AI, for simulations, but not for other agents, and Agent optimizer is not present. So this, this is the differentiation these. None of these capabilities are there with them. And why they are not there is because they are solving different problems. They are only solving observability. They are not solving the ultimate hallucinations. And why we are able to do this better than all of the market solutions is because we have fine tuned our own doing models. I think only Galileo and PETRONAS AI are the ones who have their fine tuned their own models at this stage, two weeks back, two weeks that we have published our research paper in which we have proved that the models that we have fine tuned our algorithms, they perform much, much better than Gemini 2.5 Pro, which is mostly the LLM as a judge model that many others use, which is the strongest model out there. So this is the USP that we have, and we have made it context aware. We have put all the connectors and all the feedback. So this is where the major differentiation lies with the existing any other solution that claims that they are evaluation solution, or they are observability solution, and because we have fine tuned our own models, we are we can deal with all the modalities. For example, audio, we can evaluate natively audio, instead of transcribing it, and that is why we can evaluate the tool and the emotional aspects right.
S Speaker 225:05okay. Can I run you through the actual product?
okay. Can I run you through the actual product?
okay. Can I run you through the actual product?
okay. Can I run you through the actual product?
25:09Yes, yes, that would be great.
Yes, yes, that would be great.
Yes, yes, that would be great.
Yes, yes, that would be great.
S Speaker 128:07And these agents, when you say prototype, different versions of agents, the agents are still being developed, say, on a framework like a Lang chain, things like that. Do you integrate with those?
And these agents, when you say prototype, different versions of agents, the agents are still being developed, say, on a framework like a Lang chain, things like that. Do you integrate with those?
And these agents, when you say prototype, different versions of agents, the agents are still being developed, say, on a framework like a Lang chain, things like that. Do you integrate with those?
And these agents, when you say prototype, different versions of agents, the agents are still being developed, say, on a framework like a Lang chain, things like that. Do you integrate with those?
S Speaker 228:20Yeah, absolutely, we have all the integrations, I think
Yeah, absolutely, we have all the integrations, I think
Yeah, absolutely, we have all the integrations, I think
Yeah, absolutely, we have all the integrations, I think
28:26also these two line of codes and then it
also these two line of codes and then it
also these two line of codes and then it
also these two line of codes and then it
S Speaker 228:29all sorts of all the ecosystem partners are here. If there is one more partner, we barely takes one two hours for our team to quickly set up the connector. So lot of plants who use land chain or even lengthsmith, they
all sorts of all the ecosystem partners are here. If there is one more partner, we barely takes one two hours for our team to quickly set up the connector. So lot of plants who use land chain or even lengthsmith, they
all sorts of all the ecosystem partners are here. If there is one more partner, we barely takes one two hours for our team to quickly set up the connector. So lot of plants who use land chain or even lengthsmith, they
all sorts of all the ecosystem partners are here. If there is one more partner, we barely takes one two hours for our team to quickly set up the connector. So lot of plants who use land chain or even lengthsmith, they
28:49use this agent, compass, which is,
use this agent, compass, which is,
use this agent, compass, which is,
use this agent, compass, which is,
S Speaker 228:53which summarizes, this is the research paper. In fact, I'll send you this research paper published and here, even without setting up any events at all, it starts pointing out the errors in the AI outputs
which summarizes, this is the research paper. In fact, I'll send you this research paper published and here, even without setting up any events at all, it starts pointing out the errors in the AI outputs
which summarizes, this is the research paper. In fact, I'll send you this research paper published and here, even without setting up any events at all, it starts pointing out the errors in the AI outputs
which summarizes, this is the research paper. In fact, I'll send you this research paper published and here, even without setting up any events at all, it starts pointing out the errors in the AI outputs
29:10and yeah, and then if you click
and yeah, and then if you click
and yeah, and then if you click
and yeah, and then if you click
S Speaker 229:13on it, it also gives recommendation that what you need to change in the agent, what fix need To be done so that this does not happen. Very strong. Nobody has this in the whole
on it, it also gives recommendation that what you need to change in the agent, what fix need To be done so that this does not happen. Very strong. Nobody has this in the whole
on it, it also gives recommendation that what you need to change in the agent, what fix need To be done so that this does not happen. Very strong. Nobody has this in the whole
on it, it also gives recommendation that what you need to change in the agent, what fix need To be done so that this does not happen. Very strong. Nobody has this in the whole
29:28market as of today.
S Speaker 129:30Yes, it seems pretty interesting. Charu, yes, I haven't seen this level of depth yet at the moment, like we very recently, spoken to a lot of these companies. So I know many of them are raising as well. It seems pretty interesting. I would love to take a look at the data room and the benchmark study you mentioned. I think the biggest focus for us at this point would be and I'll be frank here, Charu, because I feel that that works best for all of us. The one challenge that we have seen talking to some of these players is that they haven't grown the way it was expected to a lot of these players are quite stuck in their ARR growth, and the initial hunch is that a lot of that is coming from the fact that There aren't enough AI enterprise applications today in production, so it seems like a market of the future, and I totally believe in that, that one day they it's inevitable, but many of these players haven't, sort of scaled that way. So GTM would be one of our questions in the follow up call and competition. Like you mentioned, I'd go through the materials you have and come back with any specific questions I have on the competition side of things. So those would be the areas that we would like to double click on, but quickly on the round, how big around Are you raising and what's the timeline you're looking at?
Yes, it seems pretty interesting. Charu, yes, I haven't seen this level of depth yet at the moment, like we very recently, spoken to a lot of these companies. So I know many of them are raising as well. It seems pretty interesting. I would love to take a look at the data room and the benchmark study you mentioned. I think the biggest focus for us at this point would be and I'll be frank here, Charu, because I feel that that works best for all of us. The one challenge that we have seen talking to some of these players is that they haven't grown the way it was expected to a lot of these players are quite stuck in their ARR growth, and the initial hunch is that a lot of that is coming from the fact that There aren't enough AI enterprise applications today in production, so it seems like a market of the future, and I totally believe in that, that one day they it's inevitable, but many of these players haven't, sort of scaled that way. So GTM would be one of our questions in the follow up call and competition. Like you mentioned, I'd go through the materials you have and come back with any specific questions I have on the competition side of things. So those would be the areas that we would like to double click on, but quickly on the round, how big around Are you raising and what's the timeline you're looking at?
Yes, it seems pretty interesting. Charu, yes, I haven't seen this level of depth yet at the moment, like we very recently, spoken to a lot of these companies. So I know many of them are raising as well. It seems pretty interesting. I would love to take a look at the data room and the benchmark study you mentioned. I think the biggest focus for us at this point would be and I'll be frank here, Charu, because I feel that that works best for all of us. The one challenge that we have seen talking to some of these players is that they haven't grown the way it was expected to a lot of these players are quite stuck in their ARR growth, and the initial hunch is that a lot of that is coming from the fact that There aren't enough AI enterprise applications today in production, so it seems like a market of the future, and I totally believe in that, that one day they it's inevitable, but many of these players haven't, sort of scaled that way. So GTM would be one of our questions in the follow up call and competition. Like you mentioned, I'd go through the materials you have and come back with any specific questions I have on the competition side of things. So those would be the areas that we would like to double click on, but quickly on the round, how big around Are you raising and what's the timeline you're looking at?
Yes, it seems pretty interesting. Charu, yes, I haven't seen this level of depth yet at the moment, like we very recently, spoken to a lot of these companies. So I know many of them are raising as well. It seems pretty interesting. I would love to take a look at the data room and the benchmark study you mentioned. I think the biggest focus for us at this point would be and I'll be frank here, Charu, because I feel that that works best for all of us. The one challenge that we have seen talking to some of these players is that they haven't grown the way it was expected to a lot of these players are quite stuck in their ARR growth, and the initial hunch is that a lot of that is coming from the fact that There aren't enough AI enterprise applications today in production, so it seems like a market of the future, and I totally believe in that, that one day they it's inevitable, but many of these players haven't, sort of scaled that way. So GTM would be one of our questions in the follow up call and competition. Like you mentioned, I'd go through the materials you have and come back with any specific questions I have on the competition side of things. So those would be the areas that we would like to double click on, but quickly on the round, how big around Are you raising and what's the timeline you're looking at?
30:56So we are raising 5 million
So we are raising 5 million
So we are raising 5 million
So we are raising 5 million
S Speaker 230:59right now, five to eight is what we wanted to raise at 30 million
right now, five to eight is what we wanted to raise at 30 million
right now, five to eight is what we wanted to raise at 30 million
right now, five to eight is what we wanted to raise at 30 million
31:06premium evaluation
S Speaker 231:09and timeline wise, we do have a few VCs and soft commitments up to 2.5 mil, and we were looking to close it in the next two to three weeks. Yeah, so that was what we had in mind, so that we can get back to building and
and timeline wise, we do have a few VCs and soft commitments up to 2.5 mil, and we were looking to close it in the next two to three weeks. Yeah, so that was what we had in mind, so that we can get back to building and
and timeline wise, we do have a few VCs and soft commitments up to 2.5 mil, and we were looking to close it in the next two to three weeks. Yeah, so that was what we had in mind, so that we can get back to building and
and timeline wise, we do have a few VCs and soft commitments up to 2.5 mil, and we were looking to close it in the next two to three weeks. Yeah, so that was what we had in mind, so that we can get back to building and
S Speaker 131:29yeah, selling. Sounds. Sounds good. Charu for like, because we are corporate fund, it takes us slightly longer to sort of come to a decision. Probably our processes are five to six weeks in general. But since we have an understanding about this space, I will come back to you quickly on where, where the team resides on this we have a discussion every Monday where we discuss different prospects. So by then, I will have say initial decision, and I'd like to keep it very transparent, so that it's not wasting your time as well. But but would appreciate looking at the data room, the deck and the benchmark study, and then I'll get back to you on that
yeah, selling. Sounds. Sounds good. Charu for like, because we are corporate fund, it takes us slightly longer to sort of come to a decision. Probably our processes are five to six weeks in general. But since we have an understanding about this space, I will come back to you quickly on where, where the team resides on this we have a discussion every Monday where we discuss different prospects. So by then, I will have say initial decision, and I'd like to keep it very transparent, so that it's not wasting your time as well. But but would appreciate looking at the data room, the deck and the benchmark study, and then I'll get back to you on that
yeah, selling. Sounds. Sounds good. Charu for like, because we are corporate fund, it takes us slightly longer to sort of come to a decision. Probably our processes are five to six weeks in general. But since we have an understanding about this space, I will come back to you quickly on where, where the team resides on this we have a discussion every Monday where we discuss different prospects. So by then, I will have say initial decision, and I'd like to keep it very transparent, so that it's not wasting your time as well. But but would appreciate looking at the data room, the deck and the benchmark study, and then I'll get back to you on that
yeah, selling. Sounds. Sounds good. Charu for like, because we are corporate fund, it takes us slightly longer to sort of come to a decision. Probably our processes are five to six weeks in general. But since we have an understanding about this space, I will come back to you quickly on where, where the team resides on this we have a discussion every Monday where we discuss different prospects. So by then, I will have say initial decision, and I'd like to keep it very transparent, so that it's not wasting your time as well. But but would appreciate looking at the data room, the deck and the benchmark study, and then I'll get back to you on that
S Speaker 232:15amazing any question, we can have a follow up, quick connect with Nitin as well if you have any technical questions on the competition side and on the GTM side, what we have figured out how we built this. Who are the current enterprises? If you want to talk to anyone of them,
amazing any question, we can have a follow up, quick connect with Nitin as well if you have any technical questions on the competition side and on the GTM side, what we have figured out how we built this. Who are the current enterprises? If you want to talk to anyone of them,
amazing any question, we can have a follow up, quick connect with Nitin as well if you have any technical questions on the competition side and on the GTM side, what we have figured out how we built this. Who are the current enterprises? If you want to talk to anyone of them,
amazing any question, we can have a follow up, quick connect with Nitin as well if you have any technical questions on the competition side and on the GTM side, what we have figured out how we built this. Who are the current enterprises? If you want to talk to anyone of them,
S Speaker 232:47So how? So there are three customers right now, Ravi onyx, automate and quid, that have completed their pilot, and they want to integrate for the annual contract all of that. So, so Ravi on it. They are the price analytics company pretty big. They have clients like Walmart, all of them, and they are building the conversational AI interface. They have a team of five to six people, head of AI, up data, all of them, and text to SQL is their use case. These started with evaluation. Most of our clients think that what they need is evaluation. But once we run them through, give them a walk through, and give them access, they realize that for evaluation, they need the synthetic data first, because production data is not available anyway, then they start figuring out how to get synthetic data. But we also have the simulation capability, so that is one of our learning that simulation is a very strong product that whose need is not realized on day one, but definitely on day two. That is the number one demand, yeah, once that happens, synthetic data is generated. That is when they start testing their agent and quickly fine tuning it and testing, automated testing is available. So instead of waiting for five days, they can do it in one hour. And the optimization, we have auto optimizations available for agents and prompt engineering. So that also saves all the time. So the pilot, which might typically take one month, they if the Enterprise team is available, they're able to quickly test these things and arrive at the decision that this is very useful. Like that is one the other company, quid, they do brand research. For example, Walmart gives them an assignment that tell me which color this fall will be, will be good for curtains, and how that catalog should be like. So they have a team of 30 analysts who would scrape the internet, do the reputation management. They scrape the social media and build these reports. So now all of this is being done by llms, but their requirement is on daily basis, is to form stronger prompts that can do this on daily basis. They have to do lot of prompt engineering, and these analysts are not engineering technical. They are technical in their own speed, yeah, but not comfortable with, say, the energy they needed an UI which is easy enough for them to store and version control all the prompts and reuse their product really very easily, and optimize them and quickly evaluate if it is working fine or not, and send it back to their bigger customers, like Walmart and others again. So that is how they are using it. They also started with evaluation. They thought evaluation is not great, but then they realize what they actually need is the prompt management, right? So this whole tech solving thing is coming from our enterprises only, like I can't be a single point solution in September in last year, October 2024, we released our evaluation. We have a patent on that, yeah, and we were dumbfounded, because nobody would use it. Then we went back to the whiteboard and built the complete enterprise suit. So it's coming very organically from our customers and clients that how currently it is being used, what new we can deliver. We can't deliver value only from evaluation. It has to complete come from the complete stepping there
So how? So there are three customers right now, Ravi onyx, automate and quid, that have completed their pilot, and they want to integrate for the annual contract all of that. So, so Ravi on it. They are the price analytics company pretty big. They have clients like Walmart, all of them, and they are building the conversational AI interface. They have a team of five to six people, head of AI, up data, all of them, and text to SQL is their use case. These started with evaluation. Most of our clients think that what they need is evaluation. But once we run them through, give them a walk through, and give them access, they realize that for evaluation, they need the synthetic data first, because production data is not available anyway, then they start figuring out how to get synthetic data. But we also have the simulation capability, so that is one of our learning that simulation is a very strong product that whose need is not realized on day one, but definitely on day two. That is the number one demand, yeah, once that happens, synthetic data is generated. That is when they start testing their agent and quickly fine tuning it and testing, automated testing is available. So instead of waiting for five days, they can do it in one hour. And the optimization, we have auto optimizations available for agents and prompt engineering. So that also saves all the time. So the pilot, which might typically take one month, they if the Enterprise team is available, they're able to quickly test these things and arrive at the decision that this is very useful. Like that is one the other company, quid, they do brand research. For example, Walmart gives them an assignment that tell me which color this fall will be, will be good for curtains, and how that catalog should be like. So they have a team of 30 analysts who would scrape the internet, do the reputation management. They scrape the social media and build these reports. So now all of this is being done by llms, but their requirement is on daily basis, is to form stronger prompts that can do this on daily basis. They have to do lot of prompt engineering, and these analysts are not engineering technical. They are technical in their own speed, yeah, but not comfortable with, say, the energy they needed an UI which is easy enough for them to store and version control all the prompts and reuse their product really very easily, and optimize them and quickly evaluate if it is working fine or not, and send it back to their bigger customers, like Walmart and others again. So that is how they are using it. They also started with evaluation. They thought evaluation is not great, but then they realize what they actually need is the prompt management, right? So this whole tech solving thing is coming from our enterprises only, like I can't be a single point solution in September in last year, October 2024, we released our evaluation. We have a patent on that, yeah, and we were dumbfounded, because nobody would use it. Then we went back to the whiteboard and built the complete enterprise suit. So it's coming very organically from our customers and clients that how currently it is being used, what new we can deliver. We can't deliver value only from evaluation. It has to complete come from the complete stepping there
So how? So there are three customers right now, Ravi onyx, automate and quid, that have completed their pilot, and they want to integrate for the annual contract all of that. So, so Ravi on it. They are the price analytics company pretty big. They have clients like Walmart, all of them, and they are building the conversational AI interface. They have a team of five to six people, head of AI, up data, all of them, and text to SQL is their use case. These started with evaluation. Most of our clients think that what they need is evaluation. But once we run them through, give them a walk through, and give them access, they realize that for evaluation, they need the synthetic data first, because production data is not available anyway, then they start figuring out how to get synthetic data. But we also have the simulation capability, so that is one of our learning that simulation is a very strong product that whose need is not realized on day one, but definitely on day two. That is the number one demand, yeah, once that happens, synthetic data is generated. That is when they start testing their agent and quickly fine tuning it and testing, automated testing is available. So instead of waiting for five days, they can do it in one hour. And the optimization, we have auto optimizations available for agents and prompt engineering. So that also saves all the time. So the pilot, which might typically take one month, they if the Enterprise team is available, they're able to quickly test these things and arrive at the decision that this is very useful. Like that is one the other company, quid, they do brand research. For example, Walmart gives them an assignment that tell me which color this fall will be, will be good for curtains, and how that catalog should be like. So they have a team of 30 analysts who would scrape the internet, do the reputation management. They scrape the social media and build these reports. So now all of this is being done by llms, but their requirement is on daily basis, is to form stronger prompts that can do this on daily basis. They have to do lot of prompt engineering, and these analysts are not engineering technical. They are technical in their own speed, yeah, but not comfortable with, say, the energy they needed an UI which is easy enough for them to store and version control all the prompts and reuse their product really very easily, and optimize them and quickly evaluate if it is working fine or not, and send it back to their bigger customers, like Walmart and others again. So that is how they are using it. They also started with evaluation. They thought evaluation is not great, but then they realize what they actually need is the prompt management, right? So this whole tech solving thing is coming from our enterprises only, like I can't be a single point solution in September in last year, October 2024, we released our evaluation. We have a patent on that, yeah, and we were dumbfounded, because nobody would use it. Then we went back to the whiteboard and built the complete enterprise suit. So it's coming very organically from our customers and clients that how currently it is being used, what new we can deliver. We can't deliver value only from evaluation. It has to complete come from the complete stepping there
So how? So there are three customers right now, Ravi onyx, automate and quid, that have completed their pilot, and they want to integrate for the annual contract all of that. So, so Ravi on it. They are the price analytics company pretty big. They have clients like Walmart, all of them, and they are building the conversational AI interface. They have a team of five to six people, head of AI, up data, all of them, and text to SQL is their use case. These started with evaluation. Most of our clients think that what they need is evaluation. But once we run them through, give them a walk through, and give them access, they realize that for evaluation, they need the synthetic data first, because production data is not available anyway, then they start figuring out how to get synthetic data. But we also have the simulation capability, so that is one of our learning that simulation is a very strong product that whose need is not realized on day one, but definitely on day two. That is the number one demand, yeah, once that happens, synthetic data is generated. That is when they start testing their agent and quickly fine tuning it and testing, automated testing is available. So instead of waiting for five days, they can do it in one hour. And the optimization, we have auto optimizations available for agents and prompt engineering. So that also saves all the time. So the pilot, which might typically take one month, they if the Enterprise team is available, they're able to quickly test these things and arrive at the decision that this is very useful. Like that is one the other company, quid, they do brand research. For example, Walmart gives them an assignment that tell me which color this fall will be, will be good for curtains, and how that catalog should be like. So they have a team of 30 analysts who would scrape the internet, do the reputation management. They scrape the social media and build these reports. So now all of this is being done by llms, but their requirement is on daily basis, is to form stronger prompts that can do this on daily basis. They have to do lot of prompt engineering, and these analysts are not engineering technical. They are technical in their own speed, yeah, but not comfortable with, say, the energy they needed an UI which is easy enough for them to store and version control all the prompts and reuse their product really very easily, and optimize them and quickly evaluate if it is working fine or not, and send it back to their bigger customers, like Walmart and others again. So that is how they are using it. They also started with evaluation. They thought evaluation is not great, but then they realize what they actually need is the prompt management, right? So this whole tech solving thing is coming from our enterprises only, like I can't be a single point solution in September in last year, October 2024, we released our evaluation. We have a patent on that, yeah, and we were dumbfounded, because nobody would use it. Then we went back to the whiteboard and built the complete enterprise suit. So it's coming very organically from our customers and clients that how currently it is being used, what new we can deliver. We can't deliver value only from evaluation. It has to complete come from the complete stepping there
S Speaker 236:45Automate is launching a finance co pilot. So then they also started with evaluation as the key problem. But then they move to prototyping, because they are still prototyping their agent, and our pricing is usage based. So all of these three we are expecting, now that they are more confident about the product, because accuracy has increased, they will roll it out to all their customers. Right now they have rolled out the AI product only to one or two of them, so our pricing is usage based, and we feel that potential of all three is
Automate is launching a finance co pilot. So then they also started with evaluation as the key problem. But then they move to prototyping, because they are still prototyping their agent, and our pricing is usage based. So all of these three we are expecting, now that they are more confident about the product, because accuracy has increased, they will roll it out to all their customers. Right now they have rolled out the AI product only to one or two of them, so our pricing is usage based, and we feel that potential of all three is
Automate is launching a finance co pilot. So then they also started with evaluation as the key problem. But then they move to prototyping, because they are still prototyping their agent, and our pricing is usage based. So all of these three we are expecting, now that they are more confident about the product, because accuracy has increased, they will roll it out to all their customers. Right now they have rolled out the AI product only to one or two of them, so our pricing is usage based, and we feel that potential of all three is
Automate is launching a finance co pilot. So then they also started with evaluation as the key problem. But then they move to prototyping, because they are still prototyping their agent, and our pricing is usage based. So all of these three we are expecting, now that they are more confident about the product, because accuracy has increased, they will roll it out to all their customers. Right now they have rolled out the AI product only to one or two of them, so our pricing is usage based, and we feel that potential of all three is
37:20up to 50k 200 KBC,
S Speaker 237:32like the stories that I told you. Does it align with what you are hearing from the market? Any learnings from
like the stories that I told you. Does it align with what you are hearing from the market? Any learnings from
like the stories that I told you. Does it align with what you are hearing from the market? Any learnings from
like the stories that I told you. Does it align with what you are hearing from the market? Any learnings from
S Speaker 137:38your side? Yes, absolutely. Charu, so I totally agree with that. Many of these solutions have tried going full stack. We saw that with weights and biases as well. And then the observability tools you mentioned, all of them try to go, say, in evals, in model security, some of them have a simulation engine. I would say probably one or two encrypt has it, but not most of them don't have it. And just closing the loop and going full cycle is, is, is the way, I would say, to win this market. So that definitely aligns.
your side? Yes, absolutely. Charu, so I totally agree with that. Many of these solutions have tried going full stack. We saw that with weights and biases as well. And then the observability tools you mentioned, all of them try to go, say, in evals, in model security, some of them have a simulation engine. I would say probably one or two encrypt has it, but not most of them don't have it. And just closing the loop and going full cycle is, is, is the way, I would say, to win this market. So that definitely aligns.
your side? Yes, absolutely. Charu, so I totally agree with that. Many of these solutions have tried going full stack. We saw that with weights and biases as well. And then the observability tools you mentioned, all of them try to go, say, in evals, in model security, some of them have a simulation engine. I would say probably one or two encrypt has it, but not most of them don't have it. And just closing the loop and going full cycle is, is, is the way, I would say, to win this market. So that definitely aligns.
your side? Yes, absolutely. Charu, so I totally agree with that. Many of these solutions have tried going full stack. We saw that with weights and biases as well. And then the observability tools you mentioned, all of them try to go, say, in evals, in model security, some of them have a simulation engine. I would say probably one or two encrypt has it, but not most of them don't have it. And just closing the loop and going full cycle is, is, is the way, I would say, to win this market. So that definitely aligns.
38:16I also really like your
I also really like your
I also really like your
I also really like your
S Speaker 138:18focus a lot on agents from the other companies that we have spoken to, many of them are still around. How do you make your chatbot more reliable? Plus a quick rag fix? None of them are really going into, say, complex workflows agents today or they don't have customers in those spaces. So that's that's pretty interesting as well,
focus a lot on agents from the other companies that we have spoken to, many of them are still around. How do you make your chatbot more reliable? Plus a quick rag fix? None of them are really going into, say, complex workflows agents today or they don't have customers in those spaces. So that's that's pretty interesting as well,
focus a lot on agents from the other companies that we have spoken to, many of them are still around. How do you make your chatbot more reliable? Plus a quick rag fix? None of them are really going into, say, complex workflows agents today or they don't have customers in those spaces. So that's that's pretty interesting as well,
focus a lot on agents from the other companies that we have spoken to, many of them are still around. How do you make your chatbot more reliable? Plus a quick rag fix? None of them are really going into, say, complex workflows agents today or they don't have customers in those spaces. So that's that's pretty interesting as well,
S Speaker 238:42even the multi agent evaluation in, I think very early in March, April itself. And multimodal also, yeah, I don't think Galileo is not multimodal,
even the multi agent evaluation in, I think very early in March, April itself. And multimodal also, yeah, I don't think Galileo is not multimodal,
even the multi agent evaluation in, I think very early in March, April itself. And multimodal also, yeah, I don't think Galileo is not multimodal,
even the multi agent evaluation in, I think very early in March, April itself. And multimodal also, yeah, I don't think Galileo is not multimodal,
38:53yeah, yeah. Many of these players
yeah, yeah. Many of these players
yeah, yeah. Many of these players
yeah, yeah. Many of these players
S Speaker 238:57are not, yeah. We build this in last eight months, and all of these companies are existing for two to 456, years now, right? Very agile. Our team is very agile.
are not, yeah. We build this in last eight months, and all of these companies are existing for two to 456, years now, right? Very agile. Our team is very agile.
are not, yeah. We build this in last eight months, and all of these companies are existing for two to 456, years now, right? Very agile. Our team is very agile.
are not, yeah. We build this in last eight months, and all of these companies are existing for two to 456, years now, right? Very agile. Our team is very agile.
39:07And how many members are in the team today?
And how many members are in the team today?
And how many members are in the team today?
And how many members are in the team today?
39:10Team has 25 members.
39:15This is the team is
S Speaker 239:18here, yeah. So there are 25 people, and Sarah and Brenda are based out of behavior. Sarah is ex Oracle. She has been selling softwares for 20 years. And Rishi is the ex Microsoft. She was solving the evaluation problem in Microsoft as well for three years before joining us. Vigor has taken companies from zero to IPO as Ops Head. So apart from these key people, we have like freshers and interns as well, but pretty solid team development center is in India, while four people are based out of the GTM team is in
here, yeah. So there are 25 people, and Sarah and Brenda are based out of behavior. Sarah is ex Oracle. She has been selling softwares for 20 years. And Rishi is the ex Microsoft. She was solving the evaluation problem in Microsoft as well for three years before joining us. Vigor has taken companies from zero to IPO as Ops Head. So apart from these key people, we have like freshers and interns as well, but pretty solid team development center is in India, while four people are based out of the GTM team is in
here, yeah. So there are 25 people, and Sarah and Brenda are based out of behavior. Sarah is ex Oracle. She has been selling softwares for 20 years. And Rishi is the ex Microsoft. She was solving the evaluation problem in Microsoft as well for three years before joining us. Vigor has taken companies from zero to IPO as Ops Head. So apart from these key people, we have like freshers and interns as well, but pretty solid team development center is in India, while four people are based out of the GTM team is in
here, yeah. So there are 25 people, and Sarah and Brenda are based out of behavior. Sarah is ex Oracle. She has been selling softwares for 20 years. And Rishi is the ex Microsoft. She was solving the evaluation problem in Microsoft as well for three years before joining us. Vigor has taken companies from zero to IPO as Ops Head. So apart from these key people, we have like freshers and interns as well, but pretty solid team development center is in India, while four people are based out of the GTM team is in
S Speaker 139:59us, got it, and where are you? And Nikhil based, Nikhil is.
us, got it, and where are you? And Nikhil based, Nikhil is.
us, got it, and where are you? And Nikhil based, Nikhil is.
us, got it, and where are you? And Nikhil based, Nikhil is.
S Speaker 240:05Nikhil spends his time in SF majorly. And he has applied for o1 so we are expecting that to come as well. He has multiple patents. I shuttle. I spent six months here, six months there. Yeah. And Vrinda also spends her time in SF only. And Sara is based out of Bay Area. Got it. She's She's a native. And I also want to draw your attention to Vikas and mandar. Vikas is MD of BCG here in San Francisco, so he was our angel last year. Also he mentioned he saw the product, and he doubled his investment. And he's introducing us in BCG now, and mandar is the CTO of conversational AI in GPMC global. So they both have been they meet us every quarter and provide their inputs
Nikhil spends his time in SF majorly. And he has applied for o1 so we are expecting that to come as well. He has multiple patents. I shuttle. I spent six months here, six months there. Yeah. And Vrinda also spends her time in SF only. And Sara is based out of Bay Area. Got it. She's She's a native. And I also want to draw your attention to Vikas and mandar. Vikas is MD of BCG here in San Francisco, so he was our angel last year. Also he mentioned he saw the product, and he doubled his investment. And he's introducing us in BCG now, and mandar is the CTO of conversational AI in GPMC global. So they both have been they meet us every quarter and provide their inputs
Nikhil spends his time in SF majorly. And he has applied for o1 so we are expecting that to come as well. He has multiple patents. I shuttle. I spent six months here, six months there. Yeah. And Vrinda also spends her time in SF only. And Sara is based out of Bay Area. Got it. She's She's a native. And I also want to draw your attention to Vikas and mandar. Vikas is MD of BCG here in San Francisco, so he was our angel last year. Also he mentioned he saw the product, and he doubled his investment. And he's introducing us in BCG now, and mandar is the CTO of conversational AI in GPMC global. So they both have been they meet us every quarter and provide their inputs
Nikhil spends his time in SF majorly. And he has applied for o1 so we are expecting that to come as well. He has multiple patents. I shuttle. I spent six months here, six months there. Yeah. And Vrinda also spends her time in SF only. And Sara is based out of Bay Area. Got it. She's She's a native. And I also want to draw your attention to Vikas and mandar. Vikas is MD of BCG here in San Francisco, so he was our angel last year. Also he mentioned he saw the product, and he doubled his investment. And he's introducing us in BCG now, and mandar is the CTO of conversational AI in GPMC global. So they both have been they meet us every quarter and provide their inputs
40:51on the product as well as the market.
on the product as well as the market.
on the product as well as the market.
on the product as well as the market.
S Speaker 140:52Super interesting team, for sure. Charu, yeah, I would love to dig deeper and come back pretty soon on where we stand.
Super interesting team, for sure. Charu, yeah, I would love to dig deeper and come back pretty soon on where we stand.
Super interesting team, for sure. Charu, yeah, I would love to dig deeper and come back pretty soon on where we stand.
Super interesting team, for sure. Charu, yeah, I would love to dig deeper and come back pretty soon on where we stand.
41:01Like I mentioned, the key areas we could look at are,
Like I mentioned, the key areas we could look at are,
Like I mentioned, the key areas we could look at are,
Like I mentioned, the key areas we could look at are,
S Speaker 141:04say, GTM, motion, how your pipeline looks like, competition, differentiation, and maybe probably we will have a discussion in the team around if this round is around early for us or now, based on the check size. But I'll get back to you on all of those three friends.
say, GTM, motion, how your pipeline looks like, competition, differentiation, and maybe probably we will have a discussion in the team around if this round is around early for us or now, based on the check size. But I'll get back to you on all of those three friends.
say, GTM, motion, how your pipeline looks like, competition, differentiation, and maybe probably we will have a discussion in the team around if this round is around early for us or now, based on the check size. But I'll get back to you on all of those three friends.
say, GTM, motion, how your pipeline looks like, competition, differentiation, and maybe probably we will have a discussion in the team around if this round is around early for us or now, based on the check size. But I'll get back to you on all of those three friends.
S Speaker 141:26Yeah, yeah. As the next step, I would love to loop in some more members of my team so we can definitely do an in person meeting.
Yeah, yeah. As the next step, I would love to loop in some more members of my team so we can definitely do an in person meeting.
Yeah, yeah. As the next step, I would love to loop in some more members of my team so we can definitely do an in person meeting.
Yeah, yeah. As the next step, I would love to loop in some more members of my team so we can definitely do an in person meeting.