Meeting: Shivam - Peak XV - Catchup
Thu, Jul 3
7:30 PM
39 min
Priyesh P
Discussion on Video Firms and AI Auto
URL: https://otter.ai/u/VPARpiBYsaOT8Ye_zak22x1jfXg
Downloaded: 2025-12-21T21:43:28.362180
Method: text_extraction
============================================================

2:21I'm you're running five minutes Late.
I'm you're running five minutes Late.
I'm you're running five minutes Late.
I'm you're running five minutes Late.
3:19Running Five minutes Late,
Running Five minutes Late,
Running Five minutes Late,
Running Five minutes Late,
6:11hey, Priyesh, okay, Hi, Shiva broke You tell me, are you
hey, Priyesh, okay, Hi, Shiva broke You tell me, are you
hey, Priyesh, okay, Hi, Shiva broke You tell me, are you
hey, Priyesh, okay, Hi, Shiva broke You tell me, are you
S Speaker 16:20in office? Good. Everything. But anyway, sometimes,
in office? Good. Everything. But anyway, sometimes,
in office? Good. Everything. But anyway, sometimes,
in office? Good. Everything. But anyway, sometimes,
6:31since you left right,
since you left right,
since you left right,
since you left right,
11:14kind of listing it
S Speaker 211:17down. Basically, is that you need to have very accurate reward design. So like these models, they are very good, like, you know, in math and coding, because these are verifiable problems, right? But the enterprise workflows may not always be verifiable, so you need, like, an LLM charge on a human judge, right? So how do you do that? How do you like you know, do that robot design and algorithm based on top of that? That's, I think, one which is sort of an art second, I think, is environment building. So I think the analogy that we use here is, like, you know, flight simulators, right? So there are flight simulators who are very high fidelity. They basically, like, like, almost 9.9% limit the real world. And if a pilot can fly basically on that simulator, they are, like, directly cleared to, like, you know, operate commercial flights. So same analogy applies here, right? So the agents need to be trained on, let's say, a simulator which is very high fidelity, yeah? Because, like, you know, you don't know what kind of noise will happen in real world, what policy will change? What if, like, you know, a human user is trying to update the system at the same time, right? So you have to kind of model those kind of things, and gives, like the real world sandbox for the agents to train on. And then I think there are, like, you know, some other parts. I think one is compute. So what I have recently learned is that, like, when you can do the I'll compute on CPUs as well, but paralyzing, like, you know, trading does one CPU is hard. It's not like, you know, happens out of the box. You have to do some engineering on top of it. Then, I think, like, if you're serving enterprise customers and you're trying to, like, you know, ask them to expose that data into a sandbox, or to take care about security, governance, all that shit. And then obviously you have your observability to make sure your agent does not basically degrade in the comments, or there is a real world policy change you have to take make sure that
down. Basically, is that you need to have very accurate reward design. So like these models, they are very good, like, you know, in math and coding, because these are verifiable problems, right? But the enterprise workflows may not always be verifiable, so you need, like, an LLM charge on a human judge, right? So how do you do that? How do you like you know, do that robot design and algorithm based on top of that? That's, I think, one which is sort of an art second, I think, is environment building. So I think the analogy that we use here is, like, you know, flight simulators, right? So there are flight simulators who are very high fidelity. They basically, like, like, almost 9.9% limit the real world. And if a pilot can fly basically on that simulator, they are, like, directly cleared to, like, you know, operate commercial flights. So same analogy applies here, right? So the agents need to be trained on, let's say, a simulator which is very high fidelity, yeah? Because, like, you know, you don't know what kind of noise will happen in real world, what policy will change? What if, like, you know, a human user is trying to update the system at the same time, right? So you have to kind of model those kind of things, and gives, like the real world sandbox for the agents to train on. And then I think there are, like, you know, some other parts. I think one is compute. So what I have recently learned is that, like, when you can do the I'll compute on CPUs as well, but paralyzing, like, you know, trading does one CPU is hard. It's not like, you know, happens out of the box. You have to do some engineering on top of it. Then, I think, like, if you're serving enterprise customers and you're trying to, like, you know, ask them to expose that data into a sandbox, or to take care about security, governance, all that shit. And then obviously you have your observability to make sure your agent does not basically degrade in the comments, or there is a real world policy change you have to take make sure that
down. Basically, is that you need to have very accurate reward design. So like these models, they are very good, like, you know, in math and coding, because these are verifiable problems, right? But the enterprise workflows may not always be verifiable, so you need, like, an LLM charge on a human judge, right? So how do you do that? How do you like you know, do that robot design and algorithm based on top of that? That's, I think, one which is sort of an art second, I think, is environment building. So I think the analogy that we use here is, like, you know, flight simulators, right? So there are flight simulators who are very high fidelity. They basically, like, like, almost 9.9% limit the real world. And if a pilot can fly basically on that simulator, they are, like, directly cleared to, like, you know, operate commercial flights. So same analogy applies here, right? So the agents need to be trained on, let's say, a simulator which is very high fidelity, yeah? Because, like, you know, you don't know what kind of noise will happen in real world, what policy will change? What if, like, you know, a human user is trying to update the system at the same time, right? So you have to kind of model those kind of things, and gives, like the real world sandbox for the agents to train on. And then I think there are, like, you know, some other parts. I think one is compute. So what I have recently learned is that, like, when you can do the I'll compute on CPUs as well, but paralyzing, like, you know, trading does one CPU is hard. It's not like, you know, happens out of the box. You have to do some engineering on top of it. Then, I think, like, if you're serving enterprise customers and you're trying to, like, you know, ask them to expose that data into a sandbox, or to take care about security, governance, all that shit. And then obviously you have your observability to make sure your agent does not basically degrade in the comments, or there is a real world policy change you have to take make sure that
down. Basically, is that you need to have very accurate reward design. So like these models, they are very good, like, you know, in math and coding, because these are verifiable problems, right? But the enterprise workflows may not always be verifiable, so you need, like, an LLM charge on a human judge, right? So how do you do that? How do you like you know, do that robot design and algorithm based on top of that? That's, I think, one which is sort of an art second, I think, is environment building. So I think the analogy that we use here is, like, you know, flight simulators, right? So there are flight simulators who are very high fidelity. They basically, like, like, almost 9.9% limit the real world. And if a pilot can fly basically on that simulator, they are, like, directly cleared to, like, you know, operate commercial flights. So same analogy applies here, right? So the agents need to be trained on, let's say, a simulator which is very high fidelity, yeah? Because, like, you know, you don't know what kind of noise will happen in real world, what policy will change? What if, like, you know, a human user is trying to update the system at the same time, right? So you have to kind of model those kind of things, and gives, like the real world sandbox for the agents to train on. And then I think there are, like, you know, some other parts. I think one is compute. So what I have recently learned is that, like, when you can do the I'll compute on CPUs as well, but paralyzing, like, you know, trading does one CPU is hard. It's not like, you know, happens out of the box. You have to do some engineering on top of it. Then, I think, like, if you're serving enterprise customers and you're trying to, like, you know, ask them to expose that data into a sandbox, or to take care about security, governance, all that shit. And then obviously you have your observability to make sure your agent does not basically degrade in the comments, or there is a real world policy change you have to take make sure that
13:11Esra problem state.
S Speaker 213:14We think that building real world in relations simulations and that environment basically is a huge bottle. And the current idea is to sort of productize. We don't know how that will happen, but let's say, like, you know, if you could, let's say write basically a framework, or, let's say a platform that lets, like, you know, engineers easily spin up replicas of their real world software stack with, like, you know, some real world data with some like, you know, traces that they can do about sort of the agent on, I think that will save them, like, lots of time and lots of like, you know, expertise when they think about implementing RL for their own use case. So Priyesh, like a very broad idea. I think we have been working on this for last 10 days or so. And the reason I wanted to connect with you was, like, two fold. I think it was just to understand, like, you know, what you guys are seeing, because I know that RL is basically the hottest topic, probably right now. So wanted to understand, like, you know, what you have seen, any feedback, like, you know, on
We think that building real world in relations simulations and that environment basically is a huge bottle. And the current idea is to sort of productize. We don't know how that will happen, but let's say, like, you know, if you could, let's say write basically a framework, or, let's say a platform that lets, like, you know, engineers easily spin up replicas of their real world software stack with, like, you know, some real world data with some like, you know, traces that they can do about sort of the agent on, I think that will save them, like, lots of time and lots of like, you know, expertise when they think about implementing RL for their own use case. So Priyesh, like a very broad idea. I think we have been working on this for last 10 days or so. And the reason I wanted to connect with you was, like, two fold. I think it was just to understand, like, you know, what you guys are seeing, because I know that RL is basically the hottest topic, probably right now. So wanted to understand, like, you know, what you have seen, any feedback, like, you know, on
We think that building real world in relations simulations and that environment basically is a huge bottle. And the current idea is to sort of productize. We don't know how that will happen, but let's say, like, you know, if you could, let's say write basically a framework, or, let's say a platform that lets, like, you know, engineers easily spin up replicas of their real world software stack with, like, you know, some real world data with some like, you know, traces that they can do about sort of the agent on, I think that will save them, like, lots of time and lots of like, you know, expertise when they think about implementing RL for their own use case. So Priyesh, like a very broad idea. I think we have been working on this for last 10 days or so. And the reason I wanted to connect with you was, like, two fold. I think it was just to understand, like, you know, what you guys are seeing, because I know that RL is basically the hottest topic, probably right now. So wanted to understand, like, you know, what you have seen, any feedback, like, you know, on
We think that building real world in relations simulations and that environment basically is a huge bottle. And the current idea is to sort of productize. We don't know how that will happen, but let's say, like, you know, if you could, let's say write basically a framework, or, let's say a platform that lets, like, you know, engineers easily spin up replicas of their real world software stack with, like, you know, some real world data with some like, you know, traces that they can do about sort of the agent on, I think that will save them, like, lots of time and lots of like, you know, expertise when they think about implementing RL for their own use case. So Priyesh, like a very broad idea. I think we have been working on this for last 10 days or so. And the reason I wanted to connect with you was, like, two fold. I think it was just to understand, like, you know, what you guys are seeing, because I know that RL is basically the hottest topic, probably right now. So wanted to understand, like, you know, what you have seen, any feedback, like, you know, on
14:21the direction of
S Speaker 114:23industry, I'm thinking, yeah, Shivam so yes, very interesting space. I haven't actually, like taken a theoretical sort of look at this space, but when I we did one investment in this space recently, run by another partner, so I have some sense from there. And then I'm currently talking to one more company fits the exact thesis you're going for, and trying to see if we can go in the next round or a be this company called adaptive ml. Have you? Have you? Adaptive ml? Yeah. So they raised a big round from inside very strong frame, X Mistral, and the founder there was initial writer of some RL paper. So he's well known in COVID. The entire thesis is, how do you sort of create a or how do you product tonight? Production is an RL pipeline such that it can be adopted by different order prices, and the three broader buckets that they're working on space is first creating a data pipeline. So for most of these use cases, like you mentioned, enterprises are not very keen on sort of giving their data out. So and also to actually run a end to end RL loop, you need significant numbers of samples, more than 1000s, to actually get some loops. May upload which engineers by tiny on several you have to make sure that you also cover the entire spectrum of data that you want to capture different sort of workflows. Get Enough variability in there to go coffee, mush, killer, so they have a synthetic data pipeline as well, which then goes back to your point of creating an environment for most of these use cases. Like separately, I'll talk more about adaptive but separately, I've been seeing a lot of RL and use cases in embodied AI per se, so sorry, robotic models, every simulation engines that are being built for verticalized robotic models or cheese. You have a very in a sense, RL came from that world. They have a much better established pipeline, seeing a lot of companies sort of building that, and most of it is coming from a sim to real, real to Sim environment. So they have a 3d environment. You sort of create a replica of your robot in there and there, you have very set established rules on evaluations for in their world, like in adaptive world, a similar sort of analogy would be creating a virtual machine, kind of an environment. You have a synthetic data pipeline that you start with, you have a workflow that you have automated for them, again, I haven't seen them sort of attempting very complex workflows of multi step agents as a Bucha. What they're trying to do is, how do you train a SLM on one more defined sort of a workflow at a enterprise which is high value, high volume, and how do you sort of then use an SLM to do a better job that frontier model, and then sort of run them, run it on the trim to enterprise value proposition. Then they have this entire they sort of have a training pipeline. They train the models iteratively based on synthetic data and custom a platform to create evaluations. And that is AI as a judge kind of thing, wherein, this is where the art part of it comes, right? Like you said. So this is where they have, like enough amount of tech talent internally to do this. From what I hear in the market, I think eval part is the most critical part, and a lot of people are not really open to sharing it. So that seems like how the secret shots for all of these companies is shaping.
industry, I'm thinking, yeah, Shivam so yes, very interesting space. I haven't actually, like taken a theoretical sort of look at this space, but when I we did one investment in this space recently, run by another partner, so I have some sense from there. And then I'm currently talking to one more company fits the exact thesis you're going for, and trying to see if we can go in the next round or a be this company called adaptive ml. Have you? Have you? Adaptive ml? Yeah. So they raised a big round from inside very strong frame, X Mistral, and the founder there was initial writer of some RL paper. So he's well known in COVID. The entire thesis is, how do you sort of create a or how do you product tonight? Production is an RL pipeline such that it can be adopted by different order prices, and the three broader buckets that they're working on space is first creating a data pipeline. So for most of these use cases, like you mentioned, enterprises are not very keen on sort of giving their data out. So and also to actually run a end to end RL loop, you need significant numbers of samples, more than 1000s, to actually get some loops. May upload which engineers by tiny on several you have to make sure that you also cover the entire spectrum of data that you want to capture different sort of workflows. Get Enough variability in there to go coffee, mush, killer, so they have a synthetic data pipeline as well, which then goes back to your point of creating an environment for most of these use cases. Like separately, I'll talk more about adaptive but separately, I've been seeing a lot of RL and use cases in embodied AI per se, so sorry, robotic models, every simulation engines that are being built for verticalized robotic models or cheese. You have a very in a sense, RL came from that world. They have a much better established pipeline, seeing a lot of companies sort of building that, and most of it is coming from a sim to real, real to Sim environment. So they have a 3d environment. You sort of create a replica of your robot in there and there, you have very set established rules on evaluations for in their world, like in adaptive world, a similar sort of analogy would be creating a virtual machine, kind of an environment. You have a synthetic data pipeline that you start with, you have a workflow that you have automated for them, again, I haven't seen them sort of attempting very complex workflows of multi step agents as a Bucha. What they're trying to do is, how do you train a SLM on one more defined sort of a workflow at a enterprise which is high value, high volume, and how do you sort of then use an SLM to do a better job that frontier model, and then sort of run them, run it on the trim to enterprise value proposition. Then they have this entire they sort of have a training pipeline. They train the models iteratively based on synthetic data and custom a platform to create evaluations. And that is AI as a judge kind of thing, wherein, this is where the art part of it comes, right? Like you said. So this is where they have, like enough amount of tech talent internally to do this. From what I hear in the market, I think eval part is the most critical part, and a lot of people are not really open to sharing it. So that seems like how the secret shots for all of these companies is shaping.
industry, I'm thinking, yeah, Shivam so yes, very interesting space. I haven't actually, like taken a theoretical sort of look at this space, but when I we did one investment in this space recently, run by another partner, so I have some sense from there. And then I'm currently talking to one more company fits the exact thesis you're going for, and trying to see if we can go in the next round or a be this company called adaptive ml. Have you? Have you? Adaptive ml? Yeah. So they raised a big round from inside very strong frame, X Mistral, and the founder there was initial writer of some RL paper. So he's well known in COVID. The entire thesis is, how do you sort of create a or how do you product tonight? Production is an RL pipeline such that it can be adopted by different order prices, and the three broader buckets that they're working on space is first creating a data pipeline. So for most of these use cases, like you mentioned, enterprises are not very keen on sort of giving their data out. So and also to actually run a end to end RL loop, you need significant numbers of samples, more than 1000s, to actually get some loops. May upload which engineers by tiny on several you have to make sure that you also cover the entire spectrum of data that you want to capture different sort of workflows. Get Enough variability in there to go coffee, mush, killer, so they have a synthetic data pipeline as well, which then goes back to your point of creating an environment for most of these use cases. Like separately, I'll talk more about adaptive but separately, I've been seeing a lot of RL and use cases in embodied AI per se, so sorry, robotic models, every simulation engines that are being built for verticalized robotic models or cheese. You have a very in a sense, RL came from that world. They have a much better established pipeline, seeing a lot of companies sort of building that, and most of it is coming from a sim to real, real to Sim environment. So they have a 3d environment. You sort of create a replica of your robot in there and there, you have very set established rules on evaluations for in their world, like in adaptive world, a similar sort of analogy would be creating a virtual machine, kind of an environment. You have a synthetic data pipeline that you start with, you have a workflow that you have automated for them, again, I haven't seen them sort of attempting very complex workflows of multi step agents as a Bucha. What they're trying to do is, how do you train a SLM on one more defined sort of a workflow at a enterprise which is high value, high volume, and how do you sort of then use an SLM to do a better job that frontier model, and then sort of run them, run it on the trim to enterprise value proposition. Then they have this entire they sort of have a training pipeline. They train the models iteratively based on synthetic data and custom a platform to create evaluations. And that is AI as a judge kind of thing, wherein, this is where the art part of it comes, right? Like you said. So this is where they have, like enough amount of tech talent internally to do this. From what I hear in the market, I think eval part is the most critical part, and a lot of people are not really open to sharing it. So that seems like how the secret shots for all of these companies is shaping.
industry, I'm thinking, yeah, Shivam so yes, very interesting space. I haven't actually, like taken a theoretical sort of look at this space, but when I we did one investment in this space recently, run by another partner, so I have some sense from there. And then I'm currently talking to one more company fits the exact thesis you're going for, and trying to see if we can go in the next round or a be this company called adaptive ml. Have you? Have you? Adaptive ml? Yeah. So they raised a big round from inside very strong frame, X Mistral, and the founder there was initial writer of some RL paper. So he's well known in COVID. The entire thesis is, how do you sort of create a or how do you product tonight? Production is an RL pipeline such that it can be adopted by different order prices, and the three broader buckets that they're working on space is first creating a data pipeline. So for most of these use cases, like you mentioned, enterprises are not very keen on sort of giving their data out. So and also to actually run a end to end RL loop, you need significant numbers of samples, more than 1000s, to actually get some loops. May upload which engineers by tiny on several you have to make sure that you also cover the entire spectrum of data that you want to capture different sort of workflows. Get Enough variability in there to go coffee, mush, killer, so they have a synthetic data pipeline as well, which then goes back to your point of creating an environment for most of these use cases. Like separately, I'll talk more about adaptive but separately, I've been seeing a lot of RL and use cases in embodied AI per se, so sorry, robotic models, every simulation engines that are being built for verticalized robotic models or cheese. You have a very in a sense, RL came from that world. They have a much better established pipeline, seeing a lot of companies sort of building that, and most of it is coming from a sim to real, real to Sim environment. So they have a 3d environment. You sort of create a replica of your robot in there and there, you have very set established rules on evaluations for in their world, like in adaptive world, a similar sort of analogy would be creating a virtual machine, kind of an environment. You have a synthetic data pipeline that you start with, you have a workflow that you have automated for them, again, I haven't seen them sort of attempting very complex workflows of multi step agents as a Bucha. What they're trying to do is, how do you train a SLM on one more defined sort of a workflow at a enterprise which is high value, high volume, and how do you sort of then use an SLM to do a better job that frontier model, and then sort of run them, run it on the trim to enterprise value proposition. Then they have this entire they sort of have a training pipeline. They train the models iteratively based on synthetic data and custom a platform to create evaluations. And that is AI as a judge kind of thing, wherein, this is where the art part of it comes, right? Like you said. So this is where they have, like enough amount of tech talent internally to do this. From what I hear in the market, I think eval part is the most critical part, and a lot of people are not really open to sharing it. So that seems like how the secret shots for all of these companies is shaping.
18:42for sure. Yes, yes. I think you're
for sure. Yes, yes. I think you're
for sure. Yes, yes. I think you're
for sure. Yes, yes. I think you're
S Speaker 118:45rag optimizing a rack, doing optimizing a system prompt and things like that are commodity in the market. In general, you have you'll see people starting to work on context engineering, which is now a turn point for Pele. How do you go from a rack to a relational database to a knowledge graph, and how your system of retrieving some specific context for one particular agent run so that its accuracy is good to us. Below come, long term memory below come, and then execution engine, pillow come. What is the runtime? How do you run it? Is it scalable things like that? So mid learning, when I when I speak to some of these companies, I'm talking to a few AI agent, horizontal AI agent building companies, a few vertical ones. RL is on there, but I don't see most of them sort of having adopted that today, how do you sort of take a feedback loop in a workflow and then build a reward model around it? Is something I feel not a lot of these companies know yet, but also something that is on their sort of pipeline. So yeah, because what we figured was that
rag optimizing a rack, doing optimizing a system prompt and things like that are commodity in the market. In general, you have you'll see people starting to work on context engineering, which is now a turn point for Pele. How do you go from a rack to a relational database to a knowledge graph, and how your system of retrieving some specific context for one particular agent run so that its accuracy is good to us. Below come, long term memory below come, and then execution engine, pillow come. What is the runtime? How do you run it? Is it scalable things like that? So mid learning, when I when I speak to some of these companies, I'm talking to a few AI agent, horizontal AI agent building companies, a few vertical ones. RL is on there, but I don't see most of them sort of having adopted that today, how do you sort of take a feedback loop in a workflow and then build a reward model around it? Is something I feel not a lot of these companies know yet, but also something that is on their sort of pipeline. So yeah, because what we figured was that
rag optimizing a rack, doing optimizing a system prompt and things like that are commodity in the market. In general, you have you'll see people starting to work on context engineering, which is now a turn point for Pele. How do you go from a rack to a relational database to a knowledge graph, and how your system of retrieving some specific context for one particular agent run so that its accuracy is good to us. Below come, long term memory below come, and then execution engine, pillow come. What is the runtime? How do you run it? Is it scalable things like that? So mid learning, when I when I speak to some of these companies, I'm talking to a few AI agent, horizontal AI agent building companies, a few vertical ones. RL is on there, but I don't see most of them sort of having adopted that today, how do you sort of take a feedback loop in a workflow and then build a reward model around it? Is something I feel not a lot of these companies know yet, but also something that is on their sort of pipeline. So yeah, because what we figured was that
rag optimizing a rack, doing optimizing a system prompt and things like that are commodity in the market. In general, you have you'll see people starting to work on context engineering, which is now a turn point for Pele. How do you go from a rack to a relational database to a knowledge graph, and how your system of retrieving some specific context for one particular agent run so that its accuracy is good to us. Below come, long term memory below come, and then execution engine, pillow come. What is the runtime? How do you run it? Is it scalable things like that? So mid learning, when I when I speak to some of these companies, I'm talking to a few AI agent, horizontal AI agent building companies, a few vertical ones. RL is on there, but I don't see most of them sort of having adopted that today, how do you sort of take a feedback loop in a workflow and then build a reward model around it? Is something I feel not a lot of these companies know yet, but also something that is on their sort of pipeline. So yeah, because what we figured was that
19:56talent like, you know, it's either basically sitting in
talent like, you know, it's either basically sitting in
talent like, you know, it's either basically sitting in
talent like, you know, it's either basically sitting in
S Speaker 220:02a world of robotics and self driving cars, or basically, like, you know, it's in the big lab and from pick and open AI, right, who have been working on this part. Like, it's just very little talent, like, you know, who is basically going out and working in, I would say startups or enterprises, per se, but like, another way, I would say the other lrm stuff became popular very quickly. I think there's a good chance that it also later does. But so you're saying that Aaron is in the pipeline of most companies, but nobody has gotten to actually implementing it. But people do believe that this, okay, okay, super interesting. This kind of, like, you know, mandates, my core hypothesis key. The other question, like, you know, which basically I asked myself, is, how much of this is a point in time effort, and then when two fight, like, you know, basically comes, it will basically be very good, like, you know, in many domains, then you just do that and again. So do you guys have any view on that? Yeah, so coming
a world of robotics and self driving cars, or basically, like, you know, it's in the big lab and from pick and open AI, right, who have been working on this part. Like, it's just very little talent, like, you know, who is basically going out and working in, I would say startups or enterprises, per se, but like, another way, I would say the other lrm stuff became popular very quickly. I think there's a good chance that it also later does. But so you're saying that Aaron is in the pipeline of most companies, but nobody has gotten to actually implementing it. But people do believe that this, okay, okay, super interesting. This kind of, like, you know, mandates, my core hypothesis key. The other question, like, you know, which basically I asked myself, is, how much of this is a point in time effort, and then when two fight, like, you know, basically comes, it will basically be very good, like, you know, in many domains, then you just do that and again. So do you guys have any view on that? Yeah, so coming
a world of robotics and self driving cars, or basically, like, you know, it's in the big lab and from pick and open AI, right, who have been working on this part. Like, it's just very little talent, like, you know, who is basically going out and working in, I would say startups or enterprises, per se, but like, another way, I would say the other lrm stuff became popular very quickly. I think there's a good chance that it also later does. But so you're saying that Aaron is in the pipeline of most companies, but nobody has gotten to actually implementing it. But people do believe that this, okay, okay, super interesting. This kind of, like, you know, mandates, my core hypothesis key. The other question, like, you know, which basically I asked myself, is, how much of this is a point in time effort, and then when two fight, like, you know, basically comes, it will basically be very good, like, you know, in many domains, then you just do that and again. So do you guys have any view on that? Yeah, so coming
a world of robotics and self driving cars, or basically, like, you know, it's in the big lab and from pick and open AI, right, who have been working on this part. Like, it's just very little talent, like, you know, who is basically going out and working in, I would say startups or enterprises, per se, but like, another way, I would say the other lrm stuff became popular very quickly. I think there's a good chance that it also later does. But so you're saying that Aaron is in the pipeline of most companies, but nobody has gotten to actually implementing it. But people do believe that this, okay, okay, super interesting. This kind of, like, you know, mandates, my core hypothesis key. The other question, like, you know, which basically I asked myself, is, how much of this is a point in time effort, and then when two fight, like, you know, basically comes, it will basically be very good, like, you know, in many domains, then you just do that and again. So do you guys have any view on that? Yeah, so coming
S Speaker 121:08back to the adaptive value prop, their value prop, using RL was not a gain in accuracy, but rather, how do you get the same level of accuracy at a much cheaper cost? Can you run it on prem? Can you actually make it, sort of produce it in an environment, in an enterprise environment, kind of thing? So going value property, you become that way, I think that will not get commoditized because oh three or the next, next model from open AI frontier model would be larger, would be better in a lot of domains, would cost more, sort of thing on the other end, if, on the other end, let's say there's this, another company called pokey AI. They have this is, this is why? Sorry,
back to the adaptive value prop, their value prop, using RL was not a gain in accuracy, but rather, how do you get the same level of accuracy at a much cheaper cost? Can you run it on prem? Can you actually make it, sort of produce it in an environment, in an enterprise environment, kind of thing? So going value property, you become that way, I think that will not get commoditized because oh three or the next, next model from open AI frontier model would be larger, would be better in a lot of domains, would cost more, sort of thing on the other end, if, on the other end, let's say there's this, another company called pokey AI. They have this is, this is why? Sorry,
back to the adaptive value prop, their value prop, using RL was not a gain in accuracy, but rather, how do you get the same level of accuracy at a much cheaper cost? Can you run it on prem? Can you actually make it, sort of produce it in an environment, in an enterprise environment, kind of thing? So going value property, you become that way, I think that will not get commoditized because oh three or the next, next model from open AI frontier model would be larger, would be better in a lot of domains, would cost more, sort of thing on the other end, if, on the other end, let's say there's this, another company called pokey AI. They have this is, this is why? Sorry,
back to the adaptive value prop, their value prop, using RL was not a gain in accuracy, but rather, how do you get the same level of accuracy at a much cheaper cost? Can you run it on prem? Can you actually make it, sort of produce it in an environment, in an enterprise environment, kind of thing? So going value property, you become that way, I think that will not get commoditized because oh three or the next, next model from open AI frontier model would be larger, would be better in a lot of domains, would cost more, sort of thing on the other end, if, on the other end, let's say there's this, another company called pokey AI. They have this is, this is why? Sorry,
S Speaker 122:02poke okay, this is one of our recent investments, not announced yet. They have a base system to make function calling at agent tech infrastructure, Agent building companies more efficient so when you sort of have a very dynamic environment or COVID function to use. So when you sort of create an agent which uses more than 100, 200 agents, or has access to them and can dynamically call them, yeah, it the cost of it increases very significantly, exponentially, in a sense. So there this guy is RL engine, he has created one way he cost scales linearly, or in the function calling, using RL is poised to be the best function calling algo that you would use to and you can possibly use it to create a manners kind of thing, General Purpose agents. So in the planet, sorry. My initial thought, I think the question was that basically play on the cost, right? So in this case, this is when they are going more, I would say, deeper into workflows and then actually using very tight feedback loops on which function called, very ingrained function, function calling across 1000 tools, the workflow modular or tight net, I would say that frontier model would not be able to replicate. Got it? Got it. So you're just saying key like be very what you want to do, right?
poke okay, this is one of our recent investments, not announced yet. They have a base system to make function calling at agent tech infrastructure, Agent building companies more efficient so when you sort of have a very dynamic environment or COVID function to use. So when you sort of create an agent which uses more than 100, 200 agents, or has access to them and can dynamically call them, yeah, it the cost of it increases very significantly, exponentially, in a sense. So there this guy is RL engine, he has created one way he cost scales linearly, or in the function calling, using RL is poised to be the best function calling algo that you would use to and you can possibly use it to create a manners kind of thing, General Purpose agents. So in the planet, sorry. My initial thought, I think the question was that basically play on the cost, right? So in this case, this is when they are going more, I would say, deeper into workflows and then actually using very tight feedback loops on which function called, very ingrained function, function calling across 1000 tools, the workflow modular or tight net, I would say that frontier model would not be able to replicate. Got it? Got it. So you're just saying key like be very what you want to do, right?
poke okay, this is one of our recent investments, not announced yet. They have a base system to make function calling at agent tech infrastructure, Agent building companies more efficient so when you sort of have a very dynamic environment or COVID function to use. So when you sort of create an agent which uses more than 100, 200 agents, or has access to them and can dynamically call them, yeah, it the cost of it increases very significantly, exponentially, in a sense. So there this guy is RL engine, he has created one way he cost scales linearly, or in the function calling, using RL is poised to be the best function calling algo that you would use to and you can possibly use it to create a manners kind of thing, General Purpose agents. So in the planet, sorry. My initial thought, I think the question was that basically play on the cost, right? So in this case, this is when they are going more, I would say, deeper into workflows and then actually using very tight feedback loops on which function called, very ingrained function, function calling across 1000 tools, the workflow modular or tight net, I would say that frontier model would not be able to replicate. Got it? Got it. So you're just saying key like be very what you want to do, right?
poke okay, this is one of our recent investments, not announced yet. They have a base system to make function calling at agent tech infrastructure, Agent building companies more efficient so when you sort of have a very dynamic environment or COVID function to use. So when you sort of create an agent which uses more than 100, 200 agents, or has access to them and can dynamically call them, yeah, it the cost of it increases very significantly, exponentially, in a sense. So there this guy is RL engine, he has created one way he cost scales linearly, or in the function calling, using RL is poised to be the best function calling algo that you would use to and you can possibly use it to create a manners kind of thing, General Purpose agents. So in the planet, sorry. My initial thought, I think the question was that basically play on the cost, right? So in this case, this is when they are going more, I would say, deeper into workflows and then actually using very tight feedback loops on which function called, very ingrained function, function calling across 1000 tools, the workflow modular or tight net, I would say that frontier model would not be able to replicate. Got it? Got it. So you're just saying key like be very what you want to do, right?
S Speaker 223:42So, there are more career that I think probably you are, like, outside the blast areas of the next model release, yeah, MENA B, I think same hypothesis, for example, like, you know, I was just imagining that what the O by team will be keeping, right now, it's all about, creating these new places. Now they can create like these 1000s, or like, you know, 10s of 1000s of places for, let's say math problems, science problems, coding problems, everything more specific and do it. Let's say for accounting. Can Do It Like for legal, can do it for like HR, these like very deep areas. But when you think about the actual things after that, let's say procurement, supply chain, we are like all your entire back office. And when you think about verticals like you know, that are targeting shipping companies, energy companies, so I think those kind of things, like you know, will still be away from the past eight years. And if you are verticalizing for those use cases. Yeah, so I think a good way, but I think looks like more hypothesis here. They still stand through that like, you know, RL will outperform the other existing techniques, and the next module iteration, like, you know, won't shorten the gap so much. Key, it becomes useless. So makes sense to like, you know, be in this space, and make sense to like, sort of build something. Tkr, sounds good. The other question I wanted to, like, look at your thoughts on was, like, in your crisis, research. Like, you know, what is the like that you have figured out key RMA, like, you know, what is basically one thing that needs to be solved for people who adopted pretty
So, there are more career that I think probably you are, like, outside the blast areas of the next model release, yeah, MENA B, I think same hypothesis, for example, like, you know, I was just imagining that what the O by team will be keeping, right now, it's all about, creating these new places. Now they can create like these 1000s, or like, you know, 10s of 1000s of places for, let's say math problems, science problems, coding problems, everything more specific and do it. Let's say for accounting. Can Do It Like for legal, can do it for like HR, these like very deep areas. But when you think about the actual things after that, let's say procurement, supply chain, we are like all your entire back office. And when you think about verticals like you know, that are targeting shipping companies, energy companies, so I think those kind of things, like you know, will still be away from the past eight years. And if you are verticalizing for those use cases. Yeah, so I think a good way, but I think looks like more hypothesis here. They still stand through that like, you know, RL will outperform the other existing techniques, and the next module iteration, like, you know, won't shorten the gap so much. Key, it becomes useless. So makes sense to like, you know, be in this space, and make sense to like, sort of build something. Tkr, sounds good. The other question I wanted to, like, look at your thoughts on was, like, in your crisis, research. Like, you know, what is the like that you have figured out key RMA, like, you know, what is basically one thing that needs to be solved for people who adopted pretty
So, there are more career that I think probably you are, like, outside the blast areas of the next model release, yeah, MENA B, I think same hypothesis, for example, like, you know, I was just imagining that what the O by team will be keeping, right now, it's all about, creating these new places. Now they can create like these 1000s, or like, you know, 10s of 1000s of places for, let's say math problems, science problems, coding problems, everything more specific and do it. Let's say for accounting. Can Do It Like for legal, can do it for like HR, these like very deep areas. But when you think about the actual things after that, let's say procurement, supply chain, we are like all your entire back office. And when you think about verticals like you know, that are targeting shipping companies, energy companies, so I think those kind of things, like you know, will still be away from the past eight years. And if you are verticalizing for those use cases. Yeah, so I think a good way, but I think looks like more hypothesis here. They still stand through that like, you know, RL will outperform the other existing techniques, and the next module iteration, like, you know, won't shorten the gap so much. Key, it becomes useless. So makes sense to like, you know, be in this space, and make sense to like, sort of build something. Tkr, sounds good. The other question I wanted to, like, look at your thoughts on was, like, in your crisis, research. Like, you know, what is the like that you have figured out key RMA, like, you know, what is basically one thing that needs to be solved for people who adopted pretty
So, there are more career that I think probably you are, like, outside the blast areas of the next model release, yeah, MENA B, I think same hypothesis, for example, like, you know, I was just imagining that what the O by team will be keeping, right now, it's all about, creating these new places. Now they can create like these 1000s, or like, you know, 10s of 1000s of places for, let's say math problems, science problems, coding problems, everything more specific and do it. Let's say for accounting. Can Do It Like for legal, can do it for like HR, these like very deep areas. But when you think about the actual things after that, let's say procurement, supply chain, we are like all your entire back office. And when you think about verticals like you know, that are targeting shipping companies, energy companies, so I think those kind of things, like you know, will still be away from the past eight years. And if you are verticalizing for those use cases. Yeah, so I think a good way, but I think looks like more hypothesis here. They still stand through that like, you know, RL will outperform the other existing techniques, and the next module iteration, like, you know, won't shorten the gap so much. Key, it becomes useless. So makes sense to like, you know, be in this space, and make sense to like, sort of build something. Tkr, sounds good. The other question I wanted to, like, look at your thoughts on was, like, in your crisis, research. Like, you know, what is the like that you have figured out key RMA, like, you know, what is basically one thing that needs to be solved for people who adopted pretty
25:23quickly, yeah, personally,
quickly, yeah, personally,
quickly, yeah, personally,
quickly, yeah, personally,
S Speaker 125:26I would say just being able to create a good eval, and then that could boil down into a lot of sub points, just Short naobi. But the way I sort of envision it is, I can be very wrong here, but, but I need a more, sort of defined framework, and an easier way to sort of create evals based on business language per se. So this, yeah, this one company that we are talking to is called hyper mode, AI, Agent building company using natural language to prompt agent built background. Then you deploy a code out of it, and then you use the land thing to sort of make it more harden in May he, the way that they are trying to approach it in a way, if he they have a proprietary knowledge graph. Every run of agent, everything is then created as an additional node in the Knowledge Graph. So the next time the agent is running, it has more state. It has more knowledge of the last time builds on top of that. So in the same way, they're trying to what they essentially says every agent run, we capture it, so we have a sense of how processes are run. And down the line, they want to sort of use an RL engine to optimize their agents to get better at this, and then follow one business logic, like, how would a business analyst at Blackrock would operate? And then you exactly operate the agent based on that to maybe a pipeline to I, as a subject matter expert, I understand as a workflow run, and I can capture the knowledge based on that workflow. But how do I create them and then run the entire thing so that my small agent thing can get better? Is, is something that I would like to see, maybe
I would say just being able to create a good eval, and then that could boil down into a lot of sub points, just Short naobi. But the way I sort of envision it is, I can be very wrong here, but, but I need a more, sort of defined framework, and an easier way to sort of create evals based on business language per se. So this, yeah, this one company that we are talking to is called hyper mode, AI, Agent building company using natural language to prompt agent built background. Then you deploy a code out of it, and then you use the land thing to sort of make it more harden in May he, the way that they are trying to approach it in a way, if he they have a proprietary knowledge graph. Every run of agent, everything is then created as an additional node in the Knowledge Graph. So the next time the agent is running, it has more state. It has more knowledge of the last time builds on top of that. So in the same way, they're trying to what they essentially says every agent run, we capture it, so we have a sense of how processes are run. And down the line, they want to sort of use an RL engine to optimize their agents to get better at this, and then follow one business logic, like, how would a business analyst at Blackrock would operate? And then you exactly operate the agent based on that to maybe a pipeline to I, as a subject matter expert, I understand as a workflow run, and I can capture the knowledge based on that workflow. But how do I create them and then run the entire thing so that my small agent thing can get better? Is, is something that I would like to see, maybe
I would say just being able to create a good eval, and then that could boil down into a lot of sub points, just Short naobi. But the way I sort of envision it is, I can be very wrong here, but, but I need a more, sort of defined framework, and an easier way to sort of create evals based on business language per se. So this, yeah, this one company that we are talking to is called hyper mode, AI, Agent building company using natural language to prompt agent built background. Then you deploy a code out of it, and then you use the land thing to sort of make it more harden in May he, the way that they are trying to approach it in a way, if he they have a proprietary knowledge graph. Every run of agent, everything is then created as an additional node in the Knowledge Graph. So the next time the agent is running, it has more state. It has more knowledge of the last time builds on top of that. So in the same way, they're trying to what they essentially says every agent run, we capture it, so we have a sense of how processes are run. And down the line, they want to sort of use an RL engine to optimize their agents to get better at this, and then follow one business logic, like, how would a business analyst at Blackrock would operate? And then you exactly operate the agent based on that to maybe a pipeline to I, as a subject matter expert, I understand as a workflow run, and I can capture the knowledge based on that workflow. But how do I create them and then run the entire thing so that my small agent thing can get better? Is, is something that I would like to see, maybe
I would say just being able to create a good eval, and then that could boil down into a lot of sub points, just Short naobi. But the way I sort of envision it is, I can be very wrong here, but, but I need a more, sort of defined framework, and an easier way to sort of create evals based on business language per se. So this, yeah, this one company that we are talking to is called hyper mode, AI, Agent building company using natural language to prompt agent built background. Then you deploy a code out of it, and then you use the land thing to sort of make it more harden in May he, the way that they are trying to approach it in a way, if he they have a proprietary knowledge graph. Every run of agent, everything is then created as an additional node in the Knowledge Graph. So the next time the agent is running, it has more state. It has more knowledge of the last time builds on top of that. So in the same way, they're trying to what they essentially says every agent run, we capture it, so we have a sense of how processes are run. And down the line, they want to sort of use an RL engine to optimize their agents to get better at this, and then follow one business logic, like, how would a business analyst at Blackrock would operate? And then you exactly operate the agent based on that to maybe a pipeline to I, as a subject matter expert, I understand as a workflow run, and I can capture the knowledge based on that workflow. But how do I create them and then run the entire thing so that my small agent thing can get better? Is, is something that I would like to see, maybe
27:25got it, got it. And
S Speaker 227:30do you know, like these other companies here, Applied Computer that OpenAI team that raised from benchmark and Sakura,
do you know, like these other companies here, Applied Computer that OpenAI team that raised from benchmark and Sakura,
do you know, like these other companies here, Applied Computer that OpenAI team that raised from benchmark and Sakura,
do you know, like these other companies here, Applied Computer that OpenAI team that raised from benchmark and Sakura,
27:38are doing me, I not actually, I haven't heard of them.
are doing me, I not actually, I haven't heard of them.
are doing me, I not actually, I haven't heard of them.
are doing me, I not actually, I haven't heard of them.
27:41Yeah, so I think this was basically a hot news last week,
Yeah, so I think this was basically a hot news last week,
Yeah, so I think this was basically a hot news last week,
Yeah, so I think this was basically a hot news last week,
S Speaker 227:46some like three kids from OpenAI, who worked on reinforcement learning, stepped out.
some like three kids from OpenAI, who worked on reinforcement learning, stepped out.
some like three kids from OpenAI, who worked on reinforcement learning, stepped out.
some like three kids from OpenAI, who worked on reinforcement learning, stepped out.
27:53What was the company? Part?
What was the company? Part?
What was the company? Part?
What was the company? Part?
27:55Applied compute. I
S Speaker 228:31very curious to know, like, what direction they are taking. I think there was one more company which I had come across. I am not sure if they raised from, let's say, very top tier, bc they released
very curious to know, like, what direction they are taking. I think there was one more company which I had come across. I am not sure if they raised from, let's say, very top tier, bc they released
very curious to know, like, what direction they are taking. I think there was one more company which I had come across. I am not sure if they raised from, let's say, very top tier, bc they released
very curious to know, like, what direction they are taking. I think there was one more company which I had come across. I am not sure if they raised from, let's say, very top tier, bc they released
S Speaker 128:49from, what about the firm decibel I have, but I don't know them. I
from, what about the firm decibel I have, but I don't know them. I
from, what about the firm decibel I have, but I don't know them. I
from, what about the firm decibel I have, but I don't know them. I
S Speaker 228:56think they have done PR and stuff so pretty. I already out there. Venice.ai, V, E, R, I, s.ai,
think they have done PR and stuff so pretty. I already out there. Venice.ai, V, E, R, I, s.ai,
think they have done PR and stuff so pretty. I already out there. Venice.ai, V, E, R, I, s.ai,
think they have done PR and stuff so pretty. I already out there. Venice.ai, V, E, R, I, s.ai,
S Speaker 129:09it has been one of one. It's in our pipeline. Yeah, any,
it has been one of one. It's in our pipeline. Yeah, any,
it has been one of one. It's in our pipeline. Yeah, any,
it has been one of one. It's in our pipeline. Yeah, any,
29:21here? This is a reminder. Drink water, I
here? This is a reminder. Drink water, I
here? This is a reminder. Drink water, I
here? This is a reminder. Drink water, I
29:47yeah, I can send you some much.
yeah, I can send you some much.
yeah, I can send you some much.
yeah, I can send you some much.
29:52Yeah, if you can, then it will be
Yeah, if you can, then it will be
Yeah, if you can, then it will be
Yeah, if you can, then it will be
29:56super intro one pager.
super intro one pager.
super intro one pager.
super intro one pager.
S Speaker 130:00Seems like a simulation engine to train agents. And the thesis is you would need a simulated sandbox environment to train agents. So that on the price, is my option? Fast over?
Seems like a simulation engine to train agents. And the thesis is you would need a simulated sandbox environment to train agents. So that on the price, is my option? Fast over?
Seems like a simulation engine to train agents. And the thesis is you would need a simulated sandbox environment to train agents. So that on the price, is my option? Fast over?
Seems like a simulation engine to train agents. And the thesis is you would need a simulated sandbox environment to train agents. So that on the price, is my option? Fast over?
S Speaker 230:14Yeah, I think very similar direction to what I was pitching earlier. Got it. So looks like there is, like, you know, activity in this space, people building and, like, being able to raise money,
Yeah, I think very similar direction to what I was pitching earlier. Got it. So looks like there is, like, you know, activity in this space, people building and, like, being able to raise money,
Yeah, I think very similar direction to what I was pitching earlier. Got it. So looks like there is, like, you know, activity in this space, people building and, like, being able to raise money,
Yeah, I think very similar direction to what I was pitching earlier. Got it. So looks like there is, like, you know, activity in this space, people building and, like, being able to raise money,
30:28yeah, actually, bro,
S Speaker 130:32one question I would have is, it seems like it's a technical problem to solve, like you have to have the technical talent on the team to do it so, and then that's, that's the blocker for a lot of these companies. How are you thinking about building
one question I would have is, it seems like it's a technical problem to solve, like you have to have the technical talent on the team to do it so, and then that's, that's the blocker for a lot of these companies. How are you thinking about building
one question I would have is, it seems like it's a technical problem to solve, like you have to have the technical talent on the team to do it so, and then that's, that's the blocker for a lot of these companies. How are you thinking about building
one question I would have is, it seems like it's a technical problem to solve, like you have to have the technical talent on the team to do it so, and then that's, that's the blocker for a lot of these companies. How are you thinking about building
S Speaker 135:56import, I am in discussions with the adaptive guys, trying to save full Qualcomm partnership. So if anything establishes one assignment which I can possibly connect you to those guys, and then I'm doing a thesis on physical AI. So talking to some of these folks in the robotic side of things, man, if, if I come across anyone, I'll connect you to them. I'll keep an eye any any
import, I am in discussions with the adaptive guys, trying to save full Qualcomm partnership. So if anything establishes one assignment which I can possibly connect you to those guys, and then I'm doing a thesis on physical AI. So talking to some of these folks in the robotic side of things, man, if, if I come across anyone, I'll connect you to them. I'll keep an eye any any
import, I am in discussions with the adaptive guys, trying to save full Qualcomm partnership. So if anything establishes one assignment which I can possibly connect you to those guys, and then I'm doing a thesis on physical AI. So talking to some of these folks in the robotic side of things, man, if, if I come across anyone, I'll connect you to them. I'll keep an eye any any
import, I am in discussions with the adaptive guys, trying to save full Qualcomm partnership. So if anything establishes one assignment which I can possibly connect you to those guys, and then I'm doing a thesis on physical AI. So talking to some of these folks in the robotic side of things, man, if, if I come across anyone, I'll connect you to them. I'll keep an eye any any
36:19other thoughts or angles let me
other thoughts or angles let me
other thoughts or angles let me
other thoughts or angles let me
36:22know. We know which the thing we are missing? Yeah,
know. We know which the thing we are missing? Yeah,
know. We know which the thing we are missing? Yeah,
know. We know which the thing we are missing? Yeah,
S Speaker 136:29I don't know. I don't know enough about it to say that, but I think it's it will be a trade off between, do you go very vertical and you build for a vertical and then you are an application of an RL pipeline, or are you a product? Or are you productizing RL as a pipeline and then going to different verticals, degree of being horizontal versus vertical there, though, I'll
I don't know. I don't know enough about it to say that, but I think it's it will be a trade off between, do you go very vertical and you build for a vertical and then you are an application of an RL pipeline, or are you a product? Or are you productizing RL as a pipeline and then going to different verticals, degree of being horizontal versus vertical there, though, I'll
I don't know. I don't know enough about it to say that, but I think it's it will be a trade off between, do you go very vertical and you build for a vertical and then you are an application of an RL pipeline, or are you a product? Or are you productizing RL as a pipeline and then going to different verticals, degree of being horizontal versus vertical there, though, I'll
I don't know. I don't know enough about it to say that, but I think it's it will be a trade off between, do you go very vertical and you build for a vertical and then you are an application of an RL pipeline, or are you a product? Or are you productizing RL as a pipeline and then going to different verticals, degree of being horizontal versus vertical there, though, I'll
37:00be curious to know when,
be curious to know when,
be curious to know when,
be curious to know when,
37:01when you think of, yeah, yeah.
when you think of, yeah, yeah.
when you think of, yeah, yeah.
when you think of, yeah, yeah.
S Speaker 237:04I think when I switched to the operating side, like, you know, I just realized that these questions are so hard to answer upfront, right? All you can do is you can make an informed guess about the how the world. And you just, like, you know, basically get some customers, raise some money on the back of that test, and then you experiment, maybe in two years that you land is very different from where you started, and that's what I think is of the best. So yeah, but I do agree, if you constrain the problem as much as
I think when I switched to the operating side, like, you know, I just realized that these questions are so hard to answer upfront, right? All you can do is you can make an informed guess about the how the world. And you just, like, you know, basically get some customers, raise some money on the back of that test, and then you experiment, maybe in two years that you land is very different from where you started, and that's what I think is of the best. So yeah, but I do agree, if you constrain the problem as much as
I think when I switched to the operating side, like, you know, I just realized that these questions are so hard to answer upfront, right? All you can do is you can make an informed guess about the how the world. And you just, like, you know, basically get some customers, raise some money on the back of that test, and then you experiment, maybe in two years that you land is very different from where you started, and that's what I think is of the best. So yeah, but I do agree, if you constrain the problem as much as
I think when I switched to the operating side, like, you know, I just realized that these questions are so hard to answer upfront, right? All you can do is you can make an informed guess about the how the world. And you just, like, you know, basically get some customers, raise some money on the back of that test, and then you experiment, maybe in two years that you land is very different from where you started, and that's what I think is of the best. So yeah, but I do agree, if you constrain the problem as much as
37:38you can, I mean,
S Speaker 137:48we have some absolutely bro say, Keep me posted. Like it sounds very fun when you speak about it, though, psycho perspective is pretty cool. It must be fun on your end as well. Yeah, it is.
we have some absolutely bro say, Keep me posted. Like it sounds very fun when you speak about it, though, psycho perspective is pretty cool. It must be fun on your end as well. Yeah, it is.
we have some absolutely bro say, Keep me posted. Like it sounds very fun when you speak about it, though, psycho perspective is pretty cool. It must be fun on your end as well. Yeah, it is.
we have some absolutely bro say, Keep me posted. Like it sounds very fun when you speak about it, though, psycho perspective is pretty cool. It must be fun on your end as well. Yeah, it is.
S Speaker 238:01I think the challenge I'm facing is key. Like, you know, I personally have very few hard skill sets so that and you have to, like, you know, get people to do it. Customer skill. You have to basically do and convince people. So I sometimes do wish that hard skill set. If I got this idea, if I was able to create it myself, yeah? But, I mean, you translate it to, like, you know, a document, then you convince people that, hey, it's a good so I think that part, like, you know, is something which I'm facing a challenge,
I think the challenge I'm facing is key. Like, you know, I personally have very few hard skill sets so that and you have to, like, you know, get people to do it. Customer skill. You have to basically do and convince people. So I sometimes do wish that hard skill set. If I got this idea, if I was able to create it myself, yeah? But, I mean, you translate it to, like, you know, a document, then you convince people that, hey, it's a good so I think that part, like, you know, is something which I'm facing a challenge,
I think the challenge I'm facing is key. Like, you know, I personally have very few hard skill sets so that and you have to, like, you know, get people to do it. Customer skill. You have to basically do and convince people. So I sometimes do wish that hard skill set. If I got this idea, if I was able to create it myself, yeah? But, I mean, you translate it to, like, you know, a document, then you convince people that, hey, it's a good so I think that part, like, you know, is something which I'm facing a challenge,
I think the challenge I'm facing is key. Like, you know, I personally have very few hard skill sets so that and you have to, like, you know, get people to do it. Customer skill. You have to basically do and convince people. So I sometimes do wish that hard skill set. If I got this idea, if I was able to create it myself, yeah? But, I mean, you translate it to, like, you know, a document, then you convince people that, hey, it's a good so I think that part, like, you know, is something which I'm facing a challenge,
S Speaker 138:37yeah? But I think the you should think, think about it this way, if you actually go through this part and you you have a PMF, sort of then the orchestrator in, you will have the edge there. So, so then you'll be able to sort of add real value. So, yeah, initial fast, but then then you have actual value, basically,
yeah? But I think the you should think, think about it this way, if you actually go through this part and you you have a PMF, sort of then the orchestrator in, you will have the edge there. So, so then you'll be able to sort of add real value. So, yeah, initial fast, but then then you have actual value, basically,
yeah? But I think the you should think, think about it this way, if you actually go through this part and you you have a PMF, sort of then the orchestrator in, you will have the edge there. So, so then you'll be able to sort of add real value. So, yeah, initial fast, but then then you have actual value, basically,
yeah? But I think the you should think, think about it this way, if you actually go through this part and you you have a PMF, sort of then the orchestrator in, you will have the edge there. So, so then you'll be able to sort of add real value. So, yeah, initial fast, but then then you have actual value, basically,
39:14for you. By starting here. Keep people.
for you. By starting here. Keep people.
for you. By starting here. Keep people.
for you. By starting here. Keep people.