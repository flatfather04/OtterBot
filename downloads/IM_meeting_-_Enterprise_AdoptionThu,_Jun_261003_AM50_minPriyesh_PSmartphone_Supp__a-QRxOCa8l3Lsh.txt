Meeting: IM meeting - Enterprise Adoption
Thu, Jun 26
10:03 AM
50 min
Priyesh P
Smartphone Supply Chain and C
URL: https://otter.ai/u/_a-QRxOCa8l3LshDv4UfKFcRzn8
Downloaded: 2025-12-21T21:49:05.697291
Method: text_extraction
============================================================

S Speaker 10:00Uh, there was only one thing. So the good news is, I don't think there's anything different that from what we pitch to the start. So I was missing out on sliding. There was one thing that he said that that was different. I thought was okay. Was like to figure he said that if you're looking at, you know, so we're shipping about 200 million smartphones per quarter. And then if you're looking to get to that level of scale, even a few million units per quarter of scale, if you're thinking about that, then there's no other supply chain that's figured that out, other than the smartphones so. So then, essentially, we're the partner of choice. And then you made a few other which is, you know, there's a lot of components like you blocked out figure AI and these, like, the amount, the number of components that exist in this humanoid are immense, all the way from the shoulder chassis to your camera components to your motor controls to your brain of the robot. And then for each one of these, there's so many circuits. And then the idea is that you eventually have to shrink them down, and then you have to combine them, and then have central compute units do most of the compute, versus distributing them all over, because then there's more moving parts. So the argument is that, if you it's this is, treat this as a consumer electronics device, and then, as you see with most consumer electronics, they get compressed over time, right? And then there's no other smart value chain that's figured that out. So that was the that was the only thing that I thought we don't pitch. But that doesn't matter, because we only it doesn't apply to a lot of the software startups. But other than that, the edge AI component and everything else was exactly the same.
Uh, there was only one thing. So the good news is, I don't think there's anything different that from what we pitch to the start. So I was missing out on sliding. There was one thing that he said that that was different. I thought was okay. Was like to figure he said that if you're looking at, you know, so we're shipping about 200 million smartphones per quarter. And then if you're looking to get to that level of scale, even a few million units per quarter of scale, if you're thinking about that, then there's no other supply chain that's figured that out, other than the smartphones so. So then, essentially, we're the partner of choice. And then you made a few other which is, you know, there's a lot of components like you blocked out figure AI and these, like, the amount, the number of components that exist in this humanoid are immense, all the way from the shoulder chassis to your camera components to your motor controls to your brain of the robot. And then for each one of these, there's so many circuits. And then the idea is that you eventually have to shrink them down, and then you have to combine them, and then have central compute units do most of the compute, versus distributing them all over, because then there's more moving parts. So the argument is that, if you it's this is, treat this as a consumer electronics device, and then, as you see with most consumer electronics, they get compressed over time, right? And then there's no other smart value chain that's figured that out. So that was the that was the only thing that I thought we don't pitch. But that doesn't matter, because we only it doesn't apply to a lot of the software startups. But other than that, the edge AI component and everything else was exactly the same.
Uh, there was only one thing. So the good news is, I don't think there's anything different that from what we pitch to the start. So I was missing out on sliding. There was one thing that he said that that was different. I thought was okay. Was like to figure he said that if you're looking at, you know, so we're shipping about 200 million smartphones per quarter. And then if you're looking to get to that level of scale, even a few million units per quarter of scale, if you're thinking about that, then there's no other supply chain that's figured that out, other than the smartphones so. So then, essentially, we're the partner of choice. And then you made a few other which is, you know, there's a lot of components like you blocked out figure AI and these, like, the amount, the number of components that exist in this humanoid are immense, all the way from the shoulder chassis to your camera components to your motor controls to your brain of the robot. And then for each one of these, there's so many circuits. And then the idea is that you eventually have to shrink them down, and then you have to combine them, and then have central compute units do most of the compute, versus distributing them all over, because then there's more moving parts. So the argument is that, if you it's this is, treat this as a consumer electronics device, and then, as you see with most consumer electronics, they get compressed over time, right? And then there's no other smart value chain that's figured that out. So that was the that was the only thing that I thought we don't pitch. But that doesn't matter, because we only it doesn't apply to a lot of the software startups. But other than that, the edge AI component and everything else was exactly the same.
Uh, there was only one thing. So the good news is, I don't think there's anything different that from what we pitch to the start. So I was missing out on sliding. There was one thing that he said that that was different. I thought was okay. Was like to figure he said that if you're looking at, you know, so we're shipping about 200 million smartphones per quarter. And then if you're looking to get to that level of scale, even a few million units per quarter of scale, if you're thinking about that, then there's no other supply chain that's figured that out, other than the smartphones so. So then, essentially, we're the partner of choice. And then you made a few other which is, you know, there's a lot of components like you blocked out figure AI and these, like, the amount, the number of components that exist in this humanoid are immense, all the way from the shoulder chassis to your camera components to your motor controls to your brain of the robot. And then for each one of these, there's so many circuits. And then the idea is that you eventually have to shrink them down, and then you have to combine them, and then have central compute units do most of the compute, versus distributing them all over, because then there's more moving parts. So the argument is that, if you it's this is, treat this as a consumer electronics device, and then, as you see with most consumer electronics, they get compressed over time, right? And then there's no other smart value chain that's figured that out. So that was the that was the only thing that I thought we don't pitch. But that doesn't matter, because we only it doesn't apply to a lot of the software startups. But other than that, the edge AI component and everything else was exactly the same.
1:59We might have a few more
We might have a few more
We might have a few more
We might have a few more
S Speaker 12:03but he anyway. So the request is, supposedly, he's meeting David Sachs tomorrow. And this is a last minute request, so it just came in. So and then we have to send something today. The request is, we have a meeting with David Sachs tomorrow. The AI cryptos are understand he may have interest in knowing what we are doing to support the AI venture ecosystem. And so, I mean, that's very vague, but, but essentially, if we can spend 510 minutes to brainstorm what we can provide, and then maybe as a team, we can put together a few things to yeah, I'll also check with Eliza. This is a note, or is a slide deck. It said a briefing doc, so I think it's like, okay, briefing. Doc, so it's gonna be like a email, like a bullet. Yeah. So, yeah, thanks. So I think then maybe we can brainstorm what are all the things that we should highlight to David Sacks, that Cristiano, can I highlight and Alex Rogers, it seems can highlight to
but he anyway. So the request is, supposedly, he's meeting David Sachs tomorrow. And this is a last minute request, so it just came in. So and then we have to send something today. The request is, we have a meeting with David Sachs tomorrow. The AI cryptos are understand he may have interest in knowing what we are doing to support the AI venture ecosystem. And so, I mean, that's very vague, but, but essentially, if we can spend 510 minutes to brainstorm what we can provide, and then maybe as a team, we can put together a few things to yeah, I'll also check with Eliza. This is a note, or is a slide deck. It said a briefing doc, so I think it's like, okay, briefing. Doc, so it's gonna be like a email, like a bullet. Yeah. So, yeah, thanks. So I think then maybe we can brainstorm what are all the things that we should highlight to David Sacks, that Cristiano, can I highlight and Alex Rogers, it seems can highlight to
but he anyway. So the request is, supposedly, he's meeting David Sachs tomorrow. And this is a last minute request, so it just came in. So and then we have to send something today. The request is, we have a meeting with David Sachs tomorrow. The AI cryptos are understand he may have interest in knowing what we are doing to support the AI venture ecosystem. And so, I mean, that's very vague, but, but essentially, if we can spend 510 minutes to brainstorm what we can provide, and then maybe as a team, we can put together a few things to yeah, I'll also check with Eliza. This is a note, or is a slide deck. It said a briefing doc, so I think it's like, okay, briefing. Doc, so it's gonna be like a email, like a bullet. Yeah. So, yeah, thanks. So I think then maybe we can brainstorm what are all the things that we should highlight to David Sacks, that Cristiano, can I highlight and Alex Rogers, it seems can highlight to
but he anyway. So the request is, supposedly, he's meeting David Sachs tomorrow. And this is a last minute request, so it just came in. So and then we have to send something today. The request is, we have a meeting with David Sachs tomorrow. The AI cryptos are understand he may have interest in knowing what we are doing to support the AI venture ecosystem. And so, I mean, that's very vague, but, but essentially, if we can spend 510 minutes to brainstorm what we can provide, and then maybe as a team, we can put together a few things to yeah, I'll also check with Eliza. This is a note, or is a slide deck. It said a briefing doc, so I think it's like, okay, briefing. Doc, so it's gonna be like a email, like a bullet. Yeah. So, yeah, thanks. So I think then maybe we can brainstorm what are all the things that we should highlight to David Sacks, that Cristiano, can I highlight and Alex Rogers, it seems can highlight to
3:31in terms of what Qualcomm Ventures is doing in AI
in terms of what Qualcomm Ventures is doing in AI
in terms of what Qualcomm Ventures is doing in AI
in terms of what Qualcomm Ventures is doing in AI
S Speaker 13:37would be good, which is all of us, we know Who David Sachs is, right?
would be good, which is all of us, we know Who David Sachs is, right?
would be good, which is all of us, we know Who David Sachs is, right?
would be good, which is all of us, we know Who David Sachs is, right?
S Speaker 23:41Yeah. I think beyond the investments Tushar, we can talk about the startup event where we've tried to invest in invite like relevant companies.
Yeah. I think beyond the investments Tushar, we can talk about the startup event where we've tried to invest in invite like relevant companies.
Yeah. I think beyond the investments Tushar, we can talk about the startup event where we've tried to invest in invite like relevant companies.
Yeah. I think beyond the investments Tushar, we can talk about the startup event where we've tried to invest in invite like relevant companies.
3:51You know, those are activities
You know, those are activities
You know, those are activities
You know, those are activities
S Speaker 13:55that we've done. Take notes of all their talking points, if you can, let's put together.
that we've done. Take notes of all their talking points, if you can, let's put together.
that we've done. Take notes of all their talking points, if you can, let's put together.
that we've done. Take notes of all their talking points, if you can, let's put together.
4:04Okay, that's one idea.
Okay, that's one idea.
Okay, that's one idea.
Okay, that's one idea.
S Speaker 24:06That's one like, that's like, a, you know, table stakes, right? That's, that's a given that we talk about investments, and we talk about the start of event,
That's one like, that's like, a, you know, table stakes, right? That's, that's a given that we talk about investments, and we talk about the start of event,
That's one like, that's like, a, you know, table stakes, right? That's, that's a given that we talk about investments, and we talk about the start of event,
That's one like, that's like, a, you know, table stakes, right? That's, that's a given that we talk about investments, and we talk about the start of event,
S Speaker 24:34right? Which is two investments, right? And one of the areas, yeah. I mean, I'm trying to think
right? Which is two investments, right? And one of the areas, yeah. I mean, I'm trying to think
right? Which is two investments, right? And one of the areas, yeah. I mean, I'm trying to think
right? Which is two investments, right? And one of the areas, yeah. I mean, I'm trying to think
S Speaker 14:41so the start of event is more the what the level of detail? I don't know if it's required here.
so the start of event is more the what the level of detail? I don't know if it's required here.
so the start of event is more the what the level of detail? I don't know if it's required here.
so the start of event is more the what the level of detail? I don't know if it's required here.
S Speaker 34:52One way to look at it is, how are we enabling the entire stack in the US? And so start from start from hardware is the same stack that we use for investment, and say that we are enabling at the bottom most layer. We're enabling silicon in house, for example, and we are enabling silicon companies outside. We are enabling companies in the switch interconnect, you know. So you just build on that and say we are enabling these to be US companies providing technology globally, but predominantly based in the US. So we go that in the hardware stack, then we go on the anthropic stack, then we go on the application stack, and then we go either vertical agents, horizontal agents, but we follow the same narrative of enabling companies based in the US to have the talent and the capability to be global leaders.
One way to look at it is, how are we enabling the entire stack in the US? And so start from start from hardware is the same stack that we use for investment, and say that we are enabling at the bottom most layer. We're enabling silicon in house, for example, and we are enabling silicon companies outside. We are enabling companies in the switch interconnect, you know. So you just build on that and say we are enabling these to be US companies providing technology globally, but predominantly based in the US. So we go that in the hardware stack, then we go on the anthropic stack, then we go on the application stack, and then we go either vertical agents, horizontal agents, but we follow the same narrative of enabling companies based in the US to have the talent and the capability to be global leaders.
One way to look at it is, how are we enabling the entire stack in the US? And so start from start from hardware is the same stack that we use for investment, and say that we are enabling at the bottom most layer. We're enabling silicon in house, for example, and we are enabling silicon companies outside. We are enabling companies in the switch interconnect, you know. So you just build on that and say we are enabling these to be US companies providing technology globally, but predominantly based in the US. So we go that in the hardware stack, then we go on the anthropic stack, then we go on the application stack, and then we go either vertical agents, horizontal agents, but we follow the same narrative of enabling companies based in the US to have the talent and the capability to be global leaders.
One way to look at it is, how are we enabling the entire stack in the US? And so start from start from hardware is the same stack that we use for investment, and say that we are enabling at the bottom most layer. We're enabling silicon in house, for example, and we are enabling silicon companies outside. We are enabling companies in the switch interconnect, you know. So you just build on that and say we are enabling these to be US companies providing technology globally, but predominantly based in the US. So we go that in the hardware stack, then we go on the anthropic stack, then we go on the application stack, and then we go either vertical agents, horizontal agents, but we follow the same narrative of enabling companies based in the US to have the talent and the capability to be global leaders.
5:46I think that's a good point. That's a good point.
I think that's a good point. That's a good point.
I think that's a good point. That's a good point.
I think that's a good point. That's a good point.
S Speaker 15:50Marcia, so maybe we address it by although, yeah, I guess we could talk about paradigm and in the networking stuff we haven't met and and
Marcia, so maybe we address it by although, yeah, I guess we could talk about paradigm and in the networking stuff we haven't met and and
Marcia, so maybe we address it by although, yeah, I guess we could talk about paradigm and in the networking stuff we haven't met and and
Marcia, so maybe we address it by although, yeah, I guess we could talk about paradigm and in the networking stuff we haven't met and and
6:07Albert, we can talk about cerebrus here, right? Yeah,
Albert, we can talk about cerebrus here, right? Yeah,
Albert, we can talk about cerebrus here, right? Yeah,
Albert, we can talk about cerebrus here, right? Yeah,
S Speaker 46:10we can talk about servers. That's a that's 100% US company. Yeah, it's part of the way, and it
we can talk about servers. That's a that's 100% US company. Yeah, it's part of the way, and it
we can talk about servers. That's a that's 100% US company. Yeah, it's part of the way, and it
we can talk about servers. That's a that's 100% US company. Yeah, it's part of the way, and it
S Speaker 16:16works well. That is humane and all that Middle East stuff.
works well. That is humane and all that Middle East stuff.
works well. That is humane and all that Middle East stuff.
works well. That is humane and all that Middle East stuff.
6:22Well, that's, that's US
Well, that's, that's US
Well, that's, that's US
Well, that's, that's US
S Speaker 16:23ally, yeah, but I mean, essentially, that was the big win. But I don't think, I don't know if you want to say that, but we say, okay, sorry, Bruce, is we're enabling US companies to go build data centers and and then in that we have aI ASICs and AI networking stack. That's a good point. And then we start moving up the stack from there, which is the we're enabling foundation model companies. We're enabling a lot of the tooling companies. And then within the tooling companies, we should highlight, you know, the hugging faces of the world and the
ally, yeah, but I mean, essentially, that was the big win. But I don't think, I don't know if you want to say that, but we say, okay, sorry, Bruce, is we're enabling US companies to go build data centers and and then in that we have aI ASICs and AI networking stack. That's a good point. And then we start moving up the stack from there, which is the we're enabling foundation model companies. We're enabling a lot of the tooling companies. And then within the tooling companies, we should highlight, you know, the hugging faces of the world and the
ally, yeah, but I mean, essentially, that was the big win. But I don't think, I don't know if you want to say that, but we say, okay, sorry, Bruce, is we're enabling US companies to go build data centers and and then in that we have aI ASICs and AI networking stack. That's a good point. And then we start moving up the stack from there, which is the we're enabling foundation model companies. We're enabling a lot of the tooling companies. And then within the tooling companies, we should highlight, you know, the hugging faces of the world and the
ally, yeah, but I mean, essentially, that was the big win. But I don't think, I don't know if you want to say that, but we say, okay, sorry, Bruce, is we're enabling US companies to go build data centers and and then in that we have aI ASICs and AI networking stack. That's a good point. And then we start moving up the stack from there, which is the we're enabling foundation model companies. We're enabling a lot of the tooling companies. And then within the tooling companies, we should highlight, you know, the hugging faces of the world and the
S Speaker 17:12we should mention pokey. Pokey there
we should mention pokey. Pokey there
we should mention pokey. Pokey there
we should mention pokey. Pokey there
S Speaker 17:21and then then we talk about some vertical AI agent companies as well, like context and
and then then we talk about some vertical AI agent companies as well, like context and
and then then we talk about some vertical AI agent companies as well, like context and
and then then we talk about some vertical AI agent companies as well, like context and
7:32what else we got in verticals, agents,
what else we got in verticals, agents,
what else we got in verticals, agents,
what else we got in verticals, agents,
7:36Cresta. We can mention Cresta
Cresta. We can mention Cresta
Cresta. We can mention Cresta
Cresta. We can mention Cresta
S Speaker 57:41bias to show me some bias, but that's COVID. COVID.
bias to show me some bias, but that's COVID. COVID.
bias to show me some bias, but that's COVID. COVID.
bias to show me some bias, but that's COVID. COVID.
7:45It would be in the tooling we can add in,
It would be in the tooling we can add in,
It would be in the tooling we can add in,
It would be in the tooling we can add in,
S Speaker 27:49still in the current investments bucket, right? There are a lot more that we introduce that they work with business units, just in terms of BD work that we do. I think we can call it as ecosystem work, beyond just investments that we that's, I think, you know, it goes without saying. We can't invest in everything. We'll invest in a handful. So that's not a good representation of what we do in the space. So a lot of the ecosystem partnership enablement with, yes, with many US,
still in the current investments bucket, right? There are a lot more that we introduce that they work with business units, just in terms of BD work that we do. I think we can call it as ecosystem work, beyond just investments that we that's, I think, you know, it goes without saying. We can't invest in everything. We'll invest in a handful. So that's not a good representation of what we do in the space. So a lot of the ecosystem partnership enablement with, yes, with many US,
still in the current investments bucket, right? There are a lot more that we introduce that they work with business units, just in terms of BD work that we do. I think we can call it as ecosystem work, beyond just investments that we that's, I think, you know, it goes without saying. We can't invest in everything. We'll invest in a handful. So that's not a good representation of what we do in the space. So a lot of the ecosystem partnership enablement with, yes, with many US,
still in the current investments bucket, right? There are a lot more that we introduce that they work with business units, just in terms of BD work that we do. I think we can call it as ecosystem work, beyond just investments that we that's, I think, you know, it goes without saying. We can't invest in everything. We'll invest in a handful. So that's not a good representation of what we do in the space. So a lot of the ecosystem partnership enablement with, yes, with many US,
S Speaker 58:24show that venture is making America great again. So giver is presenting to David Sachs.
show that venture is making America great again. So giver is presenting to David Sachs.
show that venture is making America great again. So giver is presenting to David Sachs.
show that venture is making America great again. So giver is presenting to David Sachs.
S Speaker 38:32Another thing maybe to think about is we said this is now the age of inference, and inference will be enabled on endpoints where Qualcomm has very strong strength, from cell phones to IoT devices to robotics, etc. So we are working closely to enable inferences,
Another thing maybe to think about is we said this is now the age of inference, and inference will be enabled on endpoints where Qualcomm has very strong strength, from cell phones to IoT devices to robotics, etc. So we are working closely to enable inferences,
Another thing maybe to think about is we said this is now the age of inference, and inference will be enabled on endpoints where Qualcomm has very strong strength, from cell phones to IoT devices to robotics, etc. So we are working closely to enable inferences,
Another thing maybe to think about is we said this is now the age of inference, and inference will be enabled on endpoints where Qualcomm has very strong strength, from cell phones to IoT devices to robotics, etc. So we are working closely to enable inferences,
S Speaker 19:00working and investing in companies that are enabling inference at the edge. And then Sergio, we can use examples of we're enabling partnerships. And then we can use the examples of that one slide that you had for like that compute.
working and investing in companies that are enabling inference at the edge. And then Sergio, we can use examples of we're enabling partnerships. And then we can use the examples of that one slide that you had for like that compute.
working and investing in companies that are enabling inference at the edge. And then Sergio, we can use examples of we're enabling partnerships. And then we can use the examples of that one slide that you had for like that compute.
working and investing in companies that are enabling inference at the edge. And then Sergio, we can use examples of we're enabling partnerships. And then we can use the examples of that one slide that you had for like that compute.
S Speaker 19:22Okay, aipc, partnerships. So we start from the stack. I think I agree. Then we start highlighting,
Okay, aipc, partnerships. So we start from the stack. I think I agree. Then we start highlighting,
Okay, aipc, partnerships. So we start from the stack. I think I agree. Then we start highlighting,
Okay, aipc, partnerships. So we start from the stack. I think I agree. Then we start highlighting,
9:29I guess. Then we say,
I guess. Then we say,
I guess. Then we say,
I guess. Then we say,
S Speaker 19:32we believe that the age of in within the age of inference, you have other ASICs that that are not in the GPU, non GPU ASICs. And then so we're investing. And then over there, we highlight a few examples of companies that we're investing. So one is Cerberus, and then the other one is aradyne, which is more networking, then the next one, we say we're enabling a lot of the tooling companies
we believe that the age of in within the age of inference, you have other ASICs that that are not in the GPU, non GPU ASICs. And then so we're investing. And then over there, we highlight a few examples of companies that we're investing. So one is Cerberus, and then the other one is aradyne, which is more networking, then the next one, we say we're enabling a lot of the tooling companies
we believe that the age of in within the age of inference, you have other ASICs that that are not in the GPU, non GPU ASICs. And then so we're investing. And then over there, we highlight a few examples of companies that we're investing. So one is Cerberus, and then the other one is aradyne, which is more networking, then the next one, we say we're enabling a lot of the tooling companies
we believe that the age of in within the age of inference, you have other ASICs that that are not in the GPU, non GPU ASICs. And then so we're investing. And then over there, we highlight a few examples of companies that we're investing. So one is Cerberus, and then the other one is aradyne, which is more networking, then the next one, we say we're enabling a lot of the tooling companies
10:01like scale bits and basses hugging face
like scale bits and basses hugging face
like scale bits and basses hugging face
like scale bits and basses hugging face
S Speaker 110:05and then enabling partnerships with them. And then also, then we talk about some of the vertical application companies that are moving these inference workloads to the edge
and then enabling partnerships with them. And then also, then we talk about some of the vertical application companies that are moving these inference workloads to the edge
and then enabling partnerships with them. And then also, then we talk about some of the vertical application companies that are moving these inference workloads to the edge
and then enabling partnerships with them. And then also, then we talk about some of the vertical application companies that are moving these inference workloads to the edge
10:19with a lot of the US companies, and then
with a lot of the US companies, and then
with a lot of the US companies, and then
with a lot of the US companies, and then
S Speaker 110:27ecosystem development. Then we that's a separate, I think, item, which is ecosystem and a development fit many of these companies with a lot of the business units that want to deploy inference workloads on the edge. I What else
ecosystem development. Then we that's a separate, I think, item, which is ecosystem and a development fit many of these companies with a lot of the business units that want to deploy inference workloads on the edge. I What else
ecosystem development. Then we that's a separate, I think, item, which is ecosystem and a development fit many of these companies with a lot of the business units that want to deploy inference workloads on the edge. I What else
ecosystem development. Then we that's a separate, I think, item, which is ecosystem and a development fit many of these companies with a lot of the business units that want to deploy inference workloads on the edge. I What else
S Speaker 610:50Qualcomm's AI hub might be worth mentioning in the ecosystem. Play Bucha, we have partnered with a lot of startups in that space. Oh, that's a good
Qualcomm's AI hub might be worth mentioning in the ecosystem. Play Bucha, we have partnered with a lot of startups in that space. Oh, that's a good
Qualcomm's AI hub might be worth mentioning in the ecosystem. Play Bucha, we have partnered with a lot of startups in that space. Oh, that's a good
Qualcomm's AI hub might be worth mentioning in the ecosystem. Play Bucha, we have partnered with a lot of startups in that space. Oh, that's a good
11:00point. We mentioned AI hub,
point. We mentioned AI hub,
point. We mentioned AI hub,
point. We mentioned AI hub,
S Speaker 111:03and then we we enable the model AI hub to work with, with many of the startups that are moving inference to the edge.
and then we we enable the model AI hub to work with, with many of the startups that are moving inference to the edge.
and then we we enable the model AI hub to work with, with many of the startups that are moving inference to the edge.
and then we we enable the model AI hub to work with, with many of the startups that are moving inference to the edge.
11:27yeah, two sentences,
11:34Okay, so that should be enough. Yeah, all right,
Okay, so that should be enough. Yeah, all right,
Okay, so that should be enough. Yeah, all right,
Okay, so that should be enough. Yeah, all right,
S Speaker 212:02Do we know anything we're doing on the new hardware form factor for AI? I know there were conversations. David might be interested in learning cristiano's thoughts, and I don't know if he can give him some bites that.
Do we know anything we're doing on the new hardware form factor for AI? I know there were conversations. David might be interested in learning cristiano's thoughts, and I don't know if he can give him some bites that.
Do we know anything we're doing on the new hardware form factor for AI? I know there were conversations. David might be interested in learning cristiano's thoughts, and I don't know if he can give him some bites that.
Do we know anything we're doing on the new hardware form factor for AI? I know there were conversations. David might be interested in learning cristiano's thoughts, and I don't know if he can give him some bites that.
S Speaker 112:14Well, we've had a failed humane it
Well, we've had a failed humane it
Well, we've had a failed humane it
Well, we've had a failed humane it
12:19was a so that was the of course, timing, we can
was a so that was the of course, timing, we can
was a so that was the of course, timing, we can
was a so that was the of course, timing, we can
S Speaker 112:21argue no, but I think you saying enabling new form factors. We're looking for new form factors that run ag inference workloads and on device. And you know, what I don't know is if Christian is on board with that idea himself, so I don't want to,
argue no, but I think you saying enabling new form factors. We're looking for new form factors that run ag inference workloads and on device. And you know, what I don't know is if Christian is on board with that idea himself, so I don't want to,
argue no, but I think you saying enabling new form factors. We're looking for new form factors that run ag inference workloads and on device. And you know, what I don't know is if Christian is on board with that idea himself, so I don't want to,
argue no, but I think you saying enabling new form factors. We're looking for new form factors that run ag inference workloads and on device. And you know, what I don't know is if Christian is on board with that idea himself, so I don't want to,
12:41I don't want to, if you don't.
I don't want to, if you don't.
I don't want to, if you don't.
I don't want to, if you don't.
13:18the, what is the, you know, big swing.
the, what is the, you know, big swing.
the, what is the, you know, big swing.
the, what is the, you know, big swing.
S Speaker 113:24Okay, so let me that's a that's a good point. Could you add that in there? And let me see if I can.
Okay, so let me that's a that's a good point. Could you add that in there? And let me see if I can.
Okay, so let me that's a that's a good point. Could you add that in there? And let me see if I can.
Okay, so let me that's a that's a good point. Could you add that in there? And let me see if I can.
13:41Yes, which means nothing so, so that's why, that's why I was
Yes, which means nothing so, so that's why, that's why I was
Yes, which means nothing so, so that's why, that's why I was
Yes, which means nothing so, so that's why, that's why I was
S Speaker 213:50but you might have some visibility into, like, what I don't know.
but you might have some visibility into, like, what I don't know.
but you might have some visibility into, like, what I don't know.
but you might have some visibility into, like, what I don't know.
13:54Yeah, no today. So I think the world,
Yeah, no today. So I think the world,
Yeah, no today. So I think the world,
Yeah, no today. So I think the world,
S Speaker 114:01realistically, what we can do on device today is a 7 billion parameter model, which is intake, intake 7 billion parameter model. That's the limit of what we can do in a very scalable and reliable fashion today. And then that universe is still very limited. So like as of today, that's limited. And then, but for with Qualcomm ventures, what are we doing? Like, even when I come we talk to a lot of the edge, lot of the new device startups, the first device form factor doesn't include running anything on the edge. Just yet, they're okay with taking the network latency just because the quality of the models in the cloud are still significantly superior. So let me see. But it's a good point, because, you know, you want to enable the next Apple. So if I we can weave it, which is, we're on the hunt
realistically, what we can do on device today is a 7 billion parameter model, which is intake, intake 7 billion parameter model. That's the limit of what we can do in a very scalable and reliable fashion today. And then that universe is still very limited. So like as of today, that's limited. And then, but for with Qualcomm ventures, what are we doing? Like, even when I come we talk to a lot of the edge, lot of the new device startups, the first device form factor doesn't include running anything on the edge. Just yet, they're okay with taking the network latency just because the quality of the models in the cloud are still significantly superior. So let me see. But it's a good point, because, you know, you want to enable the next Apple. So if I we can weave it, which is, we're on the hunt
realistically, what we can do on device today is a 7 billion parameter model, which is intake, intake 7 billion parameter model. That's the limit of what we can do in a very scalable and reliable fashion today. And then that universe is still very limited. So like as of today, that's limited. And then, but for with Qualcomm ventures, what are we doing? Like, even when I come we talk to a lot of the edge, lot of the new device startups, the first device form factor doesn't include running anything on the edge. Just yet, they're okay with taking the network latency just because the quality of the models in the cloud are still significantly superior. So let me see. But it's a good point, because, you know, you want to enable the next Apple. So if I we can weave it, which is, we're on the hunt
realistically, what we can do on device today is a 7 billion parameter model, which is intake, intake 7 billion parameter model. That's the limit of what we can do in a very scalable and reliable fashion today. And then that universe is still very limited. So like as of today, that's limited. And then, but for with Qualcomm ventures, what are we doing? Like, even when I come we talk to a lot of the edge, lot of the new device startups, the first device form factor doesn't include running anything on the edge. Just yet, they're okay with taking the network latency just because the quality of the models in the cloud are still significantly superior. So let me see. But it's a good point, because, you know, you want to enable the next Apple. So if I we can weave it, which is, we're on the hunt
14:56for the next Apple here. And
for the next Apple here. And
for the next Apple here. And
for the next Apple here. And
S Speaker 115:01if we can leave it, then I'll see. Of course, Aliza will miss, massage it heavily before this goes
if we can leave it, then I'll see. Of course, Aliza will miss, massage it heavily before this goes
if we can leave it, then I'll see. Of course, Aliza will miss, massage it heavily before this goes
if we can leave it, then I'll see. Of course, Aliza will miss, massage it heavily before this goes
S Speaker 115:14anyway, okay, all right, we can move to the topic of discussion. Thank you.
anyway, okay, all right, we can move to the topic of discussion. Thank you.
anyway, okay, all right, we can move to the topic of discussion. Thank you.
anyway, okay, all right, we can move to the topic of discussion. Thank you.
15:21Yeah, so do you can send it to
Yeah, so do you can send it to
Yeah, so do you can send it to
Yeah, so do you can send it to
S Speaker 315:23me Sure? Just a quick question. Did which other companies did Christiano meet
me Sure? Just a quick question. Did which other companies did Christiano meet
me Sure? Just a quick question. Did which other companies did Christiano meet
me Sure? Just a quick question. Did which other companies did Christiano meet
15:28other than figure?
15:30Um, he met modular as well. So,
Um, he met modular as well. So,
Um, he met modular as well. So,
Um, he met modular as well. So,
S Speaker 315:37yeah, what changes did he say you will make,
yeah, what changes did he say you will make,
yeah, what changes did he say you will make,
yeah, what changes did he say you will make,
18:48because he sent once, he sent a message
because he sent once, he sent a message
because he sent once, he sent a message
because he sent once, he sent a message
18:52that we don't want layers of people
that we don't want layers of people
that we don't want layers of people
that we don't want layers of people
S Speaker 118:56so, but it was a good meeting. I
so, but it was a good meeting. I
so, but it was a good meeting. I
so, but it was a good meeting. I
19:02still don't have indication whether he wants us to invest or not, so we'll see. All right,
still don't have indication whether he wants us to invest or not, so we'll see. All right,
still don't have indication whether he wants us to invest or not, so we'll see. All right,
still don't have indication whether he wants us to invest or not, so we'll see. All right,
S Speaker 119:16Deepak, let's do the the other topic.
Deepak, let's do the the other topic.
Deepak, let's do the the other topic.
Deepak, let's do the the other topic.
S Speaker 219:21Yeah, we are skipping on the what was that the hot sectors thing? Like, it's fine. Was there any conclusion, Albert, or do you feel like we need another discussion? Well,
Yeah, we are skipping on the what was that the hot sectors thing? Like, it's fine. Was there any conclusion, Albert, or do you feel like we need another discussion? Well,
Yeah, we are skipping on the what was that the hot sectors thing? Like, it's fine. Was there any conclusion, Albert, or do you feel like we need another discussion? Well,
Yeah, we are skipping on the what was that the hot sectors thing? Like, it's fine. Was there any conclusion, Albert, or do you feel like we need another discussion? Well,
S Speaker 419:38you know, just based on the conversation after that session, it feels like it's hard for us to set some kind of rules, yeah, but with completely different mode of operation, we just had to, you know, push the boundaries as we do deals. I don't know if you have a different takeaway from that conversation I think we have to look at a case by case basis. It's going to be very hard to say, hey, here's the rule, and then let's follow this. It wouldn't be possible. Yeah,
you know, just based on the conversation after that session, it feels like it's hard for us to set some kind of rules, yeah, but with completely different mode of operation, we just had to, you know, push the boundaries as we do deals. I don't know if you have a different takeaway from that conversation I think we have to look at a case by case basis. It's going to be very hard to say, hey, here's the rule, and then let's follow this. It wouldn't be possible. Yeah,
you know, just based on the conversation after that session, it feels like it's hard for us to set some kind of rules, yeah, but with completely different mode of operation, we just had to, you know, push the boundaries as we do deals. I don't know if you have a different takeaway from that conversation I think we have to look at a case by case basis. It's going to be very hard to say, hey, here's the rule, and then let's follow this. It wouldn't be possible. Yeah,
you know, just based on the conversation after that session, it feels like it's hard for us to set some kind of rules, yeah, but with completely different mode of operation, we just had to, you know, push the boundaries as we do deals. I don't know if you have a different takeaway from that conversation I think we have to look at a case by case basis. It's going to be very hard to say, hey, here's the rule, and then let's follow this. It wouldn't be possible. Yeah,
S Speaker 420:42but it had to be, I think had to be done with specific investments. I don't think we can generalize
but it had to be, I think had to be done with specific investments. I don't think we can generalize
but it had to be, I think had to be done with specific investments. I don't think we can generalize
but it had to be, I think had to be done with specific investments. I don't think we can generalize
S Speaker 220:48it, right? We can't generalize it. It has to be specific sub segments and then specific investments, right? Yeah, all right, anything else anybody has to add on that topic before we go?
it, right? We can't generalize it. It has to be specific sub segments and then specific investments, right? Yeah, all right, anything else anybody has to add on that topic before we go?
it, right? We can't generalize it. It has to be specific sub segments and then specific investments, right? Yeah, all right, anything else anybody has to add on that topic before we go?
it, right? We can't generalize it. It has to be specific sub segments and then specific investments, right? Yeah, all right, anything else anybody has to add on that topic before we go?
S Speaker 121:04I agree. All right,
S Speaker 221:10so I've put together, you know, I think would be curious, firstly, for others as well, how we are making sense of what's happening in the space and how things are moving, right? I try to recap events in the past month or the week, or events that I've gone to right, and I've just put together some observations that I have. And let's keep it an open discussion. People might have different conversations with startups, investors, customers, even within Qualcomm practice, a lot of these has been deployed. So what else? There's some background
so I've put together, you know, I think would be curious, firstly, for others as well, how we are making sense of what's happening in the space and how things are moving, right? I try to recap events in the past month or the week, or events that I've gone to right, and I've just put together some observations that I have. And let's keep it an open discussion. People might have different conversations with startups, investors, customers, even within Qualcomm practice, a lot of these has been deployed. So what else? There's some background
so I've put together, you know, I think would be curious, firstly, for others as well, how we are making sense of what's happening in the space and how things are moving, right? I try to recap events in the past month or the week, or events that I've gone to right, and I've just put together some observations that I have. And let's keep it an open discussion. People might have different conversations with startups, investors, customers, even within Qualcomm practice, a lot of these has been deployed. So what else? There's some background
so I've put together, you know, I think would be curious, firstly, for others as well, how we are making sense of what's happening in the space and how things are moving, right? I try to recap events in the past month or the week, or events that I've gone to right, and I've just put together some observations that I have. And let's keep it an open discussion. People might have different conversations with startups, investors, customers, even within Qualcomm practice, a lot of these has been deployed. So what else? There's some background
S Speaker 423:45Autonomous vehicle industry kind of defining to different levels. Before that people has been talking about different levels of agentic capabilities are too used to reasoning and everything in between. I don't feel like when you get to hang up on the name of it, it's more like what you can do for the end customers. I think that's what truly matters.
Autonomous vehicle industry kind of defining to different levels. Before that people has been talking about different levels of agentic capabilities are too used to reasoning and everything in between. I don't feel like when you get to hang up on the name of it, it's more like what you can do for the end customers. I think that's what truly matters.
Autonomous vehicle industry kind of defining to different levels. Before that people has been talking about different levels of agentic capabilities are too used to reasoning and everything in between. I don't feel like when you get to hang up on the name of it, it's more like what you can do for the end customers. I think that's what truly matters.
Autonomous vehicle industry kind of defining to different levels. Before that people has been talking about different levels of agentic capabilities are too used to reasoning and everything in between. I don't feel like when you get to hang up on the name of it, it's more like what you can do for the end customers. I think that's what truly matters.
S Speaker 124:14I mean, the good thing that this is a framework understand where the technology exists today. Eventually, I agree with you, Albert, which is you could have somebody actually operating at l2 for this and still deliver value. It doesn't really matter. The only thing that'll matter is that how many people you have doing the works. In some cases, if you only have two engineers, if you get to l5 you only have two engineers doing everything. And then in case of l2 you have 20 engineers doing the same thing. So I don't think, yeah, that won't really matter eventually. But right now, with the technologies, I think, like the bet with Poki is it enables l5 I mean, that's the bet.
I mean, the good thing that this is a framework understand where the technology exists today. Eventually, I agree with you, Albert, which is you could have somebody actually operating at l2 for this and still deliver value. It doesn't really matter. The only thing that'll matter is that how many people you have doing the works. In some cases, if you only have two engineers, if you get to l5 you only have two engineers doing everything. And then in case of l2 you have 20 engineers doing the same thing. So I don't think, yeah, that won't really matter eventually. But right now, with the technologies, I think, like the bet with Poki is it enables l5 I mean, that's the bet.
I mean, the good thing that this is a framework understand where the technology exists today. Eventually, I agree with you, Albert, which is you could have somebody actually operating at l2 for this and still deliver value. It doesn't really matter. The only thing that'll matter is that how many people you have doing the works. In some cases, if you only have two engineers, if you get to l5 you only have two engineers doing everything. And then in case of l2 you have 20 engineers doing the same thing. So I don't think, yeah, that won't really matter eventually. But right now, with the technologies, I think, like the bet with Poki is it enables l5 I mean, that's the bet.
I mean, the good thing that this is a framework understand where the technology exists today. Eventually, I agree with you, Albert, which is you could have somebody actually operating at l2 for this and still deliver value. It doesn't really matter. The only thing that'll matter is that how many people you have doing the works. In some cases, if you only have two engineers, if you get to l5 you only have two engineers doing everything. And then in case of l2 you have 20 engineers doing the same thing. So I don't think, yeah, that won't really matter eventually. But right now, with the technologies, I think, like the bet with Poki is it enables l5 I mean, that's the bet.
S Speaker 724:53That's a good point. I think what Poki doesn't have, even CEO Bill, recognize that, is he has to figure out a way to kind of integrate the data within Enterprise with the agent, so agent can have a lot more context. We know the relevant content right, to allow the agent to work autonomously deliver the final result that enterprise customer really want agent solve. My problem is to kind of try to solve my problem, which is autonomously, a complicated task. The task without the data, is nothing, right? So, so, so coke kind of clearly sees that is to get the data involved, and he thinks about work with gleam. And also that echoes me during yesterday's meta presentations. Yeah, a few meta executives say that the key kind of the challenge right now for agents, or not seen agents, is to provide the best context for the agent to autonomously accomplish the tasks. So one solution, they kind of proposes, instead of having one super smart agent to do every single step of task, figure out what to do autonomously from point zero to point 10, they propose a structure, which is called sub agents within an agent. I mean, it sounds excess, but somehow, you know, in the architecture perspective, I honestly don't know how to do that sounds like a big agent, managing control sub agents, right? Structure? Yeah, that's where I got stuck yesterday. That's a question I bring, you know, in my mind, and after the conference,
That's a good point. I think what Poki doesn't have, even CEO Bill, recognize that, is he has to figure out a way to kind of integrate the data within Enterprise with the agent, so agent can have a lot more context. We know the relevant content right, to allow the agent to work autonomously deliver the final result that enterprise customer really want agent solve. My problem is to kind of try to solve my problem, which is autonomously, a complicated task. The task without the data, is nothing, right? So, so, so coke kind of clearly sees that is to get the data involved, and he thinks about work with gleam. And also that echoes me during yesterday's meta presentations. Yeah, a few meta executives say that the key kind of the challenge right now for agents, or not seen agents, is to provide the best context for the agent to autonomously accomplish the tasks. So one solution, they kind of proposes, instead of having one super smart agent to do every single step of task, figure out what to do autonomously from point zero to point 10, they propose a structure, which is called sub agents within an agent. I mean, it sounds excess, but somehow, you know, in the architecture perspective, I honestly don't know how to do that sounds like a big agent, managing control sub agents, right? Structure? Yeah, that's where I got stuck yesterday. That's a question I bring, you know, in my mind, and after the conference,
That's a good point. I think what Poki doesn't have, even CEO Bill, recognize that, is he has to figure out a way to kind of integrate the data within Enterprise with the agent, so agent can have a lot more context. We know the relevant content right, to allow the agent to work autonomously deliver the final result that enterprise customer really want agent solve. My problem is to kind of try to solve my problem, which is autonomously, a complicated task. The task without the data, is nothing, right? So, so, so coke kind of clearly sees that is to get the data involved, and he thinks about work with gleam. And also that echoes me during yesterday's meta presentations. Yeah, a few meta executives say that the key kind of the challenge right now for agents, or not seen agents, is to provide the best context for the agent to autonomously accomplish the tasks. So one solution, they kind of proposes, instead of having one super smart agent to do every single step of task, figure out what to do autonomously from point zero to point 10, they propose a structure, which is called sub agents within an agent. I mean, it sounds excess, but somehow, you know, in the architecture perspective, I honestly don't know how to do that sounds like a big agent, managing control sub agents, right? Structure? Yeah, that's where I got stuck yesterday. That's a question I bring, you know, in my mind, and after the conference,
That's a good point. I think what Poki doesn't have, even CEO Bill, recognize that, is he has to figure out a way to kind of integrate the data within Enterprise with the agent, so agent can have a lot more context. We know the relevant content right, to allow the agent to work autonomously deliver the final result that enterprise customer really want agent solve. My problem is to kind of try to solve my problem, which is autonomously, a complicated task. The task without the data, is nothing, right? So, so, so coke kind of clearly sees that is to get the data involved, and he thinks about work with gleam. And also that echoes me during yesterday's meta presentations. Yeah, a few meta executives say that the key kind of the challenge right now for agents, or not seen agents, is to provide the best context for the agent to autonomously accomplish the tasks. So one solution, they kind of proposes, instead of having one super smart agent to do every single step of task, figure out what to do autonomously from point zero to point 10, they propose a structure, which is called sub agents within an agent. I mean, it sounds excess, but somehow, you know, in the architecture perspective, I honestly don't know how to do that sounds like a big agent, managing control sub agents, right? Structure? Yeah, that's where I got stuck yesterday. That's a question I bring, you know, in my mind, and after the conference,
S Speaker 127:58they had a security issue. Just somebody uploaded something on context and showed up on an open source that was a problem because their users use their gmail id versus the Qualcomm ID, and then, if it's a call committee, then they do it on enterprise. But that wasn't the it wasn't like soft, it's super early today. Yeah. I mean the key challenge across the higher level, which is the right context integrations. These are the next level detail, but then integration right context are details of accuracy. And so everybody, essentially at the higher level problem than any CIO or any head of any department, they just care about the accuracy. Today, how you do it is context could be one way to do it. I mean, it sounds like context is the right way to do it, but down the road, you could have other techniques in order to address
they had a security issue. Just somebody uploaded something on context and showed up on an open source that was a problem because their users use their gmail id versus the Qualcomm ID, and then, if it's a call committee, then they do it on enterprise. But that wasn't the it wasn't like soft, it's super early today. Yeah. I mean the key challenge across the higher level, which is the right context integrations. These are the next level detail, but then integration right context are details of accuracy. And so everybody, essentially at the higher level problem than any CIO or any head of any department, they just care about the accuracy. Today, how you do it is context could be one way to do it. I mean, it sounds like context is the right way to do it, but down the road, you could have other techniques in order to address
they had a security issue. Just somebody uploaded something on context and showed up on an open source that was a problem because their users use their gmail id versus the Qualcomm ID, and then, if it's a call committee, then they do it on enterprise. But that wasn't the it wasn't like soft, it's super early today. Yeah. I mean the key challenge across the higher level, which is the right context integrations. These are the next level detail, but then integration right context are details of accuracy. And so everybody, essentially at the higher level problem than any CIO or any head of any department, they just care about the accuracy. Today, how you do it is context could be one way to do it. I mean, it sounds like context is the right way to do it, but down the road, you could have other techniques in order to address
they had a security issue. Just somebody uploaded something on context and showed up on an open source that was a problem because their users use their gmail id versus the Qualcomm ID, and then, if it's a call committee, then they do it on enterprise. But that wasn't the it wasn't like soft, it's super early today. Yeah. I mean the key challenge across the higher level, which is the right context integrations. These are the next level detail, but then integration right context are details of accuracy. And so everybody, essentially at the higher level problem than any CIO or any head of any department, they just care about the accuracy. Today, how you do it is context could be one way to do it. I mean, it sounds like context is the right way to do it, but down the road, you could have other techniques in order to address
S Speaker 228:55that as well, right? So in this case, context, you're referring to the context. I'm
that as well, right? So in this case, context, you're referring to the context. I'm
that as well, right? So in this case, context, you're referring to the context. I'm
that as well, right? So in this case, context, you're referring to the context. I'm
28:59referring to context this,
referring to context this,
referring to context this,
referring to context this,
S Speaker 129:01but accuracy, everybody. So when I talk to CIOs, they mentioned two things that are the most important, one is and then everything else is. One is accuracy, the second one and security is a given accuracy, and the second one is Reliability. Reliability improves scalability. So a lot of the challenges, but many such challenges with many startups today is the dropping foundation model companies, dropping Google and OpenAI, so they cannot guarantee reliability and scalability today. So then everybody's trying to figure out, Okay, should we do our own deep sea deployment somewhere so that we can guarantee reliability and scalability and then perhaps somewhat inaccuracy. So those trade offs I hear a lot, because everybody just cares about accuracy and reliability. So like, for example, contextual, not context. Contextual is required at scale and Quake. But Yuki called me last week. He said, hey, they are having challenges with scalability
but accuracy, everybody. So when I talk to CIOs, they mentioned two things that are the most important, one is and then everything else is. One is accuracy, the second one and security is a given accuracy, and the second one is Reliability. Reliability improves scalability. So a lot of the challenges, but many such challenges with many startups today is the dropping foundation model companies, dropping Google and OpenAI, so they cannot guarantee reliability and scalability today. So then everybody's trying to figure out, Okay, should we do our own deep sea deployment somewhere so that we can guarantee reliability and scalability and then perhaps somewhat inaccuracy. So those trade offs I hear a lot, because everybody just cares about accuracy and reliability. So like, for example, contextual, not context. Contextual is required at scale and Quake. But Yuki called me last week. He said, hey, they are having challenges with scalability
but accuracy, everybody. So when I talk to CIOs, they mentioned two things that are the most important, one is and then everything else is. One is accuracy, the second one and security is a given accuracy, and the second one is Reliability. Reliability improves scalability. So a lot of the challenges, but many such challenges with many startups today is the dropping foundation model companies, dropping Google and OpenAI, so they cannot guarantee reliability and scalability today. So then everybody's trying to figure out, Okay, should we do our own deep sea deployment somewhere so that we can guarantee reliability and scalability and then perhaps somewhat inaccuracy. So those trade offs I hear a lot, because everybody just cares about accuracy and reliability. So like, for example, contextual, not context. Contextual is required at scale and Quake. But Yuki called me last week. He said, hey, they are having challenges with scalability
but accuracy, everybody. So when I talk to CIOs, they mentioned two things that are the most important, one is and then everything else is. One is accuracy, the second one and security is a given accuracy, and the second one is Reliability. Reliability improves scalability. So a lot of the challenges, but many such challenges with many startups today is the dropping foundation model companies, dropping Google and OpenAI, so they cannot guarantee reliability and scalability today. So then everybody's trying to figure out, Okay, should we do our own deep sea deployment somewhere so that we can guarantee reliability and scalability and then perhaps somewhat inaccuracy. So those trade offs I hear a lot, because everybody just cares about accuracy and reliability. So like, for example, contextual, not context. Contextual is required at scale and Quake. But Yuki called me last week. He said, hey, they are having challenges with scalability
S Speaker 230:01that also will come up in the discussions in the following slides. So that's a good point. Tushar just talking about something that's, you know, hotly debated thing in the industry today. So these were two thought pieces right on the left, you have it from a cognition that wrote Devin. And in the same week, there was a research published by anthropic, right? And, of course, there's, there was in the details, but one of them is saying, Don't build multi agents. And the other one saying, you know, let me show you how we build the multi agent research system, right? And I can summarize, and it's a it's a good read for anybody who's interested in this. We should definitely spend some time on the blog. And there are a couple of videos explaining this, but Devin talked about the same pain point that Nan was talking right? Which is so they put them in a saying that if you have one agent that is spinning up multiple agents, and these agents go and do their own stuff and come back, there is a high risk of losing context, and any error by these sub agents compounds and at the end product is vastly different, right? And they have tried this and they failed. So what they came up with was a single sequential agent execution structure, right? What it means is a single agent will do multiple sub agents, but these are executed sequentially, so the memory and context is preserved, right? And this was, this was a big debate in the industry today, because the way all of the systems are architected today is the lead agent. The first agent is the orchestrator, and it's spinning up multiple sub agents, like to to do the different tasks, and that's how anthropic built its multi agent system. So this is their this is anthropic path. So anthropic in their blog have talked about this problem in detail. So what they're saying is, for certain use cases, these multi agent approaches might work, but for a lot of places where you need high accuracy, you have to do sequential execution of agents. You can't do parallel execution of agents. Parallel execution of agents, right? And that is key. So today, the first agent is the lead orchestrator, and they are actually spinning out multiple sub agents to actually get to the ultimate outcome, right? And I don't know if we've run into this challenge with any of the companies or startups or multi agent is still very early, so people have divergent views. They're still testing out architectures. It's still not being deployed as the way we would imagine it to be autonomous, is after multi agent, right? So you have, you have multi agent framework that should succeed, and then economist will come in its place, right? So, any thoughts before I move the so this one actually don't fully understand this. Yeah, I think that's, it's like a separate session. It's like, maybe, like, I can open the blog and give you the I haven't like, this is not just going deeper into the blog. We can, if you if somebody has read it, or somebody has thoughts, we can make a brainstorming session, but, uh, but, yeah. Did you understand the sub agents and sub agents losing context? That's
that also will come up in the discussions in the following slides. So that's a good point. Tushar just talking about something that's, you know, hotly debated thing in the industry today. So these were two thought pieces right on the left, you have it from a cognition that wrote Devin. And in the same week, there was a research published by anthropic, right? And, of course, there's, there was in the details, but one of them is saying, Don't build multi agents. And the other one saying, you know, let me show you how we build the multi agent research system, right? And I can summarize, and it's a it's a good read for anybody who's interested in this. We should definitely spend some time on the blog. And there are a couple of videos explaining this, but Devin talked about the same pain point that Nan was talking right? Which is so they put them in a saying that if you have one agent that is spinning up multiple agents, and these agents go and do their own stuff and come back, there is a high risk of losing context, and any error by these sub agents compounds and at the end product is vastly different, right? And they have tried this and they failed. So what they came up with was a single sequential agent execution structure, right? What it means is a single agent will do multiple sub agents, but these are executed sequentially, so the memory and context is preserved, right? And this was, this was a big debate in the industry today, because the way all of the systems are architected today is the lead agent. The first agent is the orchestrator, and it's spinning up multiple sub agents, like to to do the different tasks, and that's how anthropic built its multi agent system. So this is their this is anthropic path. So anthropic in their blog have talked about this problem in detail. So what they're saying is, for certain use cases, these multi agent approaches might work, but for a lot of places where you need high accuracy, you have to do sequential execution of agents. You can't do parallel execution of agents. Parallel execution of agents, right? And that is key. So today, the first agent is the lead orchestrator, and they are actually spinning out multiple sub agents to actually get to the ultimate outcome, right? And I don't know if we've run into this challenge with any of the companies or startups or multi agent is still very early, so people have divergent views. They're still testing out architectures. It's still not being deployed as the way we would imagine it to be autonomous, is after multi agent, right? So you have, you have multi agent framework that should succeed, and then economist will come in its place, right? So, any thoughts before I move the so this one actually don't fully understand this. Yeah, I think that's, it's like a separate session. It's like, maybe, like, I can open the blog and give you the I haven't like, this is not just going deeper into the blog. We can, if you if somebody has read it, or somebody has thoughts, we can make a brainstorming session, but, uh, but, yeah. Did you understand the sub agents and sub agents losing context? That's
that also will come up in the discussions in the following slides. So that's a good point. Tushar just talking about something that's, you know, hotly debated thing in the industry today. So these were two thought pieces right on the left, you have it from a cognition that wrote Devin. And in the same week, there was a research published by anthropic, right? And, of course, there's, there was in the details, but one of them is saying, Don't build multi agents. And the other one saying, you know, let me show you how we build the multi agent research system, right? And I can summarize, and it's a it's a good read for anybody who's interested in this. We should definitely spend some time on the blog. And there are a couple of videos explaining this, but Devin talked about the same pain point that Nan was talking right? Which is so they put them in a saying that if you have one agent that is spinning up multiple agents, and these agents go and do their own stuff and come back, there is a high risk of losing context, and any error by these sub agents compounds and at the end product is vastly different, right? And they have tried this and they failed. So what they came up with was a single sequential agent execution structure, right? What it means is a single agent will do multiple sub agents, but these are executed sequentially, so the memory and context is preserved, right? And this was, this was a big debate in the industry today, because the way all of the systems are architected today is the lead agent. The first agent is the orchestrator, and it's spinning up multiple sub agents, like to to do the different tasks, and that's how anthropic built its multi agent system. So this is their this is anthropic path. So anthropic in their blog have talked about this problem in detail. So what they're saying is, for certain use cases, these multi agent approaches might work, but for a lot of places where you need high accuracy, you have to do sequential execution of agents. You can't do parallel execution of agents. Parallel execution of agents, right? And that is key. So today, the first agent is the lead orchestrator, and they are actually spinning out multiple sub agents to actually get to the ultimate outcome, right? And I don't know if we've run into this challenge with any of the companies or startups or multi agent is still very early, so people have divergent views. They're still testing out architectures. It's still not being deployed as the way we would imagine it to be autonomous, is after multi agent, right? So you have, you have multi agent framework that should succeed, and then economist will come in its place, right? So, any thoughts before I move the so this one actually don't fully understand this. Yeah, I think that's, it's like a separate session. It's like, maybe, like, I can open the blog and give you the I haven't like, this is not just going deeper into the blog. We can, if you if somebody has read it, or somebody has thoughts, we can make a brainstorming session, but, uh, but, yeah. Did you understand the sub agents and sub agents losing context? That's
that also will come up in the discussions in the following slides. So that's a good point. Tushar just talking about something that's, you know, hotly debated thing in the industry today. So these were two thought pieces right on the left, you have it from a cognition that wrote Devin. And in the same week, there was a research published by anthropic, right? And, of course, there's, there was in the details, but one of them is saying, Don't build multi agents. And the other one saying, you know, let me show you how we build the multi agent research system, right? And I can summarize, and it's a it's a good read for anybody who's interested in this. We should definitely spend some time on the blog. And there are a couple of videos explaining this, but Devin talked about the same pain point that Nan was talking right? Which is so they put them in a saying that if you have one agent that is spinning up multiple agents, and these agents go and do their own stuff and come back, there is a high risk of losing context, and any error by these sub agents compounds and at the end product is vastly different, right? And they have tried this and they failed. So what they came up with was a single sequential agent execution structure, right? What it means is a single agent will do multiple sub agents, but these are executed sequentially, so the memory and context is preserved, right? And this was, this was a big debate in the industry today, because the way all of the systems are architected today is the lead agent. The first agent is the orchestrator, and it's spinning up multiple sub agents, like to to do the different tasks, and that's how anthropic built its multi agent system. So this is their this is anthropic path. So anthropic in their blog have talked about this problem in detail. So what they're saying is, for certain use cases, these multi agent approaches might work, but for a lot of places where you need high accuracy, you have to do sequential execution of agents. You can't do parallel execution of agents. Parallel execution of agents, right? And that is key. So today, the first agent is the lead orchestrator, and they are actually spinning out multiple sub agents to actually get to the ultimate outcome, right? And I don't know if we've run into this challenge with any of the companies or startups or multi agent is still very early, so people have divergent views. They're still testing out architectures. It's still not being deployed as the way we would imagine it to be autonomous, is after multi agent, right? So you have, you have multi agent framework that should succeed, and then economist will come in its place, right? So, any thoughts before I move the so this one actually don't fully understand this. Yeah, I think that's, it's like a separate session. It's like, maybe, like, I can open the blog and give you the I haven't like, this is not just going deeper into the blog. We can, if you if somebody has read it, or somebody has thoughts, we can make a brainstorming session, but, uh, but, yeah. Did you understand the sub agents and sub agents losing context? That's
S Speaker 432:36the main point. My understanding is it could be just a cognitions implementation. And encounter some difficulty. I don't necessarily think that negates the whole multi agent structure that other people are using. There could be different ways. And actually, if you look at the human organizations, and that's typically how it's how it's done. And of course, you can have one agent to do things sequentially, but apparently you got to trade off on some efficiency and efficacy metrics.
the main point. My understanding is it could be just a cognitions implementation. And encounter some difficulty. I don't necessarily think that negates the whole multi agent structure that other people are using. There could be different ways. And actually, if you look at the human organizations, and that's typically how it's how it's done. And of course, you can have one agent to do things sequentially, but apparently you got to trade off on some efficiency and efficacy metrics.
the main point. My understanding is it could be just a cognitions implementation. And encounter some difficulty. I don't necessarily think that negates the whole multi agent structure that other people are using. There could be different ways. And actually, if you look at the human organizations, and that's typically how it's how it's done. And of course, you can have one agent to do things sequentially, but apparently you got to trade off on some efficiency and efficacy metrics.
the main point. My understanding is it could be just a cognitions implementation. And encounter some difficulty. I don't necessarily think that negates the whole multi agent structure that other people are using. There could be different ways. And actually, if you look at the human organizations, and that's typically how it's how it's done. And of course, you can have one agent to do things sequentially, but apparently you got to trade off on some efficiency and efficacy metrics.