Meeting: SVB AI showcase 1
Thu, Oct 2
1:38 PM
1 h 9 min
Priyesh P
San Francisco's AI Ecosystem and Event Over
URL: https://otter.ai/u/76pkk7WIQfHvke5KBCwAA4caz10
Downloaded: 2025-12-21T20:14:01.986985
Method: text_extraction
============================================================

S Speaker 10:00Capital is just open AI this quarter. So just so you've got the idea of four companies four weeks ago, investments
Capital is just open AI this quarter. So just so you've got the idea of four companies four weeks ago, investments
Capital is just open AI this quarter. So just so you've got the idea of four companies four weeks ago, investments
Capital is just open AI this quarter. So just so you've got the idea of four companies four weeks ago, investments
0:12in the quarter. So open AI or x
in the quarter. So open AI or x
in the quarter. So open AI or x
in the quarter. So open AI or x
S Speaker 10:20ai, I should say so and then so you had high concentrations, all of the activity we're seeing AI, and it's also in the city, because 70% of all of the action in AI, it's coming to San Francisco. So to those of you that don't live here, trust me, we don't have dead bodies on the street, on the murder capital of America, we are really like you might find a really tasty bagel somewhere. If you hunt it's rematch is really, really vibrant. And so again, you might see some of the buildings and work again, companies
ai, I should say so and then so you had high concentrations, all of the activity we're seeing AI, and it's also in the city, because 70% of all of the action in AI, it's coming to San Francisco. So to those of you that don't live here, trust me, we don't have dead bodies on the street, on the murder capital of America, we are really like you might find a really tasty bagel somewhere. If you hunt it's rematch is really, really vibrant. And so again, you might see some of the buildings and work again, companies
ai, I should say so and then so you had high concentrations, all of the activity we're seeing AI, and it's also in the city, because 70% of all of the action in AI, it's coming to San Francisco. So to those of you that don't live here, trust me, we don't have dead bodies on the street, on the murder capital of America, we are really like you might find a really tasty bagel somewhere. If you hunt it's rematch is really, really vibrant. And so again, you might see some of the buildings and work again, companies
ai, I should say so and then so you had high concentrations, all of the activity we're seeing AI, and it's also in the city, because 70% of all of the action in AI, it's coming to San Francisco. So to those of you that don't live here, trust me, we don't have dead bodies on the street, on the murder capital of America, we are really like you might find a really tasty bagel somewhere. If you hunt it's rematch is really, really vibrant. And so again, you might see some of the buildings and work again, companies
1:00like Coinbase coming back to
like Coinbase coming back to
like Coinbase coming back to
like Coinbase coming back to
1:04the cities. Great things
the cities. Great things
the cities. Great things
the cities. Great things
S Speaker 11:08happening to the city. So again, San Francisco, please tell them it's not as bad as and then just on the bank. You know, obviously we were that bank, if you hadn't figured out one two and a half years ago, really back doing a lot of the same things. And one of the exciting things that was announced,
happening to the city. So again, San Francisco, please tell them it's not as bad as and then just on the bank. You know, obviously we were that bank, if you hadn't figured out one two and a half years ago, really back doing a lot of the same things. And one of the exciting things that was announced,
happening to the city. So again, San Francisco, please tell them it's not as bad as and then just on the bank. You know, obviously we were that bank, if you hadn't figured out one two and a half years ago, really back doing a lot of the same things. And one of the exciting things that was announced,
happening to the city. So again, San Francisco, please tell them it's not as bad as and then just on the bank. You know, obviously we were that bank, if you hadn't figured out one two and a half years ago, really back doing a lot of the same things. And one of the exciting things that was announced,
1:30citizens establishing office in Ireland.
citizens establishing office in Ireland.
citizens establishing office in Ireland.
citizens establishing office in Ireland.
1:32So you start seeing international expansion back into some markets.
So you start seeing international expansion back into some markets.
So you start seeing international expansion back into some markets.
So you start seeing international expansion back into some markets.
S Speaker 11:39So with that, good luck to our presenters. Thank you hearing
So with that, good luck to our presenters. Thank you hearing
So with that, good luck to our presenters. Thank you hearing
So with that, good luck to our presenters. Thank you hearing
S Speaker 21:53your feedback. Thank you. Second here we'll have the presenters. Please get lined up over here. You folks.
your feedback. Thank you. Second here we'll have the presenters. Please get lined up over here. You folks.
your feedback. Thank you. Second here we'll have the presenters. Please get lined up over here. You folks.
your feedback. Thank you. Second here we'll have the presenters. Please get lined up over here. You folks.
2:12Sorry, we already have some technical issues. So these
Sorry, we already have some technical issues. So these
Sorry, we already have some technical issues. So these
Sorry, we already have some technical issues. So these
S Speaker 22:15are the interviewers that were involved in the process. So just if you see them in the room, if you have questions, great people to reach out to event schedule here we're kicking it off with the pitches. They're going to be about five minutes, and then we're going to limit it to a couple of questions. We have 15 companies. All the companies ended up staying in and making it to the event, which is awesome, but we will be a little time constraint. So we're also going to have a break at 240 So about halfway through the pitches, we'll have a quick break for grabbing food, networking, do what you'd like, and then we'll get right back into the pitches. And then we'll have closing remarks and get into the networking portion of the event as well. Housekeeping stuff. Please turn your phones to silent mode. Roam throughout the room eat polite butters, though, we know it's a very long day, so do what you need to we have Wi Fi, a table that has a paper on it with the information. Downstairs is also open if you need to take a call. It's nice and quiet, and there's restrooms downstairs as well as right back here. With that, we will start it off. So up first,
are the interviewers that were involved in the process. So just if you see them in the room, if you have questions, great people to reach out to event schedule here we're kicking it off with the pitches. They're going to be about five minutes, and then we're going to limit it to a couple of questions. We have 15 companies. All the companies ended up staying in and making it to the event, which is awesome, but we will be a little time constraint. So we're also going to have a break at 240 So about halfway through the pitches, we'll have a quick break for grabbing food, networking, do what you'd like, and then we'll get right back into the pitches. And then we'll have closing remarks and get into the networking portion of the event as well. Housekeeping stuff. Please turn your phones to silent mode. Roam throughout the room eat polite butters, though, we know it's a very long day, so do what you need to we have Wi Fi, a table that has a paper on it with the information. Downstairs is also open if you need to take a call. It's nice and quiet, and there's restrooms downstairs as well as right back here. With that, we will start it off. So up first,
are the interviewers that were involved in the process. So just if you see them in the room, if you have questions, great people to reach out to event schedule here we're kicking it off with the pitches. They're going to be about five minutes, and then we're going to limit it to a couple of questions. We have 15 companies. All the companies ended up staying in and making it to the event, which is awesome, but we will be a little time constraint. So we're also going to have a break at 240 So about halfway through the pitches, we'll have a quick break for grabbing food, networking, do what you'd like, and then we'll get right back into the pitches. And then we'll have closing remarks and get into the networking portion of the event as well. Housekeeping stuff. Please turn your phones to silent mode. Roam throughout the room eat polite butters, though, we know it's a very long day, so do what you need to we have Wi Fi, a table that has a paper on it with the information. Downstairs is also open if you need to take a call. It's nice and quiet, and there's restrooms downstairs as well as right back here. With that, we will start it off. So up first,
are the interviewers that were involved in the process. So just if you see them in the room, if you have questions, great people to reach out to event schedule here we're kicking it off with the pitches. They're going to be about five minutes, and then we're going to limit it to a couple of questions. We have 15 companies. All the companies ended up staying in and making it to the event, which is awesome, but we will be a little time constraint. So we're also going to have a break at 240 So about halfway through the pitches, we'll have a quick break for grabbing food, networking, do what you'd like, and then we'll get right back into the pitches. And then we'll have closing remarks and get into the networking portion of the event as well. Housekeeping stuff. Please turn your phones to silent mode. Roam throughout the room eat polite butters, though, we know it's a very long day, so do what you need to we have Wi Fi, a table that has a paper on it with the information. Downstairs is also open if you need to take a call. It's nice and quiet, and there's restrooms downstairs as well as right back here. With that, we will start it off. So up first,
3:24Cyrus, thank you for setting
Cyrus, thank you for setting
Cyrus, thank you for setting
Cyrus, thank you for setting
3:34this up, and I know getting 15 presentations like
this up, and I know getting 15 presentations like
this up, and I know getting 15 presentations like
this up, and I know getting 15 presentations like
S Speaker 33:42that, so we pronounce our
that, so we pronounce our
that, so we pronounce our
that, so we pronounce our
S Speaker 33:50ourselves. You mentioned he has a lot of friends. Priyesh P co founders, we were all running optimally at Cisco. I've been fortunate to get acquired by Cisco a couple of times. This is my fifth venture. We closed 21 million round in seed funding, and lot of people have cursed me at that don't call it seed, but that's for first round funding in March.
ourselves. You mentioned he has a lot of friends. Priyesh P co founders, we were all running optimally at Cisco. I've been fortunate to get acquired by Cisco a couple of times. This is my fifth venture. We closed 21 million round in seed funding, and lot of people have cursed me at that don't call it seed, but that's for first round funding in March.
ourselves. You mentioned he has a lot of friends. Priyesh P co founders, we were all running optimally at Cisco. I've been fortunate to get acquired by Cisco a couple of times. This is my fifth venture. We closed 21 million round in seed funding, and lot of people have cursed me at that don't call it seed, but that's for first round funding in March.
ourselves. You mentioned he has a lot of friends. Priyesh P co founders, we were all running optimally at Cisco. I've been fortunate to get acquired by Cisco a couple of times. This is my fifth venture. We closed 21 million round in seed funding, and lot of people have cursed me at that don't call it seed, but that's for first round funding in March.
S Speaker 34:29We've also been advised, of course, there are investors who are public coming, CEOs, lot of large scale enterprise companies, ELD members, who have put trust in us and put money in it. But we are also been joined by some of the visionaries, people who define site polarity engineer and what it means to
We've also been advised, of course, there are investors who are public coming, CEOs, lot of large scale enterprise companies, ELD members, who have put trust in us and put money in it. But we are also been joined by some of the visionaries, people who define site polarity engineer and what it means to
We've also been advised, of course, there are investors who are public coming, CEOs, lot of large scale enterprise companies, ELD members, who have put trust in us and put money in it. But we are also been joined by some of the visionaries, people who define site polarity engineer and what it means to
We've also been advised, of course, there are investors who are public coming, CEOs, lot of large scale enterprise companies, ELD members, who have put trust in us and put money in it. But we are also been joined by some of the visionaries, people who define site polarity engineer and what it means to
4:49be a DevOps engineer.
be a DevOps engineer.
be a DevOps engineer.
be a DevOps engineer.
S Speaker 34:52So what are we trying to solve so far, observability, prior to it being called observability was called monitoring and the goal was always, how can we keep your site up at the highest level? Right site, meaning your web portal, your applications, your internal applications, et cetera. What has happened over a period of time as an industry, everybody has built the tools for each of the domains. What do I mean by domain? It could be a network domain. It could be a security it could be a computer, could be cloud, could be front end, could be back. And if you think about those war rooms where applications are down, whole bunch of people has to get together to figure it out, because there is not a single place where you can find all the information which is correlated, and that's the state of the industry, right? There are different approaches. People try to solve this problem by bringing the data together, building large data lake, but we've taken a little bit different approach. We're also trying to realize the gap skill set, gap the bandwidth between your site reliability engineers and your application developer, think of people using cursor or Kodak's, so their productivity is going up. You absolutely need to increase the productivity of your cycle.
So what are we trying to solve so far, observability, prior to it being called observability was called monitoring and the goal was always, how can we keep your site up at the highest level? Right site, meaning your web portal, your applications, your internal applications, et cetera. What has happened over a period of time as an industry, everybody has built the tools for each of the domains. What do I mean by domain? It could be a network domain. It could be a security it could be a computer, could be cloud, could be front end, could be back. And if you think about those war rooms where applications are down, whole bunch of people has to get together to figure it out, because there is not a single place where you can find all the information which is correlated, and that's the state of the industry, right? There are different approaches. People try to solve this problem by bringing the data together, building large data lake, but we've taken a little bit different approach. We're also trying to realize the gap skill set, gap the bandwidth between your site reliability engineers and your application developer, think of people using cursor or Kodak's, so their productivity is going up. You absolutely need to increase the productivity of your cycle.
So what are we trying to solve so far, observability, prior to it being called observability was called monitoring and the goal was always, how can we keep your site up at the highest level? Right site, meaning your web portal, your applications, your internal applications, et cetera. What has happened over a period of time as an industry, everybody has built the tools for each of the domains. What do I mean by domain? It could be a network domain. It could be a security it could be a computer, could be cloud, could be front end, could be back. And if you think about those war rooms where applications are down, whole bunch of people has to get together to figure it out, because there is not a single place where you can find all the information which is correlated, and that's the state of the industry, right? There are different approaches. People try to solve this problem by bringing the data together, building large data lake, but we've taken a little bit different approach. We're also trying to realize the gap skill set, gap the bandwidth between your site reliability engineers and your application developer, think of people using cursor or Kodak's, so their productivity is going up. You absolutely need to increase the productivity of your cycle.
So what are we trying to solve so far, observability, prior to it being called observability was called monitoring and the goal was always, how can we keep your site up at the highest level? Right site, meaning your web portal, your applications, your internal applications, et cetera. What has happened over a period of time as an industry, everybody has built the tools for each of the domains. What do I mean by domain? It could be a network domain. It could be a security it could be a computer, could be cloud, could be front end, could be back. And if you think about those war rooms where applications are down, whole bunch of people has to get together to figure it out, because there is not a single place where you can find all the information which is correlated, and that's the state of the industry, right? There are different approaches. People try to solve this problem by bringing the data together, building large data lake, but we've taken a little bit different approach. We're also trying to realize the gap skill set, gap the bandwidth between your site reliability engineers and your application developer, think of people using cursor or Kodak's, so their productivity is going up. You absolutely need to increase the productivity of your cycle.
6:12So that's the problem you're trying to go after it.
So that's the problem you're trying to go after it.
So that's the problem you're trying to go after it.
So that's the problem you're trying to go after it.
S Speaker 36:17And I kind of spoke about, spoke about our ability to go across those domains right? Because when the problem happens, your customers are suffering. They don't care where the problem is, right and when everybody's sort of doing finger pointing, trying to figure out it's not my problem or it's the network problem. You know, this is where it brings extremely critical to have that insights, which is concept of all of those domains. So what we built was, we're building a multi agentic system, right? Think about this as a multi agents, with each agent having an expertise in each of those domains, which I was talking about, right? They sort of work together. Collaborate together, like VR teams collaborate to come to the conclusion in terms of what is the root cause, what's the recommendations? How do I fix it? Right? So that's basically what we try to do, right? And in enterprise, we serve large enterprises. That's our background. I had the pleasure to scale the business from zero to $5 million at Cisco, which was a startup that I was a founding member. I came in by acquisition and then scaled that business. So we deal with a lot of enterprises. The way the product is built, also is sort of very enterprise focused. And you can imagine security compliance, you can imagine the layout, where the data go right. So we deal with lot of different options, including having them deployed into their four walls of data center, and this is where it's landing really well now we got started in February by my widest expectation. We didn't believe that we would be here. We are actually deployed into large scale enterprises, a bunch of them at a very high scale, right? Thanks to being AI ideal company, thanks to being starting in 2025 and I'm going to skip really, just to kind of give you a highlight in terms of what the benefits we are seeing it before I go to benefits, enterprises is all about integrations, right? People talk about green film deployment. Enterprise is never being filled. It is always knowledgeable. You need to exist in the ecosystem. They already have invested and work with that ecosystem. So think about silos as somebody, AI teammate, which sits across all of your ecosystem, access the data like the way your engineers extract and gets to work and update your cycle. Average engineers in the place where they are, whether it's slack, Microsoft Teams, whatever you have, right? If you see the benefits in terms of the reduction of mptr, it's massive. Is 95% we've seen incidents where, and these are production incidents where it would have taken six, seven hours, and we may let it go, right? So the benefits we are seeing is massive. And these are not some prototypes on labs. These are actually large scale production components. With that I'll open up because next give me a signal.
And I kind of spoke about, spoke about our ability to go across those domains right? Because when the problem happens, your customers are suffering. They don't care where the problem is, right and when everybody's sort of doing finger pointing, trying to figure out it's not my problem or it's the network problem. You know, this is where it brings extremely critical to have that insights, which is concept of all of those domains. So what we built was, we're building a multi agentic system, right? Think about this as a multi agents, with each agent having an expertise in each of those domains, which I was talking about, right? They sort of work together. Collaborate together, like VR teams collaborate to come to the conclusion in terms of what is the root cause, what's the recommendations? How do I fix it? Right? So that's basically what we try to do, right? And in enterprise, we serve large enterprises. That's our background. I had the pleasure to scale the business from zero to $5 million at Cisco, which was a startup that I was a founding member. I came in by acquisition and then scaled that business. So we deal with a lot of enterprises. The way the product is built, also is sort of very enterprise focused. And you can imagine security compliance, you can imagine the layout, where the data go right. So we deal with lot of different options, including having them deployed into their four walls of data center, and this is where it's landing really well now we got started in February by my widest expectation. We didn't believe that we would be here. We are actually deployed into large scale enterprises, a bunch of them at a very high scale, right? Thanks to being AI ideal company, thanks to being starting in 2025 and I'm going to skip really, just to kind of give you a highlight in terms of what the benefits we are seeing it before I go to benefits, enterprises is all about integrations, right? People talk about green film deployment. Enterprise is never being filled. It is always knowledgeable. You need to exist in the ecosystem. They already have invested and work with that ecosystem. So think about silos as somebody, AI teammate, which sits across all of your ecosystem, access the data like the way your engineers extract and gets to work and update your cycle. Average engineers in the place where they are, whether it's slack, Microsoft Teams, whatever you have, right? If you see the benefits in terms of the reduction of mptr, it's massive. Is 95% we've seen incidents where, and these are production incidents where it would have taken six, seven hours, and we may let it go, right? So the benefits we are seeing is massive. And these are not some prototypes on labs. These are actually large scale production components. With that I'll open up because next give me a signal.
And I kind of spoke about, spoke about our ability to go across those domains right? Because when the problem happens, your customers are suffering. They don't care where the problem is, right and when everybody's sort of doing finger pointing, trying to figure out it's not my problem or it's the network problem. You know, this is where it brings extremely critical to have that insights, which is concept of all of those domains. So what we built was, we're building a multi agentic system, right? Think about this as a multi agents, with each agent having an expertise in each of those domains, which I was talking about, right? They sort of work together. Collaborate together, like VR teams collaborate to come to the conclusion in terms of what is the root cause, what's the recommendations? How do I fix it? Right? So that's basically what we try to do, right? And in enterprise, we serve large enterprises. That's our background. I had the pleasure to scale the business from zero to $5 million at Cisco, which was a startup that I was a founding member. I came in by acquisition and then scaled that business. So we deal with a lot of enterprises. The way the product is built, also is sort of very enterprise focused. And you can imagine security compliance, you can imagine the layout, where the data go right. So we deal with lot of different options, including having them deployed into their four walls of data center, and this is where it's landing really well now we got started in February by my widest expectation. We didn't believe that we would be here. We are actually deployed into large scale enterprises, a bunch of them at a very high scale, right? Thanks to being AI ideal company, thanks to being starting in 2025 and I'm going to skip really, just to kind of give you a highlight in terms of what the benefits we are seeing it before I go to benefits, enterprises is all about integrations, right? People talk about green film deployment. Enterprise is never being filled. It is always knowledgeable. You need to exist in the ecosystem. They already have invested and work with that ecosystem. So think about silos as somebody, AI teammate, which sits across all of your ecosystem, access the data like the way your engineers extract and gets to work and update your cycle. Average engineers in the place where they are, whether it's slack, Microsoft Teams, whatever you have, right? If you see the benefits in terms of the reduction of mptr, it's massive. Is 95% we've seen incidents where, and these are production incidents where it would have taken six, seven hours, and we may let it go, right? So the benefits we are seeing is massive. And these are not some prototypes on labs. These are actually large scale production components. With that I'll open up because next give me a signal.
And I kind of spoke about, spoke about our ability to go across those domains right? Because when the problem happens, your customers are suffering. They don't care where the problem is, right and when everybody's sort of doing finger pointing, trying to figure out it's not my problem or it's the network problem. You know, this is where it brings extremely critical to have that insights, which is concept of all of those domains. So what we built was, we're building a multi agentic system, right? Think about this as a multi agents, with each agent having an expertise in each of those domains, which I was talking about, right? They sort of work together. Collaborate together, like VR teams collaborate to come to the conclusion in terms of what is the root cause, what's the recommendations? How do I fix it? Right? So that's basically what we try to do, right? And in enterprise, we serve large enterprises. That's our background. I had the pleasure to scale the business from zero to $5 million at Cisco, which was a startup that I was a founding member. I came in by acquisition and then scaled that business. So we deal with a lot of enterprises. The way the product is built, also is sort of very enterprise focused. And you can imagine security compliance, you can imagine the layout, where the data go right. So we deal with lot of different options, including having them deployed into their four walls of data center, and this is where it's landing really well now we got started in February by my widest expectation. We didn't believe that we would be here. We are actually deployed into large scale enterprises, a bunch of them at a very high scale, right? Thanks to being AI ideal company, thanks to being starting in 2025 and I'm going to skip really, just to kind of give you a highlight in terms of what the benefits we are seeing it before I go to benefits, enterprises is all about integrations, right? People talk about green film deployment. Enterprise is never being filled. It is always knowledgeable. You need to exist in the ecosystem. They already have invested and work with that ecosystem. So think about silos as somebody, AI teammate, which sits across all of your ecosystem, access the data like the way your engineers extract and gets to work and update your cycle. Average engineers in the place where they are, whether it's slack, Microsoft Teams, whatever you have, right? If you see the benefits in terms of the reduction of mptr, it's massive. Is 95% we've seen incidents where, and these are production incidents where it would have taken six, seven hours, and we may let it go, right? So the benefits we are seeing is massive. And these are not some prototypes on labs. These are actually large scale production components. With that I'll open up because next give me a signal.
9:14I go over. Happy to take any questions. You
I go over. Happy to take any questions. You
I go over. Happy to take any questions. You
I go over. Happy to take any questions. You
S Speaker 39:39question. So I talk about product, right? We build the product, you know, we if your friends at places where I worked, you can talk about our institutions, like record. So that's not been a
question. So I talk about product, right? We build the product, you know, we if your friends at places where I worked, you can talk about our institutions, like record. So that's not been a
question. So I talk about product, right? We build the product, you know, we if your friends at places where I worked, you can talk about our institutions, like record. So that's not been a
question. So I talk about product, right? We build the product, you know, we if your friends at places where I worked, you can talk about our institutions, like record. So that's not been a
9:52problem, AI, marketing, simple has been extremely noisy,
problem, AI, marketing, simple has been extremely noisy,
problem, AI, marketing, simple has been extremely noisy,
problem, AI, marketing, simple has been extremely noisy,
S Speaker 39:56because barrier to entry has kind of gone down in terms of building solution, right? So if you look at large, there are 30 companies in this space, right? Literally. And, you know, it takes, and this is where it is very different. So one is the noise, which has been a challenge, and how do you make sure that we are actually addressing the problem and addressing the customers means? The second thing is, in terms of pace of innovation, which is right, and how fast you move, right? Lot of times customers, enterprise customers, also take little bit time, right? So kind of getting them along. On the flip side of it, lot of enterprises have budget allocated for AI initiative, right? So the customers, where we are, much of them where we are already deployed. Those are all in mum, we actually gain reach out Splunk event, which happened week back, was the first right? So actually enough marketing, which I believe we are ready to go now. This is why we are here, but that's been basically where we have been focused on not so much of challenge.
because barrier to entry has kind of gone down in terms of building solution, right? So if you look at large, there are 30 companies in this space, right? Literally. And, you know, it takes, and this is where it is very different. So one is the noise, which has been a challenge, and how do you make sure that we are actually addressing the problem and addressing the customers means? The second thing is, in terms of pace of innovation, which is right, and how fast you move, right? Lot of times customers, enterprise customers, also take little bit time, right? So kind of getting them along. On the flip side of it, lot of enterprises have budget allocated for AI initiative, right? So the customers, where we are, much of them where we are already deployed. Those are all in mum, we actually gain reach out Splunk event, which happened week back, was the first right? So actually enough marketing, which I believe we are ready to go now. This is why we are here, but that's been basically where we have been focused on not so much of challenge.
because barrier to entry has kind of gone down in terms of building solution, right? So if you look at large, there are 30 companies in this space, right? Literally. And, you know, it takes, and this is where it is very different. So one is the noise, which has been a challenge, and how do you make sure that we are actually addressing the problem and addressing the customers means? The second thing is, in terms of pace of innovation, which is right, and how fast you move, right? Lot of times customers, enterprise customers, also take little bit time, right? So kind of getting them along. On the flip side of it, lot of enterprises have budget allocated for AI initiative, right? So the customers, where we are, much of them where we are already deployed. Those are all in mum, we actually gain reach out Splunk event, which happened week back, was the first right? So actually enough marketing, which I believe we are ready to go now. This is why we are here, but that's been basically where we have been focused on not so much of challenge.
because barrier to entry has kind of gone down in terms of building solution, right? So if you look at large, there are 30 companies in this space, right? Literally. And, you know, it takes, and this is where it is very different. So one is the noise, which has been a challenge, and how do you make sure that we are actually addressing the problem and addressing the customers means? The second thing is, in terms of pace of innovation, which is right, and how fast you move, right? Lot of times customers, enterprise customers, also take little bit time, right? So kind of getting them along. On the flip side of it, lot of enterprises have budget allocated for AI initiative, right? So the customers, where we are, much of them where we are already deployed. Those are all in mum, we actually gain reach out Splunk event, which happened week back, was the first right? So actually enough marketing, which I believe we are ready to go now. This is why we are here, but that's been basically where we have been focused on not so much of challenge.
S Speaker 411:09One quick question. Last one, how do you compare starters with other more general, AI slash agent observability startups out there, and particularly, why you picked this focus area in SRE as a maybe a starting point, or as the
One quick question. Last one, how do you compare starters with other more general, AI slash agent observability startups out there, and particularly, why you picked this focus area in SRE as a maybe a starting point, or as the
One quick question. Last one, how do you compare starters with other more general, AI slash agent observability startups out there, and particularly, why you picked this focus area in SRE as a maybe a starting point, or as the
One quick question. Last one, how do you compare starters with other more general, AI slash agent observability startups out there, and particularly, why you picked this focus area in SRE as a maybe a starting point, or as the
S Speaker 311:25focus area, focus area besides the library engineer? Yes, yeah. So I think two things, like the way for security, observability is very fragmented. There are probably, like we did a survey and we found enterprises which has 100 foods, just for observability, not security, just absolutely right? And when you have that kind of fragmented market, what ends up happening is there's a domain expert for each one of them, and there's a person, right? So that's why we decided that the market was ready. And then, like the budget for observability to look at it total cloud budget will get enterprise, on an average, they spend 12 to 15% it's a massive budget. Secondly, when we talk to CIOs and UT engineering, we're talking about, how do we make them more efficient? But when you talk to cycle library engineers, remember I talked about the gap between what is they're supposed to do, versus the more coming at that end, there's a huge gap, right? So fill that gap up. There's a need, there's a budget, and that's why we decided to take this out.
focus area, focus area besides the library engineer? Yes, yeah. So I think two things, like the way for security, observability is very fragmented. There are probably, like we did a survey and we found enterprises which has 100 foods, just for observability, not security, just absolutely right? And when you have that kind of fragmented market, what ends up happening is there's a domain expert for each one of them, and there's a person, right? So that's why we decided that the market was ready. And then, like the budget for observability to look at it total cloud budget will get enterprise, on an average, they spend 12 to 15% it's a massive budget. Secondly, when we talk to CIOs and UT engineering, we're talking about, how do we make them more efficient? But when you talk to cycle library engineers, remember I talked about the gap between what is they're supposed to do, versus the more coming at that end, there's a huge gap, right? So fill that gap up. There's a need, there's a budget, and that's why we decided to take this out.
focus area, focus area besides the library engineer? Yes, yeah. So I think two things, like the way for security, observability is very fragmented. There are probably, like we did a survey and we found enterprises which has 100 foods, just for observability, not security, just absolutely right? And when you have that kind of fragmented market, what ends up happening is there's a domain expert for each one of them, and there's a person, right? So that's why we decided that the market was ready. And then, like the budget for observability to look at it total cloud budget will get enterprise, on an average, they spend 12 to 15% it's a massive budget. Secondly, when we talk to CIOs and UT engineering, we're talking about, how do we make them more efficient? But when you talk to cycle library engineers, remember I talked about the gap between what is they're supposed to do, versus the more coming at that end, there's a huge gap, right? So fill that gap up. There's a need, there's a budget, and that's why we decided to take this out.
focus area, focus area besides the library engineer? Yes, yeah. So I think two things, like the way for security, observability is very fragmented. There are probably, like we did a survey and we found enterprises which has 100 foods, just for observability, not security, just absolutely right? And when you have that kind of fragmented market, what ends up happening is there's a domain expert for each one of them, and there's a person, right? So that's why we decided that the market was ready. And then, like the budget for observability to look at it total cloud budget will get enterprise, on an average, they spend 12 to 15% it's a massive budget. Secondly, when we talk to CIOs and UT engineering, we're talking about, how do we make them more efficient? But when you talk to cycle library engineers, remember I talked about the gap between what is they're supposed to do, versus the more coming at that end, there's a huge gap, right? So fill that gap up. There's a need, there's a budget, and that's why we decided to take this out.
12:33Thank you. I'll be around up
Thank you. I'll be around up
Thank you. I'll be around up
Thank you. I'll be around up
12:40next. We have guardrails.
next. We have guardrails.
next. We have guardrails.
next. We have guardrails.
S Speaker 512:50All right, hey everybody. I'm excited to be here and talk to you about guardrails. Specifically, the product that I'm going to talk to you about is simulation testing, which might be you know, newer paradigm for most of the people in this audience. So hopefully this is you know something before we get started. The focus of the company, guardrails, as the name suggests, is reliability. My own background is in AI. I've been working in AI, doing research, working in self driving cars, supply machine learning, robustness, etc, for the last like, 12 or 13 years. And because of that experience, you know, deeply understand the chasm between, you know, building even something that's like, maybe has very high accuracy on a test data set to actually shipping something like that out onto, you know, onto production, maybe onto even, like, real roads, you know, where there's like, super high risk. And have understood, you know, what are the techniques and tricks that have worked really well in the past in very high risk domains. And the focus of the company is really bring all of that, all of that knowledge, and build infrastructure to make your AI projects and your AI efforts more reliable, more risk free, etc. What we're probably best known for is, you know, kind of creating this paradigm of guardrails. So the company started with an open source project that we created which really introduced this idea of guardrails. Ai, guardrails as infrastructure, not just, you know, policy or governance, etc, very widely used platform today as well. The largest, you know, collection of guardrails will find anywhere used by a number of organizations, including, you know, large financial institutions, telecom companies, you know, tech for startups, etc, awesome. So the big problem that a lot of you know that is novel when it comes to this era of generative AI and building products with generative AI is, how do you really even test that? Right? Most of you, for example, might have, you know, teams in your organizations that are building AI agents. And a very common problem is, how do you, how do I even test out how this AI agent performs, typically, in the past, you know, eras of machine learning. What you would do is you would create, like, a data set at self driving cars, for example, we would spend, like, hundreds of millions of dollars on just creating a data set, like every year. But when it when it comes to agent this space that these agents can operate in this unbounded Right? Like we think about your coding agent, for example, the input for that coding agent is just unstructured test text. You can copy, paste anything into that text box, and it will take actions for you and just go out and based on how many permissions you set out, just go out and take actions, right? So anytime you're building this agent that has this very sophisticated surface area of where it can act and what it can change, it becomes just really, really challenging. And how do you start testing that? And when you create a static, manually created test data set of, you know, some prompts and some responses, etc. It just becomes very challenging to, you know, get coverage over the hundreds of 1000s of, you know, use cases, queries that your actual human users will provide it right when, when you actually go out into production. And this is also, like, this lack of test. Testing is also where, you know, a very common paradigm of, like, oh, it totally worked. You know, we had like, such high accuracy when we tested it out. You know, when you go out there, you run into all of these headlines, of your risk and hallucinations, etc. So all of those failures happen in those gaps which become very, very hard for humans to test out, just because of how unique and rare a lot of these failures end up being, and how many corner cases and edge cases there are, interestingly, while this is a new problem in AI software, it's not a net new problem in AI generally, in self driving cars, for example, this is a problem we saw very, very often. The real world is a long story distribution where there's so many
All right, hey everybody. I'm excited to be here and talk to you about guardrails. Specifically, the product that I'm going to talk to you about is simulation testing, which might be you know, newer paradigm for most of the people in this audience. So hopefully this is you know something before we get started. The focus of the company, guardrails, as the name suggests, is reliability. My own background is in AI. I've been working in AI, doing research, working in self driving cars, supply machine learning, robustness, etc, for the last like, 12 or 13 years. And because of that experience, you know, deeply understand the chasm between, you know, building even something that's like, maybe has very high accuracy on a test data set to actually shipping something like that out onto, you know, onto production, maybe onto even, like, real roads, you know, where there's like, super high risk. And have understood, you know, what are the techniques and tricks that have worked really well in the past in very high risk domains. And the focus of the company is really bring all of that, all of that knowledge, and build infrastructure to make your AI projects and your AI efforts more reliable, more risk free, etc. What we're probably best known for is, you know, kind of creating this paradigm of guardrails. So the company started with an open source project that we created which really introduced this idea of guardrails. Ai, guardrails as infrastructure, not just, you know, policy or governance, etc, very widely used platform today as well. The largest, you know, collection of guardrails will find anywhere used by a number of organizations, including, you know, large financial institutions, telecom companies, you know, tech for startups, etc, awesome. So the big problem that a lot of you know that is novel when it comes to this era of generative AI and building products with generative AI is, how do you really even test that? Right? Most of you, for example, might have, you know, teams in your organizations that are building AI agents. And a very common problem is, how do you, how do I even test out how this AI agent performs, typically, in the past, you know, eras of machine learning. What you would do is you would create, like, a data set at self driving cars, for example, we would spend, like, hundreds of millions of dollars on just creating a data set, like every year. But when it when it comes to agent this space that these agents can operate in this unbounded Right? Like we think about your coding agent, for example, the input for that coding agent is just unstructured test text. You can copy, paste anything into that text box, and it will take actions for you and just go out and based on how many permissions you set out, just go out and take actions, right? So anytime you're building this agent that has this very sophisticated surface area of where it can act and what it can change, it becomes just really, really challenging. And how do you start testing that? And when you create a static, manually created test data set of, you know, some prompts and some responses, etc. It just becomes very challenging to, you know, get coverage over the hundreds of 1000s of, you know, use cases, queries that your actual human users will provide it right when, when you actually go out into production. And this is also, like, this lack of test. Testing is also where, you know, a very common paradigm of, like, oh, it totally worked. You know, we had like, such high accuracy when we tested it out. You know, when you go out there, you run into all of these headlines, of your risk and hallucinations, etc. So all of those failures happen in those gaps which become very, very hard for humans to test out, just because of how unique and rare a lot of these failures end up being, and how many corner cases and edge cases there are, interestingly, while this is a new problem in AI software, it's not a net new problem in AI generally, in self driving cars, for example, this is a problem we saw very, very often. The real world is a long story distribution where there's so many
All right, hey everybody. I'm excited to be here and talk to you about guardrails. Specifically, the product that I'm going to talk to you about is simulation testing, which might be you know, newer paradigm for most of the people in this audience. So hopefully this is you know something before we get started. The focus of the company, guardrails, as the name suggests, is reliability. My own background is in AI. I've been working in AI, doing research, working in self driving cars, supply machine learning, robustness, etc, for the last like, 12 or 13 years. And because of that experience, you know, deeply understand the chasm between, you know, building even something that's like, maybe has very high accuracy on a test data set to actually shipping something like that out onto, you know, onto production, maybe onto even, like, real roads, you know, where there's like, super high risk. And have understood, you know, what are the techniques and tricks that have worked really well in the past in very high risk domains. And the focus of the company is really bring all of that, all of that knowledge, and build infrastructure to make your AI projects and your AI efforts more reliable, more risk free, etc. What we're probably best known for is, you know, kind of creating this paradigm of guardrails. So the company started with an open source project that we created which really introduced this idea of guardrails. Ai, guardrails as infrastructure, not just, you know, policy or governance, etc, very widely used platform today as well. The largest, you know, collection of guardrails will find anywhere used by a number of organizations, including, you know, large financial institutions, telecom companies, you know, tech for startups, etc, awesome. So the big problem that a lot of you know that is novel when it comes to this era of generative AI and building products with generative AI is, how do you really even test that? Right? Most of you, for example, might have, you know, teams in your organizations that are building AI agents. And a very common problem is, how do you, how do I even test out how this AI agent performs, typically, in the past, you know, eras of machine learning. What you would do is you would create, like, a data set at self driving cars, for example, we would spend, like, hundreds of millions of dollars on just creating a data set, like every year. But when it when it comes to agent this space that these agents can operate in this unbounded Right? Like we think about your coding agent, for example, the input for that coding agent is just unstructured test text. You can copy, paste anything into that text box, and it will take actions for you and just go out and based on how many permissions you set out, just go out and take actions, right? So anytime you're building this agent that has this very sophisticated surface area of where it can act and what it can change, it becomes just really, really challenging. And how do you start testing that? And when you create a static, manually created test data set of, you know, some prompts and some responses, etc. It just becomes very challenging to, you know, get coverage over the hundreds of 1000s of, you know, use cases, queries that your actual human users will provide it right when, when you actually go out into production. And this is also, like, this lack of test. Testing is also where, you know, a very common paradigm of, like, oh, it totally worked. You know, we had like, such high accuracy when we tested it out. You know, when you go out there, you run into all of these headlines, of your risk and hallucinations, etc. So all of those failures happen in those gaps which become very, very hard for humans to test out, just because of how unique and rare a lot of these failures end up being, and how many corner cases and edge cases there are, interestingly, while this is a new problem in AI software, it's not a net new problem in AI generally, in self driving cars, for example, this is a problem we saw very, very often. The real world is a long story distribution where there's so many
All right, hey everybody. I'm excited to be here and talk to you about guardrails. Specifically, the product that I'm going to talk to you about is simulation testing, which might be you know, newer paradigm for most of the people in this audience. So hopefully this is you know something before we get started. The focus of the company, guardrails, as the name suggests, is reliability. My own background is in AI. I've been working in AI, doing research, working in self driving cars, supply machine learning, robustness, etc, for the last like, 12 or 13 years. And because of that experience, you know, deeply understand the chasm between, you know, building even something that's like, maybe has very high accuracy on a test data set to actually shipping something like that out onto, you know, onto production, maybe onto even, like, real roads, you know, where there's like, super high risk. And have understood, you know, what are the techniques and tricks that have worked really well in the past in very high risk domains. And the focus of the company is really bring all of that, all of that knowledge, and build infrastructure to make your AI projects and your AI efforts more reliable, more risk free, etc. What we're probably best known for is, you know, kind of creating this paradigm of guardrails. So the company started with an open source project that we created which really introduced this idea of guardrails. Ai, guardrails as infrastructure, not just, you know, policy or governance, etc, very widely used platform today as well. The largest, you know, collection of guardrails will find anywhere used by a number of organizations, including, you know, large financial institutions, telecom companies, you know, tech for startups, etc, awesome. So the big problem that a lot of you know that is novel when it comes to this era of generative AI and building products with generative AI is, how do you really even test that? Right? Most of you, for example, might have, you know, teams in your organizations that are building AI agents. And a very common problem is, how do you, how do I even test out how this AI agent performs, typically, in the past, you know, eras of machine learning. What you would do is you would create, like, a data set at self driving cars, for example, we would spend, like, hundreds of millions of dollars on just creating a data set, like every year. But when it when it comes to agent this space that these agents can operate in this unbounded Right? Like we think about your coding agent, for example, the input for that coding agent is just unstructured test text. You can copy, paste anything into that text box, and it will take actions for you and just go out and based on how many permissions you set out, just go out and take actions, right? So anytime you're building this agent that has this very sophisticated surface area of where it can act and what it can change, it becomes just really, really challenging. And how do you start testing that? And when you create a static, manually created test data set of, you know, some prompts and some responses, etc. It just becomes very challenging to, you know, get coverage over the hundreds of 1000s of, you know, use cases, queries that your actual human users will provide it right when, when you actually go out into production. And this is also, like, this lack of test. Testing is also where, you know, a very common paradigm of, like, oh, it totally worked. You know, we had like, such high accuracy when we tested it out. You know, when you go out there, you run into all of these headlines, of your risk and hallucinations, etc. So all of those failures happen in those gaps which become very, very hard for humans to test out, just because of how unique and rare a lot of these failures end up being, and how many corner cases and edge cases there are, interestingly, while this is a new problem in AI software, it's not a net new problem in AI generally, in self driving cars, for example, this is a problem we saw very, very often. The real world is a long story distribution where there's so many
16:41cases what delays technology
cases what delays technology
cases what delays technology
cases what delays technology
S Speaker 620:49That's my time. I guess you have some minutes for questions. Yeah, a couple
That's my time. I guess you have some minutes for questions. Yeah, a couple
That's my time. I guess you have some minutes for questions. Yeah, a couple
That's my time. I guess you have some minutes for questions. Yeah, a couple
S Speaker 720:59questions. Great pitch. You mentioned the long tail problem, where AI agents fail and then you have a simulation engine. What approach have you taken such that your simulation engine generates synthetic data to capture all the long tail problems? I think
questions. Great pitch. You mentioned the long tail problem, where AI agents fail and then you have a simulation engine. What approach have you taken such that your simulation engine generates synthetic data to capture all the long tail problems? I think
questions. Great pitch. You mentioned the long tail problem, where AI agents fail and then you have a simulation engine. What approach have you taken such that your simulation engine generates synthetic data to capture all the long tail problems? I think
questions. Great pitch. You mentioned the long tail problem, where AI agents fail and then you have a simulation engine. What approach have you taken such that your simulation engine generates synthetic data to capture all the long tail problems? I think
S Speaker 521:13in terms of the actual algorithm under the hood, we do use, you know, like we have a multi agent LM system, so we use multiple llms that both kind of, you know, understand what the problem is, and, you know, anticipate is kind of like, start this planning trajectory where they, you know, for example, like, create a bunch of, like initial scenarios, pull those scenarios out into your agent, and then, you know, see where the risks start bearing right. And each scenario is, like, you know, multiple complex or execution, etc. So it ends up being a way complicated. But a lot of the real value comes from, like, our adaptability. So let's say we create this initial set of scenarios, and then, you know, start, start, kind of like building a distribution of how your AI system behaves on our initial set. And then we kind of keep evolving, you know, new scenarios that we create to kind of like, figure out, okay, there seems to be, like, some issues here, some like green performance there, and kind of like, do this, like Dynamic exploration. That gives you a lot of that question.
in terms of the actual algorithm under the hood, we do use, you know, like we have a multi agent LM system, so we use multiple llms that both kind of, you know, understand what the problem is, and, you know, anticipate is kind of like, start this planning trajectory where they, you know, for example, like, create a bunch of, like initial scenarios, pull those scenarios out into your agent, and then, you know, see where the risks start bearing right. And each scenario is, like, you know, multiple complex or execution, etc. So it ends up being a way complicated. But a lot of the real value comes from, like, our adaptability. So let's say we create this initial set of scenarios, and then, you know, start, start, kind of like building a distribution of how your AI system behaves on our initial set. And then we kind of keep evolving, you know, new scenarios that we create to kind of like, figure out, okay, there seems to be, like, some issues here, some like green performance there, and kind of like, do this, like Dynamic exploration. That gives you a lot of that question.
in terms of the actual algorithm under the hood, we do use, you know, like we have a multi agent LM system, so we use multiple llms that both kind of, you know, understand what the problem is, and, you know, anticipate is kind of like, start this planning trajectory where they, you know, for example, like, create a bunch of, like initial scenarios, pull those scenarios out into your agent, and then, you know, see where the risks start bearing right. And each scenario is, like, you know, multiple complex or execution, etc. So it ends up being a way complicated. But a lot of the real value comes from, like, our adaptability. So let's say we create this initial set of scenarios, and then, you know, start, start, kind of like building a distribution of how your AI system behaves on our initial set. And then we kind of keep evolving, you know, new scenarios that we create to kind of like, figure out, okay, there seems to be, like, some issues here, some like green performance there, and kind of like, do this, like Dynamic exploration. That gives you a lot of that question.
in terms of the actual algorithm under the hood, we do use, you know, like we have a multi agent LM system, so we use multiple llms that both kind of, you know, understand what the problem is, and, you know, anticipate is kind of like, start this planning trajectory where they, you know, for example, like, create a bunch of, like initial scenarios, pull those scenarios out into your agent, and then, you know, see where the risks start bearing right. And each scenario is, like, you know, multiple complex or execution, etc. So it ends up being a way complicated. But a lot of the real value comes from, like, our adaptability. So let's say we create this initial set of scenarios, and then, you know, start, start, kind of like building a distribution of how your AI system behaves on our initial set. And then we kind of keep evolving, you know, new scenarios that we create to kind of like, figure out, okay, there seems to be, like, some issues here, some like green performance there, and kind of like, do this, like Dynamic exploration. That gives you a lot of that question.
S Speaker 522:33Yeah, that's a great, great question. I think there's a lot of overlap with, you know, RL environments. I think, like one of the key differences, there's a lot that goes into, you know, like managing the training room, etc, and customization and our, like, our ICT, really, you know, like, it's basically designed to be, like, very customizable, so that the user has to do, you know, very little lift, including, like, non technical users, product owners, etc, that can also get set up with it in terms of our customers? Yeah, we, I think, like, we kind of, like, started building this up for, you know, product teams at enterprises. But since then, have received like, a lot of impound from like, large foundation model companies that do use this for generating data at scale for thank you so
Yeah, that's a great, great question. I think there's a lot of overlap with, you know, RL environments. I think, like one of the key differences, there's a lot that goes into, you know, like managing the training room, etc, and customization and our, like, our ICT, really, you know, like, it's basically designed to be, like, very customizable, so that the user has to do, you know, very little lift, including, like, non technical users, product owners, etc, that can also get set up with it in terms of our customers? Yeah, we, I think, like, we kind of, like, started building this up for, you know, product teams at enterprises. But since then, have received like, a lot of impound from like, large foundation model companies that do use this for generating data at scale for thank you so
Yeah, that's a great, great question. I think there's a lot of overlap with, you know, RL environments. I think, like one of the key differences, there's a lot that goes into, you know, like managing the training room, etc, and customization and our, like, our ICT, really, you know, like, it's basically designed to be, like, very customizable, so that the user has to do, you know, very little lift, including, like, non technical users, product owners, etc, that can also get set up with it in terms of our customers? Yeah, we, I think, like, we kind of, like, started building this up for, you know, product teams at enterprises. But since then, have received like, a lot of impound from like, large foundation model companies that do use this for generating data at scale for thank you so
Yeah, that's a great, great question. I think there's a lot of overlap with, you know, RL environments. I think, like one of the key differences, there's a lot that goes into, you know, like managing the training room, etc, and customization and our, like, our ICT, really, you know, like, it's basically designed to be, like, very customizable, so that the user has to do, you know, very little lift, including, like, non technical users, product owners, etc, that can also get set up with it in terms of our customers? Yeah, we, I think, like, we kind of, like, started building this up for, you know, product teams at enterprises. But since then, have received like, a lot of impound from like, large foundation model companies that do use this for generating data at scale for thank you so
23:24up next, we have lanai.
up next, we have lanai.
up next, we have lanai.
up next, we have lanai.
S Speaker 823:32Okay, all right, guys, everybody look under your chairs. I'm gonna put a small flask there. I want you to take a shot every time you hear observability, okay, all right. I'm Lexi. I'm co founder and CEO of Lanai. We have a team here from Splunk volunteer VMware Lanai, last slide first. We organize AI at work and make it visible, safe and impactful. We sell to CIOs, peak officers, peak AI officers, we deliver an edge based AI interaction. Ai interaction visibility. How do employees use AI?
Okay, all right, guys, everybody look under your chairs. I'm gonna put a small flask there. I want you to take a shot every time you hear observability, okay, all right. I'm Lexi. I'm co founder and CEO of Lanai. We have a team here from Splunk volunteer VMware Lanai, last slide first. We organize AI at work and make it visible, safe and impactful. We sell to CIOs, peak officers, peak AI officers, we deliver an edge based AI interaction. Ai interaction visibility. How do employees use AI?
Okay, all right, guys, everybody look under your chairs. I'm gonna put a small flask there. I want you to take a shot every time you hear observability, okay, all right. I'm Lexi. I'm co founder and CEO of Lanai. We have a team here from Splunk volunteer VMware Lanai, last slide first. We organize AI at work and make it visible, safe and impactful. We sell to CIOs, peak officers, peak AI officers, we deliver an edge based AI interaction. Ai interaction visibility. How do employees use AI?
Okay, all right, guys, everybody look under your chairs. I'm gonna put a small flask there. I want you to take a shot every time you hear observability, okay, all right. I'm Lexi. I'm co founder and CEO of Lanai. We have a team here from Splunk volunteer VMware Lanai, last slide first. We organize AI at work and make it visible, safe and impactful. We sell to CIOs, peak officers, peak AI officers, we deliver an edge based AI interaction. Ai interaction visibility. How do employees use AI?
S Speaker 826:37And if you think about every other tech wave has solved this with one thing, observability infrastructure. Apps had Datadog and New Relic security. CrowdStrike data has Databricks and snowflake record.
And if you think about every other tech wave has solved this with one thing, observability infrastructure. Apps had Datadog and New Relic security. CrowdStrike data has Databricks and snowflake record.
And if you think about every other tech wave has solved this with one thing, observability infrastructure. Apps had Datadog and New Relic security. CrowdStrike data has Databricks and snowflake record.
And if you think about every other tech wave has solved this with one thing, observability infrastructure. Apps had Datadog and New Relic security. CrowdStrike data has Databricks and snowflake record.
31:53yeah, one or two because they're quick. Okay, yes.
yeah, one or two because they're quick. Okay, yes.
yeah, one or two because they're quick. Okay, yes.
yeah, one or two because they're quick. Okay, yes.
S Speaker 931:57What's your insertion point? Do you use a plugin of something?
What's your insertion point? Do you use a plugin of something?
What's your insertion point? Do you use a plugin of something?
What's your insertion point? Do you use a plugin of something?
32:00It's all through a browser. Is it a plugin
It's all through a browser. Is it a plugin
It's all through a browser. Is it a plugin
It's all through a browser. Is it a plugin
32:03and it's deployed through
and it's deployed through
and it's deployed through
and it's deployed through
32:09and it's a plugin? Yeah, the CIO,
and it's a plugin? Yeah, the CIO,
and it's a plugin? Yeah, the CIO,
and it's a plugin? Yeah, the CIO,
S Speaker 832:18the Chief Data Analytics officer or the chief AI officer. Usually people will land it in AI experimental budget, and will be it's right now being used by the AI councils of organizations who have to go into the budget season. So even stop, start continuing investing
the Chief Data Analytics officer or the chief AI officer. Usually people will land it in AI experimental budget, and will be it's right now being used by the AI councils of organizations who have to go into the budget season. So even stop, start continuing investing
the Chief Data Analytics officer or the chief AI officer. Usually people will land it in AI experimental budget, and will be it's right now being used by the AI councils of organizations who have to go into the budget season. So even stop, start continuing investing
the Chief Data Analytics officer or the chief AI officer. Usually people will land it in AI experimental budget, and will be it's right now being used by the AI councils of organizations who have to go into the budget season. So even stop, start continuing investing
32:39in and then it lands in the it great. Thank you so much.
in and then it lands in the it great. Thank you so much.
in and then it lands in the it great. Thank you so much.
in and then it lands in the it great. Thank you so much.
32:55you. We have rocks AI. Thank
you. We have rocks AI. Thank
you. We have rocks AI. Thank
you. We have rocks AI. Thank
S Speaker 1032:59you. That's the board, very possible. Hey, thank you for coming out today. Thank you SVP for giving us the opportunity.
you. That's the board, very possible. Hey, thank you for coming out today. Thank you SVP for giving us the opportunity.
you. That's the board, very possible. Hey, thank you for coming out today. Thank you SVP for giving us the opportunity.
you. That's the board, very possible. Hey, thank you for coming out today. Thank you SVP for giving us the opportunity.
S Speaker 933:07Rocks we get revenue agents for the
Rocks we get revenue agents for the
Rocks we get revenue agents for the
Rocks we get revenue agents for the
S Speaker 933:13show of hands. Anyone in this room have a background in enterprise sales? Okay, that was fewer than I expected. We'll do some stories. How about that? We've been talking about AI for a long time. So what's changed
show of hands. Anyone in this room have a background in enterprise sales? Okay, that was fewer than I expected. We'll do some stories. How about that? We've been talking about AI for a long time. So what's changed
show of hands. Anyone in this room have a background in enterprise sales? Okay, that was fewer than I expected. We'll do some stories. How about that? We've been talking about AI for a long time. So what's changed
show of hands. Anyone in this room have a background in enterprise sales? Okay, that was fewer than I expected. We'll do some stories. How about that? We've been talking about AI for a long time. So what's changed
33:28now? Now CEOs are talking about
now? Now CEOs are talking about
now? Now CEOs are talking about
now? Now CEOs are talking about
S Speaker 933:33that we saw when we rolled out cursor and were reserved to our engineering organizations. And up until now, there hasn't really been any good answer for that. So that's why, with Rox, we start getting calls from the CEO Siemens, Philips and Intel, we've got 25 million agents in production today. Process more than 4 trillion tokens. Reasons really matters is that we're going to give back to the enterprise seller their most precious commodity, which is their time, time they can spend with their customers, time they can find deals, time they can close deals and put wins on the board. If you ask those sellers what they think about legacy CRMs, they're going to tell you that they've always been broken. They've always wanted a better solution than what they've got, and that is because the CRM that you're used to dealing with today doesn't do any work for the seller. It makes the seller take time away from the customers to do work for you. That's why you see this ecosystem of point solutions popping up around for every piece of functionality you get from an outreach, from clarity, from Gong, your salesperson has to deal with more complexity in the tool stack, more friction. At the same time, what we've seen is the customer data is moving out of the cloud and into the data warehouse. So that means if you want a true customer priyeshtop, you're actually not going to find it as CRM. On the other hand, that creates an amazing opportunity for us. We can go straight to the data warehouse. We can bring in full lifecycle AI support for your sellers, and we can power new levels of productivity. And the customers that embrace this change are going to be the winner to tomorrow. And I can give you a quick example here. You cannot swing a dead cat to San Francisco without any billboard for either ramp or brex, not the freeway. Rex decided to stick with the legacy point solution. Yeah, they got some animals, but they're still just the same. Ramp went all in with rocks. Every single 1% starts their day and ends their day with prox. Ramp is one of the fastest growing software companies of all time, Rex is not quite there, so ROX is the first AI native revenue operating system for the enterprise. We support the seller on their entire end to end journey when they're working with their customers, whether they're first analyzing the territory, fiscal year, doing deep account research, you know where they're going to spend the time, how they're going to position value, initiating outreach in response to buying sales that the agents find for them, everything else that happens, creating presentations, creating proposals. It's this big chasm in the bill that previously hasn't been addressed by any technology available salespeople, Google Docs, PowerPoint, closest we got these agents are basically McKinsey level research analysts that work for your sellers so that they get more time with their customers. We can not only do this, we can deliver it quickly, and that's because we built warehouse native the data stays in your environment, zero copy. You retain complete control of governance over that data that makes the CIOs happen. The agents have total context over all of your customer data registered for data warehouse, but we unify that with live information from the public Internet, so those buying signals are popping up boxes telling your sellers. Where do you spend the agents themselves? This is not the do it yourself. Process. Agents ready to go out of the box. You can get up and running in three weeks in production.
that we saw when we rolled out cursor and were reserved to our engineering organizations. And up until now, there hasn't really been any good answer for that. So that's why, with Rox, we start getting calls from the CEO Siemens, Philips and Intel, we've got 25 million agents in production today. Process more than 4 trillion tokens. Reasons really matters is that we're going to give back to the enterprise seller their most precious commodity, which is their time, time they can spend with their customers, time they can find deals, time they can close deals and put wins on the board. If you ask those sellers what they think about legacy CRMs, they're going to tell you that they've always been broken. They've always wanted a better solution than what they've got, and that is because the CRM that you're used to dealing with today doesn't do any work for the seller. It makes the seller take time away from the customers to do work for you. That's why you see this ecosystem of point solutions popping up around for every piece of functionality you get from an outreach, from clarity, from Gong, your salesperson has to deal with more complexity in the tool stack, more friction. At the same time, what we've seen is the customer data is moving out of the cloud and into the data warehouse. So that means if you want a true customer priyeshtop, you're actually not going to find it as CRM. On the other hand, that creates an amazing opportunity for us. We can go straight to the data warehouse. We can bring in full lifecycle AI support for your sellers, and we can power new levels of productivity. And the customers that embrace this change are going to be the winner to tomorrow. And I can give you a quick example here. You cannot swing a dead cat to San Francisco without any billboard for either ramp or brex, not the freeway. Rex decided to stick with the legacy point solution. Yeah, they got some animals, but they're still just the same. Ramp went all in with rocks. Every single 1% starts their day and ends their day with prox. Ramp is one of the fastest growing software companies of all time, Rex is not quite there, so ROX is the first AI native revenue operating system for the enterprise. We support the seller on their entire end to end journey when they're working with their customers, whether they're first analyzing the territory, fiscal year, doing deep account research, you know where they're going to spend the time, how they're going to position value, initiating outreach in response to buying sales that the agents find for them, everything else that happens, creating presentations, creating proposals. It's this big chasm in the bill that previously hasn't been addressed by any technology available salespeople, Google Docs, PowerPoint, closest we got these agents are basically McKinsey level research analysts that work for your sellers so that they get more time with their customers. We can not only do this, we can deliver it quickly, and that's because we built warehouse native the data stays in your environment, zero copy. You retain complete control of governance over that data that makes the CIOs happen. The agents have total context over all of your customer data registered for data warehouse, but we unify that with live information from the public Internet, so those buying signals are popping up boxes telling your sellers. Where do you spend the agents themselves? This is not the do it yourself. Process. Agents ready to go out of the box. You can get up and running in three weeks in production.
that we saw when we rolled out cursor and were reserved to our engineering organizations. And up until now, there hasn't really been any good answer for that. So that's why, with Rox, we start getting calls from the CEO Siemens, Philips and Intel, we've got 25 million agents in production today. Process more than 4 trillion tokens. Reasons really matters is that we're going to give back to the enterprise seller their most precious commodity, which is their time, time they can spend with their customers, time they can find deals, time they can close deals and put wins on the board. If you ask those sellers what they think about legacy CRMs, they're going to tell you that they've always been broken. They've always wanted a better solution than what they've got, and that is because the CRM that you're used to dealing with today doesn't do any work for the seller. It makes the seller take time away from the customers to do work for you. That's why you see this ecosystem of point solutions popping up around for every piece of functionality you get from an outreach, from clarity, from Gong, your salesperson has to deal with more complexity in the tool stack, more friction. At the same time, what we've seen is the customer data is moving out of the cloud and into the data warehouse. So that means if you want a true customer priyeshtop, you're actually not going to find it as CRM. On the other hand, that creates an amazing opportunity for us. We can go straight to the data warehouse. We can bring in full lifecycle AI support for your sellers, and we can power new levels of productivity. And the customers that embrace this change are going to be the winner to tomorrow. And I can give you a quick example here. You cannot swing a dead cat to San Francisco without any billboard for either ramp or brex, not the freeway. Rex decided to stick with the legacy point solution. Yeah, they got some animals, but they're still just the same. Ramp went all in with rocks. Every single 1% starts their day and ends their day with prox. Ramp is one of the fastest growing software companies of all time, Rex is not quite there, so ROX is the first AI native revenue operating system for the enterprise. We support the seller on their entire end to end journey when they're working with their customers, whether they're first analyzing the territory, fiscal year, doing deep account research, you know where they're going to spend the time, how they're going to position value, initiating outreach in response to buying sales that the agents find for them, everything else that happens, creating presentations, creating proposals. It's this big chasm in the bill that previously hasn't been addressed by any technology available salespeople, Google Docs, PowerPoint, closest we got these agents are basically McKinsey level research analysts that work for your sellers so that they get more time with their customers. We can not only do this, we can deliver it quickly, and that's because we built warehouse native the data stays in your environment, zero copy. You retain complete control of governance over that data that makes the CIOs happen. The agents have total context over all of your customer data registered for data warehouse, but we unify that with live information from the public Internet, so those buying signals are popping up boxes telling your sellers. Where do you spend the agents themselves? This is not the do it yourself. Process. Agents ready to go out of the box. You can get up and running in three weeks in production.
that we saw when we rolled out cursor and were reserved to our engineering organizations. And up until now, there hasn't really been any good answer for that. So that's why, with Rox, we start getting calls from the CEO Siemens, Philips and Intel, we've got 25 million agents in production today. Process more than 4 trillion tokens. Reasons really matters is that we're going to give back to the enterprise seller their most precious commodity, which is their time, time they can spend with their customers, time they can find deals, time they can close deals and put wins on the board. If you ask those sellers what they think about legacy CRMs, they're going to tell you that they've always been broken. They've always wanted a better solution than what they've got, and that is because the CRM that you're used to dealing with today doesn't do any work for the seller. It makes the seller take time away from the customers to do work for you. That's why you see this ecosystem of point solutions popping up around for every piece of functionality you get from an outreach, from clarity, from Gong, your salesperson has to deal with more complexity in the tool stack, more friction. At the same time, what we've seen is the customer data is moving out of the cloud and into the data warehouse. So that means if you want a true customer priyeshtop, you're actually not going to find it as CRM. On the other hand, that creates an amazing opportunity for us. We can go straight to the data warehouse. We can bring in full lifecycle AI support for your sellers, and we can power new levels of productivity. And the customers that embrace this change are going to be the winner to tomorrow. And I can give you a quick example here. You cannot swing a dead cat to San Francisco without any billboard for either ramp or brex, not the freeway. Rex decided to stick with the legacy point solution. Yeah, they got some animals, but they're still just the same. Ramp went all in with rocks. Every single 1% starts their day and ends their day with prox. Ramp is one of the fastest growing software companies of all time, Rex is not quite there, so ROX is the first AI native revenue operating system for the enterprise. We support the seller on their entire end to end journey when they're working with their customers, whether they're first analyzing the territory, fiscal year, doing deep account research, you know where they're going to spend the time, how they're going to position value, initiating outreach in response to buying sales that the agents find for them, everything else that happens, creating presentations, creating proposals. It's this big chasm in the bill that previously hasn't been addressed by any technology available salespeople, Google Docs, PowerPoint, closest we got these agents are basically McKinsey level research analysts that work for your sellers so that they get more time with their customers. We can not only do this, we can deliver it quickly, and that's because we built warehouse native the data stays in your environment, zero copy. You retain complete control of governance over that data that makes the CIOs happen. The agents have total context over all of your customer data registered for data warehouse, but we unify that with live information from the public Internet, so those buying signals are popping up boxes telling your sellers. Where do you spend the agents themselves? This is not the do it yourself. Process. Agents ready to go out of the box. You can get up and running in three weeks in production.
37:14We meet the sellers where they are,
We meet the sellers where they are,
We meet the sellers where they are,
We meet the sellers where they are,
S Speaker 937:16web app, iOS app, Mac app, API integrations. We want to make this super easy, and that's why one of our core operating principles is time to value. After those three weeks, we can show board level impact in 90 days. We don't just lay with technology. We bring in in house professional services, or BCG, Bain McKinsey analyst work on change management, organization, line top to bottom on how we do this. So we rescale your entire sales team to be aI native. Okay, I got the signal. We talked about ramp WSP when I was leading rev ops at MuleSoft, this was the hardest metric to move ramp time. Cut it in half for WSP. They also canceled requisitions to hire an entire research team, because so good to find clients in those forms. And I think we've got the best team to go to work in AI right now. Founders, multiple successful exits, former chief growth officer at New Relic, we have paying customers over 750 organizations around the world.
web app, iOS app, Mac app, API integrations. We want to make this super easy, and that's why one of our core operating principles is time to value. After those three weeks, we can show board level impact in 90 days. We don't just lay with technology. We bring in in house professional services, or BCG, Bain McKinsey analyst work on change management, organization, line top to bottom on how we do this. So we rescale your entire sales team to be aI native. Okay, I got the signal. We talked about ramp WSP when I was leading rev ops at MuleSoft, this was the hardest metric to move ramp time. Cut it in half for WSP. They also canceled requisitions to hire an entire research team, because so good to find clients in those forms. And I think we've got the best team to go to work in AI right now. Founders, multiple successful exits, former chief growth officer at New Relic, we have paying customers over 750 organizations around the world.
web app, iOS app, Mac app, API integrations. We want to make this super easy, and that's why one of our core operating principles is time to value. After those three weeks, we can show board level impact in 90 days. We don't just lay with technology. We bring in in house professional services, or BCG, Bain McKinsey analyst work on change management, organization, line top to bottom on how we do this. So we rescale your entire sales team to be aI native. Okay, I got the signal. We talked about ramp WSP when I was leading rev ops at MuleSoft, this was the hardest metric to move ramp time. Cut it in half for WSP. They also canceled requisitions to hire an entire research team, because so good to find clients in those forms. And I think we've got the best team to go to work in AI right now. Founders, multiple successful exits, former chief growth officer at New Relic, we have paying customers over 750 organizations around the world.
web app, iOS app, Mac app, API integrations. We want to make this super easy, and that's why one of our core operating principles is time to value. After those three weeks, we can show board level impact in 90 days. We don't just lay with technology. We bring in in house professional services, or BCG, Bain McKinsey analyst work on change management, organization, line top to bottom on how we do this. So we rescale your entire sales team to be aI native. Okay, I got the signal. We talked about ramp WSP when I was leading rev ops at MuleSoft, this was the hardest metric to move ramp time. Cut it in half for WSP. They also canceled requisitions to hire an entire research team, because so good to find clients in those forms. And I think we've got the best team to go to work in AI right now. Founders, multiple successful exits, former chief growth officer at New Relic, we have paying customers over 750 organizations around the world.
38:21Set of artists from our investor community
Set of artists from our investor community
Set of artists from our investor community
Set of artists from our investor community
S Speaker 938:25trying to figure out who the winners are. These guys have a pretty good tracker. You don't have to take my word for it. You go to rocks.com today. Start using it. No demo. Talk to the sales guy. Starting a revenue AI transformation journey. Sales guys. Research for sales reps is
trying to figure out who the winners are. These guys have a pretty good tracker. You don't have to take my word for it. You go to rocks.com today. Start using it. No demo. Talk to the sales guy. Starting a revenue AI transformation journey. Sales guys. Research for sales reps is
trying to figure out who the winners are. These guys have a pretty good tracker. You don't have to take my word for it. You go to rocks.com today. Start using it. No demo. Talk to the sales guy. Starting a revenue AI transformation journey. Sales guys. Research for sales reps is
trying to figure out who the winners are. These guys have a pretty good tracker. You don't have to take my word for it. You go to rocks.com today. Start using it. No demo. Talk to the sales guy. Starting a revenue AI transformation journey. Sales guys. Research for sales reps is
38:44an independent, proactive,
an independent, proactive,
an independent, proactive,
an independent, proactive,
38:56low gas industry.
S Speaker 939:02Absolutely so the Priyesh P cases for the frontline seller, we also support the typical use cases for management. One of the things that we do really, really well is improving forecast accuracy. We have very detailed risk analysis because we're reading the entire transcript history of every conversation that you have with customers, every email that will send, everything that's gone on that deal put collateral for me that makes it really awkward, because my boss knows literally everything I did right and wrong, and I can blow up on rocks right now, complete breakdown in real time,
Absolutely so the Priyesh P cases for the frontline seller, we also support the typical use cases for management. One of the things that we do really, really well is improving forecast accuracy. We have very detailed risk analysis because we're reading the entire transcript history of every conversation that you have with customers, every email that will send, everything that's gone on that deal put collateral for me that makes it really awkward, because my boss knows literally everything I did right and wrong, and I can blow up on rocks right now, complete breakdown in real time,
Absolutely so the Priyesh P cases for the frontline seller, we also support the typical use cases for management. One of the things that we do really, really well is improving forecast accuracy. We have very detailed risk analysis because we're reading the entire transcript history of every conversation that you have with customers, every email that will send, everything that's gone on that deal put collateral for me that makes it really awkward, because my boss knows literally everything I did right and wrong, and I can blow up on rocks right now, complete breakdown in real time,
Absolutely so the Priyesh P cases for the frontline seller, we also support the typical use cases for management. One of the things that we do really, really well is improving forecast accuracy. We have very detailed risk analysis because we're reading the entire transcript history of every conversation that you have with customers, every email that will send, everything that's gone on that deal put collateral for me that makes it really awkward, because my boss knows literally everything I did right and wrong, and I can blow up on rocks right now, complete breakdown in real time,
S Speaker 839:42where yield improving exactly qualified?
where yield improving exactly qualified?
where yield improving exactly qualified?
where yield improving exactly qualified?
S Speaker 440:12rocks. I'm wondering what your pricing model is. I noticed on your website that you mentioned it's like charging by action. So I'm wondering if it's more of like charging by how much revenue rocks have generated for the customer.
rocks. I'm wondering what your pricing model is. I noticed on your website that you mentioned it's like charging by action. So I'm wondering if it's more of like charging by how much revenue rocks have generated for the customer.
rocks. I'm wondering what your pricing model is. I noticed on your website that you mentioned it's like charging by action. So I'm wondering if it's more of like charging by how much revenue rocks have generated for the customer.
rocks. I'm wondering what your pricing model is. I noticed on your website that you mentioned it's like charging by action. So I'm wondering if it's more of like charging by how much revenue rocks have generated for the customer.
S Speaker 940:26I like that idea. That's not what we do. We're a consumption based model. You can think of it in terms of just tokens processed. But we go a step further, and we only charge for the value that's created. So we register what's called agent actions, if it takes, say, you know, 1000 tokens to generate an answer. But of the research the agents did only 20 tokens worth of that are useful for the seller. That's the 20
I like that idea. That's not what we do. We're a consumption based model. You can think of it in terms of just tokens processed. But we go a step further, and we only charge for the value that's created. So we register what's called agent actions, if it takes, say, you know, 1000 tokens to generate an answer. But of the research the agents did only 20 tokens worth of that are useful for the seller. That's the 20
I like that idea. That's not what we do. We're a consumption based model. You can think of it in terms of just tokens processed. But we go a step further, and we only charge for the value that's created. So we register what's called agent actions, if it takes, say, you know, 1000 tokens to generate an answer. But of the research the agents did only 20 tokens worth of that are useful for the seller. That's the 20
I like that idea. That's not what we do. We're a consumption based model. You can think of it in terms of just tokens processed. But we go a step further, and we only charge for the value that's created. So we register what's called agent actions, if it takes, say, you know, 1000 tokens to generate an answer. But of the research the agents did only 20 tokens worth of that are useful for the seller. That's the 20
40:53All right, last question. Okay, right there. Yes,
All right, last question. Okay, right there. Yes,
All right, last question. Okay, right there. Yes,
All right, last question. Okay, right there. Yes,
S Speaker 940:59great question. So the long term vision is consolidate the whole stack. Today we can do a two way, single sales force, so we can't integrate with that, but our goal is to be the primary mode of engagement for yourself.
great question. So the long term vision is consolidate the whole stack. Today we can do a two way, single sales force, so we can't integrate with that, but our goal is to be the primary mode of engagement for yourself.
great question. So the long term vision is consolidate the whole stack. Today we can do a two way, single sales force, so we can't integrate with that, but our goal is to be the primary mode of engagement for yourself.
great question. So the long term vision is consolidate the whole stack. Today we can do a two way, single sales force, so we can't integrate with that, but our goal is to be the primary mode of engagement for yourself.
41:11All right, thanks, everybody.
All right, thanks, everybody.
All right, thanks, everybody.
All right, thanks, everybody.
S Speaker 241:16All right. Up next, we have coach out. Hi
All right. Up next, we have coach out. Hi
All right. Up next, we have coach out. Hi
All right. Up next, we have coach out. Hi
S Speaker 1141:24everyone. The co founder and CEO of coding security at cogent, we develop an AI Task Force for vulnerability management of that is basically a suite of AI agents that resembles your best security IT and engineering personnel and fixes your critical security risks as possible. A little bit about the problem statement, just because I know some of the folks in the room probably are not cyber security experts. Everybody right now is live coding using tools like cursor, wind, surf, Priyesh, pedal coded 10 exploration before then, what nobody's talking about is the security implications of that work. And so what's happening right now is you have way more code. You have way more infrastructure than we did previously, a correspondingly larger amount of security flaws that are resulting from that. And attackers are actually bypacking they can feed one prompt into an LM, generate exploit code and take away from the security flaws much, much easier than before. Now to look at the defender side of the equation, way more work to do than people to do it. There's actually 4 million open positions right now for skilled cyber security labor and also security and fixed security issues is actually a team sport. So just because security is flying the risk doesn't mean that risk can just get fixed. There's IT and engineering teams that come into play, and a lot of work has to happen. So there's this really fundamental asymmetry that has downwards to think about this landscape, in a very simplistic manner, there's a bunch of tools out there that bind your problems. If you're at any security team, they will tell you, I have way more alerts, way more findings than I could ever possibly go away. What's really missing in the industry right now is getting different that is something that is extremely manual. It takes armies a few minutes across different teams to go and gather a bunch of priyeshbal knowledge. Is this system important? Is the vulnerability being exploited in the wild? Germans? What percentage of issues really matters, and then, in order to be remediation marks, to actually
everyone. The co founder and CEO of coding security at cogent, we develop an AI Task Force for vulnerability management of that is basically a suite of AI agents that resembles your best security IT and engineering personnel and fixes your critical security risks as possible. A little bit about the problem statement, just because I know some of the folks in the room probably are not cyber security experts. Everybody right now is live coding using tools like cursor, wind, surf, Priyesh, pedal coded 10 exploration before then, what nobody's talking about is the security implications of that work. And so what's happening right now is you have way more code. You have way more infrastructure than we did previously, a correspondingly larger amount of security flaws that are resulting from that. And attackers are actually bypacking they can feed one prompt into an LM, generate exploit code and take away from the security flaws much, much easier than before. Now to look at the defender side of the equation, way more work to do than people to do it. There's actually 4 million open positions right now for skilled cyber security labor and also security and fixed security issues is actually a team sport. So just because security is flying the risk doesn't mean that risk can just get fixed. There's IT and engineering teams that come into play, and a lot of work has to happen. So there's this really fundamental asymmetry that has downwards to think about this landscape, in a very simplistic manner, there's a bunch of tools out there that bind your problems. If you're at any security team, they will tell you, I have way more alerts, way more findings than I could ever possibly go away. What's really missing in the industry right now is getting different that is something that is extremely manual. It takes armies a few minutes across different teams to go and gather a bunch of priyeshbal knowledge. Is this system important? Is the vulnerability being exploited in the wild? Germans? What percentage of issues really matters, and then, in order to be remediation marks, to actually
everyone. The co founder and CEO of coding security at cogent, we develop an AI Task Force for vulnerability management of that is basically a suite of AI agents that resembles your best security IT and engineering personnel and fixes your critical security risks as possible. A little bit about the problem statement, just because I know some of the folks in the room probably are not cyber security experts. Everybody right now is live coding using tools like cursor, wind, surf, Priyesh, pedal coded 10 exploration before then, what nobody's talking about is the security implications of that work. And so what's happening right now is you have way more code. You have way more infrastructure than we did previously, a correspondingly larger amount of security flaws that are resulting from that. And attackers are actually bypacking they can feed one prompt into an LM, generate exploit code and take away from the security flaws much, much easier than before. Now to look at the defender side of the equation, way more work to do than people to do it. There's actually 4 million open positions right now for skilled cyber security labor and also security and fixed security issues is actually a team sport. So just because security is flying the risk doesn't mean that risk can just get fixed. There's IT and engineering teams that come into play, and a lot of work has to happen. So there's this really fundamental asymmetry that has downwards to think about this landscape, in a very simplistic manner, there's a bunch of tools out there that bind your problems. If you're at any security team, they will tell you, I have way more alerts, way more findings than I could ever possibly go away. What's really missing in the industry right now is getting different that is something that is extremely manual. It takes armies a few minutes across different teams to go and gather a bunch of priyeshbal knowledge. Is this system important? Is the vulnerability being exploited in the wild? Germans? What percentage of issues really matters, and then, in order to be remediation marks, to actually
everyone. The co founder and CEO of coding security at cogent, we develop an AI Task Force for vulnerability management of that is basically a suite of AI agents that resembles your best security IT and engineering personnel and fixes your critical security risks as possible. A little bit about the problem statement, just because I know some of the folks in the room probably are not cyber security experts. Everybody right now is live coding using tools like cursor, wind, surf, Priyesh, pedal coded 10 exploration before then, what nobody's talking about is the security implications of that work. And so what's happening right now is you have way more code. You have way more infrastructure than we did previously, a correspondingly larger amount of security flaws that are resulting from that. And attackers are actually bypacking they can feed one prompt into an LM, generate exploit code and take away from the security flaws much, much easier than before. Now to look at the defender side of the equation, way more work to do than people to do it. There's actually 4 million open positions right now for skilled cyber security labor and also security and fixed security issues is actually a team sport. So just because security is flying the risk doesn't mean that risk can just get fixed. There's IT and engineering teams that come into play, and a lot of work has to happen. So there's this really fundamental asymmetry that has downwards to think about this landscape, in a very simplistic manner, there's a bunch of tools out there that bind your problems. If you're at any security team, they will tell you, I have way more alerts, way more findings than I could ever possibly go away. What's really missing in the industry right now is getting different that is something that is extremely manual. It takes armies a few minutes across different teams to go and gather a bunch of priyeshbal knowledge. Is this system important? Is the vulnerability being exploited in the wild? Germans? What percentage of issues really matters, and then, in order to be remediation marks, to actually
43:18manipulate the rest
S Speaker 1143:21cogent is an autonomous system that handles that whole process like that. So we pull in a bunch of very rich data session across the enterprise that's things from vulnerability scanning tools like Wiz and flawless asset databases like ServiceNow or AWS or Azure, security tools, right intelligence,
cogent is an autonomous system that handles that whole process like that. So we pull in a bunch of very rich data session across the enterprise that's things from vulnerability scanning tools like Wiz and flawless asset databases like ServiceNow or AWS or Azure, security tools, right intelligence,
cogent is an autonomous system that handles that whole process like that. So we pull in a bunch of very rich data session across the enterprise that's things from vulnerability scanning tools like Wiz and flawless asset databases like ServiceNow or AWS or Azure, security tools, right intelligence,
cogent is an autonomous system that handles that whole process like that. So we pull in a bunch of very rich data session across the enterprise that's things from vulnerability scanning tools like Wiz and flawless asset databases like ServiceNow or AWS or Azure, security tools, right intelligence,
43:40pointing to the late
S Speaker 1143:44zero day, your JIRA, your documentation. We snitch all that data together. Think of it as something like green for security. Organize that data, and we have a collection of AI agents that are reasoning on top of that, making decisions and figuring out who should be what by Web. That takes us to the final step, which is the last mile automation, managing the ticket lifecycle, exceptions, reporting, validation,
zero day, your JIRA, your documentation. We snitch all that data together. Think of it as something like green for security. Organize that data, and we have a collection of AI agents that are reasoning on top of that, making decisions and figuring out who should be what by Web. That takes us to the final step, which is the last mile automation, managing the ticket lifecycle, exceptions, reporting, validation,
zero day, your JIRA, your documentation. We snitch all that data together. Think of it as something like green for security. Organize that data, and we have a collection of AI agents that are reasoning on top of that, making decisions and figuring out who should be what by Web. That takes us to the final step, which is the last mile automation, managing the ticket lifecycle, exceptions, reporting, validation,
zero day, your JIRA, your documentation. We snitch all that data together. Think of it as something like green for security. Organize that data, and we have a collection of AI agents that are reasoning on top of that, making decisions and figuring out who should be what by Web. That takes us to the final step, which is the last mile automation, managing the ticket lifecycle, exceptions, reporting, validation,
44:11full scale, modern mediation. But
full scale, modern mediation. But
full scale, modern mediation. But
full scale, modern mediation. But
S Speaker 1144:14as you look at this, I think a really simple way of finishing it. This is basically your Ironman suit, your enterprise. You It's all for there's a whole gamut. I won't spend a ton of time getting into all the individual details, but everything I'm telling you what your attack surface is, the assets that you have, from easy to instances, the laptops, prioritizing the top risks that organizations face, managing remediation, innovator that actually fits the business, and then being able to handle a bunch of dimensions of reporting workflows and then assistive
as you look at this, I think a really simple way of finishing it. This is basically your Ironman suit, your enterprise. You It's all for there's a whole gamut. I won't spend a ton of time getting into all the individual details, but everything I'm telling you what your attack surface is, the assets that you have, from easy to instances, the laptops, prioritizing the top risks that organizations face, managing remediation, innovator that actually fits the business, and then being able to handle a bunch of dimensions of reporting workflows and then assistive
as you look at this, I think a really simple way of finishing it. This is basically your Ironman suit, your enterprise. You It's all for there's a whole gamut. I won't spend a ton of time getting into all the individual details, but everything I'm telling you what your attack surface is, the assets that you have, from easy to instances, the laptops, prioritizing the top risks that organizations face, managing remediation, innovator that actually fits the business, and then being able to handle a bunch of dimensions of reporting workflows and then assistive
as you look at this, I think a really simple way of finishing it. This is basically your Ironman suit, your enterprise. You It's all for there's a whole gamut. I won't spend a ton of time getting into all the individual details, but everything I'm telling you what your attack surface is, the assets that you have, from easy to instances, the laptops, prioritizing the top risks that organizations face, managing remediation, innovator that actually fits the business, and then being able to handle a bunch of dimensions of reporting workflows and then assistive
44:47support, almost career
support, almost career
support, almost career
support, almost career
44:51introduction of some of the rules between organizations
introduction of some of the rules between organizations
introduction of some of the rules between organizations
introduction of some of the rules between organizations
S Speaker 1144:55a dozen, more than 100 companies, public university, public companies, top universities, a bunch of name brand organizations. What we've seen already in production is that we've reduced risk drastically. Refer folks as critical vulnerabilities. We've brought down the time to intermediate by a factor of two. We've reduced manual work by two to 5x depending on the organization. And we've also significantly simplified, consolidating the security stack, removing the blow to all the different tools that might be present, and allowing people
a dozen, more than 100 companies, public university, public companies, top universities, a bunch of name brand organizations. What we've seen already in production is that we've reduced risk drastically. Refer folks as critical vulnerabilities. We've brought down the time to intermediate by a factor of two. We've reduced manual work by two to 5x depending on the organization. And we've also significantly simplified, consolidating the security stack, removing the blow to all the different tools that might be present, and allowing people
a dozen, more than 100 companies, public university, public companies, top universities, a bunch of name brand organizations. What we've seen already in production is that we've reduced risk drastically. Refer folks as critical vulnerabilities. We've brought down the time to intermediate by a factor of two. We've reduced manual work by two to 5x depending on the organization. And we've also significantly simplified, consolidating the security stack, removing the blow to all the different tools that might be present, and allowing people
a dozen, more than 100 companies, public university, public companies, top universities, a bunch of name brand organizations. What we've seen already in production is that we've reduced risk drastically. Refer folks as critical vulnerabilities. We've brought down the time to intermediate by a factor of two. We've reduced manual work by two to 5x depending on the organization. And we've also significantly simplified, consolidating the security stack, removing the blow to all the different tools that might be present, and allowing people
45:28to really focus on exactly learning more. Happy to chat.
to really focus on exactly learning more. Happy to chat.
to really focus on exactly learning more. Happy to chat.
to really focus on exactly learning more. Happy to chat.
45:36Appreciate it. Vineet,
Appreciate it. Vineet,
Appreciate it. Vineet,
Appreciate it. Vineet,
45:39someone will context. Why is
someone will context. Why is
someone will context. Why is
someone will context. Why is
45:46that absolutely right?
that absolutely right?
that absolutely right?
that absolutely right?
S Speaker 1246:16Like, do I have to do, like crowd strike or some firewall in place?
Like, do I have to do, like crowd strike or some firewall in place?
Like, do I have to do, like crowd strike or some firewall in place?
Like, do I have to do, like crowd strike or some firewall in place?
S Speaker 1146:19Right? That actually means that this folder, or is it on, you know, some asset that doesn't matter in my dev environment, right? And therefore it doesn't matter that much. It actually gets exploited. So all those factors of exposure, and typically, what we'll bring down the volume to focus on your teams. Even better for in development.
Right? That actually means that this folder, or is it on, you know, some asset that doesn't matter in my dev environment, right? And therefore it doesn't matter that much. It actually gets exploited. So all those factors of exposure, and typically, what we'll bring down the volume to focus on your teams. Even better for in development.
Right? That actually means that this folder, or is it on, you know, some asset that doesn't matter in my dev environment, right? And therefore it doesn't matter that much. It actually gets exploited. So all those factors of exposure, and typically, what we'll bring down the volume to focus on your teams. Even better for in development.
Right? That actually means that this folder, or is it on, you know, some asset that doesn't matter in my dev environment, right? And therefore it doesn't matter that much. It actually gets exploited. So all those factors of exposure, and typically, what we'll bring down the volume to focus on your teams. Even better for in development.
46:48Other questions,
46:54excellent. Well, thank you all so much. And
excellent. Well, thank you all so much. And
excellent. Well, thank you all so much. And
excellent. Well, thank you all so much. And
S Speaker 247:02he gets the award for the quickest pitch. So thank you. Next we have browser base.
he gets the award for the quickest pitch. So thank you. Next we have browser base.
he gets the award for the quickest pitch. So thank you. Next we have browser base.
he gets the award for the quickest pitch. So thank you. Next we have browser base.
47:09Thank you. I will take the longest pitch. Hi everyone. I'm
Thank you. I will take the longest pitch. Hi everyone. I'm
Thank you. I will take the longest pitch. Hi everyone. I'm
Thank you. I will take the longest pitch. Hi everyone. I'm
S Speaker 1347:18Paul. I'm the founder browser base. Today, I'm Donna brown gates, and I'm not going to
Paul. I'm the founder browser base. Today, I'm Donna brown gates, and I'm not going to
Paul. I'm the founder browser base. Today, I'm Donna brown gates, and I'm not going to
Paul. I'm the founder browser base. Today, I'm Donna brown gates, and I'm not going to
S Speaker 1447:24visit today for 90% and then 10% to try and explain what my company does with some developers, but at least to know about the future
visit today for 90% and then 10% to try and explain what my company does with some developers, but at least to know about the future
visit today for 90% and then 10% to try and explain what my company does with some developers, but at least to know about the future
visit today for 90% and then 10% to try and explain what my company does with some developers, but at least to know about the future
47:33in the future of software is software working
in the future of software is software working
in the future of software is software working
in the future of software is software working
47:35directors happen. A lot of the work that you
directors happen. A lot of the work that you
directors happen. A lot of the work that you
directors happen. A lot of the work that you
S Speaker 1447:37and I do every day happens in a web browser, and if we're doing all our work in a web browser in this future, software is something or whatever have. We need to give software controlled web browsers and a browser assessment. We're building web browser capabilities for ad agents and applications, and we do that by providing browser infrastructure, many, many web browsers running the cloud. And I want to talk about like this giant opportunity in the way that's going to change how we work. That's what we're talking today. There's so many knowledge workers who spend all their day moving information from one penis software to another. Lexi here, fill up your offering. How many? How many people at gusto do insurance verification checks to make sure that insurance is set up correctly by gusto? 27 how many seasonal employees you guys hire to do state tax compliance every single quarter, so many people that you spend all this time when you put up AI go into that system actually check, did jail the insurance correctly? Or did you actually set up a busy tax process? Right? This is online systems and web forms that AI can vary. Ai do that so humans can do much more high leverage tasks in Arctic. About these software 3.0 talk to how the future of software is inventive software. Talk about new tools. We're going to go calculate information all three from your data sets, run code, touch Browser, because this software 3.0 future is very, very powerful with all of you should be thinking about the software that you're building. That you're building it during the new companies AI works.
and I do every day happens in a web browser, and if we're doing all our work in a web browser in this future, software is something or whatever have. We need to give software controlled web browsers and a browser assessment. We're building web browser capabilities for ad agents and applications, and we do that by providing browser infrastructure, many, many web browsers running the cloud. And I want to talk about like this giant opportunity in the way that's going to change how we work. That's what we're talking today. There's so many knowledge workers who spend all their day moving information from one penis software to another. Lexi here, fill up your offering. How many? How many people at gusto do insurance verification checks to make sure that insurance is set up correctly by gusto? 27 how many seasonal employees you guys hire to do state tax compliance every single quarter, so many people that you spend all this time when you put up AI go into that system actually check, did jail the insurance correctly? Or did you actually set up a busy tax process? Right? This is online systems and web forms that AI can vary. Ai do that so humans can do much more high leverage tasks in Arctic. About these software 3.0 talk to how the future of software is inventive software. Talk about new tools. We're going to go calculate information all three from your data sets, run code, touch Browser, because this software 3.0 future is very, very powerful with all of you should be thinking about the software that you're building. That you're building it during the new companies AI works.
and I do every day happens in a web browser, and if we're doing all our work in a web browser in this future, software is something or whatever have. We need to give software controlled web browsers and a browser assessment. We're building web browser capabilities for ad agents and applications, and we do that by providing browser infrastructure, many, many web browsers running the cloud. And I want to talk about like this giant opportunity in the way that's going to change how we work. That's what we're talking today. There's so many knowledge workers who spend all their day moving information from one penis software to another. Lexi here, fill up your offering. How many? How many people at gusto do insurance verification checks to make sure that insurance is set up correctly by gusto? 27 how many seasonal employees you guys hire to do state tax compliance every single quarter, so many people that you spend all this time when you put up AI go into that system actually check, did jail the insurance correctly? Or did you actually set up a busy tax process? Right? This is online systems and web forms that AI can vary. Ai do that so humans can do much more high leverage tasks in Arctic. About these software 3.0 talk to how the future of software is inventive software. Talk about new tools. We're going to go calculate information all three from your data sets, run code, touch Browser, because this software 3.0 future is very, very powerful with all of you should be thinking about the software that you're building. That you're building it during the new companies AI works.
and I do every day happens in a web browser, and if we're doing all our work in a web browser in this future, software is something or whatever have. We need to give software controlled web browsers and a browser assessment. We're building web browser capabilities for ad agents and applications, and we do that by providing browser infrastructure, many, many web browsers running the cloud. And I want to talk about like this giant opportunity in the way that's going to change how we work. That's what we're talking today. There's so many knowledge workers who spend all their day moving information from one penis software to another. Lexi here, fill up your offering. How many? How many people at gusto do insurance verification checks to make sure that insurance is set up correctly by gusto? 27 how many seasonal employees you guys hire to do state tax compliance every single quarter, so many people that you spend all this time when you put up AI go into that system actually check, did jail the insurance correctly? Or did you actually set up a busy tax process? Right? This is online systems and web forms that AI can vary. Ai do that so humans can do much more high leverage tasks in Arctic. About these software 3.0 talk to how the future of software is inventive software. Talk about new tools. We're going to go calculate information all three from your data sets, run code, touch Browser, because this software 3.0 future is very, very powerful with all of you should be thinking about the software that you're building. That you're building it during the new companies AI works.
49:07So software isn't even
So software isn't even
So software isn't even
So software isn't even
S Speaker 1449:10basic tools. One of these tools is the web browser. A lot of the applications that human beings every day exist on the web. That's what we're doing, the browser. So we're not rebuilding the browser. I got some text messages just say congratulations on the acquisition last year. Different browser company. We are browser based. We run the regular browser, the browser that you and I use every day in the cloud, and this is the same browser that's very slow on our computers. It's not meant for cloud infrastructure. And a browser can go anywhere. You go to any website in the world. Your agent can probably go to a bad website. You need guardrails and interval to make sure the browser actually does what you want to do, and nothing. That's what we saw with our and this isn't science fiction. Data really has escaped the valley, and large, large enterprises are thinking about not only how they can build applications internally, but how they buy applications. And I saw an interesting thing, which was the vine. Coder was being hired for at visa recently, and they realized that like instead of buying the extensive DB software, it's probably cheaper to build it in house with AI tools and plug in the best in class infrastructure. In the best AI model, the best is a really building platform, the best browser infrastructure, however, so in 2025 coder interfested peers actually build better software with the scope control for prompts, but use infrastructure that's used by the best in class providers like a rocks. Why not do that? And that's the power you can get. Use AI to build internal tools, but then use the best infrastructure to power them. And you think this role infrastructure is very, very important and important AI, because if we are having more and more developers build and manage the scope custom software, you don't want to reinvent the mission critical parts where things can really go wrong, which is the infrastructure in impact to browse based and we believe we're building a bridge to the legacy internet. As a founder, I don't want to go do my Delaware franchise taxes every quarter. I don't want to go do the same school government, file my city taxes. I don't want to go set up my ERP and manage it for 20,000 employees, I want you to do that. And the DMV is not going to have an MCP server or an API anytime soon. And if you're letting that integration hold you back, you can be using the browser today to do that. So I'll briefly talk about our product week three. So browseways is our browser infrastructure platform. Basically we run many, many browsers in the cloud that you can do in control. The thing that specialist infrastructure is that it's going to browser is highly complex, not necessarily cloud nor instead of all these roadblocks when it tries to go and use the web, we solve those for you. Secondly, this is for developers or product cards. It's called stagehand. Stagehand is our open source framework that allows anybody to automate the web. You can kind of view it as a code interface for the browser. The existing frameworks that exist so far are not designed with AI, first designed for testing. This framework is built on your AI controlled browser and repeatable and so cool. And then finally, we have director.ai if you're not programmer, this is the thing that all of you can go use today. It's really, really fun to play with, and it will be a great example show you how you, anybody here can build an application that uses AI to do a tedious web app. Give it a prompt that generates the code to do that prompt within a browser, and then it runs that with Democrat infrastructure director.ai is very powerful for you to be informed about the best practices and what AI can do. So you can go tell your product teams, drops teams what they should be doing, because you have percent experience, I really recommend you play with it. It's a pretty fun building you it's a pretty fun building so I'll end with that browser base. Once again, we believe the future of software is software doing work on your behalf, and we hope that we can power that feature with our programmable browser infrastructure. And mine is Paul Klein Phillips reached out to me, and my email us, paul@grassways.com
basic tools. One of these tools is the web browser. A lot of the applications that human beings every day exist on the web. That's what we're doing, the browser. So we're not rebuilding the browser. I got some text messages just say congratulations on the acquisition last year. Different browser company. We are browser based. We run the regular browser, the browser that you and I use every day in the cloud, and this is the same browser that's very slow on our computers. It's not meant for cloud infrastructure. And a browser can go anywhere. You go to any website in the world. Your agent can probably go to a bad website. You need guardrails and interval to make sure the browser actually does what you want to do, and nothing. That's what we saw with our and this isn't science fiction. Data really has escaped the valley, and large, large enterprises are thinking about not only how they can build applications internally, but how they buy applications. And I saw an interesting thing, which was the vine. Coder was being hired for at visa recently, and they realized that like instead of buying the extensive DB software, it's probably cheaper to build it in house with AI tools and plug in the best in class infrastructure. In the best AI model, the best is a really building platform, the best browser infrastructure, however, so in 2025 coder interfested peers actually build better software with the scope control for prompts, but use infrastructure that's used by the best in class providers like a rocks. Why not do that? And that's the power you can get. Use AI to build internal tools, but then use the best infrastructure to power them. And you think this role infrastructure is very, very important and important AI, because if we are having more and more developers build and manage the scope custom software, you don't want to reinvent the mission critical parts where things can really go wrong, which is the infrastructure in impact to browse based and we believe we're building a bridge to the legacy internet. As a founder, I don't want to go do my Delaware franchise taxes every quarter. I don't want to go do the same school government, file my city taxes. I don't want to go set up my ERP and manage it for 20,000 employees, I want you to do that. And the DMV is not going to have an MCP server or an API anytime soon. And if you're letting that integration hold you back, you can be using the browser today to do that. So I'll briefly talk about our product week three. So browseways is our browser infrastructure platform. Basically we run many, many browsers in the cloud that you can do in control. The thing that specialist infrastructure is that it's going to browser is highly complex, not necessarily cloud nor instead of all these roadblocks when it tries to go and use the web, we solve those for you. Secondly, this is for developers or product cards. It's called stagehand. Stagehand is our open source framework that allows anybody to automate the web. You can kind of view it as a code interface for the browser. The existing frameworks that exist so far are not designed with AI, first designed for testing. This framework is built on your AI controlled browser and repeatable and so cool. And then finally, we have director.ai if you're not programmer, this is the thing that all of you can go use today. It's really, really fun to play with, and it will be a great example show you how you, anybody here can build an application that uses AI to do a tedious web app. Give it a prompt that generates the code to do that prompt within a browser, and then it runs that with Democrat infrastructure director.ai is very powerful for you to be informed about the best practices and what AI can do. So you can go tell your product teams, drops teams what they should be doing, because you have percent experience, I really recommend you play with it. It's a pretty fun building you it's a pretty fun building so I'll end with that browser base. Once again, we believe the future of software is software doing work on your behalf, and we hope that we can power that feature with our programmable browser infrastructure. And mine is Paul Klein Phillips reached out to me, and my email us, paul@grassways.com
basic tools. One of these tools is the web browser. A lot of the applications that human beings every day exist on the web. That's what we're doing, the browser. So we're not rebuilding the browser. I got some text messages just say congratulations on the acquisition last year. Different browser company. We are browser based. We run the regular browser, the browser that you and I use every day in the cloud, and this is the same browser that's very slow on our computers. It's not meant for cloud infrastructure. And a browser can go anywhere. You go to any website in the world. Your agent can probably go to a bad website. You need guardrails and interval to make sure the browser actually does what you want to do, and nothing. That's what we saw with our and this isn't science fiction. Data really has escaped the valley, and large, large enterprises are thinking about not only how they can build applications internally, but how they buy applications. And I saw an interesting thing, which was the vine. Coder was being hired for at visa recently, and they realized that like instead of buying the extensive DB software, it's probably cheaper to build it in house with AI tools and plug in the best in class infrastructure. In the best AI model, the best is a really building platform, the best browser infrastructure, however, so in 2025 coder interfested peers actually build better software with the scope control for prompts, but use infrastructure that's used by the best in class providers like a rocks. Why not do that? And that's the power you can get. Use AI to build internal tools, but then use the best infrastructure to power them. And you think this role infrastructure is very, very important and important AI, because if we are having more and more developers build and manage the scope custom software, you don't want to reinvent the mission critical parts where things can really go wrong, which is the infrastructure in impact to browse based and we believe we're building a bridge to the legacy internet. As a founder, I don't want to go do my Delaware franchise taxes every quarter. I don't want to go do the same school government, file my city taxes. I don't want to go set up my ERP and manage it for 20,000 employees, I want you to do that. And the DMV is not going to have an MCP server or an API anytime soon. And if you're letting that integration hold you back, you can be using the browser today to do that. So I'll briefly talk about our product week three. So browseways is our browser infrastructure platform. Basically we run many, many browsers in the cloud that you can do in control. The thing that specialist infrastructure is that it's going to browser is highly complex, not necessarily cloud nor instead of all these roadblocks when it tries to go and use the web, we solve those for you. Secondly, this is for developers or product cards. It's called stagehand. Stagehand is our open source framework that allows anybody to automate the web. You can kind of view it as a code interface for the browser. The existing frameworks that exist so far are not designed with AI, first designed for testing. This framework is built on your AI controlled browser and repeatable and so cool. And then finally, we have director.ai if you're not programmer, this is the thing that all of you can go use today. It's really, really fun to play with, and it will be a great example show you how you, anybody here can build an application that uses AI to do a tedious web app. Give it a prompt that generates the code to do that prompt within a browser, and then it runs that with Democrat infrastructure director.ai is very powerful for you to be informed about the best practices and what AI can do. So you can go tell your product teams, drops teams what they should be doing, because you have percent experience, I really recommend you play with it. It's a pretty fun building you it's a pretty fun building so I'll end with that browser base. Once again, we believe the future of software is software doing work on your behalf, and we hope that we can power that feature with our programmable browser infrastructure. And mine is Paul Klein Phillips reached out to me, and my email us, paul@grassways.com
basic tools. One of these tools is the web browser. A lot of the applications that human beings every day exist on the web. That's what we're doing, the browser. So we're not rebuilding the browser. I got some text messages just say congratulations on the acquisition last year. Different browser company. We are browser based. We run the regular browser, the browser that you and I use every day in the cloud, and this is the same browser that's very slow on our computers. It's not meant for cloud infrastructure. And a browser can go anywhere. You go to any website in the world. Your agent can probably go to a bad website. You need guardrails and interval to make sure the browser actually does what you want to do, and nothing. That's what we saw with our and this isn't science fiction. Data really has escaped the valley, and large, large enterprises are thinking about not only how they can build applications internally, but how they buy applications. And I saw an interesting thing, which was the vine. Coder was being hired for at visa recently, and they realized that like instead of buying the extensive DB software, it's probably cheaper to build it in house with AI tools and plug in the best in class infrastructure. In the best AI model, the best is a really building platform, the best browser infrastructure, however, so in 2025 coder interfested peers actually build better software with the scope control for prompts, but use infrastructure that's used by the best in class providers like a rocks. Why not do that? And that's the power you can get. Use AI to build internal tools, but then use the best infrastructure to power them. And you think this role infrastructure is very, very important and important AI, because if we are having more and more developers build and manage the scope custom software, you don't want to reinvent the mission critical parts where things can really go wrong, which is the infrastructure in impact to browse based and we believe we're building a bridge to the legacy internet. As a founder, I don't want to go do my Delaware franchise taxes every quarter. I don't want to go do the same school government, file my city taxes. I don't want to go set up my ERP and manage it for 20,000 employees, I want you to do that. And the DMV is not going to have an MCP server or an API anytime soon. And if you're letting that integration hold you back, you can be using the browser today to do that. So I'll briefly talk about our product week three. So browseways is our browser infrastructure platform. Basically we run many, many browsers in the cloud that you can do in control. The thing that specialist infrastructure is that it's going to browser is highly complex, not necessarily cloud nor instead of all these roadblocks when it tries to go and use the web, we solve those for you. Secondly, this is for developers or product cards. It's called stagehand. Stagehand is our open source framework that allows anybody to automate the web. You can kind of view it as a code interface for the browser. The existing frameworks that exist so far are not designed with AI, first designed for testing. This framework is built on your AI controlled browser and repeatable and so cool. And then finally, we have director.ai if you're not programmer, this is the thing that all of you can go use today. It's really, really fun to play with, and it will be a great example show you how you, anybody here can build an application that uses AI to do a tedious web app. Give it a prompt that generates the code to do that prompt within a browser, and then it runs that with Democrat infrastructure director.ai is very powerful for you to be informed about the best practices and what AI can do. So you can go tell your product teams, drops teams what they should be doing, because you have percent experience, I really recommend you play with it. It's a pretty fun building you it's a pretty fun building so I'll end with that browser base. Once again, we believe the future of software is software doing work on your behalf, and we hope that we can power that feature with our programmable browser infrastructure. And mine is Paul Klein Phillips reached out to me, and my email us, paul@grassways.com
52:42Okay, thank you all very much.
Okay, thank you all very much.
Okay, thank you all very much.
Okay, thank you all very much.
S Speaker 1452:54Great question. We're selling a platform. The platform is the infrastructure, the framework, and then the application there. Generally, our customers pay for the usage based option browsers. So if you're running browser, running infrastructure, our framework is open source. We have fortune, 500 companies using our framework, without us, if you don't trust our infrastructure, because we're just maybe a year and a half old company, start with the framework and go from there. Many tools you can work for infrastructure, for time. Good questions. Also, yeah, we actually probably publish an email data set, Steam, stand out Dev, slash emails. You can see which model is best. We don't provide any models for model agnostic. Do you bring your models that can be an internal model or model that's on the open, remote, popular models, and we'll show you how well it works with a certain task trying to do as well. Show you observability about here's the construction you need, the agent, and here's the actions that actually took. So observability is built into the framework. It's one of things that people love about it, and that's shown up in our browser's dashboard. So you can actually inspect and watch every single action agent book in the browser, replay and understand well. Thank you all very
Great question. We're selling a platform. The platform is the infrastructure, the framework, and then the application there. Generally, our customers pay for the usage based option browsers. So if you're running browser, running infrastructure, our framework is open source. We have fortune, 500 companies using our framework, without us, if you don't trust our infrastructure, because we're just maybe a year and a half old company, start with the framework and go from there. Many tools you can work for infrastructure, for time. Good questions. Also, yeah, we actually probably publish an email data set, Steam, stand out Dev, slash emails. You can see which model is best. We don't provide any models for model agnostic. Do you bring your models that can be an internal model or model that's on the open, remote, popular models, and we'll show you how well it works with a certain task trying to do as well. Show you observability about here's the construction you need, the agent, and here's the actions that actually took. So observability is built into the framework. It's one of things that people love about it, and that's shown up in our browser's dashboard. So you can actually inspect and watch every single action agent book in the browser, replay and understand well. Thank you all very
Great question. We're selling a platform. The platform is the infrastructure, the framework, and then the application there. Generally, our customers pay for the usage based option browsers. So if you're running browser, running infrastructure, our framework is open source. We have fortune, 500 companies using our framework, without us, if you don't trust our infrastructure, because we're just maybe a year and a half old company, start with the framework and go from there. Many tools you can work for infrastructure, for time. Good questions. Also, yeah, we actually probably publish an email data set, Steam, stand out Dev, slash emails. You can see which model is best. We don't provide any models for model agnostic. Do you bring your models that can be an internal model or model that's on the open, remote, popular models, and we'll show you how well it works with a certain task trying to do as well. Show you observability about here's the construction you need, the agent, and here's the actions that actually took. So observability is built into the framework. It's one of things that people love about it, and that's shown up in our browser's dashboard. So you can actually inspect and watch every single action agent book in the browser, replay and understand well. Thank you all very
Great question. We're selling a platform. The platform is the infrastructure, the framework, and then the application there. Generally, our customers pay for the usage based option browsers. So if you're running browser, running infrastructure, our framework is open source. We have fortune, 500 companies using our framework, without us, if you don't trust our infrastructure, because we're just maybe a year and a half old company, start with the framework and go from there. Many tools you can work for infrastructure, for time. Good questions. Also, yeah, we actually probably publish an email data set, Steam, stand out Dev, slash emails. You can see which model is best. We don't provide any models for model agnostic. Do you bring your models that can be an internal model or model that's on the open, remote, popular models, and we'll show you how well it works with a certain task trying to do as well. Show you observability about here's the construction you need, the agent, and here's the actions that actually took. So observability is built into the framework. It's one of things that people love about it, and that's shown up in our browser's dashboard. So you can actually inspect and watch every single action agent book in the browser, replay and understand well. Thank you all very
54:05much. I appreciate the time.
much. I appreciate the time.
much. I appreciate the time.
much. I appreciate the time.
54:14All right. Up next, we have SEMA for AI.
All right. Up next, we have SEMA for AI.
All right. Up next, we have SEMA for AI.
All right. Up next, we have SEMA for AI.
S Speaker 1554:22We have afternoon, everyone. My name is, I'm a co founder and CEO of semaphore. Ai, I want to talk to you today about semaphore and what we do for enterprises before we do that. This is the nice break. How many of you have seen the MIT study about ROI? A few of you? Few of you the things that 95% of AI projects in large enterprises are having trouble demonstrating otherwise. Spoiler alert, it has no idea. So as we go through this, I'll kind of
We have afternoon, everyone. My name is, I'm a co founder and CEO of semaphore. Ai, I want to talk to you today about semaphore and what we do for enterprises before we do that. This is the nice break. How many of you have seen the MIT study about ROI? A few of you? Few of you the things that 95% of AI projects in large enterprises are having trouble demonstrating otherwise. Spoiler alert, it has no idea. So as we go through this, I'll kind of
We have afternoon, everyone. My name is, I'm a co founder and CEO of semaphore. Ai, I want to talk to you today about semaphore and what we do for enterprises before we do that. This is the nice break. How many of you have seen the MIT study about ROI? A few of you? Few of you the things that 95% of AI projects in large enterprises are having trouble demonstrating otherwise. Spoiler alert, it has no idea. So as we go through this, I'll kind of
We have afternoon, everyone. My name is, I'm a co founder and CEO of semaphore. Ai, I want to talk to you today about semaphore and what we do for enterprises before we do that. This is the nice break. How many of you have seen the MIT study about ROI? A few of you? Few of you the things that 95% of AI projects in large enterprises are having trouble demonstrating otherwise. Spoiler alert, it has no idea. So as we go through this, I'll kind of
54:58draw a picture for you why we think there is a case,
draw a picture for you why we think there is a case,
draw a picture for you why we think there is a case,
draw a picture for you why we think there is a case,
S Speaker 1555:51this is just the structured stuff. Then you got email and slack and things, and the data is all over the internet. So the one that we took was, okay, this company, we're not going to
this is just the structured stuff. Then you got email and slack and things, and the data is all over the internet. So the one that we took was, okay, this company, we're not going to
this is just the structured stuff. Then you got email and slack and things, and the data is all over the internet. So the one that we took was, okay, this company, we're not going to
this is just the structured stuff. Then you got email and slack and things, and the data is all over the internet. So the one that we took was, okay, this company, we're not going to
56:02create another system, copy data solution. The
create another system, copy data solution. The
create another system, copy data solution. The
create another system, copy data solution. The
56:07second thing that we noticed was
second thing that we noticed was
second thing that we noticed was
second thing that we noticed was
S Speaker 1556:10the customer's experience with automation as it led to the old RPA style automation, it seemed like people are really involved in that. Repeating the conversation after conversation, what we hear was scale of 100 and
the customer's experience with automation as it led to the old RPA style automation, it seemed like people are really involved in that. Repeating the conversation after conversation, what we hear was scale of 100 and
the customer's experience with automation as it led to the old RPA style automation, it seemed like people are really involved in that. Repeating the conversation after conversation, what we hear was scale of 100 and
the customer's experience with automation as it led to the old RPA style automation, it seemed like people are really involved in that. Repeating the conversation after conversation, what we hear was scale of 100 and
56:31if you disagree,
S Speaker 1556:34so it seemed like rigid automation was not doing a job. The signal for this wasn't a third thing.
so it seemed like rigid automation was not doing a job. The signal for this wasn't a third thing.
so it seemed like rigid automation was not doing a job. The signal for this wasn't a third thing.
so it seemed like rigid automation was not doing a job. The signal for this wasn't a third thing.
56:40You can see that the number of people on the platform.
You can see that the number of people on the platform.
You can see that the number of people on the platform.
You can see that the number of people on the platform.