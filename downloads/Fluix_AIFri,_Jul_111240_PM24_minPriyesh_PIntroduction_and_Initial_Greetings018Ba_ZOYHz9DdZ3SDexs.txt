Meeting: Fluix AI
Fri, Jul 11
12:40 PM
24 min
Priyesh P
Introduction and Initial Greetings
0:18
Background an
URL: https://otter.ai/u/ZOYHz9DdZ3SDexsPWWCFKvkdvA4
Downloaded: 2025-12-21T21:35:55.445165
Method: text_extraction
============================================================

S Speaker 10:18As seen a joke Fear, as in a jofia.
As seen a joke Fear, as in a jofia.
As seen a joke Fear, as in a jofia.
As seen a joke Fear, as in a jofia.
S Speaker 10:58Hey, hi, I'm doing good. We were scheduled a year back. We've been trying to set up this call. So glad that we're finally getting to talk Same here.
Hey, hi, I'm doing good. We were scheduled a year back. We've been trying to set up this call. So glad that we're finally getting to talk Same here.
Hey, hi, I'm doing good. We were scheduled a year back. We've been trying to set up this call. So glad that we're finally getting to talk Same here.
Hey, hi, I'm doing good. We were scheduled a year back. We've been trying to set up this call. So glad that we're finally getting to talk Same here.
S Speaker 21:07I'm sorry about the chat bot. It follows me around. Feel free to kick it if you'd like. I can take handouts as well. I don't mind if you want to keep it Sure, sure. I'm so glad we didn't get connected. We're probably maybe 20 minute drive from each other right now.
I'm sorry about the chat bot. It follows me around. Feel free to kick it if you'd like. I can take handouts as well. I don't mind if you want to keep it Sure, sure. I'm so glad we didn't get connected. We're probably maybe 20 minute drive from each other right now.
I'm sorry about the chat bot. It follows me around. Feel free to kick it if you'd like. I can take handouts as well. I don't mind if you want to keep it Sure, sure. I'm so glad we didn't get connected. We're probably maybe 20 minute drive from each other right now.
I'm sorry about the chat bot. It follows me around. Feel free to kick it if you'd like. I can take handouts as well. I don't mind if you want to keep it Sure, sure. I'm so glad we didn't get connected. We're probably maybe 20 minute drive from each other right now.
S Speaker 11:18Are you in South Bay? Yes, yes. I'm in San Mateo. Our offices. Our office is Qualcomm in South Bay, so that's where most of the team members
Are you in South Bay? Yes, yes. I'm in San Mateo. Our offices. Our office is Qualcomm in South Bay, so that's where most of the team members
Are you in South Bay? Yes, yes. I'm in San Mateo. Our offices. Our office is Qualcomm in South Bay, so that's where most of the team members
Are you in South Bay? Yes, yes. I'm in San Mateo. Our offices. Our office is Qualcomm in South Bay, so that's where most of the team members
S Speaker 21:23are. This is Sri, I believe you met him before. Yeah, I think he's our chief of staff. And funny enough, I'm so glad we did get connected, because we're about to head to Saudi in just a few hours, so it's one of the most difficult time zones for us, calls, especially west
are. This is Sri, I believe you met him before. Yeah, I think he's our chief of staff. And funny enough, I'm so glad we did get connected, because we're about to head to Saudi in just a few hours, so it's one of the most difficult time zones for us, calls, especially west
are. This is Sri, I believe you met him before. Yeah, I think he's our chief of staff. And funny enough, I'm so glad we did get connected, because we're about to head to Saudi in just a few hours, so it's one of the most difficult time zones for us, calls, especially west
are. This is Sri, I believe you met him before. Yeah, I think he's our chief of staff. And funny enough, I'm so glad we did get connected, because we're about to head to Saudi in just a few hours, so it's one of the most difficult time zones for us, calls, especially west
S Speaker 11:38coast, I can imagine. And thanks a lot for taking the time. And I'm sure it's busy. You have active momentum. There's a fundraising coming around, so So I guess you would be actively talking to investors. So good time to connect a Bucha. We'd love to get updated on the processes. The last time, I know last time we only spoke for five or 10 minutes, it was around the closing of your last round, so it didn't make sense then, but we'd love to have a chat, and then quickly, I can give you a background about myself, Qualcomm ventures, and there is some strategy play in the space for us as well. So that's getting us more excited about the entire space, I'd say. So I'm originally from India, in my regard there, worked at an early stage company, so I grew from series unicorn, moved to the US about three years back. Since then, have been in venture. I spent a year with Morpheus in LA about six months with my law ventures in Bay Area, and then currently with Qualcomm ventures for a year and a half now, leading our AI investments, both in, I would say, applied AI and imported AI, particularly don't look at the data data center stack. We have another partner in the team, Varsha, who has an amazing investment background from India. She leads our data center stack, and also works with internal views for a lot of our data center collaborations. Internally at Qualcomm, we have recently launched our chip sets for data center, which is AIC 100 and then we have launched a few partnership with some hype, I wouldn't say hyperscalers, but g 42 and a few more players. So we are expanding our data center play as well, actively looking at investments in the entire stack. We have invested in a few switch companies, and then AI based pooling is also on our radar. I worked with Bucha last year to sort of scope the space. We had a chat with Fidra as well when they when they were using their last round. So quite familiar with the space, but we love to understand what you're building, how you're approaching the space and everything. And then the space and everything, and then quickly about bottom and just check size has two $15 million series A plus investor Global Fund have offices across five regions in US aim to deploy about 100 $50 million a year broadly around that probably would fall in between the strategic to financial VC spectrum, if I if it were like that. Try to actively, sort of forge partnerships with portfolio companies, get them to enterprises we work closely with, or even involve, explore Qualcomm as a customer, Qualcomm as a GTM partner, engineering partner prospects.
coast, I can imagine. And thanks a lot for taking the time. And I'm sure it's busy. You have active momentum. There's a fundraising coming around, so So I guess you would be actively talking to investors. So good time to connect a Bucha. We'd love to get updated on the processes. The last time, I know last time we only spoke for five or 10 minutes, it was around the closing of your last round, so it didn't make sense then, but we'd love to have a chat, and then quickly, I can give you a background about myself, Qualcomm ventures, and there is some strategy play in the space for us as well. So that's getting us more excited about the entire space, I'd say. So I'm originally from India, in my regard there, worked at an early stage company, so I grew from series unicorn, moved to the US about three years back. Since then, have been in venture. I spent a year with Morpheus in LA about six months with my law ventures in Bay Area, and then currently with Qualcomm ventures for a year and a half now, leading our AI investments, both in, I would say, applied AI and imported AI, particularly don't look at the data data center stack. We have another partner in the team, Varsha, who has an amazing investment background from India. She leads our data center stack, and also works with internal views for a lot of our data center collaborations. Internally at Qualcomm, we have recently launched our chip sets for data center, which is AIC 100 and then we have launched a few partnership with some hype, I wouldn't say hyperscalers, but g 42 and a few more players. So we are expanding our data center play as well, actively looking at investments in the entire stack. We have invested in a few switch companies, and then AI based pooling is also on our radar. I worked with Bucha last year to sort of scope the space. We had a chat with Fidra as well when they when they were using their last round. So quite familiar with the space, but we love to understand what you're building, how you're approaching the space and everything. And then the space and everything, and then quickly about bottom and just check size has two $15 million series A plus investor Global Fund have offices across five regions in US aim to deploy about 100 $50 million a year broadly around that probably would fall in between the strategic to financial VC spectrum, if I if it were like that. Try to actively, sort of forge partnerships with portfolio companies, get them to enterprises we work closely with, or even involve, explore Qualcomm as a customer, Qualcomm as a GTM partner, engineering partner prospects.
coast, I can imagine. And thanks a lot for taking the time. And I'm sure it's busy. You have active momentum. There's a fundraising coming around, so So I guess you would be actively talking to investors. So good time to connect a Bucha. We'd love to get updated on the processes. The last time, I know last time we only spoke for five or 10 minutes, it was around the closing of your last round, so it didn't make sense then, but we'd love to have a chat, and then quickly, I can give you a background about myself, Qualcomm ventures, and there is some strategy play in the space for us as well. So that's getting us more excited about the entire space, I'd say. So I'm originally from India, in my regard there, worked at an early stage company, so I grew from series unicorn, moved to the US about three years back. Since then, have been in venture. I spent a year with Morpheus in LA about six months with my law ventures in Bay Area, and then currently with Qualcomm ventures for a year and a half now, leading our AI investments, both in, I would say, applied AI and imported AI, particularly don't look at the data data center stack. We have another partner in the team, Varsha, who has an amazing investment background from India. She leads our data center stack, and also works with internal views for a lot of our data center collaborations. Internally at Qualcomm, we have recently launched our chip sets for data center, which is AIC 100 and then we have launched a few partnership with some hype, I wouldn't say hyperscalers, but g 42 and a few more players. So we are expanding our data center play as well, actively looking at investments in the entire stack. We have invested in a few switch companies, and then AI based pooling is also on our radar. I worked with Bucha last year to sort of scope the space. We had a chat with Fidra as well when they when they were using their last round. So quite familiar with the space, but we love to understand what you're building, how you're approaching the space and everything. And then the space and everything, and then quickly about bottom and just check size has two $15 million series A plus investor Global Fund have offices across five regions in US aim to deploy about 100 $50 million a year broadly around that probably would fall in between the strategic to financial VC spectrum, if I if it were like that. Try to actively, sort of forge partnerships with portfolio companies, get them to enterprises we work closely with, or even involve, explore Qualcomm as a customer, Qualcomm as a GTM partner, engineering partner prospects.
coast, I can imagine. And thanks a lot for taking the time. And I'm sure it's busy. You have active momentum. There's a fundraising coming around, so So I guess you would be actively talking to investors. So good time to connect a Bucha. We'd love to get updated on the processes. The last time, I know last time we only spoke for five or 10 minutes, it was around the closing of your last round, so it didn't make sense then, but we'd love to have a chat, and then quickly, I can give you a background about myself, Qualcomm ventures, and there is some strategy play in the space for us as well. So that's getting us more excited about the entire space, I'd say. So I'm originally from India, in my regard there, worked at an early stage company, so I grew from series unicorn, moved to the US about three years back. Since then, have been in venture. I spent a year with Morpheus in LA about six months with my law ventures in Bay Area, and then currently with Qualcomm ventures for a year and a half now, leading our AI investments, both in, I would say, applied AI and imported AI, particularly don't look at the data data center stack. We have another partner in the team, Varsha, who has an amazing investment background from India. She leads our data center stack, and also works with internal views for a lot of our data center collaborations. Internally at Qualcomm, we have recently launched our chip sets for data center, which is AIC 100 and then we have launched a few partnership with some hype, I wouldn't say hyperscalers, but g 42 and a few more players. So we are expanding our data center play as well, actively looking at investments in the entire stack. We have invested in a few switch companies, and then AI based pooling is also on our radar. I worked with Bucha last year to sort of scope the space. We had a chat with Fidra as well when they when they were using their last round. So quite familiar with the space, but we love to understand what you're building, how you're approaching the space and everything. And then the space and everything, and then quickly about bottom and just check size has two $15 million series A plus investor Global Fund have offices across five regions in US aim to deploy about 100 $50 million a year broadly around that probably would fall in between the strategic to financial VC spectrum, if I if it were like that. Try to actively, sort of forge partnerships with portfolio companies, get them to enterprises we work closely with, or even involve, explore Qualcomm as a customer, Qualcomm as a GTM partner, engineering partner prospects.
S Speaker 23:30That's amazing. That's a lot of context. And I'm glad you guys did a deep dive on the data center optimization space. A little bit about me. It was born in Bangalore. Spent most of my childhood in Montreal. In middle school, became obsessed with high performance computing. I would build computers, go to Craigslist, Facebook, marketplace, put everything together. In high school, I started building gaming PCs. I looked out for gamers, streamers, Esports players. This was like early 2010 so it wasn't as big as the industry. Went to school for aerospace engineering. Fell in love with fluid dynamics, heat transfer, so naturally, I fell in love with liquid cooling for gaming PCs. At my time, there were a lot of people mining crypto. So if you came into my dorm room in college, I would have a whole bunch of GPUs remove the air cooler, which shunt voltage makes like water coolers on them, and I started a business building water cooled servers that got me into about 30 plus data centers. Got to see how data centers ran, but my focus was how to push high performance computers. So we would build some of the most advanced liquid cooled servers at the time. Because of our obsession, I invented a liquid cooling solution at the age of 21 actually got a patent in the year 2020, and a new cooling solution that cooled down CPUs and GPUs that got me into Department of Energy Oak Ridge National Laboratory, where we tested the solution with the supercomputer and our technology. One, we actually showed a lower temperature on the cooler than the incumbent solution. Unfortunately, we did not win the sale my competitor one is because they could fulfill 90,000 units that the supercomputer needed. But very quickly, what happened? Interestingly enough, 12 months later, summit, the supercomputer at ORNL changed to frontier, and they ripped out that cooling solution. So I'm trying to say is in the data center space hardware changes constantly. So that's something that I had learned. Later I got to work with Raytheon. That was my primary subcontractor with netron systems. I was a third level and systems engineer. Systems Engineer. I ran the data center at St Pete, Florida, if you know anything about the year we get a hurricane, so I got to really get integrated with facility management. I was a facilities person, me and my team. I was in charge of HVAC, cooling optimization, you know, data acquisition, change management. And my team were there, and that's where I got introduced to some of the automation products in the space. Trinam and I grow from Honeywell Schneider's eco structure software, JCI software, all the gateway sensors. I really built a look at some of the problem statements. And I think what we've built today, I'm happy to go over some of our differentiation from amazing companies like Phaedra Ray box, cool, great idea, or volta echo sense, all the amazing people out there as well, too. But in 2023 I met my co founder. He's not on the call today. His name is Chase over cash. He led the AI labs at UCI and ASU. He focused on deep reinforcement learning, I'm sure, and he also focused on natural language processing and some multimodal different models. Obviously, there's a new term for these models, but we've known them for a long time, called physical AI, and we're excited to tell you some of our progress. A little bit about our team. We're a team of six. We're based in Santa Clara, having over our customers, but we have customers in the US and in LATAM. These customers are data center customers, and have to walk you through what we do in the value props, we closed a $2.1 million safe round last year. We've grown. We've signed on contracts. We're looking to hefty round. We're very aware of grid care that did a $13 million round. We're very aware with claros that did a $10 million round, and we're very aware of emerald AI that did a 24 million round. I think those companies are all great. I think we have a unique angle here with real customer traction. And love to tell you more that's a little bit
That's amazing. That's a lot of context. And I'm glad you guys did a deep dive on the data center optimization space. A little bit about me. It was born in Bangalore. Spent most of my childhood in Montreal. In middle school, became obsessed with high performance computing. I would build computers, go to Craigslist, Facebook, marketplace, put everything together. In high school, I started building gaming PCs. I looked out for gamers, streamers, Esports players. This was like early 2010 so it wasn't as big as the industry. Went to school for aerospace engineering. Fell in love with fluid dynamics, heat transfer, so naturally, I fell in love with liquid cooling for gaming PCs. At my time, there were a lot of people mining crypto. So if you came into my dorm room in college, I would have a whole bunch of GPUs remove the air cooler, which shunt voltage makes like water coolers on them, and I started a business building water cooled servers that got me into about 30 plus data centers. Got to see how data centers ran, but my focus was how to push high performance computers. So we would build some of the most advanced liquid cooled servers at the time. Because of our obsession, I invented a liquid cooling solution at the age of 21 actually got a patent in the year 2020, and a new cooling solution that cooled down CPUs and GPUs that got me into Department of Energy Oak Ridge National Laboratory, where we tested the solution with the supercomputer and our technology. One, we actually showed a lower temperature on the cooler than the incumbent solution. Unfortunately, we did not win the sale my competitor one is because they could fulfill 90,000 units that the supercomputer needed. But very quickly, what happened? Interestingly enough, 12 months later, summit, the supercomputer at ORNL changed to frontier, and they ripped out that cooling solution. So I'm trying to say is in the data center space hardware changes constantly. So that's something that I had learned. Later I got to work with Raytheon. That was my primary subcontractor with netron systems. I was a third level and systems engineer. Systems Engineer. I ran the data center at St Pete, Florida, if you know anything about the year we get a hurricane, so I got to really get integrated with facility management. I was a facilities person, me and my team. I was in charge of HVAC, cooling optimization, you know, data acquisition, change management. And my team were there, and that's where I got introduced to some of the automation products in the space. Trinam and I grow from Honeywell Schneider's eco structure software, JCI software, all the gateway sensors. I really built a look at some of the problem statements. And I think what we've built today, I'm happy to go over some of our differentiation from amazing companies like Phaedra Ray box, cool, great idea, or volta echo sense, all the amazing people out there as well, too. But in 2023 I met my co founder. He's not on the call today. His name is Chase over cash. He led the AI labs at UCI and ASU. He focused on deep reinforcement learning, I'm sure, and he also focused on natural language processing and some multimodal different models. Obviously, there's a new term for these models, but we've known them for a long time, called physical AI, and we're excited to tell you some of our progress. A little bit about our team. We're a team of six. We're based in Santa Clara, having over our customers, but we have customers in the US and in LATAM. These customers are data center customers, and have to walk you through what we do in the value props, we closed a $2.1 million safe round last year. We've grown. We've signed on contracts. We're looking to hefty round. We're very aware of grid care that did a $13 million round. We're very aware with claros that did a $10 million round, and we're very aware of emerald AI that did a 24 million round. I think those companies are all great. I think we have a unique angle here with real customer traction. And love to tell you more that's a little bit
That's amazing. That's a lot of context. And I'm glad you guys did a deep dive on the data center optimization space. A little bit about me. It was born in Bangalore. Spent most of my childhood in Montreal. In middle school, became obsessed with high performance computing. I would build computers, go to Craigslist, Facebook, marketplace, put everything together. In high school, I started building gaming PCs. I looked out for gamers, streamers, Esports players. This was like early 2010 so it wasn't as big as the industry. Went to school for aerospace engineering. Fell in love with fluid dynamics, heat transfer, so naturally, I fell in love with liquid cooling for gaming PCs. At my time, there were a lot of people mining crypto. So if you came into my dorm room in college, I would have a whole bunch of GPUs remove the air cooler, which shunt voltage makes like water coolers on them, and I started a business building water cooled servers that got me into about 30 plus data centers. Got to see how data centers ran, but my focus was how to push high performance computers. So we would build some of the most advanced liquid cooled servers at the time. Because of our obsession, I invented a liquid cooling solution at the age of 21 actually got a patent in the year 2020, and a new cooling solution that cooled down CPUs and GPUs that got me into Department of Energy Oak Ridge National Laboratory, where we tested the solution with the supercomputer and our technology. One, we actually showed a lower temperature on the cooler than the incumbent solution. Unfortunately, we did not win the sale my competitor one is because they could fulfill 90,000 units that the supercomputer needed. But very quickly, what happened? Interestingly enough, 12 months later, summit, the supercomputer at ORNL changed to frontier, and they ripped out that cooling solution. So I'm trying to say is in the data center space hardware changes constantly. So that's something that I had learned. Later I got to work with Raytheon. That was my primary subcontractor with netron systems. I was a third level and systems engineer. Systems Engineer. I ran the data center at St Pete, Florida, if you know anything about the year we get a hurricane, so I got to really get integrated with facility management. I was a facilities person, me and my team. I was in charge of HVAC, cooling optimization, you know, data acquisition, change management. And my team were there, and that's where I got introduced to some of the automation products in the space. Trinam and I grow from Honeywell Schneider's eco structure software, JCI software, all the gateway sensors. I really built a look at some of the problem statements. And I think what we've built today, I'm happy to go over some of our differentiation from amazing companies like Phaedra Ray box, cool, great idea, or volta echo sense, all the amazing people out there as well, too. But in 2023 I met my co founder. He's not on the call today. His name is Chase over cash. He led the AI labs at UCI and ASU. He focused on deep reinforcement learning, I'm sure, and he also focused on natural language processing and some multimodal different models. Obviously, there's a new term for these models, but we've known them for a long time, called physical AI, and we're excited to tell you some of our progress. A little bit about our team. We're a team of six. We're based in Santa Clara, having over our customers, but we have customers in the US and in LATAM. These customers are data center customers, and have to walk you through what we do in the value props, we closed a $2.1 million safe round last year. We've grown. We've signed on contracts. We're looking to hefty round. We're very aware of grid care that did a $13 million round. We're very aware with claros that did a $10 million round, and we're very aware of emerald AI that did a 24 million round. I think those companies are all great. I think we have a unique angle here with real customer traction. And love to tell you more that's a little bit
That's amazing. That's a lot of context. And I'm glad you guys did a deep dive on the data center optimization space. A little bit about me. It was born in Bangalore. Spent most of my childhood in Montreal. In middle school, became obsessed with high performance computing. I would build computers, go to Craigslist, Facebook, marketplace, put everything together. In high school, I started building gaming PCs. I looked out for gamers, streamers, Esports players. This was like early 2010 so it wasn't as big as the industry. Went to school for aerospace engineering. Fell in love with fluid dynamics, heat transfer, so naturally, I fell in love with liquid cooling for gaming PCs. At my time, there were a lot of people mining crypto. So if you came into my dorm room in college, I would have a whole bunch of GPUs remove the air cooler, which shunt voltage makes like water coolers on them, and I started a business building water cooled servers that got me into about 30 plus data centers. Got to see how data centers ran, but my focus was how to push high performance computers. So we would build some of the most advanced liquid cooled servers at the time. Because of our obsession, I invented a liquid cooling solution at the age of 21 actually got a patent in the year 2020, and a new cooling solution that cooled down CPUs and GPUs that got me into Department of Energy Oak Ridge National Laboratory, where we tested the solution with the supercomputer and our technology. One, we actually showed a lower temperature on the cooler than the incumbent solution. Unfortunately, we did not win the sale my competitor one is because they could fulfill 90,000 units that the supercomputer needed. But very quickly, what happened? Interestingly enough, 12 months later, summit, the supercomputer at ORNL changed to frontier, and they ripped out that cooling solution. So I'm trying to say is in the data center space hardware changes constantly. So that's something that I had learned. Later I got to work with Raytheon. That was my primary subcontractor with netron systems. I was a third level and systems engineer. Systems Engineer. I ran the data center at St Pete, Florida, if you know anything about the year we get a hurricane, so I got to really get integrated with facility management. I was a facilities person, me and my team. I was in charge of HVAC, cooling optimization, you know, data acquisition, change management. And my team were there, and that's where I got introduced to some of the automation products in the space. Trinam and I grow from Honeywell Schneider's eco structure software, JCI software, all the gateway sensors. I really built a look at some of the problem statements. And I think what we've built today, I'm happy to go over some of our differentiation from amazing companies like Phaedra Ray box, cool, great idea, or volta echo sense, all the amazing people out there as well, too. But in 2023 I met my co founder. He's not on the call today. His name is Chase over cash. He led the AI labs at UCI and ASU. He focused on deep reinforcement learning, I'm sure, and he also focused on natural language processing and some multimodal different models. Obviously, there's a new term for these models, but we've known them for a long time, called physical AI, and we're excited to tell you some of our progress. A little bit about our team. We're a team of six. We're based in Santa Clara, having over our customers, but we have customers in the US and in LATAM. These customers are data center customers, and have to walk you through what we do in the value props, we closed a $2.1 million safe round last year. We've grown. We've signed on contracts. We're looking to hefty round. We're very aware of grid care that did a $13 million round. We're very aware with claros that did a $10 million round, and we're very aware of emerald AI that did a 24 million round. I think those companies are all great. I think we have a unique angle here with real customer traction. And love to tell you more that's a little bit
S Speaker 16:25about us. Absolutely, that's an amazing career background, very, very exciting stuff. Love to get deeper now, 100%
about us. Absolutely, that's an amazing career background, very, very exciting stuff. Love to get deeper now, 100%
about us. Absolutely, that's an amazing career background, very, very exciting stuff. Love to get deeper now, 100%
about us. Absolutely, that's an amazing career background, very, very exciting stuff. Love to get deeper now, 100%
S Speaker 18:01Yeah, it does. It does. AI is one of our portfolio companies. It made a good mother. Can sort of create a story around data pipelines for physically and have a really great push
Yeah, it does. It does. AI is one of our portfolio companies. It made a good mother. Can sort of create a story around data pipelines for physically and have a really great push
Yeah, it does. It does. AI is one of our portfolio companies. It made a good mother. Can sort of create a story around data pipelines for physically and have a really great push
Yeah, it does. It does. AI is one of our portfolio companies. It made a good mother. Can sort of create a story around data pipelines for physically and have a really great push
S Speaker 111:58It makes sense. A few follow up questions, just for clarity here for the four customers that you have today, are you have today, are they, have they adopted automation, or have they just sorted sites for now and then, the adoption automation is probably on the pipeline sometime. Three out of five have adopted automation. This is the craziest thing. Production ready. Co Location data centers are allowing us to control the retracted that's pretty interesting. And on the other end, you said you use CPU, GPU, data to sort of is that, is that predictive or reactive in the model today?
It makes sense. A few follow up questions, just for clarity here for the four customers that you have today, are you have today, are they, have they adopted automation, or have they just sorted sites for now and then, the adoption automation is probably on the pipeline sometime. Three out of five have adopted automation. This is the craziest thing. Production ready. Co Location data centers are allowing us to control the retracted that's pretty interesting. And on the other end, you said you use CPU, GPU, data to sort of is that, is that predictive or reactive in the model today?
It makes sense. A few follow up questions, just for clarity here for the four customers that you have today, are you have today, are they, have they adopted automation, or have they just sorted sites for now and then, the adoption automation is probably on the pipeline sometime. Three out of five have adopted automation. This is the craziest thing. Production ready. Co Location data centers are allowing us to control the retracted that's pretty interesting. And on the other end, you said you use CPU, GPU, data to sort of is that, is that predictive or reactive in the model today?
It makes sense. A few follow up questions, just for clarity here for the four customers that you have today, are you have today, are they, have they adopted automation, or have they just sorted sites for now and then, the adoption automation is probably on the pipeline sometime. Three out of five have adopted automation. This is the craziest thing. Production ready. Co Location data centers are allowing us to control the retracted that's pretty interesting. And on the other end, you said you use CPU, GPU, data to sort of is that, is that predictive or reactive in the model today?
S Speaker 212:24Yeah, so it's very hard to be predictive. It's kind of like the randomization question, right? CPG views are random, and the decimal point to a randomized number is almost 10 to the ninth. So technically, we have to be reactive. The problem is Johnson Schneider, they rely on the HVAC units return temperature sensor by the time the air gets hot in a data center, and the HVAC unit senses that it's too late. CPU, GP, model, Okay, then let's go to Phaedra, or some of those other amazing companies, a little bit predictive, but predictive on the environmental conditions right and the thermodynamic equations, that's great. That's what has a lag about 40 to 50% so we're reactive to the fastest leading indicator in the data center, CPG people, the best example of this, if you remember, brain box in 2017 we found a pitch that they did. They were using linear model to peak idling. They would look at a chiller plant, and it would peak at certain times, and they would stage the chiller plant so the amplitudes of the peak would be lower. Same energy, very good. You can't do that in the data center. These things are changing. So how do you match the peaks that this? The easiest way is to go to the heat source. So what I'm trying to say is, today we're reactive. With enough data, there might be an opportunity to predict a holy grail problem. That's a moonshot
Yeah, so it's very hard to be predictive. It's kind of like the randomization question, right? CPG views are random, and the decimal point to a randomized number is almost 10 to the ninth. So technically, we have to be reactive. The problem is Johnson Schneider, they rely on the HVAC units return temperature sensor by the time the air gets hot in a data center, and the HVAC unit senses that it's too late. CPU, GP, model, Okay, then let's go to Phaedra, or some of those other amazing companies, a little bit predictive, but predictive on the environmental conditions right and the thermodynamic equations, that's great. That's what has a lag about 40 to 50% so we're reactive to the fastest leading indicator in the data center, CPG people, the best example of this, if you remember, brain box in 2017 we found a pitch that they did. They were using linear model to peak idling. They would look at a chiller plant, and it would peak at certain times, and they would stage the chiller plant so the amplitudes of the peak would be lower. Same energy, very good. You can't do that in the data center. These things are changing. So how do you match the peaks that this? The easiest way is to go to the heat source. So what I'm trying to say is, today we're reactive. With enough data, there might be an opportunity to predict a holy grail problem. That's a moonshot
Yeah, so it's very hard to be predictive. It's kind of like the randomization question, right? CPG views are random, and the decimal point to a randomized number is almost 10 to the ninth. So technically, we have to be reactive. The problem is Johnson Schneider, they rely on the HVAC units return temperature sensor by the time the air gets hot in a data center, and the HVAC unit senses that it's too late. CPU, GP, model, Okay, then let's go to Phaedra, or some of those other amazing companies, a little bit predictive, but predictive on the environmental conditions right and the thermodynamic equations, that's great. That's what has a lag about 40 to 50% so we're reactive to the fastest leading indicator in the data center, CPG people, the best example of this, if you remember, brain box in 2017 we found a pitch that they did. They were using linear model to peak idling. They would look at a chiller plant, and it would peak at certain times, and they would stage the chiller plant so the amplitudes of the peak would be lower. Same energy, very good. You can't do that in the data center. These things are changing. So how do you match the peaks that this? The easiest way is to go to the heat source. So what I'm trying to say is, today we're reactive. With enough data, there might be an opportunity to predict a holy grail problem. That's a moonshot
Yeah, so it's very hard to be predictive. It's kind of like the randomization question, right? CPG views are random, and the decimal point to a randomized number is almost 10 to the ninth. So technically, we have to be reactive. The problem is Johnson Schneider, they rely on the HVAC units return temperature sensor by the time the air gets hot in a data center, and the HVAC unit senses that it's too late. CPU, GP, model, Okay, then let's go to Phaedra, or some of those other amazing companies, a little bit predictive, but predictive on the environmental conditions right and the thermodynamic equations, that's great. That's what has a lag about 40 to 50% so we're reactive to the fastest leading indicator in the data center, CPG people, the best example of this, if you remember, brain box in 2017 we found a pitch that they did. They were using linear model to peak idling. They would look at a chiller plant, and it would peak at certain times, and they would stage the chiller plant so the amplitudes of the peak would be lower. Same energy, very good. You can't do that in the data center. These things are changing. So how do you match the peaks that this? The easiest way is to go to the heat source. So what I'm trying to say is, today we're reactive. With enough data, there might be an opportunity to predict a holy grail problem. That's a moonshot
S Speaker 113:27problem. Yeah, as the lag is not much, I think you're still showing a lot of ROI with still being reactive. So that makes to make sense 100%
problem. Yeah, as the lag is not much, I think you're still showing a lot of ROI with still being reactive. So that makes to make sense 100%
problem. Yeah, as the lag is not much, I think you're still showing a lot of ROI with still being reactive. So that makes to make sense 100%
problem. Yeah, as the lag is not much, I think you're still showing a lot of ROI with still being reactive. So that makes to make sense 100%
S Speaker 118:57from. Totally Yes, and arguably one of the most important sources of data as well. It's much more critical than EV
from. Totally Yes, and arguably one of the most important sources of data as well. It's much more critical than EV
from. Totally Yes, and arguably one of the most important sources of data as well. It's much more critical than EV
from. Totally Yes, and arguably one of the most important sources of data as well. It's much more critical than EV
S Speaker 219:05charging and things like that, hardest to get to. And the risk is this. Can you believe our team can go and install across 500 data centers with an on prem solution? That's the risk. It's all about trust, and I'm happy to go through with my plan on how doing it. But we realized that all this infrastructure data could be anonymized. The reason is, the data center agrees it to get it to its stakeholders. So the power company is a stakeholder. So TDA gave one of our clients locked in rate for financial incentives that's called energy right TV is an energy right program. Guess what? Dominion has it, national grid has it. PGD has it. Because data center low growth is so so high, they're look. They have programs and financing to curtail data center load graph. So that's what the financial incentive for this data center give the data. I can't name the data center, but as you can imagine, the data is valuable. So we realized that this is where we are talking about data centers, the ECD 100 to a million. It's very difficult. The sales cycle is six months. It's on prem. It's getting there. We showed that people are saying yes, and we can get them to say yes. But you know how we really wrap this up? As we sell data to the utility, we get part of their build spec. This is the go to market. So for the last 18 months, I was able to find sell five data centers on POCs. It's very difficult. I had my team and our skills to be able to do that. Our most recent client. We were able to sell it in two months because TDA walked us into the client, the utilities. What I'm trying to say is, if we're able to sell data, we get part of a build spec, and the utility and all the data centers, part of the energy incentive program. TD has only one dominion, has over 250 our build spec. We just need the introduction. And because we're on prem, and because we train our model in one month, we're able to show ROI in a matter of three months. And that's how we get through the different data centers. But as we do that, the way we increase our ECD, because remember, the CAC is still the same. Our CAC is about 40k right now. To do a data center. An LTE could be about 150 but the same cap to that 40k the data pipeline could almost be a million dollar contract. And this is the data clairos. Please check out Claro. When you get a chance reaction, they show this. We're able to do this with just software, CP, like GPU, load. We do everything on the left right now. Now we're sharing that with everything in the middle, and soon, we think you can get into simulation on the right. So I want to be wary of time, but I'm happy to show you what we think the cloud will look like, how they transact the data, because I think this is the scale one day people will be able to log on and download data sets, and they'll be paying a hefty
charging and things like that, hardest to get to. And the risk is this. Can you believe our team can go and install across 500 data centers with an on prem solution? That's the risk. It's all about trust, and I'm happy to go through with my plan on how doing it. But we realized that all this infrastructure data could be anonymized. The reason is, the data center agrees it to get it to its stakeholders. So the power company is a stakeholder. So TDA gave one of our clients locked in rate for financial incentives that's called energy right TV is an energy right program. Guess what? Dominion has it, national grid has it. PGD has it. Because data center low growth is so so high, they're look. They have programs and financing to curtail data center load graph. So that's what the financial incentive for this data center give the data. I can't name the data center, but as you can imagine, the data is valuable. So we realized that this is where we are talking about data centers, the ECD 100 to a million. It's very difficult. The sales cycle is six months. It's on prem. It's getting there. We showed that people are saying yes, and we can get them to say yes. But you know how we really wrap this up? As we sell data to the utility, we get part of their build spec. This is the go to market. So for the last 18 months, I was able to find sell five data centers on POCs. It's very difficult. I had my team and our skills to be able to do that. Our most recent client. We were able to sell it in two months because TDA walked us into the client, the utilities. What I'm trying to say is, if we're able to sell data, we get part of a build spec, and the utility and all the data centers, part of the energy incentive program. TD has only one dominion, has over 250 our build spec. We just need the introduction. And because we're on prem, and because we train our model in one month, we're able to show ROI in a matter of three months. And that's how we get through the different data centers. But as we do that, the way we increase our ECD, because remember, the CAC is still the same. Our CAC is about 40k right now. To do a data center. An LTE could be about 150 but the same cap to that 40k the data pipeline could almost be a million dollar contract. And this is the data clairos. Please check out Claro. When you get a chance reaction, they show this. We're able to do this with just software, CP, like GPU, load. We do everything on the left right now. Now we're sharing that with everything in the middle, and soon, we think you can get into simulation on the right. So I want to be wary of time, but I'm happy to show you what we think the cloud will look like, how they transact the data, because I think this is the scale one day people will be able to log on and download data sets, and they'll be paying a hefty
charging and things like that, hardest to get to. And the risk is this. Can you believe our team can go and install across 500 data centers with an on prem solution? That's the risk. It's all about trust, and I'm happy to go through with my plan on how doing it. But we realized that all this infrastructure data could be anonymized. The reason is, the data center agrees it to get it to its stakeholders. So the power company is a stakeholder. So TDA gave one of our clients locked in rate for financial incentives that's called energy right TV is an energy right program. Guess what? Dominion has it, national grid has it. PGD has it. Because data center low growth is so so high, they're look. They have programs and financing to curtail data center load graph. So that's what the financial incentive for this data center give the data. I can't name the data center, but as you can imagine, the data is valuable. So we realized that this is where we are talking about data centers, the ECD 100 to a million. It's very difficult. The sales cycle is six months. It's on prem. It's getting there. We showed that people are saying yes, and we can get them to say yes. But you know how we really wrap this up? As we sell data to the utility, we get part of their build spec. This is the go to market. So for the last 18 months, I was able to find sell five data centers on POCs. It's very difficult. I had my team and our skills to be able to do that. Our most recent client. We were able to sell it in two months because TDA walked us into the client, the utilities. What I'm trying to say is, if we're able to sell data, we get part of a build spec, and the utility and all the data centers, part of the energy incentive program. TD has only one dominion, has over 250 our build spec. We just need the introduction. And because we're on prem, and because we train our model in one month, we're able to show ROI in a matter of three months. And that's how we get through the different data centers. But as we do that, the way we increase our ECD, because remember, the CAC is still the same. Our CAC is about 40k right now. To do a data center. An LTE could be about 150 but the same cap to that 40k the data pipeline could almost be a million dollar contract. And this is the data clairos. Please check out Claro. When you get a chance reaction, they show this. We're able to do this with just software, CP, like GPU, load. We do everything on the left right now. Now we're sharing that with everything in the middle, and soon, we think you can get into simulation on the right. So I want to be wary of time, but I'm happy to show you what we think the cloud will look like, how they transact the data, because I think this is the scale one day people will be able to log on and download data sets, and they'll be paying a hefty
charging and things like that, hardest to get to. And the risk is this. Can you believe our team can go and install across 500 data centers with an on prem solution? That's the risk. It's all about trust, and I'm happy to go through with my plan on how doing it. But we realized that all this infrastructure data could be anonymized. The reason is, the data center agrees it to get it to its stakeholders. So the power company is a stakeholder. So TDA gave one of our clients locked in rate for financial incentives that's called energy right TV is an energy right program. Guess what? Dominion has it, national grid has it. PGD has it. Because data center low growth is so so high, they're look. They have programs and financing to curtail data center load graph. So that's what the financial incentive for this data center give the data. I can't name the data center, but as you can imagine, the data is valuable. So we realized that this is where we are talking about data centers, the ECD 100 to a million. It's very difficult. The sales cycle is six months. It's on prem. It's getting there. We showed that people are saying yes, and we can get them to say yes. But you know how we really wrap this up? As we sell data to the utility, we get part of their build spec. This is the go to market. So for the last 18 months, I was able to find sell five data centers on POCs. It's very difficult. I had my team and our skills to be able to do that. Our most recent client. We were able to sell it in two months because TDA walked us into the client, the utilities. What I'm trying to say is, if we're able to sell data, we get part of a build spec, and the utility and all the data centers, part of the energy incentive program. TD has only one dominion, has over 250 our build spec. We just need the introduction. And because we're on prem, and because we train our model in one month, we're able to show ROI in a matter of three months. And that's how we get through the different data centers. But as we do that, the way we increase our ECD, because remember, the CAC is still the same. Our CAC is about 40k right now. To do a data center. An LTE could be about 150 but the same cap to that 40k the data pipeline could almost be a million dollar contract. And this is the data clairos. Please check out Claro. When you get a chance reaction, they show this. We're able to do this with just software, CP, like GPU, load. We do everything on the left right now. Now we're sharing that with everything in the middle, and soon, we think you can get into simulation on the right. So I want to be wary of time, but I'm happy to show you what we think the cloud will look like, how they transact the data, because I think this is the scale one day people will be able to log on and download data sets, and they'll be paying a hefty
S Speaker 121:17that's fair. That's fair. I do have to run in five minutes, so I'd love to discuss a little bit around the DA the around the DEA, around the round that you're raising currently. What's the timeline you're thinking of how they got on? Are you going to price the things with
that's fair. That's fair. I do have to run in five minutes, so I'd love to discuss a little bit around the DA the around the DEA, around the round that you're raising currently. What's the timeline you're thinking of how they got on? Are you going to price the things with
that's fair. That's fair. I do have to run in five minutes, so I'd love to discuss a little bit around the DA the around the DEA, around the round that you're raising currently. What's the timeline you're thinking of how they got on? Are you going to price the things with
that's fair. That's fair. I do have to run in five minutes, so I'd love to discuss a little bit around the DA the around the DEA, around the round that you're raising currently. What's the timeline you're thinking of how they got on? Are you going to price the things with
S Speaker 123:18So typically, we don't lead a lot of rounds. Typically, we have like 80% of our investment, so we the rounds that we've led have been highly strategic for us. So maybe I'll have to check with the team in some cloud business units if, if this is something that we can COVID with some of our solutions. I don't know. I'm not sure yet, but I would probably not bank on it totally understand.
So typically, we don't lead a lot of rounds. Typically, we have like 80% of our investment, so we the rounds that we've led have been highly strategic for us. So maybe I'll have to check with the team in some cloud business units if, if this is something that we can COVID with some of our solutions. I don't know. I'm not sure yet, but I would probably not bank on it totally understand.
So typically, we don't lead a lot of rounds. Typically, we have like 80% of our investment, so we the rounds that we've led have been highly strategic for us. So maybe I'll have to check with the team in some cloud business units if, if this is something that we can COVID with some of our solutions. I don't know. I'm not sure yet, but I would probably not bank on it totally understand.
So typically, we don't lead a lot of rounds. Typically, we have like 80% of our investment, so we the rounds that we've led have been highly strategic for us. So maybe I'll have to check with the team in some cloud business units if, if this is something that we can COVID with some of our solutions. I don't know. I'm not sure yet, but I would probably not bank on it totally understand.
S Speaker 223:39But if there's a scenario where a lead comes in, and obviously we've gone through diligence because diligence partnership follow up would probably be where this fits. That makes a lot of sense. And as you can imagine, for a large round, there are certain funds that do the whole thing. The leads that we're discussing are looking at about 30 to 40% of the fore right now. So I'll keep you posted. I'll send over those materials and happen to hop
But if there's a scenario where a lead comes in, and obviously we've gone through diligence because diligence partnership follow up would probably be where this fits. That makes a lot of sense. And as you can imagine, for a large round, there are certain funds that do the whole thing. The leads that we're discussing are looking at about 30 to 40% of the fore right now. So I'll keep you posted. I'll send over those materials and happen to hop
But if there's a scenario where a lead comes in, and obviously we've gone through diligence because diligence partnership follow up would probably be where this fits. That makes a lot of sense. And as you can imagine, for a large round, there are certain funds that do the whole thing. The leads that we're discussing are looking at about 30 to 40% of the fore right now. So I'll keep you posted. I'll send over those materials and happen to hop
But if there's a scenario where a lead comes in, and obviously we've gone through diligence because diligence partnership follow up would probably be where this fits. That makes a lot of sense. And as you can imagine, for a large round, there are certain funds that do the whole thing. The leads that we're discussing are looking at about 30 to 40% of the fore right now. So I'll keep you posted. I'll send over those materials and happen to hop
S Speaker 123:57on follow on calls. Absolutely yes. Next one. I think I'd like to look in Russia as well. But let me think of it currently. Back to you. I that's a lot for your ninth grade interesting love the problem. Thank you so much again, thank you.
on follow on calls. Absolutely yes. Next one. I think I'd like to look in Russia as well. But let me think of it currently. Back to you. I that's a lot for your ninth grade interesting love the problem. Thank you so much again, thank you.
on follow on calls. Absolutely yes. Next one. I think I'd like to look in Russia as well. But let me think of it currently. Back to you. I that's a lot for your ninth grade interesting love the problem. Thank you so much again, thank you.
on follow on calls. Absolutely yes. Next one. I think I'd like to look in Russia as well. But let me think of it currently. Back to you. I that's a lot for your ninth grade interesting love the problem. Thank you so much again, thank you.