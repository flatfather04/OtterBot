Meeting: Creati #2
Tue, Jul 15
2:37 PM
15 min
Priyesh P
Consistency Issues in Generative Technology
0:00
Chal
URL: https://otter.ai/u/BcyC0WtpP82O8gsqFm1Om7ZQMV0
Downloaded: 2025-12-21T21:33:59.771780
Method: text_extraction
============================================================

0:06you can see that, right? Yes,
you can see that, right? Yes,
you can see that, right? Yes,
you can see that, right? Yes,
S Speaker 10:09yeah. So first of all, what I will see there is, I think, like, you are, like, from the large picture, I think you are right that in the end, I think consistency, like, our technology mode is not the consistency. Because, like, no matter what is happening today, I think, like in the very long term wise, consistency issue will be resolved in the end. But the thing is, like, how do you evaluate that? How do you evaluate that consistency issue is, the more like, you know, I will give you an example. I think, like some in some products, the consistency will be solved. It may be about 90% but never 100% let me give you a quick example like, so let's say, Okay, I have, I don't have the I don't have the flow there. But the basically thing is, let me show you one thing is about the fashion industry, right? So I think what they may get to deal with, like, I haven't tried the mid journey one, but I have tried the flow one. So the thing is that, you know, like, right now, what they can do is, is more I will see on the maybe, on the photo stage, like, you know, like they can generate a photo, or things like that, to have the kind of like this, like, more like a rigid product, right? More consistent. But when it comes to fashion industry, it's kind of a totally different mindset, right? The thing is, like, when, like, I do not think like, mid journey, or like flow, or video three, or any of the of the product, they can actually, you know, just give it a close image, and they can actually understand the material of the clothes and how it's, you know, wearing on the body, and when the model is stretching the clothes, like, whether it's really like this is cashmere, right? Like, whether it shows how the stretch of the clothes should look like. And the reason being that is, what I say is, I think for some products, maybe the consistency you think it's much better, but for most of the product, it's pretty hard, because you are not just needing the generation technology. Also need to level the material, you know, like the cut, the shape, how is a wearing on the people's body? And that part is actually, you know, like, pretty hard. I will give you example of what we cooperate before with. Let me, let me find that one. I think it's there. They are. Brand for,
yeah. So first of all, what I will see there is, I think, like, you are, like, from the large picture, I think you are right that in the end, I think consistency, like, our technology mode is not the consistency. Because, like, no matter what is happening today, I think, like in the very long term wise, consistency issue will be resolved in the end. But the thing is, like, how do you evaluate that? How do you evaluate that consistency issue is, the more like, you know, I will give you an example. I think, like some in some products, the consistency will be solved. It may be about 90% but never 100% let me give you a quick example like, so let's say, Okay, I have, I don't have the I don't have the flow there. But the basically thing is, let me show you one thing is about the fashion industry, right? So I think what they may get to deal with, like, I haven't tried the mid journey one, but I have tried the flow one. So the thing is that, you know, like, right now, what they can do is, is more I will see on the maybe, on the photo stage, like, you know, like they can generate a photo, or things like that, to have the kind of like this, like, more like a rigid product, right? More consistent. But when it comes to fashion industry, it's kind of a totally different mindset, right? The thing is, like, when, like, I do not think like, mid journey, or like flow, or video three, or any of the of the product, they can actually, you know, just give it a close image, and they can actually understand the material of the clothes and how it's, you know, wearing on the body, and when the model is stretching the clothes, like, whether it's really like this is cashmere, right? Like, whether it shows how the stretch of the clothes should look like. And the reason being that is, what I say is, I think for some products, maybe the consistency you think it's much better, but for most of the product, it's pretty hard, because you are not just needing the generation technology. Also need to level the material, you know, like the cut, the shape, how is a wearing on the people's body? And that part is actually, you know, like, pretty hard. I will give you example of what we cooperate before with. Let me, let me find that one. I think it's there. They are. Brand for,
yeah. So first of all, what I will see there is, I think, like, you are, like, from the large picture, I think you are right that in the end, I think consistency, like, our technology mode is not the consistency. Because, like, no matter what is happening today, I think, like in the very long term wise, consistency issue will be resolved in the end. But the thing is, like, how do you evaluate that? How do you evaluate that consistency issue is, the more like, you know, I will give you an example. I think, like some in some products, the consistency will be solved. It may be about 90% but never 100% let me give you a quick example like, so let's say, Okay, I have, I don't have the I don't have the flow there. But the basically thing is, let me show you one thing is about the fashion industry, right? So I think what they may get to deal with, like, I haven't tried the mid journey one, but I have tried the flow one. So the thing is that, you know, like, right now, what they can do is, is more I will see on the maybe, on the photo stage, like, you know, like they can generate a photo, or things like that, to have the kind of like this, like, more like a rigid product, right? More consistent. But when it comes to fashion industry, it's kind of a totally different mindset, right? The thing is, like, when, like, I do not think like, mid journey, or like flow, or video three, or any of the of the product, they can actually, you know, just give it a close image, and they can actually understand the material of the clothes and how it's, you know, wearing on the body, and when the model is stretching the clothes, like, whether it's really like this is cashmere, right? Like, whether it shows how the stretch of the clothes should look like. And the reason being that is, what I say is, I think for some products, maybe the consistency you think it's much better, but for most of the product, it's pretty hard, because you are not just needing the generation technology. Also need to level the material, you know, like the cut, the shape, how is a wearing on the people's body? And that part is actually, you know, like, pretty hard. I will give you example of what we cooperate before with. Let me, let me find that one. I think it's there. They are. Brand for,
yeah. So first of all, what I will see there is, I think, like, you are, like, from the large picture, I think you are right that in the end, I think consistency, like, our technology mode is not the consistency. Because, like, no matter what is happening today, I think, like in the very long term wise, consistency issue will be resolved in the end. But the thing is, like, how do you evaluate that? How do you evaluate that consistency issue is, the more like, you know, I will give you an example. I think, like some in some products, the consistency will be solved. It may be about 90% but never 100% let me give you a quick example like, so let's say, Okay, I have, I don't have the I don't have the flow there. But the basically thing is, let me show you one thing is about the fashion industry, right? So I think what they may get to deal with, like, I haven't tried the mid journey one, but I have tried the flow one. So the thing is that, you know, like, right now, what they can do is, is more I will see on the maybe, on the photo stage, like, you know, like they can generate a photo, or things like that, to have the kind of like this, like, more like a rigid product, right? More consistent. But when it comes to fashion industry, it's kind of a totally different mindset, right? The thing is, like, when, like, I do not think like, mid journey, or like flow, or video three, or any of the of the product, they can actually, you know, just give it a close image, and they can actually understand the material of the clothes and how it's, you know, wearing on the body, and when the model is stretching the clothes, like, whether it's really like this is cashmere, right? Like, whether it shows how the stretch of the clothes should look like. And the reason being that is, what I say is, I think for some products, maybe the consistency you think it's much better, but for most of the product, it's pretty hard, because you are not just needing the generation technology. Also need to level the material, you know, like the cut, the shape, how is a wearing on the people's body? And that part is actually, you know, like, pretty hard. I will give you example of what we cooperate before with. Let me, let me find that one. I think it's there. They are. Brand for,
2:52okay, I don't know where it goes. I
okay, I don't know where it goes. I
okay, I don't know where it goes. I
okay, I don't know where it goes. I
S Speaker 12:54think it's Oh, this one, right? So the thing is, like, what we see for some of the brands there is when they have, like, such clothes, they are a lot of detail, details of like, you know, like the shape and how many flowers in this race is totally different when she is when they are generating and when she is walking, you know, like, the dress doesn't flow as naturally as it is in the AI model. So, like, I tried flow before, I think, like, here, right? So I think what they have done is frames to video where you can, I think that is what you are talking about, right? Basically, is you can, you know, upload a photo or something. Let's say you can upload, like a product or something like that, and then, you know, like, based on this product, you can generate a video, right? Let's say we can see a model is holding the product. And, you know, sell to the camera or something like that. So the thing is, like, what? Oh, I need, I need, I need credit. Sorry, let me get another account. Give me one moment. So the problem there, basically, is, you know, for flow, they are more like, you know, like generating from, you know, like that. They are generating from that new, you know, like image, but you know, like they cannot really have the model to hold it. Let me generate new one. Let's see.
think it's Oh, this one, right? So the thing is, like, what we see for some of the brands there is when they have, like, such clothes, they are a lot of detail, details of like, you know, like the shape and how many flowers in this race is totally different when she is when they are generating and when she is walking, you know, like, the dress doesn't flow as naturally as it is in the AI model. So, like, I tried flow before, I think, like, here, right? So I think what they have done is frames to video where you can, I think that is what you are talking about, right? Basically, is you can, you know, upload a photo or something. Let's say you can upload, like a product or something like that, and then, you know, like, based on this product, you can generate a video, right? Let's say we can see a model is holding the product. And, you know, sell to the camera or something like that. So the thing is, like, what? Oh, I need, I need, I need credit. Sorry, let me get another account. Give me one moment. So the problem there, basically, is, you know, for flow, they are more like, you know, like generating from, you know, like that. They are generating from that new, you know, like image, but you know, like they cannot really have the model to hold it. Let me generate new one. Let's see.
think it's Oh, this one, right? So the thing is, like, what we see for some of the brands there is when they have, like, such clothes, they are a lot of detail, details of like, you know, like the shape and how many flowers in this race is totally different when she is when they are generating and when she is walking, you know, like, the dress doesn't flow as naturally as it is in the AI model. So, like, I tried flow before, I think, like, here, right? So I think what they have done is frames to video where you can, I think that is what you are talking about, right? Basically, is you can, you know, upload a photo or something. Let's say you can upload, like a product or something like that, and then, you know, like, based on this product, you can generate a video, right? Let's say we can see a model is holding the product. And, you know, sell to the camera or something like that. So the thing is, like, what? Oh, I need, I need, I need credit. Sorry, let me get another account. Give me one moment. So the problem there, basically, is, you know, for flow, they are more like, you know, like generating from, you know, like that. They are generating from that new, you know, like image, but you know, like they cannot really have the model to hold it. Let me generate new one. Let's see.
think it's Oh, this one, right? So the thing is, like, what we see for some of the brands there is when they have, like, such clothes, they are a lot of detail, details of like, you know, like the shape and how many flowers in this race is totally different when she is when they are generating and when she is walking, you know, like, the dress doesn't flow as naturally as it is in the AI model. So, like, I tried flow before, I think, like, here, right? So I think what they have done is frames to video where you can, I think that is what you are talking about, right? Basically, is you can, you know, upload a photo or something. Let's say you can upload, like a product or something like that, and then, you know, like, based on this product, you can generate a video, right? Let's say we can see a model is holding the product. And, you know, sell to the camera or something like that. So the thing is, like, what? Oh, I need, I need, I need credit. Sorry, let me get another account. Give me one moment. So the problem there, basically, is, you know, for flow, they are more like, you know, like generating from, you know, like that. They are generating from that new, you know, like image, but you know, like they cannot really have the model to hold it. Let me generate new one. Let's see.
4:41Sorry, no worries. Say, This one
Sorry, no worries. Say, This one
Sorry, no worries. Say, This one
Sorry, no worries. Say, This one
S Speaker 24:47always happens. We they discharge so much. There is always
always happens. We they discharge so much. There is always
always happens. We they discharge so much. There is always
always happens. We they discharge so much. There is always
S Speaker 14:53model is holding the product and selling to the camera, right? So the thing is that you know, for this more like a static I will see more like a static product. What, via three is able to do is more like an image to video, or like, maybe in the future, ingredients to video, right? They can more maybe, like hold it or do something like that. But for clothes, is pretty hard, because they do not know how the clothes is wearing on the model, you know, because that is more like, I will not say it's something like a virtual trial problem. It's not just, you know, like a consistent, consistency issue, right? So let me show you one moment or so, what I would do another experiment is, you know, like, this is like cider, right? We just, you know, get a close image from them and upload it to view three and mid journey. We can try that. I
model is holding the product and selling to the camera, right? So the thing is that you know, for this more like a static I will see more like a static product. What, via three is able to do is more like an image to video, or like, maybe in the future, ingredients to video, right? They can more maybe, like hold it or do something like that. But for clothes, is pretty hard, because they do not know how the clothes is wearing on the model, you know, because that is more like, I will not say it's something like a virtual trial problem. It's not just, you know, like a consistent, consistency issue, right? So let me show you one moment or so, what I would do another experiment is, you know, like, this is like cider, right? We just, you know, get a close image from them and upload it to view three and mid journey. We can try that. I
model is holding the product and selling to the camera, right? So the thing is that you know, for this more like a static I will see more like a static product. What, via three is able to do is more like an image to video, or like, maybe in the future, ingredients to video, right? They can more maybe, like hold it or do something like that. But for clothes, is pretty hard, because they do not know how the clothes is wearing on the model, you know, because that is more like, I will not say it's something like a virtual trial problem. It's not just, you know, like a consistent, consistency issue, right? So let me show you one moment or so, what I would do another experiment is, you know, like, this is like cider, right? We just, you know, get a close image from them and upload it to view three and mid journey. We can try that. I
model is holding the product and selling to the camera, right? So the thing is that you know, for this more like a static I will see more like a static product. What, via three is able to do is more like an image to video, or like, maybe in the future, ingredients to video, right? They can more maybe, like hold it or do something like that. But for clothes, is pretty hard, because they do not know how the clothes is wearing on the model, you know, because that is more like, I will not say it's something like a virtual trial problem. It's not just, you know, like a consistent, consistency issue, right? So let me show you one moment or so, what I would do another experiment is, you know, like, this is like cider, right? We just, you know, get a close image from them and upload it to view three and mid journey. We can try that. I
S Speaker 36:07um, yeah, so, yes, so a model is wearing the the opera
um, yeah, so, yes, so a model is wearing the the opera
um, yeah, so, yes, so a model is wearing the the opera
um, yeah, so, yes, so a model is wearing the the opera
S Speaker 36:20and pose to the camera.
and pose to the camera.
and pose to the camera.
and pose to the camera.
6:24So this is for that.
6:27Let me show you what it's generated. This
Let me show you what it's generated. This
Let me show you what it's generated. This
Let me show you what it's generated. This
6:29is summer Friday's cloud,
is summer Friday's cloud,
is summer Friday's cloud,
is summer Friday's cloud,
6:34think you can see it
S Speaker 46:36gel cream. It's ultra lightweight gel cream that gives your skin a burst of hydration. This is summer Friday,
gel cream. It's ultra lightweight gel cream that gives your skin a burst of hydration. This is summer Friday,
gel cream. It's ultra lightweight gel cream that gives your skin a burst of hydration. This is summer Friday,
gel cream. It's ultra lightweight gel cream that gives your skin a burst of hydration. This is summer Friday,
S Speaker 16:43so you can see that I think it's like much better, you know, like, then what's like compared to other platform. But when you compare this to, you know, like previous results, it will be different. This is our brand, like, this is another one. Let me get back to,
so you can see that I think it's like much better, you know, like, then what's like compared to other platform. But when you compare this to, you know, like previous results, it will be different. This is our brand, like, this is another one. Let me get back to,
so you can see that I think it's like much better, you know, like, then what's like compared to other platform. But when you compare this to, you know, like previous results, it will be different. This is our brand, like, this is another one. Let me get back to,
so you can see that I think it's like much better, you know, like, then what's like compared to other platform. But when you compare this to, you know, like previous results, it will be different. This is our brand, like, this is another one. Let me get back to,
S Speaker 17:08oh, this is not exactly the same product, but I think is it the same product? Give me one moment. Let me double check
oh, this is not exactly the same product, but I think is it the same product? Give me one moment. Let me double check
oh, this is not exactly the same product, but I think is it the same product? Give me one moment. Let me double check
oh, this is not exactly the same product, but I think is it the same product? Give me one moment. Let me double check
7:17I think this one, uh,
I think this one, uh,
I think this one, uh,
I think this one, uh,
S Speaker 511:05Okay, I think I don't have it. Let me. Let me quit
Okay, I think I don't have it. Let me. Let me quit
Okay, I think I don't have it. Let me. Let me quit
Okay, I think I don't have it. Let me. Let me quit
11:09and start. Yeah,
S Speaker 611:57my skin's been freaking out from all these PhDs, and honestly, nothing was working until I found the salicylic acid solution from the ordinary it's only $6 literally cleared my stress breakouts in days. No fragrance, not sticking, and I can throw it in my bag without worrying about weeks. I apply it right after showering off the salt waters look way smaller, perfect for when you're constantly sweating and reapplying sunscreen, but still want to look
my skin's been freaking out from all these PhDs, and honestly, nothing was working until I found the salicylic acid solution from the ordinary it's only $6 literally cleared my stress breakouts in days. No fragrance, not sticking, and I can throw it in my bag without worrying about weeks. I apply it right after showering off the salt waters look way smaller, perfect for when you're constantly sweating and reapplying sunscreen, but still want to look
my skin's been freaking out from all these PhDs, and honestly, nothing was working until I found the salicylic acid solution from the ordinary it's only $6 literally cleared my stress breakouts in days. No fragrance, not sticking, and I can throw it in my bag without worrying about weeks. I apply it right after showering off the salt waters look way smaller, perfect for when you're constantly sweating and reapplying sunscreen, but still want to look
my skin's been freaking out from all these PhDs, and honestly, nothing was working until I found the salicylic acid solution from the ordinary it's only $6 literally cleared my stress breakouts in days. No fragrance, not sticking, and I can throw it in my bag without worrying about weeks. I apply it right after showering off the salt waters look way smaller, perfect for when you're constantly sweating and reapplying sunscreen, but still want to look
S Speaker 212:18decent in all those funniest sunset pics. For this video, the prompt was just the product pictures and a general idea. And the AI was able to sort of generate the entire script, do a chain of card reasoning, break down different scenes, and then create videos, all of them separately for that,
decent in all those funniest sunset pics. For this video, the prompt was just the product pictures and a general idea. And the AI was able to sort of generate the entire script, do a chain of card reasoning, break down different scenes, and then create videos, all of them separately for that,
decent in all those funniest sunset pics. For this video, the prompt was just the product pictures and a general idea. And the AI was able to sort of generate the entire script, do a chain of card reasoning, break down different scenes, and then create videos, all of them separately for that,
decent in all those funniest sunset pics. For this video, the prompt was just the product pictures and a general idea. And the AI was able to sort of generate the entire script, do a chain of card reasoning, break down different scenes, and then create videos, all of them separately for that,
S Speaker 112:32yeah. So for this, actually, the input is one product photo and one URL. So basically it's like how we're doing in our product right now, right? So basically from the IO we understand the product description, the target audience, then itself will generate the storyline, bring it into different things. Then finally, have the view. And then basically, is after the content is generated, you upload it to the ads manager and social media to do the AB testing, and then you feed that to the model, saying, Oh, this is not good. The CPI is pretty bad. And then on the right side, it's the after idea or story it generates, I will say it's really out of box, because we never thought like aI wants to adjust the storyline like this,
yeah. So for this, actually, the input is one product photo and one URL. So basically it's like how we're doing in our product right now, right? So basically from the IO we understand the product description, the target audience, then itself will generate the storyline, bring it into different things. Then finally, have the view. And then basically, is after the content is generated, you upload it to the ads manager and social media to do the AB testing, and then you feed that to the model, saying, Oh, this is not good. The CPI is pretty bad. And then on the right side, it's the after idea or story it generates, I will say it's really out of box, because we never thought like aI wants to adjust the storyline like this,
yeah. So for this, actually, the input is one product photo and one URL. So basically it's like how we're doing in our product right now, right? So basically from the IO we understand the product description, the target audience, then itself will generate the storyline, bring it into different things. Then finally, have the view. And then basically, is after the content is generated, you upload it to the ads manager and social media to do the AB testing, and then you feed that to the model, saying, Oh, this is not good. The CPI is pretty bad. And then on the right side, it's the after idea or story it generates, I will say it's really out of box, because we never thought like aI wants to adjust the storyline like this,
yeah. So for this, actually, the input is one product photo and one URL. So basically it's like how we're doing in our product right now, right? So basically from the IO we understand the product description, the target audience, then itself will generate the storyline, bring it into different things. Then finally, have the view. And then basically, is after the content is generated, you upload it to the ads manager and social media to do the AB testing, and then you feed that to the model, saying, Oh, this is not good. The CPI is pretty bad. And then on the right side, it's the after idea or story it generates, I will say it's really out of box, because we never thought like aI wants to adjust the storyline like this,
S Speaker 713:03so I've been abducted for skincare advice. Your face glows. Can you explain? It's just nice and wide and sink. There's oil, even stone. No rocket science. This is not infused with quantum plasma, nah. Just $8 on Amazon. Welcome to Skincare heaven. I feel balanced, hydrated, empowered.
so I've been abducted for skincare advice. Your face glows. Can you explain? It's just nice and wide and sink. There's oil, even stone. No rocket science. This is not infused with quantum plasma, nah. Just $8 on Amazon. Welcome to Skincare heaven. I feel balanced, hydrated, empowered.
so I've been abducted for skincare advice. Your face glows. Can you explain? It's just nice and wide and sink. There's oil, even stone. No rocket science. This is not infused with quantum plasma, nah. Just $8 on Amazon. Welcome to Skincare heaven. I feel balanced, hydrated, empowered.
so I've been abducted for skincare advice. Your face glows. Can you explain? It's just nice and wide and sink. There's oil, even stone. No rocket science. This is not infused with quantum plasma, nah. Just $8 on Amazon. Welcome to Skincare heaven. I feel balanced, hydrated, empowered.
13:21I agree. I agree this.
I agree. I agree this.
I agree. I agree this.
I agree. I agree this.
S Speaker 113:22Know, Like AI for ideation is not just, you know, like a fantasy, right? Like, it really can sometimes jump out of like, human beings, you know, like experience or their mindset, right? So the thing is, like, we do see this have model potential, and that's reason we think, you know, for technology wise, our True Love in the Future is this ideation aware? Because that is driven by a lot of data. It actually, you know, will actually, you know, monitoring, monitoring all the like, as data from different SMB people, and it will proactive, do a lot of creation there, right? So that I think it's more important in the future. Yeah,
Know, Like AI for ideation is not just, you know, like a fantasy, right? Like, it really can sometimes jump out of like, human beings, you know, like experience or their mindset, right? So the thing is, like, we do see this have model potential, and that's reason we think, you know, for technology wise, our True Love in the Future is this ideation aware? Because that is driven by a lot of data. It actually, you know, will actually, you know, monitoring, monitoring all the like, as data from different SMB people, and it will proactive, do a lot of creation there, right? So that I think it's more important in the future. Yeah,
Know, Like AI for ideation is not just, you know, like a fantasy, right? Like, it really can sometimes jump out of like, human beings, you know, like experience or their mindset, right? So the thing is, like, we do see this have model potential, and that's reason we think, you know, for technology wise, our True Love in the Future is this ideation aware? Because that is driven by a lot of data. It actually, you know, will actually, you know, monitoring, monitoring all the like, as data from different SMB people, and it will proactive, do a lot of creation there, right? So that I think it's more important in the future. Yeah,
Know, Like AI for ideation is not just, you know, like a fantasy, right? Like, it really can sometimes jump out of like, human beings, you know, like experience or their mindset, right? So the thing is, like, we do see this have model potential, and that's reason we think, you know, for technology wise, our True Love in the Future is this ideation aware? Because that is driven by a lot of data. It actually, you know, will actually, you know, monitoring, monitoring all the like, as data from different SMB people, and it will proactive, do a lot of creation there, right? So that I think it's more important in the future. Yeah,
S Speaker 213:52that makes sense. And I'm absolutely glad we had this conversation before I met Trisha, because now it clears things out. And I do see some of this working the last time, when we started, I just felt that from ADS data and AB testing, maybe you will just change the scene slightly, or the model a little bit, but, but the ideation engine is actually generating good content. That's pretty easy. Can you send me the new deck? I would love to go through some of the new details you have in there. Sure,
that makes sense. And I'm absolutely glad we had this conversation before I met Trisha, because now it clears things out. And I do see some of this working the last time, when we started, I just felt that from ADS data and AB testing, maybe you will just change the scene slightly, or the model a little bit, but, but the ideation engine is actually generating good content. That's pretty easy. Can you send me the new deck? I would love to go through some of the new details you have in there. Sure,
that makes sense. And I'm absolutely glad we had this conversation before I met Trisha, because now it clears things out. And I do see some of this working the last time, when we started, I just felt that from ADS data and AB testing, maybe you will just change the scene slightly, or the model a little bit, but, but the ideation engine is actually generating good content. That's pretty easy. Can you send me the new deck? I would love to go through some of the new details you have in there. Sure,
that makes sense. And I'm absolutely glad we had this conversation before I met Trisha, because now it clears things out. And I do see some of this working the last time, when we started, I just felt that from ADS data and AB testing, maybe you will just change the scene slightly, or the model a little bit, but, but the ideation engine is actually generating good content. That's pretty easy. Can you send me the new deck? I would love to go through some of the new details you have in there. Sure,
S Speaker 114:11sure. Maybe, like, you can go through the new deck with with the partner first, and then he may have a better idea before, like, our second chance. Absolutely,
sure. Maybe, like, you can go through the new deck with with the partner first, and then he may have a better idea before, like, our second chance. Absolutely,
sure. Maybe, like, you can go through the new deck with with the partner first, and then he may have a better idea before, like, our second chance. Absolutely,
sure. Maybe, like, you can go through the new deck with with the partner first, and then he may have a better idea before, like, our second chance. Absolutely,
S Speaker 114:24of like, yeah, we are discussing with some, you know, like, tier one, like investors recently, and they roughly will, like, we roughly, we're trying to, you know, finalize, maybe, like, by end of July or early August. They are still in the process. But the thing is, like, I think once we know the like, I definitely like, I think, like, we really have several of them actually have potential. So I will see, like, once, like we can do the process, but likely, yeah, maybe end of July sounds
of like, yeah, we are discussing with some, you know, like, tier one, like investors recently, and they roughly will, like, we roughly, we're trying to, you know, finalize, maybe, like, by end of July or early August. They are still in the process. But the thing is, like, I think once we know the like, I definitely like, I think, like, we really have several of them actually have potential. So I will see, like, once, like we can do the process, but likely, yeah, maybe end of July sounds
of like, yeah, we are discussing with some, you know, like, tier one, like investors recently, and they roughly will, like, we roughly, we're trying to, you know, finalize, maybe, like, by end of July or early August. They are still in the process. But the thing is, like, I think once we know the like, I definitely like, I think, like, we really have several of them actually have potential. So I will see, like, once, like we can do the process, but likely, yeah, maybe end of July sounds
of like, yeah, we are discussing with some, you know, like, tier one, like investors recently, and they roughly will, like, we roughly, we're trying to, you know, finalize, maybe, like, by end of July or early August. They are still in the process. But the thing is, like, I think once we know the like, I definitely like, I think, like, we really have several of them actually have potential. So I will see, like, once, like we can do the process, but likely, yeah, maybe end of July sounds
S Speaker 214:47good. I think on timeline wise, we are aligned. So would love to get the deck, have a chat with the team, set up another call with Bucha. Meanwhile, it may come back with a few questions that, if Kim case would be better to get them answered before the call with the shirt. But if not, we can have that next call as the next step on our end? Sure,
good. I think on timeline wise, we are aligned. So would love to get the deck, have a chat with the team, set up another call with Bucha. Meanwhile, it may come back with a few questions that, if Kim case would be better to get them answered before the call with the shirt. But if not, we can have that next call as the next step on our end? Sure,
good. I think on timeline wise, we are aligned. So would love to get the deck, have a chat with the team, set up another call with Bucha. Meanwhile, it may come back with a few questions that, if Kim case would be better to get them answered before the call with the shirt. But if not, we can have that next call as the next step on our end? Sure,
good. I think on timeline wise, we are aligned. So would love to get the deck, have a chat with the team, set up another call with Bucha. Meanwhile, it may come back with a few questions that, if Kim case would be better to get them answered before the call with the shirt. But if not, we can have that next call as the next step on our end? Sure,
S Speaker 615:03sure, definitely. So I got a question. So after the call is popular, like, what will be the remaining process on your side?
sure, definitely. So I got a question. So after the call is popular, like, what will be the remaining process on your side?
sure, definitely. So I got a question. So after the call is popular, like, what will be the remaining process on your side?
sure, definitely. So I got a question. So after the call is popular, like, what will be the remaining process on your side?
S Speaker 215:08So with all with Bucha parallely, I will have a team wide discussion on VAT next Monday. So I will prepare a little bit of somebody else on my end, have a discussion with the team, and then we would require you to present to the entire team as well. So that's one step in the process sometime when you will meet most of the members of the team we will do a zoom for some time and post that we just have an internal voting.
So with all with Bucha parallely, I will have a team wide discussion on VAT next Monday. So I will prepare a little bit of somebody else on my end, have a discussion with the team, and then we would require you to present to the entire team as well. So that's one step in the process sometime when you will meet most of the members of the team we will do a zoom for some time and post that we just have an internal voting.
So with all with Bucha parallely, I will have a team wide discussion on VAT next Monday. So I will prepare a little bit of somebody else on my end, have a discussion with the team, and then we would require you to present to the entire team as well. So that's one step in the process sometime when you will meet most of the members of the team we will do a zoom for some time and post that we just have an internal voting.
So with all with Bucha parallely, I will have a team wide discussion on VAT next Monday. So I will prepare a little bit of somebody else on my end, have a discussion with the team, and then we would require you to present to the entire team as well. So that's one step in the process sometime when you will meet most of the members of the team we will do a zoom for some time and post that we just have an internal voting.
S Speaker 115:27Thank you. Yeah, that's pretty cool. Thank you. I will send you the update, and also the video which is the so they can have.
Thank you. Yeah, that's pretty cool. Thank you. I will send you the update, and also the video which is the so they can have.
Thank you. Yeah, that's pretty cool. Thank you. I will send you the update, and also the video which is the so they can have.
Thank you. Yeah, that's pretty cool. Thank you. I will send you the update, and also the video which is the so they can have.
15:34Thanks. Thanks a lot of this. Appreciate it.
Thanks. Thanks a lot of this. Appreciate it.
Thanks. Thanks a lot of this. Appreciate it.
Thanks. Thanks a lot of this. Appreciate it.