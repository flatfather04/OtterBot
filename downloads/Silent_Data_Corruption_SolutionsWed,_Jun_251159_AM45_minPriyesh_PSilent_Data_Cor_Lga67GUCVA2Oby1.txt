Meeting: Silent Data Corruption Solutions
Wed, Jun 25
11:59 AM
45 min
Priyesh P
Silent Data Corruptions (SDCs
URL: https://otter.ai/u/Lga67GUCVA2Oby1Rkhx1KoX-nYs
Downloaded: 2025-12-21T21:52:15.448582
Method: text_extraction
============================================================

S Speaker 22:26Thanks, David. Let's embark on the journey. It all starts with quantum physics. So transistors are the basic building blocks of whole chips. They carry and process sedimentary big information at a very basic label, transistors are quantum physics devices. We're not talking about quantum computing here. However, at the scale of today's transistor, they are subject to quantum effects, and certain probabilistic behaviors become significant. What that means is that they are vulnerable to certain perturbations to their environment, such as cosmic rays and charges in voltage and temperature. When that happens, the transistor may respond more slowly, or may become temporarily unstable, jumping back and forth in the open, enclosed state. So we distinguish between two growth categories of SDCs, our transient SDCs, which are random, isolated errors posed by stripes of high energy particles such as cosmic rays. And then there are permanent SDCs, which are repeating or intended to errors caused by a variety of factors, including aging and Chinese COVID aging. All of this is highly non deterministic, all right, so moving up to the next layer of a step, transistors are combined into large and complex structures to implement GPU functions, that includes register files, Al news, tensor cores and so forth. Question is, how vulnerable are those functions to faulty transistors? Well, it depends on multiple complex factors, including the exact timing and site of a faulty transistor. Many faulty bits actually not tracked by downstream logic, and are banishing that trace. However, some are captured and lead to a fault. For that reason, many circuits are protected today. A well known example of this is ECC, which protects most of today's memory. Typically protects up to two bit errors and correct one in terms now, these protections are expensive. Can take up valuable space on sacred and for that reason, they're not always practical, in particular for compute, for concrete logic. Okay, so when, when a faulty transistor does lead to an execution error, the blast ranges can vary enormously. The error can be as small as a tiny math error on the six decimal of a calculation, or it can cause that same calculation to be off by a billion. Or even worse, they actually incorrectly flagged as incomputable by math. In other cases, the fault just pushes the GPU to some invalid state and it hangs there. All right, so at this point, the fault has jumped out of a silicon and entered the realm of software. As we just mentioned, the execution errors can take multiple forms. In the case of a hang a watchdog is likely to detect the problem and throw an exception. At this point, it is no longer silent calculation errors, on the other hand, are more likely to go unnoticed. So let's focus on that. Most of the math behind AI is rooted in linear algebra, and matrix multiplication is the workhorse. They're often called gem for general matrix multiplication. Those gems also happen to be one of the most expensive operations used by models, and that makes them particularly affordable to SDCs. All right. So these gems are implemented in low level libraries, and they use highly optimized Bucha kernels to take advantage of tensor cores. At the elementary level, those gems are long sequences of matrix, multiply, add a structure. So when the original error is small, it tends to vanish in those long summations because of a limited precision of floating point arithmetic. However, when it is large, it may propagate or even explode, particularly in the case of an in coordinate. So what you see here is that the outcome of an SDC that goes through a jam depends on the initial error your data set surrounds it. It makes it very difficult, if not practically impossible, to predict. All right, reaching out the last layer of a stack the AI model. So models essentially complex network of interconnected gems and activation functions. So what's going to happen to our SDC has survived a trip so far, made it over gem and now reaching the layers of a model? Well, once again, depends on multiple complex factors. But first we should state that many models are intrinsically resilient to noise. A good illustration of that is quantization. Some models can be trained on as little as a single digit of precision, but guess better, models may even benefit from noise. Think drawback layers that actually accelerate training convergence by injecting random zeros or LLM temperature that improves on the quality of predictions, but also injecting random noise some some of that resiliency can be traced back to certain activation functions using transformers and specifically layer norms, softmax and puzzle maps, which tend to greatly reduce the impact of huge numbers that may be had caused by an SDC outliers. That is right, they may actually even mask entirely inverted exposure. In
Thanks, David. Let's embark on the journey. It all starts with quantum physics. So transistors are the basic building blocks of whole chips. They carry and process sedimentary big information at a very basic label, transistors are quantum physics devices. We're not talking about quantum computing here. However, at the scale of today's transistor, they are subject to quantum effects, and certain probabilistic behaviors become significant. What that means is that they are vulnerable to certain perturbations to their environment, such as cosmic rays and charges in voltage and temperature. When that happens, the transistor may respond more slowly, or may become temporarily unstable, jumping back and forth in the open, enclosed state. So we distinguish between two growth categories of SDCs, our transient SDCs, which are random, isolated errors posed by stripes of high energy particles such as cosmic rays. And then there are permanent SDCs, which are repeating or intended to errors caused by a variety of factors, including aging and Chinese COVID aging. All of this is highly non deterministic, all right, so moving up to the next layer of a step, transistors are combined into large and complex structures to implement GPU functions, that includes register files, Al news, tensor cores and so forth. Question is, how vulnerable are those functions to faulty transistors? Well, it depends on multiple complex factors, including the exact timing and site of a faulty transistor. Many faulty bits actually not tracked by downstream logic, and are banishing that trace. However, some are captured and lead to a fault. For that reason, many circuits are protected today. A well known example of this is ECC, which protects most of today's memory. Typically protects up to two bit errors and correct one in terms now, these protections are expensive. Can take up valuable space on sacred and for that reason, they're not always practical, in particular for compute, for concrete logic. Okay, so when, when a faulty transistor does lead to an execution error, the blast ranges can vary enormously. The error can be as small as a tiny math error on the six decimal of a calculation, or it can cause that same calculation to be off by a billion. Or even worse, they actually incorrectly flagged as incomputable by math. In other cases, the fault just pushes the GPU to some invalid state and it hangs there. All right, so at this point, the fault has jumped out of a silicon and entered the realm of software. As we just mentioned, the execution errors can take multiple forms. In the case of a hang a watchdog is likely to detect the problem and throw an exception. At this point, it is no longer silent calculation errors, on the other hand, are more likely to go unnoticed. So let's focus on that. Most of the math behind AI is rooted in linear algebra, and matrix multiplication is the workhorse. They're often called gem for general matrix multiplication. Those gems also happen to be one of the most expensive operations used by models, and that makes them particularly affordable to SDCs. All right. So these gems are implemented in low level libraries, and they use highly optimized Bucha kernels to take advantage of tensor cores. At the elementary level, those gems are long sequences of matrix, multiply, add a structure. So when the original error is small, it tends to vanish in those long summations because of a limited precision of floating point arithmetic. However, when it is large, it may propagate or even explode, particularly in the case of an in coordinate. So what you see here is that the outcome of an SDC that goes through a jam depends on the initial error your data set surrounds it. It makes it very difficult, if not practically impossible, to predict. All right, reaching out the last layer of a stack the AI model. So models essentially complex network of interconnected gems and activation functions. So what's going to happen to our SDC has survived a trip so far, made it over gem and now reaching the layers of a model? Well, once again, depends on multiple complex factors. But first we should state that many models are intrinsically resilient to noise. A good illustration of that is quantization. Some models can be trained on as little as a single digit of precision, but guess better, models may even benefit from noise. Think drawback layers that actually accelerate training convergence by injecting random zeros or LLM temperature that improves on the quality of predictions, but also injecting random noise some some of that resiliency can be traced back to certain activation functions using transformers and specifically layer norms, softmax and puzzle maps, which tend to greatly reduce the impact of huge numbers that may be had caused by an SDC outliers. That is right, they may actually even mask entirely inverted exposure. In
Thanks, David. Let's embark on the journey. It all starts with quantum physics. So transistors are the basic building blocks of whole chips. They carry and process sedimentary big information at a very basic label, transistors are quantum physics devices. We're not talking about quantum computing here. However, at the scale of today's transistor, they are subject to quantum effects, and certain probabilistic behaviors become significant. What that means is that they are vulnerable to certain perturbations to their environment, such as cosmic rays and charges in voltage and temperature. When that happens, the transistor may respond more slowly, or may become temporarily unstable, jumping back and forth in the open, enclosed state. So we distinguish between two growth categories of SDCs, our transient SDCs, which are random, isolated errors posed by stripes of high energy particles such as cosmic rays. And then there are permanent SDCs, which are repeating or intended to errors caused by a variety of factors, including aging and Chinese COVID aging. All of this is highly non deterministic, all right, so moving up to the next layer of a step, transistors are combined into large and complex structures to implement GPU functions, that includes register files, Al news, tensor cores and so forth. Question is, how vulnerable are those functions to faulty transistors? Well, it depends on multiple complex factors, including the exact timing and site of a faulty transistor. Many faulty bits actually not tracked by downstream logic, and are banishing that trace. However, some are captured and lead to a fault. For that reason, many circuits are protected today. A well known example of this is ECC, which protects most of today's memory. Typically protects up to two bit errors and correct one in terms now, these protections are expensive. Can take up valuable space on sacred and for that reason, they're not always practical, in particular for compute, for concrete logic. Okay, so when, when a faulty transistor does lead to an execution error, the blast ranges can vary enormously. The error can be as small as a tiny math error on the six decimal of a calculation, or it can cause that same calculation to be off by a billion. Or even worse, they actually incorrectly flagged as incomputable by math. In other cases, the fault just pushes the GPU to some invalid state and it hangs there. All right, so at this point, the fault has jumped out of a silicon and entered the realm of software. As we just mentioned, the execution errors can take multiple forms. In the case of a hang a watchdog is likely to detect the problem and throw an exception. At this point, it is no longer silent calculation errors, on the other hand, are more likely to go unnoticed. So let's focus on that. Most of the math behind AI is rooted in linear algebra, and matrix multiplication is the workhorse. They're often called gem for general matrix multiplication. Those gems also happen to be one of the most expensive operations used by models, and that makes them particularly affordable to SDCs. All right. So these gems are implemented in low level libraries, and they use highly optimized Bucha kernels to take advantage of tensor cores. At the elementary level, those gems are long sequences of matrix, multiply, add a structure. So when the original error is small, it tends to vanish in those long summations because of a limited precision of floating point arithmetic. However, when it is large, it may propagate or even explode, particularly in the case of an in coordinate. So what you see here is that the outcome of an SDC that goes through a jam depends on the initial error your data set surrounds it. It makes it very difficult, if not practically impossible, to predict. All right, reaching out the last layer of a stack the AI model. So models essentially complex network of interconnected gems and activation functions. So what's going to happen to our SDC has survived a trip so far, made it over gem and now reaching the layers of a model? Well, once again, depends on multiple complex factors. But first we should state that many models are intrinsically resilient to noise. A good illustration of that is quantization. Some models can be trained on as little as a single digit of precision, but guess better, models may even benefit from noise. Think drawback layers that actually accelerate training convergence by injecting random zeros or LLM temperature that improves on the quality of predictions, but also injecting random noise some some of that resiliency can be traced back to certain activation functions using transformers and specifically layer norms, softmax and puzzle maps, which tend to greatly reduce the impact of huge numbers that may be had caused by an SDC outliers. That is right, they may actually even mask entirely inverted exposure. In
Thanks, David. Let's embark on the journey. It all starts with quantum physics. So transistors are the basic building blocks of whole chips. They carry and process sedimentary big information at a very basic label, transistors are quantum physics devices. We're not talking about quantum computing here. However, at the scale of today's transistor, they are subject to quantum effects, and certain probabilistic behaviors become significant. What that means is that they are vulnerable to certain perturbations to their environment, such as cosmic rays and charges in voltage and temperature. When that happens, the transistor may respond more slowly, or may become temporarily unstable, jumping back and forth in the open, enclosed state. So we distinguish between two growth categories of SDCs, our transient SDCs, which are random, isolated errors posed by stripes of high energy particles such as cosmic rays. And then there are permanent SDCs, which are repeating or intended to errors caused by a variety of factors, including aging and Chinese COVID aging. All of this is highly non deterministic, all right, so moving up to the next layer of a step, transistors are combined into large and complex structures to implement GPU functions, that includes register files, Al news, tensor cores and so forth. Question is, how vulnerable are those functions to faulty transistors? Well, it depends on multiple complex factors, including the exact timing and site of a faulty transistor. Many faulty bits actually not tracked by downstream logic, and are banishing that trace. However, some are captured and lead to a fault. For that reason, many circuits are protected today. A well known example of this is ECC, which protects most of today's memory. Typically protects up to two bit errors and correct one in terms now, these protections are expensive. Can take up valuable space on sacred and for that reason, they're not always practical, in particular for compute, for concrete logic. Okay, so when, when a faulty transistor does lead to an execution error, the blast ranges can vary enormously. The error can be as small as a tiny math error on the six decimal of a calculation, or it can cause that same calculation to be off by a billion. Or even worse, they actually incorrectly flagged as incomputable by math. In other cases, the fault just pushes the GPU to some invalid state and it hangs there. All right, so at this point, the fault has jumped out of a silicon and entered the realm of software. As we just mentioned, the execution errors can take multiple forms. In the case of a hang a watchdog is likely to detect the problem and throw an exception. At this point, it is no longer silent calculation errors, on the other hand, are more likely to go unnoticed. So let's focus on that. Most of the math behind AI is rooted in linear algebra, and matrix multiplication is the workhorse. They're often called gem for general matrix multiplication. Those gems also happen to be one of the most expensive operations used by models, and that makes them particularly affordable to SDCs. All right. So these gems are implemented in low level libraries, and they use highly optimized Bucha kernels to take advantage of tensor cores. At the elementary level, those gems are long sequences of matrix, multiply, add a structure. So when the original error is small, it tends to vanish in those long summations because of a limited precision of floating point arithmetic. However, when it is large, it may propagate or even explode, particularly in the case of an in coordinate. So what you see here is that the outcome of an SDC that goes through a jam depends on the initial error your data set surrounds it. It makes it very difficult, if not practically impossible, to predict. All right, reaching out the last layer of a stack the AI model. So models essentially complex network of interconnected gems and activation functions. So what's going to happen to our SDC has survived a trip so far, made it over gem and now reaching the layers of a model? Well, once again, depends on multiple complex factors. But first we should state that many models are intrinsically resilient to noise. A good illustration of that is quantization. Some models can be trained on as little as a single digit of precision, but guess better, models may even benefit from noise. Think drawback layers that actually accelerate training convergence by injecting random zeros or LLM temperature that improves on the quality of predictions, but also injecting random noise some some of that resiliency can be traced back to certain activation functions using transformers and specifically layer norms, softmax and puzzle maps, which tend to greatly reduce the impact of huge numbers that may be had caused by an SDC outliers. That is right, they may actually even mask entirely inverted exposure. In
7:52some cases, some errors do propagate,
some cases, some errors do propagate,
some cases, some errors do propagate,
some cases, some errors do propagate,
S Speaker 27:55however, and that's because some regions of the model are vulnerable. For example, the logit layer, which is the last layer of the lnn that turns the embeddings back into tokens, is not protected by an activation function. Errors that happen in a backward pass may corrupt a gradient and derail training. So we've done some some analysis on this, and data from simulations suggest that under 1% of SDCs translate into numeric exposure by training models. All right, so in summary, we have followed the journey of NSDC from the initial perturbation in silicon all the way to the model. We've seen that many of these spots vanish as they move up step. However, some do survive, and I have effects ranging from tiny math errors that are extremely noticeable and easy recovered from all the way to numerical exposures. All right, so we're seeing how complex and insidious SDCs are, yet they are inevitable. So how should we tackle them? Something we've learned over time at Nvidia is that no single solution is going to fully address a problem, so we gradually developed a multi tiered strategy consisting of multiple lines of defense and both proactive and reactive measures that covers the entire life cycle of a GPU, from its birth at the factory all the way to its end of life in a Data Center. David is going to walk us through this.
however, and that's because some regions of the model are vulnerable. For example, the logit layer, which is the last layer of the lnn that turns the embeddings back into tokens, is not protected by an activation function. Errors that happen in a backward pass may corrupt a gradient and derail training. So we've done some some analysis on this, and data from simulations suggest that under 1% of SDCs translate into numeric exposure by training models. All right, so in summary, we have followed the journey of NSDC from the initial perturbation in silicon all the way to the model. We've seen that many of these spots vanish as they move up step. However, some do survive, and I have effects ranging from tiny math errors that are extremely noticeable and easy recovered from all the way to numerical exposures. All right, so we're seeing how complex and insidious SDCs are, yet they are inevitable. So how should we tackle them? Something we've learned over time at Nvidia is that no single solution is going to fully address a problem, so we gradually developed a multi tiered strategy consisting of multiple lines of defense and both proactive and reactive measures that covers the entire life cycle of a GPU, from its birth at the factory all the way to its end of life in a Data Center. David is going to walk us through this.
however, and that's because some regions of the model are vulnerable. For example, the logit layer, which is the last layer of the lnn that turns the embeddings back into tokens, is not protected by an activation function. Errors that happen in a backward pass may corrupt a gradient and derail training. So we've done some some analysis on this, and data from simulations suggest that under 1% of SDCs translate into numeric exposure by training models. All right, so in summary, we have followed the journey of NSDC from the initial perturbation in silicon all the way to the model. We've seen that many of these spots vanish as they move up step. However, some do survive, and I have effects ranging from tiny math errors that are extremely noticeable and easy recovered from all the way to numerical exposures. All right, so we're seeing how complex and insidious SDCs are, yet they are inevitable. So how should we tackle them? Something we've learned over time at Nvidia is that no single solution is going to fully address a problem, so we gradually developed a multi tiered strategy consisting of multiple lines of defense and both proactive and reactive measures that covers the entire life cycle of a GPU, from its birth at the factory all the way to its end of life in a Data Center. David is going to walk us through this.
however, and that's because some regions of the model are vulnerable. For example, the logit layer, which is the last layer of the lnn that turns the embeddings back into tokens, is not protected by an activation function. Errors that happen in a backward pass may corrupt a gradient and derail training. So we've done some some analysis on this, and data from simulations suggest that under 1% of SDCs translate into numeric exposure by training models. All right, so in summary, we have followed the journey of NSDC from the initial perturbation in silicon all the way to the model. We've seen that many of these spots vanish as they move up step. However, some do survive, and I have effects ranging from tiny math errors that are extremely noticeable and easy recovered from all the way to numerical exposures. All right, so we're seeing how complex and insidious SDCs are, yet they are inevitable. So how should we tackle them? Something we've learned over time at Nvidia is that no single solution is going to fully address a problem, so we gradually developed a multi tiered strategy consisting of multiple lines of defense and both proactive and reactive measures that covers the entire life cycle of a GPU, from its birth at the factory all the way to its end of life in a Data Center. David is going to walk us through this.
S Speaker 217:07Thanks, David. So all the solutions we just spoke through really aim at identifying and winning undetected GPUs and therefore improve the health of our data center. However, there is another indirect benefit to this, which is by deploying diagnostics and detection tools at scale in data centers, we collect a lot of valuable insights about the failures, observed, the types, frequencies and so forth. By incorporating those precious learnings into the design of future GP generations, we really, really give back to the community. So in a sense here, in a sense here, what we have is a virtuous cycle from Foundry to industry and back, and each iteration of that cycle really improving on the last time. All right. So to recap, we've seen that SDCs are increasingly inevitable at the broad scale of two way data centers, and as we continue to push the boundaries of physics, we've seen how complex and yet fully understood this area is. This is an issue that NVIDIA is taking very seriously, and we believe we're uniquely positioned to tackle it, thanks to our deep expertise in GPS, we put together a multi tiered solutions for this. Some pieces of it are already available to the ecosystem. Others are in active development and will be gradually released. All right, I want to thank you for listening, and we look forward to the next iteration for virtual cycle. Bye. No more
Thanks, David. So all the solutions we just spoke through really aim at identifying and winning undetected GPUs and therefore improve the health of our data center. However, there is another indirect benefit to this, which is by deploying diagnostics and detection tools at scale in data centers, we collect a lot of valuable insights about the failures, observed, the types, frequencies and so forth. By incorporating those precious learnings into the design of future GP generations, we really, really give back to the community. So in a sense here, in a sense here, what we have is a virtuous cycle from Foundry to industry and back, and each iteration of that cycle really improving on the last time. All right. So to recap, we've seen that SDCs are increasingly inevitable at the broad scale of two way data centers, and as we continue to push the boundaries of physics, we've seen how complex and yet fully understood this area is. This is an issue that NVIDIA is taking very seriously, and we believe we're uniquely positioned to tackle it, thanks to our deep expertise in GPS, we put together a multi tiered solutions for this. Some pieces of it are already available to the ecosystem. Others are in active development and will be gradually released. All right, I want to thank you for listening, and we look forward to the next iteration for virtual cycle. Bye. No more
Thanks, David. So all the solutions we just spoke through really aim at identifying and winning undetected GPUs and therefore improve the health of our data center. However, there is another indirect benefit to this, which is by deploying diagnostics and detection tools at scale in data centers, we collect a lot of valuable insights about the failures, observed, the types, frequencies and so forth. By incorporating those precious learnings into the design of future GP generations, we really, really give back to the community. So in a sense here, in a sense here, what we have is a virtuous cycle from Foundry to industry and back, and each iteration of that cycle really improving on the last time. All right. So to recap, we've seen that SDCs are increasingly inevitable at the broad scale of two way data centers, and as we continue to push the boundaries of physics, we've seen how complex and yet fully understood this area is. This is an issue that NVIDIA is taking very seriously, and we believe we're uniquely positioned to tackle it, thanks to our deep expertise in GPS, we put together a multi tiered solutions for this. Some pieces of it are already available to the ecosystem. Others are in active development and will be gradually released. All right, I want to thank you for listening, and we look forward to the next iteration for virtual cycle. Bye. No more
Thanks, David. So all the solutions we just spoke through really aim at identifying and winning undetected GPUs and therefore improve the health of our data center. However, there is another indirect benefit to this, which is by deploying diagnostics and detection tools at scale in data centers, we collect a lot of valuable insights about the failures, observed, the types, frequencies and so forth. By incorporating those precious learnings into the design of future GP generations, we really, really give back to the community. So in a sense here, in a sense here, what we have is a virtuous cycle from Foundry to industry and back, and each iteration of that cycle really improving on the last time. All right. So to recap, we've seen that SDCs are increasingly inevitable at the broad scale of two way data centers, and as we continue to push the boundaries of physics, we've seen how complex and yet fully understood this area is. This is an issue that NVIDIA is taking very seriously, and we believe we're uniquely positioned to tackle it, thanks to our deep expertise in GPS, we put together a multi tiered solutions for this. Some pieces of it are already available to the ecosystem. Others are in active development and will be gradually released. All right, I want to thank you for listening, and we look forward to the next iteration for virtual cycle. Bye. No more
S Speaker 318:42crucial. Welcome to the stage, Governor, Bishop, inch Hussein, Mahana jedhallan, shashir Patil and Cyril moriyon. You.
crucial. Welcome to the stage, Governor, Bishop, inch Hussein, Mahana jedhallan, shashir Patil and Cyril moriyon. You.
crucial. Welcome to the stage, Governor, Bishop, inch Hussein, Mahana jedhallan, shashir Patil and Cyril moriyon. You.
crucial. Welcome to the stage, Governor, Bishop, inch Hussein, Mahana jedhallan, shashir Patil and Cyril moriyon. You.
S Speaker 520:08Yeah, it's a great question. There's a there's a lot of techniques that we use, but I'll just mention two important ones. So at training time you really want to scrub your data for any PII information. You want to get a very good job of that. And then at inference time, you also want to make sure that your rack agents are operating under the same authorization of the user, so that the agent can only see what the user can see, and could not pull out any data. There's a lot of other techniques you could always have filters, filtering the answers, watching out for things that look suspicious in their lucky answer, et cetera. But it's becoming more and more of a solved problem. I guess my point here is, don't let that make you afraid of using it.
Yeah, it's a great question. There's a there's a lot of techniques that we use, but I'll just mention two important ones. So at training time you really want to scrub your data for any PII information. You want to get a very good job of that. And then at inference time, you also want to make sure that your rack agents are operating under the same authorization of the user, so that the agent can only see what the user can see, and could not pull out any data. There's a lot of other techniques you could always have filters, filtering the answers, watching out for things that look suspicious in their lucky answer, et cetera. But it's becoming more and more of a solved problem. I guess my point here is, don't let that make you afraid of using it.
Yeah, it's a great question. There's a there's a lot of techniques that we use, but I'll just mention two important ones. So at training time you really want to scrub your data for any PII information. You want to get a very good job of that. And then at inference time, you also want to make sure that your rack agents are operating under the same authorization of the user, so that the agent can only see what the user can see, and could not pull out any data. There's a lot of other techniques you could always have filters, filtering the answers, watching out for things that look suspicious in their lucky answer, et cetera. But it's becoming more and more of a solved problem. I guess my point here is, don't let that make you afraid of using it.
Yeah, it's a great question. There's a there's a lot of techniques that we use, but I'll just mention two important ones. So at training time you really want to scrub your data for any PII information. You want to get a very good job of that. And then at inference time, you also want to make sure that your rack agents are operating under the same authorization of the user, so that the agent can only see what the user can see, and could not pull out any data. There's a lot of other techniques you could always have filters, filtering the answers, watching out for things that look suspicious in their lucky answer, et cetera. But it's becoming more and more of a solved problem. I guess my point here is, don't let that make you afraid of using it.
S Speaker 423:06Thank you. Shashir, you talked about developing a llama stack, right? What do you see as the most open challenges in that space?
Thank you. Shashir, you talked about developing a llama stack, right? What do you see as the most open challenges in that space?
Thank you. Shashir, you talked about developing a llama stack, right? What do you see as the most open challenges in that space?
Thank you. Shashir, you talked about developing a llama stack, right? What do you see as the most open challenges in that space?
S Speaker 723:15Yeah, with llama stack, I think there's two possibilities, right? One is the technical part, which I think, but I guess there's a more philosophical question is, how do you think of building the vital capital? Because in a lot of agentic scenarios, it's not like classical systems, where you can say, Oh, well, there's throughput, is latency, let's just measure that. Okay. Well, people are going to have different applications. People are going to have different interfaces, different languages. So different languages, and then how do you now build the right vocabulary? Then people can come in and then either plug their evals or lift their evals in a very small, significant lines of code contributions into normal stack, or adapt Lama stack. It's in a fashion that it's immediately very applicable to them. So just making that
Yeah, with llama stack, I think there's two possibilities, right? One is the technical part, which I think, but I guess there's a more philosophical question is, how do you think of building the vital capital? Because in a lot of agentic scenarios, it's not like classical systems, where you can say, Oh, well, there's throughput, is latency, let's just measure that. Okay. Well, people are going to have different applications. People are going to have different interfaces, different languages. So different languages, and then how do you now build the right vocabulary? Then people can come in and then either plug their evals or lift their evals in a very small, significant lines of code contributions into normal stack, or adapt Lama stack. It's in a fashion that it's immediately very applicable to them. So just making that
Yeah, with llama stack, I think there's two possibilities, right? One is the technical part, which I think, but I guess there's a more philosophical question is, how do you think of building the vital capital? Because in a lot of agentic scenarios, it's not like classical systems, where you can say, Oh, well, there's throughput, is latency, let's just measure that. Okay. Well, people are going to have different applications. People are going to have different interfaces, different languages. So different languages, and then how do you now build the right vocabulary? Then people can come in and then either plug their evals or lift their evals in a very small, significant lines of code contributions into normal stack, or adapt Lama stack. It's in a fashion that it's immediately very applicable to them. So just making that
Yeah, with llama stack, I think there's two possibilities, right? One is the technical part, which I think, but I guess there's a more philosophical question is, how do you think of building the vital capital? Because in a lot of agentic scenarios, it's not like classical systems, where you can say, Oh, well, there's throughput, is latency, let's just measure that. Okay. Well, people are going to have different applications. People are going to have different interfaces, different languages. So different languages, and then how do you now build the right vocabulary? Then people can come in and then either plug their evals or lift their evals in a very small, significant lines of code contributions into normal stack, or adapt Lama stack. It's in a fashion that it's immediately very applicable to them. So just making that
S Speaker 424:08making a child. Thank you. Cyril, one question for you, what is the weirdest cause of silent
making a child. Thank you. Cyril, one question for you, what is the weirdest cause of silent
making a child. Thank you. Cyril, one question for you, what is the weirdest cause of silent
making a child. Thank you. Cyril, one question for you, what is the weirdest cause of silent
S Speaker 224:17data corruptions you have seen? Well, the ones I qualify the most, most intriguing are the ones stemming from cosmic rays by the thought that particle has trouble moving in a billion of miles machine even come from a different galaxy, lands on your GPU and messes up your Math. Is rather intriguing. Now, obviously we don't have particle detectors in data centers, not yet, at least, so we can only speculate. But we do observe. We do have a single failure. So in the case of a permanent issue, you know, we'll find some kind of intermittence or pattern, but those are truly random. We do have, we do have a few isolated events that, at this point we can only put on particles now in a lab. So in a lab environment, you know, it has actually been, you know, caught and actually created. We have, we have physicists that takes GPUs and they convert them with particles and see what happens. It's been observed in the control Thank you.
data corruptions you have seen? Well, the ones I qualify the most, most intriguing are the ones stemming from cosmic rays by the thought that particle has trouble moving in a billion of miles machine even come from a different galaxy, lands on your GPU and messes up your Math. Is rather intriguing. Now, obviously we don't have particle detectors in data centers, not yet, at least, so we can only speculate. But we do observe. We do have a single failure. So in the case of a permanent issue, you know, we'll find some kind of intermittence or pattern, but those are truly random. We do have, we do have a few isolated events that, at this point we can only put on particles now in a lab. So in a lab environment, you know, it has actually been, you know, caught and actually created. We have, we have physicists that takes GPUs and they convert them with particles and see what happens. It's been observed in the control Thank you.
data corruptions you have seen? Well, the ones I qualify the most, most intriguing are the ones stemming from cosmic rays by the thought that particle has trouble moving in a billion of miles machine even come from a different galaxy, lands on your GPU and messes up your Math. Is rather intriguing. Now, obviously we don't have particle detectors in data centers, not yet, at least, so we can only speculate. But we do observe. We do have a single failure. So in the case of a permanent issue, you know, we'll find some kind of intermittence or pattern, but those are truly random. We do have, we do have a few isolated events that, at this point we can only put on particles now in a lab. So in a lab environment, you know, it has actually been, you know, caught and actually created. We have, we have physicists that takes GPUs and they convert them with particles and see what happens. It's been observed in the control Thank you.
data corruptions you have seen? Well, the ones I qualify the most, most intriguing are the ones stemming from cosmic rays by the thought that particle has trouble moving in a billion of miles machine even come from a different galaxy, lands on your GPU and messes up your Math. Is rather intriguing. Now, obviously we don't have particle detectors in data centers, not yet, at least, so we can only speculate. But we do observe. We do have a single failure. So in the case of a permanent issue, you know, we'll find some kind of intermittence or pattern, but those are truly random. We do have, we do have a few isolated events that, at this point we can only put on particles now in a lab. So in a lab environment, you know, it has actually been, you know, caught and actually created. We have, we have physicists that takes GPUs and they convert them with particles and see what happens. It's been observed in the control Thank you.
S Speaker 425:25I see we have some questions, like, in person, let's go to the first
I see we have some questions, like, in person, let's go to the first
I see we have some questions, like, in person, let's go to the first
I see we have some questions, like, in person, let's go to the first
S Speaker 725:30guys. Thank you all for the wonderful talks. By all of you. My question was for Hussein, like, what were the key business metrics that the meta main team has been using, and I'm sure there are some internal tough debates of what's the right metric, at least at the early stage, and how those metrics kind of changed or evolved over the course of time.
guys. Thank you all for the wonderful talks. By all of you. My question was for Hussein, like, what were the key business metrics that the meta main team has been using, and I'm sure there are some internal tough debates of what's the right metric, at least at the early stage, and how those metrics kind of changed or evolved over the course of time.
guys. Thank you all for the wonderful talks. By all of you. My question was for Hussein, like, what were the key business metrics that the meta main team has been using, and I'm sure there are some internal tough debates of what's the right metric, at least at the early stage, and how those metrics kind of changed or evolved over the course of time.
guys. Thank you all for the wonderful talks. By all of you. My question was for Hussein, like, what were the key business metrics that the meta main team has been using, and I'm sure there are some internal tough debates of what's the right metric, at least at the early stage, and how those metrics kind of changed or evolved over the course of time.
S Speaker 525:51That's a it's a great question like those business metrics are, are never a straightforward answer, but we do have some, what I would call proxies of satisfaction, either users just clicking in and saying you're satisfied or not. Feedback is also very useful, but we do want to involve the metrics to start understanding how much time are we saving actually, and that's not a very easy question, because, you know, monitoring and observing all workflows is very hard, but you do come up with various proxies, and you find a proxy that the team is comfortable with, my advice is, don't trust it forever. It eventually breaks and you'll have to figure out a different one.
That's a it's a great question like those business metrics are, are never a straightforward answer, but we do have some, what I would call proxies of satisfaction, either users just clicking in and saying you're satisfied or not. Feedback is also very useful, but we do want to involve the metrics to start understanding how much time are we saving actually, and that's not a very easy question, because, you know, monitoring and observing all workflows is very hard, but you do come up with various proxies, and you find a proxy that the team is comfortable with, my advice is, don't trust it forever. It eventually breaks and you'll have to figure out a different one.
That's a it's a great question like those business metrics are, are never a straightforward answer, but we do have some, what I would call proxies of satisfaction, either users just clicking in and saying you're satisfied or not. Feedback is also very useful, but we do want to involve the metrics to start understanding how much time are we saving actually, and that's not a very easy question, because, you know, monitoring and observing all workflows is very hard, but you do come up with various proxies, and you find a proxy that the team is comfortable with, my advice is, don't trust it forever. It eventually breaks and you'll have to figure out a different one.
That's a it's a great question like those business metrics are, are never a straightforward answer, but we do have some, what I would call proxies of satisfaction, either users just clicking in and saying you're satisfied or not. Feedback is also very useful, but we do want to involve the metrics to start understanding how much time are we saving actually, and that's not a very easy question, because, you know, monitoring and observing all workflows is very hard, but you do come up with various proxies, and you find a proxy that the team is comfortable with, my advice is, don't trust it forever. It eventually breaks and you'll have to figure out a different one.
S Speaker 426:40It's kind of hard to see, but I do have one question like that came in from before, like Hussein, and please jump in everyone you had analogy with microservices. And historically, one of the challenges, there are many challenges with microservices as well, problems like complexity management, data consistency, fault tolerance. How do you see that type of problems playing out in a world of MBO and sub agents?
It's kind of hard to see, but I do have one question like that came in from before, like Hussein, and please jump in everyone you had analogy with microservices. And historically, one of the challenges, there are many challenges with microservices as well, problems like complexity management, data consistency, fault tolerance. How do you see that type of problems playing out in a world of MBO and sub agents?
It's kind of hard to see, but I do have one question like that came in from before, like Hussein, and please jump in everyone you had analogy with microservices. And historically, one of the challenges, there are many challenges with microservices as well, problems like complexity management, data consistency, fault tolerance. How do you see that type of problems playing out in a world of MBO and sub agents?
It's kind of hard to see, but I do have one question like that came in from before, like Hussein, and please jump in everyone you had analogy with microservices. And historically, one of the challenges, there are many challenges with microservices as well, problems like complexity management, data consistency, fault tolerance. How do you see that type of problems playing out in a world of MBO and sub agents?
27:54that would be my shorthand.
that would be my shorthand.
that would be my shorthand.
that would be my shorthand.
S Speaker 627:58I love that. I think the only additional spin, at least that, to me, makes this interesting. You know, even prior to some of the time I've spent now working on some of the AI things I spent a bit of my career working on, like microservices and Kubernetes and whatever else, I think one of the things that we've started to observe as we're starting to implement some of these sub ancient things is some of the really, really hard problems when it comes to microservices, you mentioned a few fault tolerance, you name it like they could be very finicky, and it wouldn't be uncommon at all as a board organization, they're like, Oh man, we have such a hard time knowing what microservices to do. What happens if there's a ripple effect where, you know, we don't have this web of all these different dependencies? How do we make sure things go many of those same principles hold true. But I think the part to me that gets exciting is with an LLM, kind of at the core, orchestrating and raising around some of these things. It actually does a really good job of, like, taking care of some of the marginal work automatically for you, meaning that, like, there can be a blip in the system, or there might be some, you know, whatever common woe in microservice land is what happens when my upstream microservice or downstream microservice makes a change. And how do you make sure that doesn't break everything else that can still be a concern when you have a sub agent, but some of the agents who actually find it on their own, like the big, oh, it looks like something here changed. I'm actually going to adjust. I'm going to interact with this other system or do whatever else. So many of the same things hold true. I think where I get optimistic, though, is the ability for us to scale these things and scale them really quickly becomes easier in some ways, because you have this regioning agent that can deal with more ambiguity than the previous world of Intel statements that are very, very finicky To any change of variable. Oh, yeah. Self reflective,
I love that. I think the only additional spin, at least that, to me, makes this interesting. You know, even prior to some of the time I've spent now working on some of the AI things I spent a bit of my career working on, like microservices and Kubernetes and whatever else, I think one of the things that we've started to observe as we're starting to implement some of these sub ancient things is some of the really, really hard problems when it comes to microservices, you mentioned a few fault tolerance, you name it like they could be very finicky, and it wouldn't be uncommon at all as a board organization, they're like, Oh man, we have such a hard time knowing what microservices to do. What happens if there's a ripple effect where, you know, we don't have this web of all these different dependencies? How do we make sure things go many of those same principles hold true. But I think the part to me that gets exciting is with an LLM, kind of at the core, orchestrating and raising around some of these things. It actually does a really good job of, like, taking care of some of the marginal work automatically for you, meaning that, like, there can be a blip in the system, or there might be some, you know, whatever common woe in microservice land is what happens when my upstream microservice or downstream microservice makes a change. And how do you make sure that doesn't break everything else that can still be a concern when you have a sub agent, but some of the agents who actually find it on their own, like the big, oh, it looks like something here changed. I'm actually going to adjust. I'm going to interact with this other system or do whatever else. So many of the same things hold true. I think where I get optimistic, though, is the ability for us to scale these things and scale them really quickly becomes easier in some ways, because you have this regioning agent that can deal with more ambiguity than the previous world of Intel statements that are very, very finicky To any change of variable. Oh, yeah. Self reflective,
I love that. I think the only additional spin, at least that, to me, makes this interesting. You know, even prior to some of the time I've spent now working on some of the AI things I spent a bit of my career working on, like microservices and Kubernetes and whatever else, I think one of the things that we've started to observe as we're starting to implement some of these sub ancient things is some of the really, really hard problems when it comes to microservices, you mentioned a few fault tolerance, you name it like they could be very finicky, and it wouldn't be uncommon at all as a board organization, they're like, Oh man, we have such a hard time knowing what microservices to do. What happens if there's a ripple effect where, you know, we don't have this web of all these different dependencies? How do we make sure things go many of those same principles hold true. But I think the part to me that gets exciting is with an LLM, kind of at the core, orchestrating and raising around some of these things. It actually does a really good job of, like, taking care of some of the marginal work automatically for you, meaning that, like, there can be a blip in the system, or there might be some, you know, whatever common woe in microservice land is what happens when my upstream microservice or downstream microservice makes a change. And how do you make sure that doesn't break everything else that can still be a concern when you have a sub agent, but some of the agents who actually find it on their own, like the big, oh, it looks like something here changed. I'm actually going to adjust. I'm going to interact with this other system or do whatever else. So many of the same things hold true. I think where I get optimistic, though, is the ability for us to scale these things and scale them really quickly becomes easier in some ways, because you have this regioning agent that can deal with more ambiguity than the previous world of Intel statements that are very, very finicky To any change of variable. Oh, yeah. Self reflective,
I love that. I think the only additional spin, at least that, to me, makes this interesting. You know, even prior to some of the time I've spent now working on some of the AI things I spent a bit of my career working on, like microservices and Kubernetes and whatever else, I think one of the things that we've started to observe as we're starting to implement some of these sub ancient things is some of the really, really hard problems when it comes to microservices, you mentioned a few fault tolerance, you name it like they could be very finicky, and it wouldn't be uncommon at all as a board organization, they're like, Oh man, we have such a hard time knowing what microservices to do. What happens if there's a ripple effect where, you know, we don't have this web of all these different dependencies? How do we make sure things go many of those same principles hold true. But I think the part to me that gets exciting is with an LLM, kind of at the core, orchestrating and raising around some of these things. It actually does a really good job of, like, taking care of some of the marginal work automatically for you, meaning that, like, there can be a blip in the system, or there might be some, you know, whatever common woe in microservice land is what happens when my upstream microservice or downstream microservice makes a change. And how do you make sure that doesn't break everything else that can still be a concern when you have a sub agent, but some of the agents who actually find it on their own, like the big, oh, it looks like something here changed. I'm actually going to adjust. I'm going to interact with this other system or do whatever else. So many of the same things hold true. I think where I get optimistic, though, is the ability for us to scale these things and scale them really quickly becomes easier in some ways, because you have this regioning agent that can deal with more ambiguity than the previous world of Intel statements that are very, very finicky To any change of variable. Oh, yeah. Self reflective,
S Speaker 729:42yeah. Think on the modeling side, it's already becoming pretty clear, right? You had the narrow base with microservices,
yeah. Think on the modeling side, it's already becoming pretty clear, right? You had the narrow base with microservices,
yeah. Think on the modeling side, it's already becoming pretty clear, right? You had the narrow base with microservices,
yeah. Think on the modeling side, it's already becoming pretty clear, right? You had the narrow base with microservices,
29:50like you mentioned,
S Speaker 729:53and now the equivalent of that on the LLM side is you have very clear so you're going to have very clear interfaces where the LLM itself is about to do multiple things, use multimodal information, do custom compute as much as you need. But then, as long as you guarantee that here's a scenario based and a promise of how you interact with different migrators, interact with each other, or interact with one orchestrator, I think as long as we control this narrow based, and right now, function seems to be the
and now the equivalent of that on the LLM side is you have very clear so you're going to have very clear interfaces where the LLM itself is about to do multiple things, use multimodal information, do custom compute as much as you need. But then, as long as you guarantee that here's a scenario based and a promise of how you interact with different migrators, interact with each other, or interact with one orchestrator, I think as long as we control this narrow based, and right now, function seems to be the
and now the equivalent of that on the LLM side is you have very clear so you're going to have very clear interfaces where the LLM itself is about to do multiple things, use multimodal information, do custom compute as much as you need. But then, as long as you guarantee that here's a scenario based and a promise of how you interact with different migrators, interact with each other, or interact with one orchestrator, I think as long as we control this narrow based, and right now, function seems to be the
and now the equivalent of that on the LLM side is you have very clear so you're going to have very clear interfaces where the LLM itself is about to do multiple things, use multimodal information, do custom compute as much as you need. But then, as long as you guarantee that here's a scenario based and a promise of how you interact with different migrators, interact with each other, or interact with one orchestrator, I think as long as we control this narrow based, and right now, function seems to be the
S Speaker 230:27way. I think, you know, the full tolerance I role, yeah, I believe that models are increasingly resilient, and teaching those subsystems models to kind of learn to operate when you know some probably okay. So next question
way. I think, you know, the full tolerance I role, yeah, I believe that models are increasingly resilient, and teaching those subsystems models to kind of learn to operate when you know some probably okay. So next question
way. I think, you know, the full tolerance I role, yeah, I believe that models are increasingly resilient, and teaching those subsystems models to kind of learn to operate when you know some probably okay. So next question
way. I think, you know, the full tolerance I role, yeah, I believe that models are increasingly resilient, and teaching those subsystems models to kind of learn to operate when you know some probably okay. So next question
S Speaker 830:48in person, it was Alexa Carver from Ai human architect INFJ. And I also run an open source science initiative in focus, which connects scientists with open source developers and for scientists, as you know. And for engineers, reproducibility is top of mind, right? So we used to have reproducibility. You write tests, your data sets are fixed, right? You usually get the same result. And with models, the key difference is they're constantly evolving, right? And so you can put the walls on them, but they also can say the things are different, right? And you can suddenly stop answering, suddenly out of the blue, hallucinate. So how do we institute reproducibility? For instance, at meta scale, how do you snapshot your data? How can you snapshot meta data, right? Not better than meta data at scale. How do you like do timestamps? Do you timestamp agents? Is everything in every time stand. How do you guys approach this and proposed? How do you approach this? What if agents give you different results, right? And just wonder, what's your push to reproducibility? As an
in person, it was Alexa Carver from Ai human architect INFJ. And I also run an open source science initiative in focus, which connects scientists with open source developers and for scientists, as you know. And for engineers, reproducibility is top of mind, right? So we used to have reproducibility. You write tests, your data sets are fixed, right? You usually get the same result. And with models, the key difference is they're constantly evolving, right? And so you can put the walls on them, but they also can say the things are different, right? And you can suddenly stop answering, suddenly out of the blue, hallucinate. So how do we institute reproducibility? For instance, at meta scale, how do you snapshot your data? How can you snapshot meta data, right? Not better than meta data at scale. How do you like do timestamps? Do you timestamp agents? Is everything in every time stand. How do you guys approach this and proposed? How do you approach this? What if agents give you different results, right? And just wonder, what's your push to reproducibility? As an
in person, it was Alexa Carver from Ai human architect INFJ. And I also run an open source science initiative in focus, which connects scientists with open source developers and for scientists, as you know. And for engineers, reproducibility is top of mind, right? So we used to have reproducibility. You write tests, your data sets are fixed, right? You usually get the same result. And with models, the key difference is they're constantly evolving, right? And so you can put the walls on them, but they also can say the things are different, right? And you can suddenly stop answering, suddenly out of the blue, hallucinate. So how do we institute reproducibility? For instance, at meta scale, how do you snapshot your data? How can you snapshot meta data, right? Not better than meta data at scale. How do you like do timestamps? Do you timestamp agents? Is everything in every time stand. How do you guys approach this and proposed? How do you approach this? What if agents give you different results, right? And just wonder, what's your push to reproducibility? As an
in person, it was Alexa Carver from Ai human architect INFJ. And I also run an open source science initiative in focus, which connects scientists with open source developers and for scientists, as you know. And for engineers, reproducibility is top of mind, right? So we used to have reproducibility. You write tests, your data sets are fixed, right? You usually get the same result. And with models, the key difference is they're constantly evolving, right? And so you can put the walls on them, but they also can say the things are different, right? And you can suddenly stop answering, suddenly out of the blue, hallucinate. So how do we institute reproducibility? For instance, at meta scale, how do you snapshot your data? How can you snapshot meta data, right? Not better than meta data at scale. How do you like do timestamps? Do you timestamp agents? Is everything in every time stand. How do you guys approach this and proposed? How do you approach this? What if agents give you different results, right? And just wonder, what's your push to reproducibility? As an
31:55engineer, I invite you here to start.
engineer, I invite you here to start.
engineer, I invite you here to start.
engineer, I invite you here to start.
S Speaker 731:58Yeah. So there's a very good question, right? And the way we think about this is, you can choose to have reproducibility at the very core model level, which could be at the tokens level, but understanding that it's not but you can go pretty far with it, honestly, as long as you have very good control of your underlying system interrupt by saying the right topic, and so on and so forth. But the other way to also think about this is, can you expect and run your evals as I expect, reproducibility at a specification level, right? If you can have very clear specifications that, okay, well, in a rather than this is the document that I want the LLM to take, and this exact sentence I want to come out with to say, well, here is my namespace that I expect the other to touch for a given query, and then this is, I expect these substrings to perhaps exist. I'm going to detail here, but just to illustrate the point, so if you can have specifications, then you get really good reproducibility, and then you can swap in and out the underlying algorithm. You don't have to worry too much as people might opt using different techniques. So there is, there is ways where you can do that, right? It's pretty open, but I think we are, as a community, we are now trying to understand what's the right level.
Yeah. So there's a very good question, right? And the way we think about this is, you can choose to have reproducibility at the very core model level, which could be at the tokens level, but understanding that it's not but you can go pretty far with it, honestly, as long as you have very good control of your underlying system interrupt by saying the right topic, and so on and so forth. But the other way to also think about this is, can you expect and run your evals as I expect, reproducibility at a specification level, right? If you can have very clear specifications that, okay, well, in a rather than this is the document that I want the LLM to take, and this exact sentence I want to come out with to say, well, here is my namespace that I expect the other to touch for a given query, and then this is, I expect these substrings to perhaps exist. I'm going to detail here, but just to illustrate the point, so if you can have specifications, then you get really good reproducibility, and then you can swap in and out the underlying algorithm. You don't have to worry too much as people might opt using different techniques. So there is, there is ways where you can do that, right? It's pretty open, but I think we are, as a community, we are now trying to understand what's the right level.
Yeah. So there's a very good question, right? And the way we think about this is, you can choose to have reproducibility at the very core model level, which could be at the tokens level, but understanding that it's not but you can go pretty far with it, honestly, as long as you have very good control of your underlying system interrupt by saying the right topic, and so on and so forth. But the other way to also think about this is, can you expect and run your evals as I expect, reproducibility at a specification level, right? If you can have very clear specifications that, okay, well, in a rather than this is the document that I want the LLM to take, and this exact sentence I want to come out with to say, well, here is my namespace that I expect the other to touch for a given query, and then this is, I expect these substrings to perhaps exist. I'm going to detail here, but just to illustrate the point, so if you can have specifications, then you get really good reproducibility, and then you can swap in and out the underlying algorithm. You don't have to worry too much as people might opt using different techniques. So there is, there is ways where you can do that, right? It's pretty open, but I think we are, as a community, we are now trying to understand what's the right level.
Yeah. So there's a very good question, right? And the way we think about this is, you can choose to have reproducibility at the very core model level, which could be at the tokens level, but understanding that it's not but you can go pretty far with it, honestly, as long as you have very good control of your underlying system interrupt by saying the right topic, and so on and so forth. But the other way to also think about this is, can you expect and run your evals as I expect, reproducibility at a specification level, right? If you can have very clear specifications that, okay, well, in a rather than this is the document that I want the LLM to take, and this exact sentence I want to come out with to say, well, here is my namespace that I expect the other to touch for a given query, and then this is, I expect these substrings to perhaps exist. I'm going to detail here, but just to illustrate the point, so if you can have specifications, then you get really good reproducibility, and then you can swap in and out the underlying algorithm. You don't have to worry too much as people might opt using different techniques. So there is, there is ways where you can do that, right? It's pretty open, but I think we are, as a community, we are now trying to understand what's the right level.
S Speaker 934:41Next I mentioned that's speaking today, my question is about defining the responsibilities of sub agents. And Jeff had a really good example of a query comes in. You want to make sure it's unambiguous enough. And if it is, is it a time series? Is it dot, dot, dot. When we think about how much work should be done in that one inference, how do you think about let's go ahead and bundle it versus split it out. Is it just kind of or is there more science? I'll
Next I mentioned that's speaking today, my question is about defining the responsibilities of sub agents. And Jeff had a really good example of a query comes in. You want to make sure it's unambiguous enough. And if it is, is it a time series? Is it dot, dot, dot. When we think about how much work should be done in that one inference, how do you think about let's go ahead and bundle it versus split it out. Is it just kind of or is there more science? I'll
Next I mentioned that's speaking today, my question is about defining the responsibilities of sub agents. And Jeff had a really good example of a query comes in. You want to make sure it's unambiguous enough. And if it is, is it a time series? Is it dot, dot, dot. When we think about how much work should be done in that one inference, how do you think about let's go ahead and bundle it versus split it out. Is it just kind of or is there more science? I'll
Next I mentioned that's speaking today, my question is about defining the responsibilities of sub agents. And Jeff had a really good example of a query comes in. You want to make sure it's unambiguous enough. And if it is, is it a time series? Is it dot, dot, dot. When we think about how much work should be done in that one inference, how do you think about let's go ahead and bundle it versus split it out. Is it just kind of or is there more science? I'll
S Speaker 536:26could not agree more. I just, this is not an addition. It's just, it's just out of my experience, you'd be surprised how many people treat their evals very superficially. Just think it's the word of God, and they don't really understand what's inside of it. You really need to understand your evals inside out, you need to understand what they stand for, and then finally, don't trust them, you know, indefinitely, because they get saturated, and they often become they lack representation with customer use cases. So the more you understand your evals, the more your team is looking at debugging these evals, the more they realize that evals themselves have issues, the better they are from here.
could not agree more. I just, this is not an addition. It's just, it's just out of my experience, you'd be surprised how many people treat their evals very superficially. Just think it's the word of God, and they don't really understand what's inside of it. You really need to understand your evals inside out, you need to understand what they stand for, and then finally, don't trust them, you know, indefinitely, because they get saturated, and they often become they lack representation with customer use cases. So the more you understand your evals, the more your team is looking at debugging these evals, the more they realize that evals themselves have issues, the better they are from here.
could not agree more. I just, this is not an addition. It's just, it's just out of my experience, you'd be surprised how many people treat their evals very superficially. Just think it's the word of God, and they don't really understand what's inside of it. You really need to understand your evals inside out, you need to understand what they stand for, and then finally, don't trust them, you know, indefinitely, because they get saturated, and they often become they lack representation with customer use cases. So the more you understand your evals, the more your team is looking at debugging these evals, the more they realize that evals themselves have issues, the better they are from here.
could not agree more. I just, this is not an addition. It's just, it's just out of my experience, you'd be surprised how many people treat their evals very superficially. Just think it's the word of God, and they don't really understand what's inside of it. You really need to understand your evals inside out, you need to understand what they stand for, and then finally, don't trust them, you know, indefinitely, because they get saturated, and they often become they lack representation with customer use cases. So the more you understand your evals, the more your team is looking at debugging these evals, the more they realize that evals themselves have issues, the better they are from here.
37:10Can you have a next in person
Can you have a next in person
Can you have a next in person
Can you have a next in person
S Speaker 1037:13question? Good afternoon, and thank you for the very inspiring and insightful morning of docs. This is laminus from Stanford University. And my question today is about eval and reliability without this warning about how Asians need to be reliable in order to be able to integrate with the workforce. And obviously this is for the technology data companies. My question about the non native technology companies what needs to be true in order to be able to integrate Asians into the workforce. And some of the ideas that comes to mind is online, maybe privacy, but I'm thinking about health care, thinking about banking, I'm thinking about offline. Yes, even the question is, what needs to be true for Asians to be able to be integrated into this kind of workforce? Thank you. Applause. Thank
question? Good afternoon, and thank you for the very inspiring and insightful morning of docs. This is laminus from Stanford University. And my question today is about eval and reliability without this warning about how Asians need to be reliable in order to be able to integrate with the workforce. And obviously this is for the technology data companies. My question about the non native technology companies what needs to be true in order to be able to integrate Asians into the workforce. And some of the ideas that comes to mind is online, maybe privacy, but I'm thinking about health care, thinking about banking, I'm thinking about offline. Yes, even the question is, what needs to be true for Asians to be able to be integrated into this kind of workforce? Thank you. Applause. Thank
question? Good afternoon, and thank you for the very inspiring and insightful morning of docs. This is laminus from Stanford University. And my question today is about eval and reliability without this warning about how Asians need to be reliable in order to be able to integrate with the workforce. And obviously this is for the technology data companies. My question about the non native technology companies what needs to be true in order to be able to integrate Asians into the workforce. And some of the ideas that comes to mind is online, maybe privacy, but I'm thinking about health care, thinking about banking, I'm thinking about offline. Yes, even the question is, what needs to be true for Asians to be able to be integrated into this kind of workforce? Thank you. Applause. Thank
question? Good afternoon, and thank you for the very inspiring and insightful morning of docs. This is laminus from Stanford University. And my question today is about eval and reliability without this warning about how Asians need to be reliable in order to be able to integrate with the workforce. And obviously this is for the technology data companies. My question about the non native technology companies what needs to be true in order to be able to integrate Asians into the workforce. And some of the ideas that comes to mind is online, maybe privacy, but I'm thinking about health care, thinking about banking, I'm thinking about offline. Yes, even the question is, what needs to be true for Asians to be able to be integrated into this kind of workforce? Thank you. Applause. Thank
S Speaker 739:47So there is maybe, like, two things that you can do, right? You start, we already see some of these things. The first is, can we build these services? Keeping this in mind. Common example is Kubernetes. If you go to Kubernetes, there's something called a dry run option. So you can, like, try to fake out the option, see what the potential end result is, and then you can choose whether on it or not. So giving this more for agentic systems, where you can try to dry run things is one is one way to do it. The second is to have very unique session identifiers, right? So you basically tell the agent, hey, do something. Otherwise, give me, give me an undo button, right? Just give me a clean slate. Erase everything that you tried and do not live in a whole messy estate. So in terms of transactions, this is the commit, was the support, right? So can you give, can people who are building all these different services or applications that they then want to interface with agents, can then now start enabling the scenario where you can the agent itself has an ability to either completely accept or completely reject and go to a slave. So I think, yeah, there's some, there's some ways in which, obviously, early adopters, hyperscalers, are super early in adopting this. And then, you know, of course, healthcare and banking, they haven't there yet, but there's been a scary stream of techniques to enable
So there is maybe, like, two things that you can do, right? You start, we already see some of these things. The first is, can we build these services? Keeping this in mind. Common example is Kubernetes. If you go to Kubernetes, there's something called a dry run option. So you can, like, try to fake out the option, see what the potential end result is, and then you can choose whether on it or not. So giving this more for agentic systems, where you can try to dry run things is one is one way to do it. The second is to have very unique session identifiers, right? So you basically tell the agent, hey, do something. Otherwise, give me, give me an undo button, right? Just give me a clean slate. Erase everything that you tried and do not live in a whole messy estate. So in terms of transactions, this is the commit, was the support, right? So can you give, can people who are building all these different services or applications that they then want to interface with agents, can then now start enabling the scenario where you can the agent itself has an ability to either completely accept or completely reject and go to a slave. So I think, yeah, there's some, there's some ways in which, obviously, early adopters, hyperscalers, are super early in adopting this. And then, you know, of course, healthcare and banking, they haven't there yet, but there's been a scary stream of techniques to enable
So there is maybe, like, two things that you can do, right? You start, we already see some of these things. The first is, can we build these services? Keeping this in mind. Common example is Kubernetes. If you go to Kubernetes, there's something called a dry run option. So you can, like, try to fake out the option, see what the potential end result is, and then you can choose whether on it or not. So giving this more for agentic systems, where you can try to dry run things is one is one way to do it. The second is to have very unique session identifiers, right? So you basically tell the agent, hey, do something. Otherwise, give me, give me an undo button, right? Just give me a clean slate. Erase everything that you tried and do not live in a whole messy estate. So in terms of transactions, this is the commit, was the support, right? So can you give, can people who are building all these different services or applications that they then want to interface with agents, can then now start enabling the scenario where you can the agent itself has an ability to either completely accept or completely reject and go to a slave. So I think, yeah, there's some, there's some ways in which, obviously, early adopters, hyperscalers, are super early in adopting this. And then, you know, of course, healthcare and banking, they haven't there yet, but there's been a scary stream of techniques to enable
So there is maybe, like, two things that you can do, right? You start, we already see some of these things. The first is, can we build these services? Keeping this in mind. Common example is Kubernetes. If you go to Kubernetes, there's something called a dry run option. So you can, like, try to fake out the option, see what the potential end result is, and then you can choose whether on it or not. So giving this more for agentic systems, where you can try to dry run things is one is one way to do it. The second is to have very unique session identifiers, right? So you basically tell the agent, hey, do something. Otherwise, give me, give me an undo button, right? Just give me a clean slate. Erase everything that you tried and do not live in a whole messy estate. So in terms of transactions, this is the commit, was the support, right? So can you give, can people who are building all these different services or applications that they then want to interface with agents, can then now start enabling the scenario where you can the agent itself has an ability to either completely accept or completely reject and go to a slave. So I think, yeah, there's some, there's some ways in which, obviously, early adopters, hyperscalers, are super early in adopting this. And then, you know, of course, healthcare and banking, they haven't there yet, but there's been a scary stream of techniques to enable
S Speaker 241:07very nice I fully agree that the psychological component is really fundamental here. But I think, you know, the trust really starts building on technology, and people need to trust the technology. And thinking of the aerospace industry, where you have, you know, very strict compliance, redundancy and so forth, understanding that, you know, some of it may be more psychological than practical in the context of AI, but we look at the AV space, where today there is no, I don't think there's a piece of enforced certification on the reliability of the calculators use behind it. But there's some
very nice I fully agree that the psychological component is really fundamental here. But I think, you know, the trust really starts building on technology, and people need to trust the technology. And thinking of the aerospace industry, where you have, you know, very strict compliance, redundancy and so forth, understanding that, you know, some of it may be more psychological than practical in the context of AI, but we look at the AV space, where today there is no, I don't think there's a piece of enforced certification on the reliability of the calculators use behind it. But there's some
very nice I fully agree that the psychological component is really fundamental here. But I think, you know, the trust really starts building on technology, and people need to trust the technology. And thinking of the aerospace industry, where you have, you know, very strict compliance, redundancy and so forth, understanding that, you know, some of it may be more psychological than practical in the context of AI, but we look at the AV space, where today there is no, I don't think there's a piece of enforced certification on the reliability of the calculators use behind it. But there's some
very nice I fully agree that the psychological component is really fundamental here. But I think, you know, the trust really starts building on technology, and people need to trust the technology. And thinking of the aerospace industry, where you have, you know, very strict compliance, redundancy and so forth, understanding that, you know, some of it may be more psychological than practical in the context of AI, but we look at the AV space, where today there is no, I don't think there's a piece of enforced certification on the reliability of the calculators use behind it. But there's some
41:44companies, you know, also volunteering,
companies, you know, also volunteering,
companies, you know, also volunteering,
companies, you know, also volunteering,
S Speaker 241:46you know, safety standards, you know, making sure that you don't get the Nan. You know, more often than you can, and if you do, you can, you can recover. So totally agree with the fact that at the end of the day, it's, it's trust, right? Psychology, I think you know, providing insurance actions is that the technology works or works well enough can happen.
you know, safety standards, you know, making sure that you don't get the Nan. You know, more often than you can, and if you do, you can, you can recover. So totally agree with the fact that at the end of the day, it's, it's trust, right? Psychology, I think you know, providing insurance actions is that the technology works or works well enough can happen.
you know, safety standards, you know, making sure that you don't get the Nan. You know, more often than you can, and if you do, you can, you can recover. So totally agree with the fact that at the end of the day, it's, it's trust, right? Psychology, I think you know, providing insurance actions is that the technology works or works well enough can happen.
you know, safety standards, you know, making sure that you don't get the Nan. You know, more often than you can, and if you do, you can, you can recover. So totally agree with the fact that at the end of the day, it's, it's trust, right? Psychology, I think you know, providing insurance actions is that the technology works or works well enough can happen.
S Speaker 542:12These are definitely great answers. I think what enterprise users definitely want to build trust is signals and science that the answer is accurate and also explainable. And I've met with various startup founders who are working in this field, particularly with financial services, and they mentioned that citing resources is an extremely important aspect of answers. So I think there's a big experience aspect of how you present an answer to those users that would actually either accelerate or de accelerate the document.
These are definitely great answers. I think what enterprise users definitely want to build trust is signals and science that the answer is accurate and also explainable. And I've met with various startup founders who are working in this field, particularly with financial services, and they mentioned that citing resources is an extremely important aspect of answers. So I think there's a big experience aspect of how you present an answer to those users that would actually either accelerate or de accelerate the document.
These are definitely great answers. I think what enterprise users definitely want to build trust is signals and science that the answer is accurate and also explainable. And I've met with various startup founders who are working in this field, particularly with financial services, and they mentioned that citing resources is an extremely important aspect of answers. So I think there's a big experience aspect of how you present an answer to those users that would actually either accelerate or de accelerate the document.
These are definitely great answers. I think what enterprise users definitely want to build trust is signals and science that the answer is accurate and also explainable. And I've met with various startup founders who are working in this field, particularly with financial services, and they mentioned that citing resources is an extremely important aspect of answers. So I think there's a big experience aspect of how you present an answer to those users that would actually either accelerate or de accelerate the document.
S Speaker 442:51See, we still have people, but we're also very close to the time. So I'm going to ask, like, one final question, and this one is for all of you. And the
See, we still have people, but we're also very close to the time. So I'm going to ask, like, one final question, and this one is for all of you. And the
See, we still have people, but we're also very close to the time. So I'm going to ask, like, one final question, and this one is for all of you. And the
See, we still have people, but we're also very close to the time. So I'm going to ask, like, one final question, and this one is for all of you. And the
42:58question is, what gets you most excited about the next year of
question is, what gets you most excited about the next year of
question is, what gets you most excited about the next year of
question is, what gets you most excited about the next year of
43:06AI robotics. Can't wait for something to fold my laundry.
AI robotics. Can't wait for something to fold my laundry.
AI robotics. Can't wait for something to fold my laundry.
AI robotics. Can't wait for something to fold my laundry.
43:17I love the agents.
S Speaker 744:07I think what I find particularly interesting is just how accessible, right? So there's no one, one winner of an agent, since we don't get accessible open sources. So
I think what I find particularly interesting is just how accessible, right? So there's no one, one winner of an agent, since we don't get accessible open sources. So
I think what I find particularly interesting is just how accessible, right? So there's no one, one winner of an agent, since we don't get accessible open sources. So
I think what I find particularly interesting is just how accessible, right? So there's no one, one winner of an agent, since we don't get accessible open sources. So
44:21just seeing so many new things show up
just seeing so many new things show up
just seeing so many new things show up
just seeing so many new things show up
S Speaker 244:27one year, that's an easier question than Pfizer. So I, you know, what I probably most excited about is autonomous vehicle. I think it's real. I mean, after years and years of promises, I think it's we're seeing it happening now, and I find that extremely exciting, because it really is changing lives in very concrete ways. So yeah, I'm excited to see that happening with my eyes.
one year, that's an easier question than Pfizer. So I, you know, what I probably most excited about is autonomous vehicle. I think it's real. I mean, after years and years of promises, I think it's we're seeing it happening now, and I find that extremely exciting, because it really is changing lives in very concrete ways. So yeah, I'm excited to see that happening with my eyes.
one year, that's an easier question than Pfizer. So I, you know, what I probably most excited about is autonomous vehicle. I think it's real. I mean, after years and years of promises, I think it's we're seeing it happening now, and I find that extremely exciting, because it really is changing lives in very concrete ways. So yeah, I'm excited to see that happening with my eyes.
one year, that's an easier question than Pfizer. So I, you know, what I probably most excited about is autonomous vehicle. I think it's real. I mean, after years and years of promises, I think it's we're seeing it happening now, and I find that extremely exciting, because it really is changing lives in very concrete ways. So yeah, I'm excited to see that happening with my eyes.
S Speaker 444:49Thank you. Well, let's thank our speakers. We got it
Thank you. Well, let's thank our speakers. We got it
Thank you. Well, let's thank our speakers. We got it
Thank you. Well, let's thank our speakers. We got it
S Speaker 444:58right. We're closing this part of the program. We have a lunch, and then we come back for a startup panel. dynamic, discuss forums and policies
right. We're closing this part of the program. We have a lunch, and then we come back for a startup panel. dynamic, discuss forums and policies
right. We're closing this part of the program. We have a lunch, and then we come back for a startup panel. dynamic, discuss forums and policies
right. We're closing this part of the program. We have a lunch, and then we come back for a startup panel. dynamic, discuss forums and policies
S Speaker 345:11at scale, AI, and data will resume after this break. Please proceed, outside to the lobby area for lunch.
at scale, AI, and data will resume after this break. Please proceed, outside to the lobby area for lunch.
at scale, AI, and data will resume after this break. Please proceed, outside to the lobby area for lunch.
at scale, AI, and data will resume after this break. Please proceed, outside to the lobby area for lunch.