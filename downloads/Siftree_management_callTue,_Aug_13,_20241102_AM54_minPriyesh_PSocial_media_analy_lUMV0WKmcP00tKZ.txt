Meeting: Siftree management call
Tue, Aug 13, 2024
11:02 AM
54 min
Priyesh P
Social media analytics and the e
URL: https://otter.ai/u/lUMV0WKmcP00tKZtvyCOjYVqQlw
Downloaded: 2025-12-22T14:53:24.996595
Method: text_extraction
============================================================

S Speaker 10:06think we have a quorum. Albert is also joining so so we can get started. So Thanks Kyle and Aaron for doing this. We discussed about 73 in our partners meeting, and had enough excitement to learn more. And so we have Quinn, who's based in San Diego. He runs Qualcomm ventures. Carlos runs ventures for Americas, and Albert and Nan budgets met. They're also in the US team and priyesh,
think we have a quorum. Albert is also joining so so we can get started. So Thanks Kyle and Aaron for doing this. We discussed about 73 in our partners meeting, and had enough excitement to learn more. And so we have Quinn, who's based in San Diego. He runs Qualcomm ventures. Carlos runs ventures for Americas, and Albert and Nan budgets met. They're also in the US team and priyesh,
think we have a quorum. Albert is also joining so so we can get started. So Thanks Kyle and Aaron for doing this. We discussed about 73 in our partners meeting, and had enough excitement to learn more. And so we have Quinn, who's based in San Diego. He runs Qualcomm ventures. Carlos runs ventures for Americas, and Albert and Nan budgets met. They're also in the US team and priyesh,
think we have a quorum. Albert is also joining so so we can get started. So Thanks Kyle and Aaron for doing this. We discussed about 73 in our partners meeting, and had enough excitement to learn more. And so we have Quinn, who's based in San Diego. He runs Qualcomm ventures. Carlos runs ventures for Americas, and Albert and Nan budgets met. They're also in the US team and priyesh,
S Speaker 10:51for our team, Kyle and Aaron are the two co founders of SIFT tree that was based in Chicago. They were introduced by Rohan, who knows them well in Chicago, from quillbot,
for our team, Kyle and Aaron are the two co founders of SIFT tree that was based in Chicago. They were introduced by Rohan, who knows them well in Chicago, from quillbot,
for our team, Kyle and Aaron are the two co founders of SIFT tree that was based in Chicago. They were introduced by Rohan, who knows them well in Chicago, from quillbot,
for our team, Kyle and Aaron are the two co founders of SIFT tree that was based in Chicago. They were introduced by Rohan, who knows them well in Chicago, from quillbot,
S Speaker 21:11Yeah, definitely. We can just do real quick intro so you guys can get to know us a little bit more. So yeah, my name is Kyle. I'm one of the co founders. Originally started off in the data science space. So right out of school, I was one of three people chosen for Comcast corporate rotation program, so basically bounced in between Atlanta and HQ in Philly. Worked specifically on the Comcast business side, mostly doing like rev ops analysis and optimization processes with their data science team. After that came up back to the Midwest, originally from the Detroit area, so a lot of my families around the space, but really got interested in product and went to a software company called CCC. They're in the property and casualty insurance space. So I led their analytics products team there. I worked with a lot of people in the automotive industry, like Ford, rivian, BMW, etc, designed a lot of their architecture around the analytics products there, and also designed some of the solutions that they had within their insurance and supply distribution chain, etc. But yeah, actually, Rohan was the one that introduced me to Aaron, and that's how we all got connected here. So Aaron, do you want quick background on yourself? Hey,
Yeah, definitely. We can just do real quick intro so you guys can get to know us a little bit more. So yeah, my name is Kyle. I'm one of the co founders. Originally started off in the data science space. So right out of school, I was one of three people chosen for Comcast corporate rotation program, so basically bounced in between Atlanta and HQ in Philly. Worked specifically on the Comcast business side, mostly doing like rev ops analysis and optimization processes with their data science team. After that came up back to the Midwest, originally from the Detroit area, so a lot of my families around the space, but really got interested in product and went to a software company called CCC. They're in the property and casualty insurance space. So I led their analytics products team there. I worked with a lot of people in the automotive industry, like Ford, rivian, BMW, etc, designed a lot of their architecture around the analytics products there, and also designed some of the solutions that they had within their insurance and supply distribution chain, etc. But yeah, actually, Rohan was the one that introduced me to Aaron, and that's how we all got connected here. So Aaron, do you want quick background on yourself? Hey,
Yeah, definitely. We can just do real quick intro so you guys can get to know us a little bit more. So yeah, my name is Kyle. I'm one of the co founders. Originally started off in the data science space. So right out of school, I was one of three people chosen for Comcast corporate rotation program, so basically bounced in between Atlanta and HQ in Philly. Worked specifically on the Comcast business side, mostly doing like rev ops analysis and optimization processes with their data science team. After that came up back to the Midwest, originally from the Detroit area, so a lot of my families around the space, but really got interested in product and went to a software company called CCC. They're in the property and casualty insurance space. So I led their analytics products team there. I worked with a lot of people in the automotive industry, like Ford, rivian, BMW, etc, designed a lot of their architecture around the analytics products there, and also designed some of the solutions that they had within their insurance and supply distribution chain, etc. But yeah, actually, Rohan was the one that introduced me to Aaron, and that's how we all got connected here. So Aaron, do you want quick background on yourself? Hey,
Yeah, definitely. We can just do real quick intro so you guys can get to know us a little bit more. So yeah, my name is Kyle. I'm one of the co founders. Originally started off in the data science space. So right out of school, I was one of three people chosen for Comcast corporate rotation program, so basically bounced in between Atlanta and HQ in Philly. Worked specifically on the Comcast business side, mostly doing like rev ops analysis and optimization processes with their data science team. After that came up back to the Midwest, originally from the Detroit area, so a lot of my families around the space, but really got interested in product and went to a software company called CCC. They're in the property and casualty insurance space. So I led their analytics products team there. I worked with a lot of people in the automotive industry, like Ford, rivian, BMW, etc, designed a lot of their architecture around the analytics products there, and also designed some of the solutions that they had within their insurance and supply distribution chain, etc. But yeah, actually, Rohan was the one that introduced me to Aaron, and that's how we all got connected here. So Aaron, do you want quick background on yourself? Hey,
S Speaker 32:32My name is Aaron. My background is computer science. I was previously at an E commerce startup where we're building a proprietary and then E commerce. E commerce system. I was the head of technology there. That was a lot of fun. Built a lot of technology, lots of different user applications. So I got a taste for you software development through that I've been working on kind of as, like a hobby, and what's now become a fashion, social media analytics, just, you know, being able to answer the question, like, what's going on? What are people talking about? What's happening online for a long time, for like, six to eight years, started officially with Kyle turning that into a business. And then, you know, we did a soft launch in February. And, yeah, this is kind of my dream, is what I want to be doing
My name is Aaron. My background is computer science. I was previously at an E commerce startup where we're building a proprietary and then E commerce. E commerce system. I was the head of technology there. That was a lot of fun. Built a lot of technology, lots of different user applications. So I got a taste for you software development through that I've been working on kind of as, like a hobby, and what's now become a fashion, social media analytics, just, you know, being able to answer the question, like, what's going on? What are people talking about? What's happening online for a long time, for like, six to eight years, started officially with Kyle turning that into a business. And then, you know, we did a soft launch in February. And, yeah, this is kind of my dream, is what I want to be doing
My name is Aaron. My background is computer science. I was previously at an E commerce startup where we're building a proprietary and then E commerce. E commerce system. I was the head of technology there. That was a lot of fun. Built a lot of technology, lots of different user applications. So I got a taste for you software development through that I've been working on kind of as, like a hobby, and what's now become a fashion, social media analytics, just, you know, being able to answer the question, like, what's going on? What are people talking about? What's happening online for a long time, for like, six to eight years, started officially with Kyle turning that into a business. And then, you know, we did a soft launch in February. And, yeah, this is kind of my dream, is what I want to be doing
My name is Aaron. My background is computer science. I was previously at an E commerce startup where we're building a proprietary and then E commerce. E commerce system. I was the head of technology there. That was a lot of fun. Built a lot of technology, lots of different user applications. So I got a taste for you software development through that I've been working on kind of as, like a hobby, and what's now become a fashion, social media analytics, just, you know, being able to answer the question, like, what's going on? What are people talking about? What's happening online for a long time, for like, six to eight years, started officially with Kyle turning that into a business. And then, you know, we did a soft launch in February. And, yeah, this is kind of my dream, is what I want to be doing
S Speaker 43:20now. How you guys meet through, you say Rohan and
S Speaker 47:22can you give, give me a, maybe, a specific example of the, you know, I was just trying to figure out these, like, social media postings from restaurants, or is it from companies? No, we're talking about hotels, like, yeah, it's
can you give, give me a, maybe, a specific example of the, you know, I was just trying to figure out these, like, social media postings from restaurants, or is it from companies? No, we're talking about hotels, like, yeah, it's
can you give, give me a, maybe, a specific example of the, you know, I was just trying to figure out these, like, social media postings from restaurants, or is it from companies? No, we're talking about hotels, like, yeah, it's
can you give, give me a, maybe, a specific example of the, you know, I was just trying to figure out these, like, social media postings from restaurants, or is it from companies? No, we're talking about hotels, like, yeah, it's
S Speaker 47:59And these are, these are social media posts, both first party, meaning first
And these are, these are social media posts, both first party, meaning first
And these are, these are social media posts, both first party, meaning first
And these are, these are social media posts, both first party, meaning first
S Speaker 28:07party, meaning the platform is like obligated to give you your data, like, meaning like, it's my posts my comments, and it's not another accounts post in their comments. Yeah. So just for example, I've actually pulled up tick tock. We're looking at Duolingo account right here is the number. You can see my cursor muncher, yeah, that's the number of comments here, yeah. So on one post, there's 192,000 comments. Oh, my God. And right now, Duolingo has a team that is reading through this and trying to understand what's happening. And if we go to just this first post, we see there's 86 replies. If we keep scrolling down, we see there's essentially worlds within worlds that are created. And what we're trying to do is understand and synthesize, like an opinion or a conclusion based on everything that's happening. And that's really hard for them to do.
party, meaning the platform is like obligated to give you your data, like, meaning like, it's my posts my comments, and it's not another accounts post in their comments. Yeah. So just for example, I've actually pulled up tick tock. We're looking at Duolingo account right here is the number. You can see my cursor muncher, yeah, that's the number of comments here, yeah. So on one post, there's 192,000 comments. Oh, my God. And right now, Duolingo has a team that is reading through this and trying to understand what's happening. And if we go to just this first post, we see there's 86 replies. If we keep scrolling down, we see there's essentially worlds within worlds that are created. And what we're trying to do is understand and synthesize, like an opinion or a conclusion based on everything that's happening. And that's really hard for them to do.
party, meaning the platform is like obligated to give you your data, like, meaning like, it's my posts my comments, and it's not another accounts post in their comments. Yeah. So just for example, I've actually pulled up tick tock. We're looking at Duolingo account right here is the number. You can see my cursor muncher, yeah, that's the number of comments here, yeah. So on one post, there's 192,000 comments. Oh, my God. And right now, Duolingo has a team that is reading through this and trying to understand what's happening. And if we go to just this first post, we see there's 86 replies. If we keep scrolling down, we see there's essentially worlds within worlds that are created. And what we're trying to do is understand and synthesize, like an opinion or a conclusion based on everything that's happening. And that's really hard for them to do.
party, meaning the platform is like obligated to give you your data, like, meaning like, it's my posts my comments, and it's not another accounts post in their comments. Yeah. So just for example, I've actually pulled up tick tock. We're looking at Duolingo account right here is the number. You can see my cursor muncher, yeah, that's the number of comments here, yeah. So on one post, there's 192,000 comments. Oh, my God. And right now, Duolingo has a team that is reading through this and trying to understand what's happening. And if we go to just this first post, we see there's 86 replies. If we keep scrolling down, we see there's essentially worlds within worlds that are created. And what we're trying to do is understand and synthesize, like an opinion or a conclusion based on everything that's happening. And that's really hard for them to do.
S Speaker 49:04I see, I see. So these are, these are like, just p case, 1000s of comments, and you have a way of what, summarizing these comments, or find the key takeaways, if you will, from these comments, if you will, yeah,
I see, I see. So these are, these are like, just p case, 1000s of comments, and you have a way of what, summarizing these comments, or find the key takeaways, if you will, from these comments, if you will, yeah,
I see, I see. So these are, these are like, just p case, 1000s of comments, and you have a way of what, summarizing these comments, or find the key takeaways, if you will, from these comments, if you will, yeah,
I see, I see. So these are, these are like, just p case, 1000s of comments, and you have a way of what, summarizing these comments, or find the key takeaways, if you will, from these comments, if you will, yeah,
S Speaker 29:17key takeaways, but synthesizing, what are the varying aspects within a given conversation? So basically, if everyone is talking about, for example, if there was a competitor conversation in that Duolingo thread, and you had five people that liked it, five people that said no, but everyone's giving various perspectives, how can we break that down? And then how could a user instantly find that pocket of conversation, of that pocket of that conversation across billions of other conversations that might be semantically similar, and that's a really hard way of essentially finding a needle in a haystack.
key takeaways, but synthesizing, what are the varying aspects within a given conversation? So basically, if everyone is talking about, for example, if there was a competitor conversation in that Duolingo thread, and you had five people that liked it, five people that said no, but everyone's giving various perspectives, how can we break that down? And then how could a user instantly find that pocket of conversation, of that pocket of that conversation across billions of other conversations that might be semantically similar, and that's a really hard way of essentially finding a needle in a haystack.
key takeaways, but synthesizing, what are the varying aspects within a given conversation? So basically, if everyone is talking about, for example, if there was a competitor conversation in that Duolingo thread, and you had five people that liked it, five people that said no, but everyone's giving various perspectives, how can we break that down? And then how could a user instantly find that pocket of conversation, of that pocket of that conversation across billions of other conversations that might be semantically similar, and that's a really hard way of essentially finding a needle in a haystack.
key takeaways, but synthesizing, what are the varying aspects within a given conversation? So basically, if everyone is talking about, for example, if there was a competitor conversation in that Duolingo thread, and you had five people that liked it, five people that said no, but everyone's giving various perspectives, how can we break that down? And then how could a user instantly find that pocket of conversation, of that pocket of that conversation across billions of other conversations that might be semantically similar, and that's a really hard way of essentially finding a needle in a haystack.
S Speaker 59:54I guess the STEM field can apply to Yelp comments, right?
I guess the STEM field can apply to Yelp comments, right?
I guess the STEM field can apply to Yelp comments, right?
I guess the STEM field can apply to Yelp comments, right?
S Speaker 59:59or photographer nearby, or tons of comments for different, you know, professions,
or photographer nearby, or tons of comments for different, you know, professions,
or photographer nearby, or tons of comments for different, you know, professions,
or photographer nearby, or tons of comments for different, you know, professions,
S Speaker 210:05yeah, in one way, but another place that we see this being huge is is discord. So Discord is just essentially a black box of conversations right here. If you guys are familiar with, you know, with mid journey, for example, you can see in the bottom right hand corner, there are around 21 million members in this Discord server, and there's over a million on online in this server right now. If we look at video games like valor and Minecraft, again, over millions of people in these servers, and almost 300,000 in here right now, talking this is essentially just a black box in just a mess of conversations, and they have no idea what's going on. They're applying massive teams. They get paid really well to do this because it's a really hard problem. And we see this essentially across every industry, including things like government and politics.
yeah, in one way, but another place that we see this being huge is is discord. So Discord is just essentially a black box of conversations right here. If you guys are familiar with, you know, with mid journey, for example, you can see in the bottom right hand corner, there are around 21 million members in this Discord server, and there's over a million on online in this server right now. If we look at video games like valor and Minecraft, again, over millions of people in these servers, and almost 300,000 in here right now, talking this is essentially just a black box in just a mess of conversations, and they have no idea what's going on. They're applying massive teams. They get paid really well to do this because it's a really hard problem. And we see this essentially across every industry, including things like government and politics.
yeah, in one way, but another place that we see this being huge is is discord. So Discord is just essentially a black box of conversations right here. If you guys are familiar with, you know, with mid journey, for example, you can see in the bottom right hand corner, there are around 21 million members in this Discord server, and there's over a million on online in this server right now. If we look at video games like valor and Minecraft, again, over millions of people in these servers, and almost 300,000 in here right now, talking this is essentially just a black box in just a mess of conversations, and they have no idea what's going on. They're applying massive teams. They get paid really well to do this because it's a really hard problem. And we see this essentially across every industry, including things like government and politics.
yeah, in one way, but another place that we see this being huge is is discord. So Discord is just essentially a black box of conversations right here. If you guys are familiar with, you know, with mid journey, for example, you can see in the bottom right hand corner, there are around 21 million members in this Discord server, and there's over a million on online in this server right now. If we look at video games like valor and Minecraft, again, over millions of people in these servers, and almost 300,000 in here right now, talking this is essentially just a black box in just a mess of conversations, and they have no idea what's going on. They're applying massive teams. They get paid really well to do this because it's a really hard problem. And we see this essentially across every industry, including things like government and politics.
S Speaker 511:00That's true. That's where all the Gen Z's are gathered. Yeah,
That's true. That's where all the Gen Z's are gathered. Yeah,
That's true. That's where all the Gen Z's are gathered. Yeah,
That's true. That's where all the Gen Z's are gathered. Yeah,
S Speaker 411:08Oh, this is discord, right? So basically, people in Minecraft, they're talking about this 275,000
Oh, this is discord, right? So basically, people in Minecraft, they're talking about this 275,000
Oh, this is discord, right? So basically, people in Minecraft, they're talking about this 275,000
Oh, this is discord, right? So basically, people in Minecraft, they're talking about this 275,000
S Speaker 111:24and Kyle, my health also, like you were telling us before, that there's no other tool that exists for discord today.
and Kyle, my health also, like you were telling us before, that there's no other tool that exists for discord today.
and Kyle, my health also, like you were telling us before, that there's no other tool that exists for discord today.
and Kyle, my health also, like you were telling us before, that there's no other tool that exists for discord today.
S Speaker 211:34No, there's no other tool that exists for discord, YouTube or Twitch, which when we're looking at the Creator space and looking at like where Gen Z is going in terms of what they're attracted to. It's really like this peer to peer connection of direct conversations or direct contact with gather the brand or creator, and there is nothing that can do it for either of those three platforms
No, there's no other tool that exists for discord, YouTube or Twitch, which when we're looking at the Creator space and looking at like where Gen Z is going in terms of what they're attracted to. It's really like this peer to peer connection of direct conversations or direct contact with gather the brand or creator, and there is nothing that can do it for either of those three platforms
No, there's no other tool that exists for discord, YouTube or Twitch, which when we're looking at the Creator space and looking at like where Gen Z is going in terms of what they're attracted to. It's really like this peer to peer connection of direct conversations or direct contact with gather the brand or creator, and there is nothing that can do it for either of those three platforms
No, there's no other tool that exists for discord, YouTube or Twitch, which when we're looking at the Creator space and looking at like where Gen Z is going in terms of what they're attracted to. It's really like this peer to peer connection of direct conversations or direct contact with gather the brand or creator, and there is nothing that can do it for either of those three platforms
S Speaker 212:00Tiktok is interesting. You have to have, like, a direct agreement. A lot of the larger brands do, which is great for us, because now we can access that data on behalf of the brand. And Twitter, you can actually pay, you know, to scrape all that information, but if you're getting it from the first party, sense that we do, it lowers that cost tremendously.
Tiktok is interesting. You have to have, like, a direct agreement. A lot of the larger brands do, which is great for us, because now we can access that data on behalf of the brand. And Twitter, you can actually pay, you know, to scrape all that information, but if you're getting it from the first party, sense that we do, it lowers that cost tremendously.
Tiktok is interesting. You have to have, like, a direct agreement. A lot of the larger brands do, which is great for us, because now we can access that data on behalf of the brand. And Twitter, you can actually pay, you know, to scrape all that information, but if you're getting it from the first party, sense that we do, it lowers that cost tremendously.
Tiktok is interesting. You have to have, like, a direct agreement. A lot of the larger brands do, which is great for us, because now we can access that data on behalf of the brand. And Twitter, you can actually pay, you know, to scrape all that information, but if you're getting it from the first party, sense that we do, it lowers that cost tremendously.
S Speaker 612:22Hey, curious. There are a lot of customer intelligence, or like a voice customer solutions out there, like, what prevent them from coming into discord?
Hey, curious. There are a lot of customer intelligence, or like a voice customer solutions out there, like, what prevent them from coming into discord?
Hey, curious. There are a lot of customer intelligence, or like a voice customer solutions out there, like, what prevent them from coming into discord?
Hey, curious. There are a lot of customer intelligence, or like a voice customer solutions out there, like, what prevent them from coming into discord?
S Speaker 212:33Yeah, it's, in all honesty, yeah, nothing would necessarily prevent them from going into discord. But we truly think that that type of company wouldn't be a competitor. They'd probably be a customer, because a lot of those Voice of the Customer platforms or solutions like sprinkler, et cetera, they're tagging those individual documents, like individual comments, as like, this is a feature request or this is a complaint, but they still don't understand all the other conversations around that that might be agreeing or disagreeing with that context. And we can kind of dive into, I might have an example visually of what we mean by that. And I think this does a really good job. For
Yeah, it's, in all honesty, yeah, nothing would necessarily prevent them from going into discord. But we truly think that that type of company wouldn't be a competitor. They'd probably be a customer, because a lot of those Voice of the Customer platforms or solutions like sprinkler, et cetera, they're tagging those individual documents, like individual comments, as like, this is a feature request or this is a complaint, but they still don't understand all the other conversations around that that might be agreeing or disagreeing with that context. And we can kind of dive into, I might have an example visually of what we mean by that. And I think this does a really good job. For
Yeah, it's, in all honesty, yeah, nothing would necessarily prevent them from going into discord. But we truly think that that type of company wouldn't be a competitor. They'd probably be a customer, because a lot of those Voice of the Customer platforms or solutions like sprinkler, et cetera, they're tagging those individual documents, like individual comments, as like, this is a feature request or this is a complaint, but they still don't understand all the other conversations around that that might be agreeing or disagreeing with that context. And we can kind of dive into, I might have an example visually of what we mean by that. And I think this does a really good job. For
Yeah, it's, in all honesty, yeah, nothing would necessarily prevent them from going into discord. But we truly think that that type of company wouldn't be a competitor. They'd probably be a customer, because a lot of those Voice of the Customer platforms or solutions like sprinkler, et cetera, they're tagging those individual documents, like individual comments, as like, this is a feature request or this is a complaint, but they still don't understand all the other conversations around that that might be agreeing or disagreeing with that context. And we can kind of dive into, I might have an example visually of what we mean by that. And I think this does a really good job. For
13:16example, you use speakers, kind of host, right?
S Speaker 713:27like, how about those flats, or what you see platform they can upgrade, yeah, I think, I
like, how about those flats, or what you see platform they can upgrade, yeah, I think, I
like, how about those flats, or what you see platform they can upgrade, yeah, I think, I
like, how about those flats, or what you see platform they can upgrade, yeah, I think, I
S Speaker 313:32think it's also important to note that, like, there's really no, there's very, very few social media analytics platforms for or or tools for platforms like discord. But beyond that, there's really, you know, we haven't identified a competitor that does exactly what we do for any any data platform, or has our approach to the problem, which we'll get into later. So even if you know it doesn't matter the platform, there really isn't necessarily a direct competitor to us, or somebody that does exactly what we do, yet, at least.
think it's also important to note that, like, there's really no, there's very, very few social media analytics platforms for or or tools for platforms like discord. But beyond that, there's really, you know, we haven't identified a competitor that does exactly what we do for any any data platform, or has our approach to the problem, which we'll get into later. So even if you know it doesn't matter the platform, there really isn't necessarily a direct competitor to us, or somebody that does exactly what we do, yet, at least.
think it's also important to note that, like, there's really no, there's very, very few social media analytics platforms for or or tools for platforms like discord. But beyond that, there's really, you know, we haven't identified a competitor that does exactly what we do for any any data platform, or has our approach to the problem, which we'll get into later. So even if you know it doesn't matter the platform, there really isn't necessarily a direct competitor to us, or somebody that does exactly what we do, yet, at least.
think it's also important to note that, like, there's really no, there's very, very few social media analytics platforms for or or tools for platforms like discord. But beyond that, there's really, you know, we haven't identified a competitor that does exactly what we do for any any data platform, or has our approach to the problem, which we'll get into later. So even if you know it doesn't matter the platform, there really isn't necessarily a direct competitor to us, or somebody that does exactly what we do, yet, at least.
S Speaker 114:16exactly what you mean by that, which is okay. What is it like? You know, topic modeling, which is, what is it like? What's the key differentiation? Which is, what is it? Where is it that the other platforms dot?
exactly what you mean by that, which is okay. What is it like? You know, topic modeling, which is, what is it like? What's the key differentiation? Which is, what is it? Where is it that the other platforms dot?
exactly what you mean by that, which is okay. What is it like? You know, topic modeling, which is, what is it like? What's the key differentiation? Which is, what is it? Where is it that the other platforms dot?
exactly what you mean by that, which is okay. What is it like? You know, topic modeling, which is, what is it like? What's the key differentiation? Which is, what is it? Where is it that the other platforms dot?
S Speaker 314:31Yeah, so there's like a chaotic mess of conversations that are happening in these channels like Twitch discord, where there's like single threaded conversations that are all coming in at, you know, anywhere between 10 a minute to 1000 a minute. We're talking like million, and then, you know, millions of comments a month. So you know, your traditional social media analytics platforms are going to give you all the metrics and are very future events. They're going to give you all the metrics associated with all that information and keyword analysis. But what they're not going to do is just give you a very clear understanding of truth and what those conversations mean. And they're not necessarily untangling the conversations and pairing them together. I can give you guys a little, a short presentation. Yeah,
Yeah, so there's like a chaotic mess of conversations that are happening in these channels like Twitch discord, where there's like single threaded conversations that are all coming in at, you know, anywhere between 10 a minute to 1000 a minute. We're talking like million, and then, you know, millions of comments a month. So you know, your traditional social media analytics platforms are going to give you all the metrics and are very future events. They're going to give you all the metrics associated with all that information and keyword analysis. But what they're not going to do is just give you a very clear understanding of truth and what those conversations mean. And they're not necessarily untangling the conversations and pairing them together. I can give you guys a little, a short presentation. Yeah,
Yeah, so there's like a chaotic mess of conversations that are happening in these channels like Twitch discord, where there's like single threaded conversations that are all coming in at, you know, anywhere between 10 a minute to 1000 a minute. We're talking like million, and then, you know, millions of comments a month. So you know, your traditional social media analytics platforms are going to give you all the metrics and are very future events. They're going to give you all the metrics associated with all that information and keyword analysis. But what they're not going to do is just give you a very clear understanding of truth and what those conversations mean. And they're not necessarily untangling the conversations and pairing them together. I can give you guys a little, a short presentation. Yeah,
Yeah, so there's like a chaotic mess of conversations that are happening in these channels like Twitch discord, where there's like single threaded conversations that are all coming in at, you know, anywhere between 10 a minute to 1000 a minute. We're talking like million, and then, you know, millions of comments a month. So you know, your traditional social media analytics platforms are going to give you all the metrics and are very future events. They're going to give you all the metrics associated with all that information and keyword analysis. But what they're not going to do is just give you a very clear understanding of truth and what those conversations mean. And they're not necessarily untangling the conversations and pairing them together. I can give you guys a little, a short presentation. Yeah,
S Speaker 215:15I think that's a really good idea, diving into showing like, the examples of you know how it's actually different,
I think that's a really good idea, diving into showing like, the examples of you know how it's actually different,
I think that's a really good idea, diving into showing like, the examples of you know how it's actually different,
I think that's a really good idea, diving into showing like, the examples of you know how it's actually different,
S Speaker 815:27sprinkler as a somebody who's doing this in the space with sort of old school technology, correct?
sprinkler as a somebody who's doing this in the space with sort of old school technology, correct?
sprinkler as a somebody who's doing this in the space with sort of old school technology, correct?
sprinkler as a somebody who's doing this in the space with sort of old school technology, correct?
15:35I didn't catch that. I'm sorry. Can you repeat that? Did
I didn't catch that. I'm sorry. Can you repeat that? Did
I didn't catch that. I'm sorry. Can you repeat that? Did
I didn't catch that. I'm sorry. Can you repeat that? Did
S Speaker 815:41Sprinkler is a company that has is a company that has some of these features,
Sprinkler is a company that has is a company that has some of these features,
Sprinkler is a company that has is a company that has some of these features,
Sprinkler is a company that has is a company that has some of these features,
S Speaker 115:56I'm sorry I'm having Carlos. Your your microphones. I think some reason, your microphone probably switched to something else as well.
I'm sorry I'm having Carlos. Your your microphones. I think some reason, your microphone probably switched to something else as well.
I'm sorry I'm having Carlos. Your your microphones. I think some reason, your microphone probably switched to something else as well.
I'm sorry I'm having Carlos. Your your microphones. I think some reason, your microphone probably switched to something else as well.
S Speaker 116:08he was talking, he was asking a question about sprinkler being the competitor that you mentioned that I didn't get the rest of the part of the question. Yeah,
he was talking, he was asking a question about sprinkler being the competitor that you mentioned that I didn't get the rest of the part of the question. Yeah,
he was talking, he was asking a question about sprinkler being the competitor that you mentioned that I didn't get the rest of the part of the question. Yeah,
he was talking, he was asking a question about sprinkler being the competitor that you mentioned that I didn't get the rest of the part of the question. Yeah,
S Speaker 216:20that's another thing too. We don't really view sprinkler as a competitor, like when we were looking at social listening platforms and social media management and analytics platforms. We genuinely don't see them as competitors. We're actually getting an introduction to sprout and sprinkler from a customer perspective, not a competitor perspective, because we actually think they could benefit in their own products from from this type of technology as well. And it's mostly around the topic modeling that Aaron's going to dive into right now.
that's another thing too. We don't really view sprinkler as a competitor, like when we were looking at social listening platforms and social media management and analytics platforms. We genuinely don't see them as competitors. We're actually getting an introduction to sprout and sprinkler from a customer perspective, not a competitor perspective, because we actually think they could benefit in their own products from from this type of technology as well. And it's mostly around the topic modeling that Aaron's going to dive into right now.
that's another thing too. We don't really view sprinkler as a competitor, like when we were looking at social listening platforms and social media management and analytics platforms. We genuinely don't see them as competitors. We're actually getting an introduction to sprout and sprinkler from a customer perspective, not a competitor perspective, because we actually think they could benefit in their own products from from this type of technology as well. And it's mostly around the topic modeling that Aaron's going to dive into right now.
that's another thing too. We don't really view sprinkler as a competitor, like when we were looking at social listening platforms and social media management and analytics platforms. We genuinely don't see them as competitors. We're actually getting an introduction to sprout and sprinkler from a customer perspective, not a competitor perspective, because we actually think they could benefit in their own products from from this type of technology as well. And it's mostly around the topic modeling that Aaron's going to dive into right now.
S Speaker 816:56Okay, yeah, my question was, wanted to go from Spring sprinklers, the name I heard, because I remember them playing in this place. So basically, you know, whatever tempos, Hero technology. You guys Correct. Okay, got it, okay, correct. Thank you. Yeah,
Okay, yeah, my question was, wanted to go from Spring sprinklers, the name I heard, because I remember them playing in this place. So basically, you know, whatever tempos, Hero technology. You guys Correct. Okay, got it, okay, correct. Thank you. Yeah,
Okay, yeah, my question was, wanted to go from Spring sprinklers, the name I heard, because I remember them playing in this place. So basically, you know, whatever tempos, Hero technology. You guys Correct. Okay, got it, okay, correct. Thank you. Yeah,
Okay, yeah, my question was, wanted to go from Spring sprinklers, the name I heard, because I remember them playing in this place. So basically, you know, whatever tempos, Hero technology. You guys Correct. Okay, got it, okay, correct. Thank you. Yeah,
S Speaker 317:15you guys able to see the presentation. Yeah, I'm good, cool. Okay, so we're going to go through the pipeline at a high level here. We want to answer the question that you guys specifically asked, Why can't llms Do everything here? So we'll get good. I want to answer these that question, but we'll come back to this after I go through the general pipeline. But at a high level, we do use llms. I just want to make that that clear in our pipeline, but for specific tasks, our value is really like in our approach to the problem. So if you were using LLM it would be orchestrating like you would be doing all these tasks that are involved in our pipeline. It does a lot of them it can't do others. Generally speaking, llms suffer the same shortcomings as humans for this issue, they just do it a little bit faster. And generally speaking, we want to provide the customer a scientific representation of their community. So we want to answer like we want to elevate what the truth is for conversations that are occurring inside the customer's community or data or origin of interest. So generally speaking, this at a high level is our pipeline. It starts with statements. So you can imagine discord, Twitch, Reddit, really, any social media platform, but we excel in the ones that are naturally, very difficult to untangle. So we have an example conversation here. These are six statements. Normally, we're dealing with anywhere, you know, like I said, between 1000, millions, too much, too much for a person to read. But when we read this, we can come come to a conclusion about what is being discussed here. So first person says, What do you guys think of of a given brand? And we want to talk about brands because to our customers, that's very important to them. When users are discussing given, given brands for music artists, for example, like those artists, are looking for collaboration opportunities, and they want to know what their fans in their communities think of a given brand. So that's why I'm going with that example. Somebody says I'm not a fan. Statement. Three says same. So these are in response to that one, then number four comes in. This has nothing to do with these other three. So this is where people are going to struggle, and this is where llms also struggle. And this is the problem. One of the main problems that we're solving, statement five says, I think it is great. And so there's like a disconnect here between four and five as a person. When you're reading through this, when you hit this statement, you have to scan back and say, What is this in response to is it in response to four? No, those don't connect three. Three and five don't connect two and five don't connect one. Oh, okay, that makes sense. Statement five is the response to statement one, and these are coming in very, very quickly. Statement six. Nothing to do with statement five. Then, as a human being, our processes began to iterate backwards. We hit four, and then we can see that statement six is a response to statement four. So that's the process that our pipeline goes through in a pseudo deterministic way, illustrating that so the user might have a query, just a general search query, their query might be brand. In a traditional social media, social media analytics or social listening platform, the user's queries brand, you'd only get statement one back and mentions of that specific brand name. That's very easy to do. And of course, if the user's just looking for keyword mentions, we can do that as well. But I think if the user, the customer is more interested in the sentiment behind the brand. They want, they want to see all statements relative to that brand. So for that query, you would see 123, and five, because we've context, because going through the pipeline, we've turned the statements into vectors, and we've clustered them to find conversations. Now we have contextualized vectors that we're doing neural search over, and that's how we return this data. So not only can we find brand we can do sentiment as well. So brand good, we get statement number five. I think it is great that's valuable to our customers. They want to know if people like a brand similarly, brand bad. They get two and three. I'm not a fan insane. This is very difficult for traditional social media analytics platforms to do. As I said before, you need AI to do this kind of thing. Going into another use case where we take things up to a higher level, where it's like a meta query, where you're not searching about you're not necessarily searching by brand or by song or by keyword. You're searching for conversations about song preferences. So after we contextualize the vectors with the surrounding information, we turn those into clusters. We annotate the data using an LLM. Now we have annotation vectors, and now we're doing neural search over those vectors as well. So conversations about song preferences returns four and six, obviously traditional search would not be able to get statement six, and it in some cases, wouldn't even be able to get statement number four. Now going through another use case that you have 100,000 comments over a given week in a Discord server. You don't really know what people are talking about in there. I mean, you might have an idea, but you don't. You don't necessarily know there's too much information to read. So you want the things that people are actually discussing to be elevated. So we'll show, show the user pre annotated data that that gives them a starting point to investigate the conversations that are happening. So the user just has this general question, what's going on today, and then we deliver that that answer, discussion on sentiment towards brand and discussion about song preferences, this is the truth that we're giving to the user like this is the truth of these conversations that we've elevated to them, and that's where a lot of the power of our of our platform, comes in. Now, as like to throw rag in here, we do brag over over both of these concepts to combine everything to get that like magical sort of experience. So the customer's queries, what do people think about brand? And from those previous steps, the L, the you know, an LLM, can draw in that data, pull in that data to give you a very definitive answer. There's one conversation about brand. Two users express negative sentiment. One user expresses positive sentiment. That's the point of truth. That's what the customer is interested and we need all of these ingredients to do that. And that's where the main value of our platform
you guys able to see the presentation. Yeah, I'm good, cool. Okay, so we're going to go through the pipeline at a high level here. We want to answer the question that you guys specifically asked, Why can't llms Do everything here? So we'll get good. I want to answer these that question, but we'll come back to this after I go through the general pipeline. But at a high level, we do use llms. I just want to make that that clear in our pipeline, but for specific tasks, our value is really like in our approach to the problem. So if you were using LLM it would be orchestrating like you would be doing all these tasks that are involved in our pipeline. It does a lot of them it can't do others. Generally speaking, llms suffer the same shortcomings as humans for this issue, they just do it a little bit faster. And generally speaking, we want to provide the customer a scientific representation of their community. So we want to answer like we want to elevate what the truth is for conversations that are occurring inside the customer's community or data or origin of interest. So generally speaking, this at a high level is our pipeline. It starts with statements. So you can imagine discord, Twitch, Reddit, really, any social media platform, but we excel in the ones that are naturally, very difficult to untangle. So we have an example conversation here. These are six statements. Normally, we're dealing with anywhere, you know, like I said, between 1000, millions, too much, too much for a person to read. But when we read this, we can come come to a conclusion about what is being discussed here. So first person says, What do you guys think of of a given brand? And we want to talk about brands because to our customers, that's very important to them. When users are discussing given, given brands for music artists, for example, like those artists, are looking for collaboration opportunities, and they want to know what their fans in their communities think of a given brand. So that's why I'm going with that example. Somebody says I'm not a fan. Statement. Three says same. So these are in response to that one, then number four comes in. This has nothing to do with these other three. So this is where people are going to struggle, and this is where llms also struggle. And this is the problem. One of the main problems that we're solving, statement five says, I think it is great. And so there's like a disconnect here between four and five as a person. When you're reading through this, when you hit this statement, you have to scan back and say, What is this in response to is it in response to four? No, those don't connect three. Three and five don't connect two and five don't connect one. Oh, okay, that makes sense. Statement five is the response to statement one, and these are coming in very, very quickly. Statement six. Nothing to do with statement five. Then, as a human being, our processes began to iterate backwards. We hit four, and then we can see that statement six is a response to statement four. So that's the process that our pipeline goes through in a pseudo deterministic way, illustrating that so the user might have a query, just a general search query, their query might be brand. In a traditional social media, social media analytics or social listening platform, the user's queries brand, you'd only get statement one back and mentions of that specific brand name. That's very easy to do. And of course, if the user's just looking for keyword mentions, we can do that as well. But I think if the user, the customer is more interested in the sentiment behind the brand. They want, they want to see all statements relative to that brand. So for that query, you would see 123, and five, because we've context, because going through the pipeline, we've turned the statements into vectors, and we've clustered them to find conversations. Now we have contextualized vectors that we're doing neural search over, and that's how we return this data. So not only can we find brand we can do sentiment as well. So brand good, we get statement number five. I think it is great that's valuable to our customers. They want to know if people like a brand similarly, brand bad. They get two and three. I'm not a fan insane. This is very difficult for traditional social media analytics platforms to do. As I said before, you need AI to do this kind of thing. Going into another use case where we take things up to a higher level, where it's like a meta query, where you're not searching about you're not necessarily searching by brand or by song or by keyword. You're searching for conversations about song preferences. So after we contextualize the vectors with the surrounding information, we turn those into clusters. We annotate the data using an LLM. Now we have annotation vectors, and now we're doing neural search over those vectors as well. So conversations about song preferences returns four and six, obviously traditional search would not be able to get statement six, and it in some cases, wouldn't even be able to get statement number four. Now going through another use case that you have 100,000 comments over a given week in a Discord server. You don't really know what people are talking about in there. I mean, you might have an idea, but you don't. You don't necessarily know there's too much information to read. So you want the things that people are actually discussing to be elevated. So we'll show, show the user pre annotated data that that gives them a starting point to investigate the conversations that are happening. So the user just has this general question, what's going on today, and then we deliver that that answer, discussion on sentiment towards brand and discussion about song preferences, this is the truth that we're giving to the user like this is the truth of these conversations that we've elevated to them, and that's where a lot of the power of our of our platform, comes in. Now, as like to throw rag in here, we do brag over over both of these concepts to combine everything to get that like magical sort of experience. So the customer's queries, what do people think about brand? And from those previous steps, the L, the you know, an LLM, can draw in that data, pull in that data to give you a very definitive answer. There's one conversation about brand. Two users express negative sentiment. One user expresses positive sentiment. That's the point of truth. That's what the customer is interested and we need all of these ingredients to do that. And that's where the main value of our platform
you guys able to see the presentation. Yeah, I'm good, cool. Okay, so we're going to go through the pipeline at a high level here. We want to answer the question that you guys specifically asked, Why can't llms Do everything here? So we'll get good. I want to answer these that question, but we'll come back to this after I go through the general pipeline. But at a high level, we do use llms. I just want to make that that clear in our pipeline, but for specific tasks, our value is really like in our approach to the problem. So if you were using LLM it would be orchestrating like you would be doing all these tasks that are involved in our pipeline. It does a lot of them it can't do others. Generally speaking, llms suffer the same shortcomings as humans for this issue, they just do it a little bit faster. And generally speaking, we want to provide the customer a scientific representation of their community. So we want to answer like we want to elevate what the truth is for conversations that are occurring inside the customer's community or data or origin of interest. So generally speaking, this at a high level is our pipeline. It starts with statements. So you can imagine discord, Twitch, Reddit, really, any social media platform, but we excel in the ones that are naturally, very difficult to untangle. So we have an example conversation here. These are six statements. Normally, we're dealing with anywhere, you know, like I said, between 1000, millions, too much, too much for a person to read. But when we read this, we can come come to a conclusion about what is being discussed here. So first person says, What do you guys think of of a given brand? And we want to talk about brands because to our customers, that's very important to them. When users are discussing given, given brands for music artists, for example, like those artists, are looking for collaboration opportunities, and they want to know what their fans in their communities think of a given brand. So that's why I'm going with that example. Somebody says I'm not a fan. Statement. Three says same. So these are in response to that one, then number four comes in. This has nothing to do with these other three. So this is where people are going to struggle, and this is where llms also struggle. And this is the problem. One of the main problems that we're solving, statement five says, I think it is great. And so there's like a disconnect here between four and five as a person. When you're reading through this, when you hit this statement, you have to scan back and say, What is this in response to is it in response to four? No, those don't connect three. Three and five don't connect two and five don't connect one. Oh, okay, that makes sense. Statement five is the response to statement one, and these are coming in very, very quickly. Statement six. Nothing to do with statement five. Then, as a human being, our processes began to iterate backwards. We hit four, and then we can see that statement six is a response to statement four. So that's the process that our pipeline goes through in a pseudo deterministic way, illustrating that so the user might have a query, just a general search query, their query might be brand. In a traditional social media, social media analytics or social listening platform, the user's queries brand, you'd only get statement one back and mentions of that specific brand name. That's very easy to do. And of course, if the user's just looking for keyword mentions, we can do that as well. But I think if the user, the customer is more interested in the sentiment behind the brand. They want, they want to see all statements relative to that brand. So for that query, you would see 123, and five, because we've context, because going through the pipeline, we've turned the statements into vectors, and we've clustered them to find conversations. Now we have contextualized vectors that we're doing neural search over, and that's how we return this data. So not only can we find brand we can do sentiment as well. So brand good, we get statement number five. I think it is great that's valuable to our customers. They want to know if people like a brand similarly, brand bad. They get two and three. I'm not a fan insane. This is very difficult for traditional social media analytics platforms to do. As I said before, you need AI to do this kind of thing. Going into another use case where we take things up to a higher level, where it's like a meta query, where you're not searching about you're not necessarily searching by brand or by song or by keyword. You're searching for conversations about song preferences. So after we contextualize the vectors with the surrounding information, we turn those into clusters. We annotate the data using an LLM. Now we have annotation vectors, and now we're doing neural search over those vectors as well. So conversations about song preferences returns four and six, obviously traditional search would not be able to get statement six, and it in some cases, wouldn't even be able to get statement number four. Now going through another use case that you have 100,000 comments over a given week in a Discord server. You don't really know what people are talking about in there. I mean, you might have an idea, but you don't. You don't necessarily know there's too much information to read. So you want the things that people are actually discussing to be elevated. So we'll show, show the user pre annotated data that that gives them a starting point to investigate the conversations that are happening. So the user just has this general question, what's going on today, and then we deliver that that answer, discussion on sentiment towards brand and discussion about song preferences, this is the truth that we're giving to the user like this is the truth of these conversations that we've elevated to them, and that's where a lot of the power of our of our platform, comes in. Now, as like to throw rag in here, we do brag over over both of these concepts to combine everything to get that like magical sort of experience. So the customer's queries, what do people think about brand? And from those previous steps, the L, the you know, an LLM, can draw in that data, pull in that data to give you a very definitive answer. There's one conversation about brand. Two users express negative sentiment. One user expresses positive sentiment. That's the point of truth. That's what the customer is interested and we need all of these ingredients to do that. And that's where the main value of our platform
you guys able to see the presentation. Yeah, I'm good, cool. Okay, so we're going to go through the pipeline at a high level here. We want to answer the question that you guys specifically asked, Why can't llms Do everything here? So we'll get good. I want to answer these that question, but we'll come back to this after I go through the general pipeline. But at a high level, we do use llms. I just want to make that that clear in our pipeline, but for specific tasks, our value is really like in our approach to the problem. So if you were using LLM it would be orchestrating like you would be doing all these tasks that are involved in our pipeline. It does a lot of them it can't do others. Generally speaking, llms suffer the same shortcomings as humans for this issue, they just do it a little bit faster. And generally speaking, we want to provide the customer a scientific representation of their community. So we want to answer like we want to elevate what the truth is for conversations that are occurring inside the customer's community or data or origin of interest. So generally speaking, this at a high level is our pipeline. It starts with statements. So you can imagine discord, Twitch, Reddit, really, any social media platform, but we excel in the ones that are naturally, very difficult to untangle. So we have an example conversation here. These are six statements. Normally, we're dealing with anywhere, you know, like I said, between 1000, millions, too much, too much for a person to read. But when we read this, we can come come to a conclusion about what is being discussed here. So first person says, What do you guys think of of a given brand? And we want to talk about brands because to our customers, that's very important to them. When users are discussing given, given brands for music artists, for example, like those artists, are looking for collaboration opportunities, and they want to know what their fans in their communities think of a given brand. So that's why I'm going with that example. Somebody says I'm not a fan. Statement. Three says same. So these are in response to that one, then number four comes in. This has nothing to do with these other three. So this is where people are going to struggle, and this is where llms also struggle. And this is the problem. One of the main problems that we're solving, statement five says, I think it is great. And so there's like a disconnect here between four and five as a person. When you're reading through this, when you hit this statement, you have to scan back and say, What is this in response to is it in response to four? No, those don't connect three. Three and five don't connect two and five don't connect one. Oh, okay, that makes sense. Statement five is the response to statement one, and these are coming in very, very quickly. Statement six. Nothing to do with statement five. Then, as a human being, our processes began to iterate backwards. We hit four, and then we can see that statement six is a response to statement four. So that's the process that our pipeline goes through in a pseudo deterministic way, illustrating that so the user might have a query, just a general search query, their query might be brand. In a traditional social media, social media analytics or social listening platform, the user's queries brand, you'd only get statement one back and mentions of that specific brand name. That's very easy to do. And of course, if the user's just looking for keyword mentions, we can do that as well. But I think if the user, the customer is more interested in the sentiment behind the brand. They want, they want to see all statements relative to that brand. So for that query, you would see 123, and five, because we've context, because going through the pipeline, we've turned the statements into vectors, and we've clustered them to find conversations. Now we have contextualized vectors that we're doing neural search over, and that's how we return this data. So not only can we find brand we can do sentiment as well. So brand good, we get statement number five. I think it is great that's valuable to our customers. They want to know if people like a brand similarly, brand bad. They get two and three. I'm not a fan insane. This is very difficult for traditional social media analytics platforms to do. As I said before, you need AI to do this kind of thing. Going into another use case where we take things up to a higher level, where it's like a meta query, where you're not searching about you're not necessarily searching by brand or by song or by keyword. You're searching for conversations about song preferences. So after we contextualize the vectors with the surrounding information, we turn those into clusters. We annotate the data using an LLM. Now we have annotation vectors, and now we're doing neural search over those vectors as well. So conversations about song preferences returns four and six, obviously traditional search would not be able to get statement six, and it in some cases, wouldn't even be able to get statement number four. Now going through another use case that you have 100,000 comments over a given week in a Discord server. You don't really know what people are talking about in there. I mean, you might have an idea, but you don't. You don't necessarily know there's too much information to read. So you want the things that people are actually discussing to be elevated. So we'll show, show the user pre annotated data that that gives them a starting point to investigate the conversations that are happening. So the user just has this general question, what's going on today, and then we deliver that that answer, discussion on sentiment towards brand and discussion about song preferences, this is the truth that we're giving to the user like this is the truth of these conversations that we've elevated to them, and that's where a lot of the power of our of our platform, comes in. Now, as like to throw rag in here, we do brag over over both of these concepts to combine everything to get that like magical sort of experience. So the customer's queries, what do people think about brand? And from those previous steps, the L, the you know, an LLM, can draw in that data, pull in that data to give you a very definitive answer. There's one conversation about brand. Two users express negative sentiment. One user expresses positive sentiment. That's the point of truth. That's what the customer is interested and we need all of these ingredients to do that. And that's where the main value of our platform
S Speaker 324:07So as kind of a little bit of an appendix here, as you guys have asked about this before, these are not all of the ingredients, but some of the core ingredients of our pipeline, embedding text. We use open source models, vectorizing to vectorize the text, these are a couple of the specific models we use. They're on talking face, which I you guys are familiar with clustering. We use the stochastic algorithms, which are combined to a library and a research paper called perv topic. We the person who invented this is a consultant for us. This is probably the best topic modeling algorithm out there right now from our perspective. So he's a huge asset to our team, and we're very confident about that. And this is where, you know, I don't think traditional platforms are using this technology, then we have classification, where we use a lot of different models, but we do use llms for that in some cases, because they're very well suited to classify documents. In certain cases, generation and rag we use llms and then neural search. Pretty self explanatory. We use embeddings and, you know, KNN to power that
So as kind of a little bit of an appendix here, as you guys have asked about this before, these are not all of the ingredients, but some of the core ingredients of our pipeline, embedding text. We use open source models, vectorizing to vectorize the text, these are a couple of the specific models we use. They're on talking face, which I you guys are familiar with clustering. We use the stochastic algorithms, which are combined to a library and a research paper called perv topic. We the person who invented this is a consultant for us. This is probably the best topic modeling algorithm out there right now from our perspective. So he's a huge asset to our team, and we're very confident about that. And this is where, you know, I don't think traditional platforms are using this technology, then we have classification, where we use a lot of different models, but we do use llms for that in some cases, because they're very well suited to classify documents. In certain cases, generation and rag we use llms and then neural search. Pretty self explanatory. We use embeddings and, you know, KNN to power that
So as kind of a little bit of an appendix here, as you guys have asked about this before, these are not all of the ingredients, but some of the core ingredients of our pipeline, embedding text. We use open source models, vectorizing to vectorize the text, these are a couple of the specific models we use. They're on talking face, which I you guys are familiar with clustering. We use the stochastic algorithms, which are combined to a library and a research paper called perv topic. We the person who invented this is a consultant for us. This is probably the best topic modeling algorithm out there right now from our perspective. So he's a huge asset to our team, and we're very confident about that. And this is where, you know, I don't think traditional platforms are using this technology, then we have classification, where we use a lot of different models, but we do use llms for that in some cases, because they're very well suited to classify documents. In certain cases, generation and rag we use llms and then neural search. Pretty self explanatory. We use embeddings and, you know, KNN to power that
So as kind of a little bit of an appendix here, as you guys have asked about this before, these are not all of the ingredients, but some of the core ingredients of our pipeline, embedding text. We use open source models, vectorizing to vectorize the text, these are a couple of the specific models we use. They're on talking face, which I you guys are familiar with clustering. We use the stochastic algorithms, which are combined to a library and a research paper called perv topic. We the person who invented this is a consultant for us. This is probably the best topic modeling algorithm out there right now from our perspective. So he's a huge asset to our team, and we're very confident about that. And this is where, you know, I don't think traditional platforms are using this technology, then we have classification, where we use a lot of different models, but we do use llms for that in some cases, because they're very well suited to classify documents. In certain cases, generation and rag we use llms and then neural search. Pretty self explanatory. We use embeddings and, you know, KNN to power that
S Speaker 125:22and and Aaron and Kyle, I guess the idea is to also hire that per topic person,
and and Aaron and Kyle, I guess the idea is to also hire that per topic person,
and and Aaron and Kyle, I guess the idea is to also hire that per topic person,
and and Aaron and Kyle, I guess the idea is to also hire that per topic person,
S Speaker 225:31yeah, yeah, yeah, correct, yeah, right now, he's like a part time engineer for the most part, but he's been very valuable to our team, So we'd like to bring them on full time. Okay, yeah, going
yeah, yeah, yeah, correct, yeah, right now, he's like a part time engineer for the most part, but he's been very valuable to our team, So we'd like to bring them on full time. Okay, yeah, going
yeah, yeah, yeah, correct, yeah, right now, he's like a part time engineer for the most part, but he's been very valuable to our team, So we'd like to bring them on full time. Okay, yeah, going
yeah, yeah, yeah, correct, yeah, right now, he's like a part time engineer for the most part, but he's been very valuable to our team, So we'd like to bring them on full time. Okay, yeah, going
S Speaker 325:47back to this last question, just because I want to answer, I think, I think it's easier to answer this in the context of the pipeline, so I'll just open it up to questions. And this is kind of like, not only Why can't llms do everything, but why this problem is difficult, and where our kind of, I guess, technological moat is. So
back to this last question, just because I want to answer, I think, I think it's easier to answer this in the context of the pipeline, so I'll just open it up to questions. And this is kind of like, not only Why can't llms do everything, but why this problem is difficult, and where our kind of, I guess, technological moat is. So
back to this last question, just because I want to answer, I think, I think it's easier to answer this in the context of the pipeline, so I'll just open it up to questions. And this is kind of like, not only Why can't llms do everything, but why this problem is difficult, and where our kind of, I guess, technological moat is. So
back to this last question, just because I want to answer, I think, I think it's easier to answer this in the context of the pipeline, so I'll just open it up to questions. And this is kind of like, not only Why can't llms do everything, but why this problem is difficult, and where our kind of, I guess, technological moat is. So
26:09any questions on these points or anything previous?
any questions on these points or anything previous?
any questions on these points or anything previous?
any questions on these points or anything previous?
S Speaker 426:19If you go back to the kind of flow charts you say you do use Lim, right? Yeah, use different things, I guess, for different pieces here. So this is the core ingredients, okay? So these are different LM. Some are GPT four. Some are open source models they're using, and that neural search is, what do you do there, embedding it? KNN, yeah, so that's a
If you go back to the kind of flow charts you say you do use Lim, right? Yeah, use different things, I guess, for different pieces here. So this is the core ingredients, okay? So these are different LM. Some are GPT four. Some are open source models they're using, and that neural search is, what do you do there, embedding it? KNN, yeah, so that's a
If you go back to the kind of flow charts you say you do use Lim, right? Yeah, use different things, I guess, for different pieces here. So this is the core ingredients, okay? So these are different LM. Some are GPT four. Some are open source models they're using, and that neural search is, what do you do there, embedding it? KNN, yeah, so that's a
If you go back to the kind of flow charts you say you do use Lim, right? Yeah, use different things, I guess, for different pieces here. So this is the core ingredients, okay? So these are different LM. Some are GPT four. Some are open source models they're using, and that neural search is, what do you do there, embedding it? KNN, yeah, so that's a
S Speaker 326:50little bit redundant. We use the open source models to embed the text. So one of the core like aspects to this pipeline is like, we have statements, right? We need to turn these statements and the vectors. That's like the core fundamental piece, and that's the underlying technology that llms utilize from the get go, like our best representation for what a statement is right now. And AI is, like, very powerful. There's been some like, major advancements in the last, like, four to six years in this space. We have, like, a pretty profound, profound, relative to 10 years ago, ability to turn statements into numerical, like vector representations. So in terms of like, what a given statement means, we can encapsulate that meaning in these in vectors, which we have a lot of you know, the open source models are very powerful. That's getting better all the time. But generally speaking, that's an example where for like mode, you know, l, or for y and LLM can't do that. I mean, it just, it can. It's just like, this is the fundamental piece that has to occur, right? Like, that's a task to turn turn conversations into vectors. Sorry,
little bit redundant. We use the open source models to embed the text. So one of the core like aspects to this pipeline is like, we have statements, right? We need to turn these statements and the vectors. That's like the core fundamental piece, and that's the underlying technology that llms utilize from the get go, like our best representation for what a statement is right now. And AI is, like, very powerful. There's been some like, major advancements in the last, like, four to six years in this space. We have, like, a pretty profound, profound, relative to 10 years ago, ability to turn statements into numerical, like vector representations. So in terms of like, what a given statement means, we can encapsulate that meaning in these in vectors, which we have a lot of you know, the open source models are very powerful. That's getting better all the time. But generally speaking, that's an example where for like mode, you know, l, or for y and LLM can't do that. I mean, it just, it can. It's just like, this is the fundamental piece that has to occur, right? Like, that's a task to turn turn conversations into vectors. Sorry,
little bit redundant. We use the open source models to embed the text. So one of the core like aspects to this pipeline is like, we have statements, right? We need to turn these statements and the vectors. That's like the core fundamental piece, and that's the underlying technology that llms utilize from the get go, like our best representation for what a statement is right now. And AI is, like, very powerful. There's been some like, major advancements in the last, like, four to six years in this space. We have, like, a pretty profound, profound, relative to 10 years ago, ability to turn statements into numerical, like vector representations. So in terms of like, what a given statement means, we can encapsulate that meaning in these in vectors, which we have a lot of you know, the open source models are very powerful. That's getting better all the time. But generally speaking, that's an example where for like mode, you know, l, or for y and LLM can't do that. I mean, it just, it can. It's just like, this is the fundamental piece that has to occur, right? Like, that's a task to turn turn conversations into vectors. Sorry,
little bit redundant. We use the open source models to embed the text. So one of the core like aspects to this pipeline is like, we have statements, right? We need to turn these statements and the vectors. That's like the core fundamental piece, and that's the underlying technology that llms utilize from the get go, like our best representation for what a statement is right now. And AI is, like, very powerful. There's been some like, major advancements in the last, like, four to six years in this space. We have, like, a pretty profound, profound, relative to 10 years ago, ability to turn statements into numerical, like vector representations. So in terms of like, what a given statement means, we can encapsulate that meaning in these in vectors, which we have a lot of you know, the open source models are very powerful. That's getting better all the time. But generally speaking, that's an example where for like mode, you know, l, or for y and LLM can't do that. I mean, it just, it can. It's just like, this is the fundamental piece that has to occur, right? Like, that's a task to turn turn conversations into vectors. Sorry,
27:57does that answer your question? I got a little bit off track
does that answer your question? I got a little bit off track
does that answer your question? I got a little bit off track
does that answer your question? I got a little bit off track
S Speaker 427:59there. When you say, Turn statements into vector, talking about the statements or just the comments, essentially right to vector representations, and then you use open source models to do that. Is that right?
there. When you say, Turn statements into vector, talking about the statements or just the comments, essentially right to vector representations, and then you use open source models to do that. Is that right?
there. When you say, Turn statements into vector, talking about the statements or just the comments, essentially right to vector representations, and then you use open source models to do that. Is that right?
there. When you say, Turn statements into vector, talking about the statements or just the comments, essentially right to vector representations, and then you use open source models to do that. Is that right?
S Speaker 328:15Yep, we could use paid models as well. It doesn't necessarily matter. Point is, that as a task, like, that's part of our pipeline, right? Yeah, okay. And we're like, embedding. Llms can do that as well. It's just not. They don't really give you the right embeddings for this sort of problem. So like I said, you know, we're like, this is about orchestration and our approach to the problem, not that that's where the value is, I
Yep, we could use paid models as well. It doesn't necessarily matter. Point is, that as a task, like, that's part of our pipeline, right? Yeah, okay. And we're like, embedding. Llms can do that as well. It's just not. They don't really give you the right embeddings for this sort of problem. So like I said, you know, we're like, this is about orchestration and our approach to the problem, not that that's where the value is, I
Yep, we could use paid models as well. It doesn't necessarily matter. Point is, that as a task, like, that's part of our pipeline, right? Yeah, okay. And we're like, embedding. Llms can do that as well. It's just not. They don't really give you the right embeddings for this sort of problem. So like I said, you know, we're like, this is about orchestration and our approach to the problem, not that that's where the value is, I
Yep, we could use paid models as well. It doesn't necessarily matter. Point is, that as a task, like, that's part of our pipeline, right? Yeah, okay. And we're like, embedding. Llms can do that as well. It's just not. They don't really give you the right embeddings for this sort of problem. So like I said, you know, we're like, this is about orchestration and our approach to the problem, not that that's where the value is, I
S Speaker 428:41suppose. Yeah. And then when you do clustering, you you're talking about cluster similar statements together. Or is that maybe I missed it earlier, when you get clustering similar like sentiment or similar statements together, is that right?
suppose. Yeah. And then when you do clustering, you you're talking about cluster similar statements together. Or is that maybe I missed it earlier, when you get clustering similar like sentiment or similar statements together, is that right?
suppose. Yeah. And then when you do clustering, you you're talking about cluster similar statements together. Or is that maybe I missed it earlier, when you get clustering similar like sentiment or similar statements together, is that right?
suppose. Yeah. And then when you do clustering, you you're talking about cluster similar statements together. Or is that maybe I missed it earlier, when you get clustering similar like sentiment or similar statements together, is that right?
S Speaker 328:58Yeah, so there's some proprietary stuff there that's hard to encapsulate here, yeah, but, but a lot of that is, it's like, iterate, you know, again, going through as a human being, like, when you read through this data, yeah, you have to, you have to relate statements back to one another. So again, like, I think it's great that doesn't, that doesn't necessarily relate to for, I mean, it could, but there's probably a better match for that one, right? So we go up and this is within the context window. Obviously, like there's a time period. There's a lot that goes into that, but this is a response to this statement, right? So we cluster all of the like statements about a given subject together, and then the ones that don't fit. I'm getting a little bit of the proprietary stuff here, but the ones that don't fit. Basically, we iterate backwards and find the next like statement of fact, if that makes sense. But this is difficult to do, and this is where, this is where our value is, yeah. Okay.
Yeah, so there's some proprietary stuff there that's hard to encapsulate here, yeah, but, but a lot of that is, it's like, iterate, you know, again, going through as a human being, like, when you read through this data, yeah, you have to, you have to relate statements back to one another. So again, like, I think it's great that doesn't, that doesn't necessarily relate to for, I mean, it could, but there's probably a better match for that one, right? So we go up and this is within the context window. Obviously, like there's a time period. There's a lot that goes into that, but this is a response to this statement, right? So we cluster all of the like statements about a given subject together, and then the ones that don't fit. I'm getting a little bit of the proprietary stuff here, but the ones that don't fit. Basically, we iterate backwards and find the next like statement of fact, if that makes sense. But this is difficult to do, and this is where, this is where our value is, yeah. Okay.
Yeah, so there's some proprietary stuff there that's hard to encapsulate here, yeah, but, but a lot of that is, it's like, iterate, you know, again, going through as a human being, like, when you read through this data, yeah, you have to, you have to relate statements back to one another. So again, like, I think it's great that doesn't, that doesn't necessarily relate to for, I mean, it could, but there's probably a better match for that one, right? So we go up and this is within the context window. Obviously, like there's a time period. There's a lot that goes into that, but this is a response to this statement, right? So we cluster all of the like statements about a given subject together, and then the ones that don't fit. I'm getting a little bit of the proprietary stuff here, but the ones that don't fit. Basically, we iterate backwards and find the next like statement of fact, if that makes sense. But this is difficult to do, and this is where, this is where our value is, yeah. Okay.
Yeah, so there's some proprietary stuff there that's hard to encapsulate here, yeah, but, but a lot of that is, it's like, iterate, you know, again, going through as a human being, like, when you read through this data, yeah, you have to, you have to relate statements back to one another. So again, like, I think it's great that doesn't, that doesn't necessarily relate to for, I mean, it could, but there's probably a better match for that one, right? So we go up and this is within the context window. Obviously, like there's a time period. There's a lot that goes into that, but this is a response to this statement, right? So we cluster all of the like statements about a given subject together, and then the ones that don't fit. I'm getting a little bit of the proprietary stuff here, but the ones that don't fit. Basically, we iterate backwards and find the next like statement of fact, if that makes sense. But this is difficult to do, and this is where, this is where our value is, yeah. Okay.
S Speaker 629:56For this part, do you leverage topic to to cluster them.
For this part, do you leverage topic to to cluster them.
For this part, do you leverage topic to to cluster them.
For this part, do you leverage topic to to cluster them.
S Speaker 330:03We leverage bird topic in multiple places, here and here. So we use bird topic to find the conversations and define conversational sorry. We use per topic to cluster semantically similar statements to like give you to bubble up a point of truth and like quantify given given sentiments, and then we leverage those clusters to find conversations. And then from those conversations, we cluster the conversations as well to give you that higher level context so we use per topic in multiple different places. Clustering is a big part of our
We leverage bird topic in multiple places, here and here. So we use bird topic to find the conversations and define conversational sorry. We use per topic to cluster semantically similar statements to like give you to bubble up a point of truth and like quantify given given sentiments, and then we leverage those clusters to find conversations. And then from those conversations, we cluster the conversations as well to give you that higher level context so we use per topic in multiple different places. Clustering is a big part of our
We leverage bird topic in multiple places, here and here. So we use bird topic to find the conversations and define conversational sorry. We use per topic to cluster semantically similar statements to like give you to bubble up a point of truth and like quantify given given sentiments, and then we leverage those clusters to find conversations. And then from those conversations, we cluster the conversations as well to give you that higher level context so we use per topic in multiple different places. Clustering is a big part of our
We leverage bird topic in multiple places, here and here. So we use bird topic to find the conversations and define conversational sorry. We use per topic to cluster semantically similar statements to like give you to bubble up a point of truth and like quantify given given sentiments, and then we leverage those clusters to find conversations. And then from those conversations, we cluster the conversations as well to give you that higher level context so we use per topic in multiple different places. Clustering is a big part of our
S Speaker 830:42pipeline. Aha. How do you measure how lack of a better word precise your tool is, and how do you measure improvement over time? So, just getting a sense for obviously, llms are known for hallucination. So just curious to see how you approach this, and how do you you know what confidence level you have that your answers or your clustering and your analysis, analytics, etc, are correct?
pipeline. Aha. How do you measure how lack of a better word precise your tool is, and how do you measure improvement over time? So, just getting a sense for obviously, llms are known for hallucination. So just curious to see how you approach this, and how do you you know what confidence level you have that your answers or your clustering and your analysis, analytics, etc, are correct?
pipeline. Aha. How do you measure how lack of a better word precise your tool is, and how do you measure improvement over time? So, just getting a sense for obviously, llms are known for hallucination. So just curious to see how you approach this, and how do you you know what confidence level you have that your answers or your clustering and your analysis, analytics, etc, are correct?
pipeline. Aha. How do you measure how lack of a better word precise your tool is, and how do you measure improvement over time? So, just getting a sense for obviously, llms are known for hallucination. So just curious to see how you approach this, and how do you you know what confidence level you have that your answers or your clustering and your analysis, analytics, etc, are correct?
S Speaker 331:15That's a great question. So this is a fairly scientific approach. So in terms of like, the point of truth are really the vectors and the statements. So like, a given statement is a piece of data. We represent that in the vector, and then we cluster I'm sorry that's a little bit redundant, but that's a scientific process. So like, statements are clustered together scientifically, right? It's stochastic. But in terms of, like, inaccuracy, a cluster is a cluster, like saying things mathematically pair together, or they don't. Of course, there is, like, some subjectivity in that. If we were to ask the LLM like, give us so I think this might be better. Might be better illustrated with this problem. If we were to ask the LLM straight up, like, what's going on today? With six statements, with this data set, it might be able to do it, but if you give it 50,000 documents, there's no guarantee that it's actually going to give you the like, the highest frequency topics for the ones you're most interested in, it might just randomly select them that's similar, like a human being reading through a large thread of conversations, they're going to like, you know, it's going to be like, subjective. There's no guarantee that the truth that they give you is going to be the truth that actually exists. But by going through this process, we've quantified like, we've already quantified and clustered the conversation. So, like, we know from this, scientifically speaking, that there are two conversations that happen today, and then the LLM is basically annotating them and giving this like it's just describing what those conversations are about. And so in that sense, yeah, there's room for error, but it's not very high. It's just like the task is read this conversation and tell me what it's about. We've scientifically found that conversation already with the best tools available.
That's a great question. So this is a fairly scientific approach. So in terms of like, the point of truth are really the vectors and the statements. So like, a given statement is a piece of data. We represent that in the vector, and then we cluster I'm sorry that's a little bit redundant, but that's a scientific process. So like, statements are clustered together scientifically, right? It's stochastic. But in terms of, like, inaccuracy, a cluster is a cluster, like saying things mathematically pair together, or they don't. Of course, there is, like, some subjectivity in that. If we were to ask the LLM like, give us so I think this might be better. Might be better illustrated with this problem. If we were to ask the LLM straight up, like, what's going on today? With six statements, with this data set, it might be able to do it, but if you give it 50,000 documents, there's no guarantee that it's actually going to give you the like, the highest frequency topics for the ones you're most interested in, it might just randomly select them that's similar, like a human being reading through a large thread of conversations, they're going to like, you know, it's going to be like, subjective. There's no guarantee that the truth that they give you is going to be the truth that actually exists. But by going through this process, we've quantified like, we've already quantified and clustered the conversation. So, like, we know from this, scientifically speaking, that there are two conversations that happen today, and then the LLM is basically annotating them and giving this like it's just describing what those conversations are about. And so in that sense, yeah, there's room for error, but it's not very high. It's just like the task is read this conversation and tell me what it's about. We've scientifically found that conversation already with the best tools available.
That's a great question. So this is a fairly scientific approach. So in terms of like, the point of truth are really the vectors and the statements. So like, a given statement is a piece of data. We represent that in the vector, and then we cluster I'm sorry that's a little bit redundant, but that's a scientific process. So like, statements are clustered together scientifically, right? It's stochastic. But in terms of, like, inaccuracy, a cluster is a cluster, like saying things mathematically pair together, or they don't. Of course, there is, like, some subjectivity in that. If we were to ask the LLM like, give us so I think this might be better. Might be better illustrated with this problem. If we were to ask the LLM straight up, like, what's going on today? With six statements, with this data set, it might be able to do it, but if you give it 50,000 documents, there's no guarantee that it's actually going to give you the like, the highest frequency topics for the ones you're most interested in, it might just randomly select them that's similar, like a human being reading through a large thread of conversations, they're going to like, you know, it's going to be like, subjective. There's no guarantee that the truth that they give you is going to be the truth that actually exists. But by going through this process, we've quantified like, we've already quantified and clustered the conversation. So, like, we know from this, scientifically speaking, that there are two conversations that happen today, and then the LLM is basically annotating them and giving this like it's just describing what those conversations are about. And so in that sense, yeah, there's room for error, but it's not very high. It's just like the task is read this conversation and tell me what it's about. We've scientifically found that conversation already with the best tools available.
That's a great question. So this is a fairly scientific approach. So in terms of like, the point of truth are really the vectors and the statements. So like, a given statement is a piece of data. We represent that in the vector, and then we cluster I'm sorry that's a little bit redundant, but that's a scientific process. So like, statements are clustered together scientifically, right? It's stochastic. But in terms of, like, inaccuracy, a cluster is a cluster, like saying things mathematically pair together, or they don't. Of course, there is, like, some subjectivity in that. If we were to ask the LLM like, give us so I think this might be better. Might be better illustrated with this problem. If we were to ask the LLM straight up, like, what's going on today? With six statements, with this data set, it might be able to do it, but if you give it 50,000 documents, there's no guarantee that it's actually going to give you the like, the highest frequency topics for the ones you're most interested in, it might just randomly select them that's similar, like a human being reading through a large thread of conversations, they're going to like, you know, it's going to be like, subjective. There's no guarantee that the truth that they give you is going to be the truth that actually exists. But by going through this process, we've quantified like, we've already quantified and clustered the conversation. So, like, we know from this, scientifically speaking, that there are two conversations that happen today, and then the LLM is basically annotating them and giving this like it's just describing what those conversations are about. And so in that sense, yeah, there's room for error, but it's not very high. It's just like the task is read this conversation and tell me what it's about. We've scientifically found that conversation already with the best tools available.
S Speaker 133:15like as you're testing this so are you collecting ground truth manually? How do you go about testing against like, as you improve the algorithm, how do you go about testing and verifying that your algorithm is actually improving?
like as you're testing this so are you collecting ground truth manually? How do you go about testing against like, as you improve the algorithm, how do you go about testing and verifying that your algorithm is actually improving?
like as you're testing this so are you collecting ground truth manually? How do you go about testing against like, as you improve the algorithm, how do you go about testing and verifying that your algorithm is actually improving?
like as you're testing this so are you collecting ground truth manually? How do you go about testing against like, as you improve the algorithm, how do you go about testing and verifying that your algorithm is actually improving?
S Speaker 333:28So there's lots of metrics that we use with different like, different stages of the pipeline, especially within the clusters. So one metric that we can use is, you know, after we cluster, the semantic vectors. This is just basic cluster optimization. We can test that the actual data matches, like the parasimilarity between all the statements in a given cluster match. That's relatively scientific we go to when we get to the annotation level, we can test this by matching the actual statements within a conversation against like the sent the sorry, semantically find the distance between every statement within a conversation and the description of that conversation. So a discussion about song preferences, we would test for ground truth by finding semantic similarity between or relevancy to this annotation, between this statement and this statement. So, like, these two statements are pretty close to this topic, so we have a pretty high score there. And that's also part of, like, the way we score the relevancy of annotations. I apologize it's a little bit difficult to explain this stuff. These are really good questions. And then beyond that, of course, like, we need user feedback. Like, that's like, the last line of like the last line of defense, clearly, and that's something we're always working on. Like, getting, getting that user feedback, figuring out from them, like, which
So there's lots of metrics that we use with different like, different stages of the pipeline, especially within the clusters. So one metric that we can use is, you know, after we cluster, the semantic vectors. This is just basic cluster optimization. We can test that the actual data matches, like the parasimilarity between all the statements in a given cluster match. That's relatively scientific we go to when we get to the annotation level, we can test this by matching the actual statements within a conversation against like the sent the sorry, semantically find the distance between every statement within a conversation and the description of that conversation. So a discussion about song preferences, we would test for ground truth by finding semantic similarity between or relevancy to this annotation, between this statement and this statement. So, like, these two statements are pretty close to this topic, so we have a pretty high score there. And that's also part of, like, the way we score the relevancy of annotations. I apologize it's a little bit difficult to explain this stuff. These are really good questions. And then beyond that, of course, like, we need user feedback. Like, that's like, the last line of like the last line of defense, clearly, and that's something we're always working on. Like, getting, getting that user feedback, figuring out from them, like, which
So there's lots of metrics that we use with different like, different stages of the pipeline, especially within the clusters. So one metric that we can use is, you know, after we cluster, the semantic vectors. This is just basic cluster optimization. We can test that the actual data matches, like the parasimilarity between all the statements in a given cluster match. That's relatively scientific we go to when we get to the annotation level, we can test this by matching the actual statements within a conversation against like the sent the sorry, semantically find the distance between every statement within a conversation and the description of that conversation. So a discussion about song preferences, we would test for ground truth by finding semantic similarity between or relevancy to this annotation, between this statement and this statement. So, like, these two statements are pretty close to this topic, so we have a pretty high score there. And that's also part of, like, the way we score the relevancy of annotations. I apologize it's a little bit difficult to explain this stuff. These are really good questions. And then beyond that, of course, like, we need user feedback. Like, that's like, the last line of like the last line of defense, clearly, and that's something we're always working on. Like, getting, getting that user feedback, figuring out from them, like, which
So there's lots of metrics that we use with different like, different stages of the pipeline, especially within the clusters. So one metric that we can use is, you know, after we cluster, the semantic vectors. This is just basic cluster optimization. We can test that the actual data matches, like the parasimilarity between all the statements in a given cluster match. That's relatively scientific we go to when we get to the annotation level, we can test this by matching the actual statements within a conversation against like the sent the sorry, semantically find the distance between every statement within a conversation and the description of that conversation. So a discussion about song preferences, we would test for ground truth by finding semantic similarity between or relevancy to this annotation, between this statement and this statement. So, like, these two statements are pretty close to this topic, so we have a pretty high score there. And that's also part of, like, the way we score the relevancy of annotations. I apologize it's a little bit difficult to explain this stuff. These are really good questions. And then beyond that, of course, like, we need user feedback. Like, that's like, the last line of like the last line of defense, clearly, and that's something we're always working on. Like, getting, getting that user feedback, figuring out from them, like, which
34:51which annotations are useful, which ones aren't, which ones
which annotations are useful, which ones aren't, which ones
which annotations are useful, which ones aren't, which ones
which annotations are useful, which ones aren't, which ones
S Speaker 135:00yeah, and there's no benchmarks per se in this industry.
yeah, and there's no benchmarks per se in this industry.
yeah, and there's no benchmarks per se in this industry.
yeah, and there's no benchmarks per se in this industry.
S Speaker 235:05There are topic modeling benchmarks per se, like, in terms of human readability scores, we're at a point now with the annotations to where the like, we can kind of go beyond that, that specific score, given, you know, similar to what Aaron was saying, if we can match semantically what the annotation is saying versus the actual representative documents, you can find the minimization between those vectors and it actually prevents it kind of presents, like a more complete score, as opposed to the human readability scores that are typically just focused on the clusters themselves. Yeah, thanks,
There are topic modeling benchmarks per se, like, in terms of human readability scores, we're at a point now with the annotations to where the like, we can kind of go beyond that, that specific score, given, you know, similar to what Aaron was saying, if we can match semantically what the annotation is saying versus the actual representative documents, you can find the minimization between those vectors and it actually prevents it kind of presents, like a more complete score, as opposed to the human readability scores that are typically just focused on the clusters themselves. Yeah, thanks,
There are topic modeling benchmarks per se, like, in terms of human readability scores, we're at a point now with the annotations to where the like, we can kind of go beyond that, that specific score, given, you know, similar to what Aaron was saying, if we can match semantically what the annotation is saying versus the actual representative documents, you can find the minimization between those vectors and it actually prevents it kind of presents, like a more complete score, as opposed to the human readability scores that are typically just focused on the clusters themselves. Yeah, thanks,
There are topic modeling benchmarks per se, like, in terms of human readability scores, we're at a point now with the annotations to where the like, we can kind of go beyond that, that specific score, given, you know, similar to what Aaron was saying, if we can match semantically what the annotation is saying versus the actual representative documents, you can find the minimization between those vectors and it actually prevents it kind of presents, like a more complete score, as opposed to the human readability scores that are typically just focused on the clusters themselves. Yeah, thanks,
S Speaker 335:48thanks. We also annotate data ourselves. Sorry, like, with given a test set of like, 100 documents, like, we will go through and manually mark those as, like, another line of defense as well. So there's a lot of different aspects that go into testing. Yeah,
thanks. We also annotate data ourselves. Sorry, like, with given a test set of like, 100 documents, like, we will go through and manually mark those as, like, another line of defense as well. So there's a lot of different aspects that go into testing. Yeah,
thanks. We also annotate data ourselves. Sorry, like, with given a test set of like, 100 documents, like, we will go through and manually mark those as, like, another line of defense as well. So there's a lot of different aspects that go into testing. Yeah,
thanks. We also annotate data ourselves. Sorry, like, with given a test set of like, 100 documents, like, we will go through and manually mark those as, like, another line of defense as well. So there's a lot of different aspects that go into testing. Yeah,
S Speaker 136:02thanks. We've got about 20 minutes left. I think let's move the conversation to go to market traction pipeline. How do you think?
thanks. We've got about 20 minutes left. I think let's move the conversation to go to market traction pipeline. How do you think?
thanks. We've got about 20 minutes left. I think let's move the conversation to go to market traction pipeline. How do you think?
thanks. We've got about 20 minutes left. I think let's move the conversation to go to market traction pipeline. How do you think?
S Speaker 540:53So for this customers, what is a specific user interface looking like? Is that just API for them to or have a chatbot enter for them to have their customers steal the insights. We're
So for this customers, what is a specific user interface looking like? Is that just API for them to or have a chatbot enter for them to have their customers steal the insights. We're
So for this customers, what is a specific user interface looking like? Is that just API for them to or have a chatbot enter for them to have their customers steal the insights. We're
So for this customers, what is a specific user interface looking like? Is that just API for them to or have a chatbot enter for them to have their customers steal the insights. We're
S Speaker 241:09in the middle right now of building out the application. So just an API alone was valuable for them to get this conversation, and valuable to get a P, O, C, valuable to sign a contract. These companies are investing heavily in analytics, and actually endeavor just got taken private by a private equity firm to invest more in their analytics team and build it out even further. So that's why we're trying to go when we're doing distribution, I'm not going to a marketing team. I'm not going to a brand partnership team. I'm targeting a very active and growing budget, which is analytics technology. And AI, when we go to these teams and we say, hey, we have an API that can do XYZ, their eyes light up, and they say, oh my gosh, this is going to save us a ton of time. We're going to be able to focus on new initiatives, et cetera. But what we're trying to do on the back end is build that application that you're talking about. So when we, when we give the API access to these companies, these analytics teams, are able to essentially, you know, put data in and get the answers that they need out, and then they can build custom data platforms, or like customer data platforms, essentially intelligence tools, etc, products on top of that, we're essentially an intelligence layer that we can build on top. But in terms of the end user application, we think there's an upsell opportunity down the line to say, Hey, you guys love this so much you can do so many cool things for it. How about we get all 6000 of your employees and offload even more work to where? To your point? They could ask the application, hey, what brands and my fans talk about today, bringing up more time for the analytics team, but also providing essentially instantaneous values all 6000 employees.
in the middle right now of building out the application. So just an API alone was valuable for them to get this conversation, and valuable to get a P, O, C, valuable to sign a contract. These companies are investing heavily in analytics, and actually endeavor just got taken private by a private equity firm to invest more in their analytics team and build it out even further. So that's why we're trying to go when we're doing distribution, I'm not going to a marketing team. I'm not going to a brand partnership team. I'm targeting a very active and growing budget, which is analytics technology. And AI, when we go to these teams and we say, hey, we have an API that can do XYZ, their eyes light up, and they say, oh my gosh, this is going to save us a ton of time. We're going to be able to focus on new initiatives, et cetera. But what we're trying to do on the back end is build that application that you're talking about. So when we, when we give the API access to these companies, these analytics teams, are able to essentially, you know, put data in and get the answers that they need out, and then they can build custom data platforms, or like customer data platforms, essentially intelligence tools, etc, products on top of that, we're essentially an intelligence layer that we can build on top. But in terms of the end user application, we think there's an upsell opportunity down the line to say, Hey, you guys love this so much you can do so many cool things for it. How about we get all 6000 of your employees and offload even more work to where? To your point? They could ask the application, hey, what brands and my fans talk about today, bringing up more time for the analytics team, but also providing essentially instantaneous values all 6000 employees.
in the middle right now of building out the application. So just an API alone was valuable for them to get this conversation, and valuable to get a P, O, C, valuable to sign a contract. These companies are investing heavily in analytics, and actually endeavor just got taken private by a private equity firm to invest more in their analytics team and build it out even further. So that's why we're trying to go when we're doing distribution, I'm not going to a marketing team. I'm not going to a brand partnership team. I'm targeting a very active and growing budget, which is analytics technology. And AI, when we go to these teams and we say, hey, we have an API that can do XYZ, their eyes light up, and they say, oh my gosh, this is going to save us a ton of time. We're going to be able to focus on new initiatives, et cetera. But what we're trying to do on the back end is build that application that you're talking about. So when we, when we give the API access to these companies, these analytics teams, are able to essentially, you know, put data in and get the answers that they need out, and then they can build custom data platforms, or like customer data platforms, essentially intelligence tools, etc, products on top of that, we're essentially an intelligence layer that we can build on top. But in terms of the end user application, we think there's an upsell opportunity down the line to say, Hey, you guys love this so much you can do so many cool things for it. How about we get all 6000 of your employees and offload even more work to where? To your point? They could ask the application, hey, what brands and my fans talk about today, bringing up more time for the analytics team, but also providing essentially instantaneous values all 6000 employees.
in the middle right now of building out the application. So just an API alone was valuable for them to get this conversation, and valuable to get a P, O, C, valuable to sign a contract. These companies are investing heavily in analytics, and actually endeavor just got taken private by a private equity firm to invest more in their analytics team and build it out even further. So that's why we're trying to go when we're doing distribution, I'm not going to a marketing team. I'm not going to a brand partnership team. I'm targeting a very active and growing budget, which is analytics technology. And AI, when we go to these teams and we say, hey, we have an API that can do XYZ, their eyes light up, and they say, oh my gosh, this is going to save us a ton of time. We're going to be able to focus on new initiatives, et cetera. But what we're trying to do on the back end is build that application that you're talking about. So when we, when we give the API access to these companies, these analytics teams, are able to essentially, you know, put data in and get the answers that they need out, and then they can build custom data platforms, or like customer data platforms, essentially intelligence tools, etc, products on top of that, we're essentially an intelligence layer that we can build on top. But in terms of the end user application, we think there's an upsell opportunity down the line to say, Hey, you guys love this so much you can do so many cool things for it. How about we get all 6000 of your employees and offload even more work to where? To your point? They could ask the application, hey, what brands and my fans talk about today, bringing up more time for the analytics team, but also providing essentially instantaneous values all 6000 employees.
42:48So phase one API, phase two, application, exactly.
S Speaker 242:51Yeah. Try to highlight that a little bit here as well. So like, if we're looking at where we're at in the company, we want to go to their data stack and their tech stack first, and then we see this once we're done, upsell the application later to both their internal stakeholders and then their event customers as well. So we're going to get into the growing budget first that allows us to get a bigger contract. And then as that engagement matures in our relationship, we say, hey, we have a beautiful application. You have 5000 people that are still talking to you. They can talk to our platform instead, free up even more time for your team.
Yeah. Try to highlight that a little bit here as well. So like, if we're looking at where we're at in the company, we want to go to their data stack and their tech stack first, and then we see this once we're done, upsell the application later to both their internal stakeholders and then their event customers as well. So we're going to get into the growing budget first that allows us to get a bigger contract. And then as that engagement matures in our relationship, we say, hey, we have a beautiful application. You have 5000 people that are still talking to you. They can talk to our platform instead, free up even more time for your team.
Yeah. Try to highlight that a little bit here as well. So like, if we're looking at where we're at in the company, we want to go to their data stack and their tech stack first, and then we see this once we're done, upsell the application later to both their internal stakeholders and then their event customers as well. So we're going to get into the growing budget first that allows us to get a bigger contract. And then as that engagement matures in our relationship, we say, hey, we have a beautiful application. You have 5000 people that are still talking to you. They can talk to our platform instead, free up even more time for your team.
Yeah. Try to highlight that a little bit here as well. So like, if we're looking at where we're at in the company, we want to go to their data stack and their tech stack first, and then we see this once we're done, upsell the application later to both their internal stakeholders and then their event customers as well. So we're going to get into the growing budget first that allows us to get a bigger contract. And then as that engagement matures in our relationship, we say, hey, we have a beautiful application. You have 5000 people that are still talking to you. They can talk to our platform instead, free up even more time for your team.
S Speaker 143:34is loaded waiting for that application? Are they? Yeah,
is loaded waiting for that application? Are they? Yeah,
is loaded waiting for that application? Are they? Yeah,
is loaded waiting for that application? Are they? Yeah,
S Speaker 243:37basically, so we're in the midst of, like, testing right now, but we expect to, you know, book revenue by the end of the month of September. Okay, they're
basically, so we're in the midst of, like, testing right now, but we expect to, you know, book revenue by the end of the month of September. Okay, they're
basically, so we're in the midst of, like, testing right now, but we expect to, you know, book revenue by the end of the month of September. Okay, they're
basically, so we're in the midst of, like, testing right now, but we expect to, you know, book revenue by the end of the month of September. Okay, they're
S Speaker 343:48using API. They're an API customer at this point, so
using API. They're an API customer at this point, so
using API. They're an API customer at this point, so
using API. They're an API customer at this point, so
43:51they're actively testing and then using it now. Yeah, we're
they're actively testing and then using it now. Yeah, we're
they're actively testing and then using it now. Yeah, we're
they're actively testing and then using it now. Yeah, we're
S Speaker 343:54communicate with them regularly. They're an API user. But like Kyle said, We think there's opportunity to upsell on the app, which we're going to have a pretty major overhaul and release by the end of the month here, and we're hoping to try and sell that as well.
communicate with them regularly. They're an API user. But like Kyle said, We think there's opportunity to upsell on the app, which we're going to have a pretty major overhaul and release by the end of the month here, and we're hoping to try and sell that as well.
communicate with them regularly. They're an API user. But like Kyle said, We think there's opportunity to upsell on the app, which we're going to have a pretty major overhaul and release by the end of the month here, and we're hoping to try and sell that as well.
communicate with them regularly. They're an API user. But like Kyle said, We think there's opportunity to upsell on the app, which we're going to have a pretty major overhaul and release by the end of the month here, and we're hoping to try and sell that as well.
S Speaker 244:15Can you talk to load it? Yeah, sure, yeah, I can. Yeah. Let me make it up. Yeah.
Can you talk to load it? Yeah, sure, yeah, I can. Yeah. Let me make it up. Yeah.
Can you talk to load it? Yeah, sure, yeah, I can. Yeah. Let me make it up. Yeah.
Can you talk to load it? Yeah, sure, yeah, I can. Yeah. Let me make it up. Yeah.
S Speaker 644:24So in terms of platform integration, do you integrate with second or something like that?
So in terms of platform integration, do you integrate with second or something like that?
So in terms of platform integration, do you integrate with second or something like that?
So in terms of platform integration, do you integrate with second or something like that?
S Speaker 344:34We're integrating with, like, the the points that where the conversations are happening, but we have talked about like Hootsuite, HubSpot integrations. We have discussed that in the past. Right now, our integrations are focused on the actual social media platforms where the data is coming from, or the customer can upload the API. That
We're integrating with, like, the the points that where the conversations are happening, but we have talked about like Hootsuite, HubSpot integrations. We have discussed that in the past. Right now, our integrations are focused on the actual social media platforms where the data is coming from, or the customer can upload the API. That
We're integrating with, like, the the points that where the conversations are happening, but we have talked about like Hootsuite, HubSpot integrations. We have discussed that in the past. Right now, our integrations are focused on the actual social media platforms where the data is coming from, or the customer can upload the API. That
We're integrating with, like, the the points that where the conversations are happening, but we have talked about like Hootsuite, HubSpot integrations. We have discussed that in the past. Right now, our integrations are focused on the actual social media platforms where the data is coming from, or the customer can upload the API. That
45:01Yeah. I assume you may have any scale use cost,
S Speaker 345:09yeah, yeah, we definitely are looking into that. We haven't done it yet. That's, that's the answer.
yeah, yeah, we definitely are looking into that. We haven't done it yet. That's, that's the answer.
yeah, yeah, we definitely are looking into that. We haven't done it yet. That's, that's the answer.
yeah, yeah, we definitely are looking into that. We haven't done it yet. That's, that's the answer.
S Speaker 145:19Yeah. So, thanks. Any other questions from our team?
Yeah. So, thanks. Any other questions from our team?
Yeah. So, thanks. Any other questions from our team?
Yeah. So, thanks. Any other questions from our team?
S Speaker 845:27I have a question. It's not critical, just curious. Clearly, you had a slide earlier. Sometimes it's applicable to many, many different industries, applications. So I'm wondering is, would this technology, and I'm not advocating to do that, but I think it's another pain point for people who are forum users. Would this technology be applicable to forums? Right? You go to a forum, it's just a mess, you know, it's really hard to find. You know, I'm an audio guy, I'm a car guy. I go to these forums, and in no time you get lost. You know, with trying to look for something and people divert that go all over the place, right?
I have a question. It's not critical, just curious. Clearly, you had a slide earlier. Sometimes it's applicable to many, many different industries, applications. So I'm wondering is, would this technology, and I'm not advocating to do that, but I think it's another pain point for people who are forum users. Would this technology be applicable to forums? Right? You go to a forum, it's just a mess, you know, it's really hard to find. You know, I'm an audio guy, I'm a car guy. I go to these forums, and in no time you get lost. You know, with trying to look for something and people divert that go all over the place, right?
I have a question. It's not critical, just curious. Clearly, you had a slide earlier. Sometimes it's applicable to many, many different industries, applications. So I'm wondering is, would this technology, and I'm not advocating to do that, but I think it's another pain point for people who are forum users. Would this technology be applicable to forums? Right? You go to a forum, it's just a mess, you know, it's really hard to find. You know, I'm an audio guy, I'm a car guy. I go to these forums, and in no time you get lost. You know, with trying to look for something and people divert that go all over the place, right?
I have a question. It's not critical, just curious. Clearly, you had a slide earlier. Sometimes it's applicable to many, many different industries, applications. So I'm wondering is, would this technology, and I'm not advocating to do that, but I think it's another pain point for people who are forum users. Would this technology be applicable to forums? Right? You go to a forum, it's just a mess, you know, it's really hard to find. You know, I'm an audio guy, I'm a car guy. I go to these forums, and in no time you get lost. You know, with trying to look for something and people divert that go all over the place, right?
S Speaker 846:09can you apply this to putting some order in that? Yeah,
can you apply this to putting some order in that? Yeah,
can you apply this to putting some order in that? Yeah,
can you apply this to putting some order in that? Yeah,
S Speaker 246:15yeah. I mean, Aaron, it's funny. Aaron said this maybe, like last week, out of nowhere. And it's kind of true. It's almost like we're creating a dynamic table of content for your data. Like, that's just like a natural it's naturally indexing your the conversations that are happening, and it's like triaging them, in a way that's actually, like very mathematical. So in terms of forums, that would be a great opportunity. It would essentially dynamically create, like, a table of index,
yeah. I mean, Aaron, it's funny. Aaron said this maybe, like last week, out of nowhere. And it's kind of true. It's almost like we're creating a dynamic table of content for your data. Like, that's just like a natural it's naturally indexing your the conversations that are happening, and it's like triaging them, in a way that's actually, like very mathematical. So in terms of forums, that would be a great opportunity. It would essentially dynamically create, like, a table of index,
yeah. I mean, Aaron, it's funny. Aaron said this maybe, like last week, out of nowhere. And it's kind of true. It's almost like we're creating a dynamic table of content for your data. Like, that's just like a natural it's naturally indexing your the conversations that are happening, and it's like triaging them, in a way that's actually, like very mathematical. So in terms of forums, that would be a great opportunity. It would essentially dynamically create, like, a table of index,
yeah. I mean, Aaron, it's funny. Aaron said this maybe, like last week, out of nowhere. And it's kind of true. It's almost like we're creating a dynamic table of content for your data. Like, that's just like a natural it's naturally indexing your the conversations that are happening, and it's like triaging them, in a way that's actually, like very mathematical. So in terms of forums, that would be a great opportunity. It would essentially dynamically create, like, a table of index,
S Speaker 346:46yeah? And like, I think so for forum users, like forum moderators on a B to B basis, like, absolutely, absolutely yes. In terms of, like, B to C, it's something that we're definitely very tough to monetize. Yeah, it's something that we're definitely thinking about. It's like, it's a it's a fun one, but yeah, to your point, tough to monetize, so we're just not sure yet. Yeah, definitely. For the moderator of, like, the community, absolutely no. Okay. Thank you.
yeah? And like, I think so for forum users, like forum moderators on a B to B basis, like, absolutely, absolutely yes. In terms of, like, B to C, it's something that we're definitely very tough to monetize. Yeah, it's something that we're definitely thinking about. It's like, it's a it's a fun one, but yeah, to your point, tough to monetize, so we're just not sure yet. Yeah, definitely. For the moderator of, like, the community, absolutely no. Okay. Thank you.
yeah? And like, I think so for forum users, like forum moderators on a B to B basis, like, absolutely, absolutely yes. In terms of, like, B to C, it's something that we're definitely very tough to monetize. Yeah, it's something that we're definitely thinking about. It's like, it's a it's a fun one, but yeah, to your point, tough to monetize, so we're just not sure yet. Yeah, definitely. For the moderator of, like, the community, absolutely no. Okay. Thank you.
yeah? And like, I think so for forum users, like forum moderators on a B to B basis, like, absolutely, absolutely yes. In terms of, like, B to C, it's something that we're definitely very tough to monetize. Yeah, it's something that we're definitely thinking about. It's like, it's a it's a fun one, but yeah, to your point, tough to monetize, so we're just not sure yet. Yeah, definitely. For the moderator of, like, the community, absolutely no. Okay. Thank you.
S Speaker 547:11One more question, so from the text that you just showed the topic modeling, do you think there is a specific technique that you're gradually building, because, since, to me, there are a bunch of open source techniques there, like, later, software, vector, database, rag and based on extract that. So given this is such a lucrative market, let's say if there is, for example, Stanford team, or whatever, other smart teams like seeing this opportunity to build something that's similar. Do you think that you will have to be able to form a leading modes about things based on the stack the data?
One more question, so from the text that you just showed the topic modeling, do you think there is a specific technique that you're gradually building, because, since, to me, there are a bunch of open source techniques there, like, later, software, vector, database, rag and based on extract that. So given this is such a lucrative market, let's say if there is, for example, Stanford team, or whatever, other smart teams like seeing this opportunity to build something that's similar. Do you think that you will have to be able to form a leading modes about things based on the stack the data?
One more question, so from the text that you just showed the topic modeling, do you think there is a specific technique that you're gradually building, because, since, to me, there are a bunch of open source techniques there, like, later, software, vector, database, rag and based on extract that. So given this is such a lucrative market, let's say if there is, for example, Stanford team, or whatever, other smart teams like seeing this opportunity to build something that's similar. Do you think that you will have to be able to form a leading modes about things based on the stack the data?
One more question, so from the text that you just showed the topic modeling, do you think there is a specific technique that you're gradually building, because, since, to me, there are a bunch of open source techniques there, like, later, software, vector, database, rag and based on extract that. So given this is such a lucrative market, let's say if there is, for example, Stanford team, or whatever, other smart teams like seeing this opportunity to build something that's similar. Do you think that you will have to be able to form a leading modes about things based on the stack the data?
S Speaker 347:50Yeah, yes. So the first topic, right? That's the research paper that the probably most influential research paper that we're using, like I said, he's a consultant for us that said, Though our tech Mode isn't the way we apply that technology, not in the app like not in just using it itself, the proprietary methods that we have are for actually leveraging the clusters to connect conversations together and then contextualize those conversations, like in a thread. So if you had, like, a string of conversations in the thread that the one I showed where somebody says same exclamation point, if you take that and just topic model that relative to the whole community, you would get a given topic that says instances of people saying same. You know, because, like, that's kind of semantically meaningless. Our proprietary method is the way that we iterate over the thread and find, find how those things connect, and then, you know, there's more to it than that, as well, than that. But like that is probably where most of our value is. There's, yeah, it's a very tough problem to solve. And so yes, we're confident, yeah,
Yeah, yes. So the first topic, right? That's the research paper that the probably most influential research paper that we're using, like I said, he's a consultant for us that said, Though our tech Mode isn't the way we apply that technology, not in the app like not in just using it itself, the proprietary methods that we have are for actually leveraging the clusters to connect conversations together and then contextualize those conversations, like in a thread. So if you had, like, a string of conversations in the thread that the one I showed where somebody says same exclamation point, if you take that and just topic model that relative to the whole community, you would get a given topic that says instances of people saying same. You know, because, like, that's kind of semantically meaningless. Our proprietary method is the way that we iterate over the thread and find, find how those things connect, and then, you know, there's more to it than that, as well, than that. But like that is probably where most of our value is. There's, yeah, it's a very tough problem to solve. And so yes, we're confident, yeah,
Yeah, yes. So the first topic, right? That's the research paper that the probably most influential research paper that we're using, like I said, he's a consultant for us that said, Though our tech Mode isn't the way we apply that technology, not in the app like not in just using it itself, the proprietary methods that we have are for actually leveraging the clusters to connect conversations together and then contextualize those conversations, like in a thread. So if you had, like, a string of conversations in the thread that the one I showed where somebody says same exclamation point, if you take that and just topic model that relative to the whole community, you would get a given topic that says instances of people saying same. You know, because, like, that's kind of semantically meaningless. Our proprietary method is the way that we iterate over the thread and find, find how those things connect, and then, you know, there's more to it than that, as well, than that. But like that is probably where most of our value is. There's, yeah, it's a very tough problem to solve. And so yes, we're confident, yeah,
Yeah, yes. So the first topic, right? That's the research paper that the probably most influential research paper that we're using, like I said, he's a consultant for us that said, Though our tech Mode isn't the way we apply that technology, not in the app like not in just using it itself, the proprietary methods that we have are for actually leveraging the clusters to connect conversations together and then contextualize those conversations, like in a thread. So if you had, like, a string of conversations in the thread that the one I showed where somebody says same exclamation point, if you take that and just topic model that relative to the whole community, you would get a given topic that says instances of people saying same. You know, because, like, that's kind of semantically meaningless. Our proprietary method is the way that we iterate over the thread and find, find how those things connect, and then, you know, there's more to it than that, as well, than that. But like that is probably where most of our value is. There's, yeah, it's a very tough problem to solve. And so yes, we're confident, yeah,
S Speaker 248:57yeah. Like using Bert topic alone, if there's a bunch of people saying same in terms of agreeing to something her topic would create a cluster of people saying, sane. What Aaron's trying to say is our proprietary method is understanding the context that what is same in response to like, what are they agreeing to, and actually taking that as a cluster, and then it provides a lot more information about people or agreeing about their favorite song or album, et cetera, as opposed to just blindly applying Bert topic or any clustering algorithm, you're just going to get semantically similar things, and you're just creating meaningless clusters, when really they're probably in response to something that is very valuable, and that's one
yeah. Like using Bert topic alone, if there's a bunch of people saying same in terms of agreeing to something her topic would create a cluster of people saying, sane. What Aaron's trying to say is our proprietary method is understanding the context that what is same in response to like, what are they agreeing to, and actually taking that as a cluster, and then it provides a lot more information about people or agreeing about their favorite song or album, et cetera, as opposed to just blindly applying Bert topic or any clustering algorithm, you're just going to get semantically similar things, and you're just creating meaningless clusters, when really they're probably in response to something that is very valuable, and that's one
yeah. Like using Bert topic alone, if there's a bunch of people saying same in terms of agreeing to something her topic would create a cluster of people saying, sane. What Aaron's trying to say is our proprietary method is understanding the context that what is same in response to like, what are they agreeing to, and actually taking that as a cluster, and then it provides a lot more information about people or agreeing about their favorite song or album, et cetera, as opposed to just blindly applying Bert topic or any clustering algorithm, you're just going to get semantically similar things, and you're just creating meaningless clusters, when really they're probably in response to something that is very valuable, and that's one
yeah. Like using Bert topic alone, if there's a bunch of people saying same in terms of agreeing to something her topic would create a cluster of people saying, sane. What Aaron's trying to say is our proprietary method is understanding the context that what is same in response to like, what are they agreeing to, and actually taking that as a cluster, and then it provides a lot more information about people or agreeing about their favorite song or album, et cetera, as opposed to just blindly applying Bert topic or any clustering algorithm, you're just going to get semantically similar things, and you're just creating meaningless clusters, when really they're probably in response to something that is very valuable, and that's one
S Speaker 349:35of the biggest examples. But I'm trying to emphasize there's more to that as well. Another very difficult problem to solve with topic modeling is like merging topics together from one time period to the next, and having that data evolve over time. When you have billions and millions of comments, even if you have like most like the most compute possible, it's not possible to do that like every comment that comes in changes the point of truth for the data as polls. So if you were to just blindly apply the open source methods to it. Without our methodology, you would have to remodel the entire thing. But we have a methodology that keeps that point of truth consistent and shifting relative to each individual statement that comes in. Okay, thanks. That's
of the biggest examples. But I'm trying to emphasize there's more to that as well. Another very difficult problem to solve with topic modeling is like merging topics together from one time period to the next, and having that data evolve over time. When you have billions and millions of comments, even if you have like most like the most compute possible, it's not possible to do that like every comment that comes in changes the point of truth for the data as polls. So if you were to just blindly apply the open source methods to it. Without our methodology, you would have to remodel the entire thing. But we have a methodology that keeps that point of truth consistent and shifting relative to each individual statement that comes in. Okay, thanks. That's
of the biggest examples. But I'm trying to emphasize there's more to that as well. Another very difficult problem to solve with topic modeling is like merging topics together from one time period to the next, and having that data evolve over time. When you have billions and millions of comments, even if you have like most like the most compute possible, it's not possible to do that like every comment that comes in changes the point of truth for the data as polls. So if you were to just blindly apply the open source methods to it. Without our methodology, you would have to remodel the entire thing. But we have a methodology that keeps that point of truth consistent and shifting relative to each individual statement that comes in. Okay, thanks. That's
of the biggest examples. But I'm trying to emphasize there's more to that as well. Another very difficult problem to solve with topic modeling is like merging topics together from one time period to the next, and having that data evolve over time. When you have billions and millions of comments, even if you have like most like the most compute possible, it's not possible to do that like every comment that comes in changes the point of truth for the data as polls. So if you were to just blindly apply the open source methods to it. Without our methodology, you would have to remodel the entire thing. But we have a methodology that keeps that point of truth consistent and shifting relative to each individual statement that comes in. Okay, thanks. That's
50:15a good question. I mean, yeah, abstractly, I got
S Speaker 451:29Thanks. So thanks. Kyle, couple of quick questions, hopefully. Question pricing model, how do you plan to charge customers? You talk about 500k Yeah, I got distracted for a second. And also, you're raising a seed round right now, just the financing kind of quick update on where it takes that. Yeah.
Thanks. So thanks. Kyle, couple of quick questions, hopefully. Question pricing model, how do you plan to charge customers? You talk about 500k Yeah, I got distracted for a second. And also, you're raising a seed round right now, just the financing kind of quick update on where it takes that. Yeah.
Thanks. So thanks. Kyle, couple of quick questions, hopefully. Question pricing model, how do you plan to charge customers? You talk about 500k Yeah, I got distracted for a second. And also, you're raising a seed round right now, just the financing kind of quick update on where it takes that. Yeah.
Thanks. So thanks. Kyle, couple of quick questions, hopefully. Question pricing model, how do you plan to charge customers? You talk about 500k Yeah, I got distracted for a second. And also, you're raising a seed round right now, just the financing kind of quick update on where it takes that. Yeah.
S Speaker 251:54So revenue model API is strictly usage based, so think of us as like GCP or AWS. Data comes in, data flows out. They pay for what they use on the application side, where we will looking at more of like a per seat per month, but also the concept of agents that actually are, you know, your personal agent conducting real tasks for you. So potentially paying per agent doing specific tasks as well on like our actual application. So kind of two different models depending on what product the user wants to use. In terms of the raise. We're technically calling it a pre seed. This is our first round of institutional funding that we're having, looking for one and a half million looking to raise on a safe, okay,
So revenue model API is strictly usage based, so think of us as like GCP or AWS. Data comes in, data flows out. They pay for what they use on the application side, where we will looking at more of like a per seat per month, but also the concept of agents that actually are, you know, your personal agent conducting real tasks for you. So potentially paying per agent doing specific tasks as well on like our actual application. So kind of two different models depending on what product the user wants to use. In terms of the raise. We're technically calling it a pre seed. This is our first round of institutional funding that we're having, looking for one and a half million looking to raise on a safe, okay,
So revenue model API is strictly usage based, so think of us as like GCP or AWS. Data comes in, data flows out. They pay for what they use on the application side, where we will looking at more of like a per seat per month, but also the concept of agents that actually are, you know, your personal agent conducting real tasks for you. So potentially paying per agent doing specific tasks as well on like our actual application. So kind of two different models depending on what product the user wants to use. In terms of the raise. We're technically calling it a pre seed. This is our first round of institutional funding that we're having, looking for one and a half million looking to raise on a safe, okay,
So revenue model API is strictly usage based, so think of us as like GCP or AWS. Data comes in, data flows out. They pay for what they use on the application side, where we will looking at more of like a per seat per month, but also the concept of agents that actually are, you know, your personal agent conducting real tasks for you. So potentially paying per agent doing specific tasks as well on like our actual application. So kind of two different models depending on what product the user wants to use. In terms of the raise. We're technically calling it a pre seed. This is our first round of institutional funding that we're having, looking for one and a half million looking to raise on a safe, okay,
S Speaker 452:37one and a half million on a safe. Okay, how much of that one and a half? Have you any commitments for, for the one and a half, or how much you have so far, we
one and a half million on a safe. Okay, how much of that one and a half? Have you any commitments for, for the one and a half, or how much you have so far, we
one and a half million on a safe. Okay, how much of that one and a half? Have you any commitments for, for the one and a half, or how much you have so far, we
one and a half million on a safe. Okay, how much of that one and a half? Have you any commitments for, for the one and a half, or how much you have so far, we
S Speaker 252:50have not raised anything so far to that one and a half. Oh,
have not raised anything so far to that one and a half. Oh,
have not raised anything so far to that one and a half. Oh,
have not raised anything so far to that one and a half. Oh,
S Speaker 452:53yeah. Okay, you just did the beginning of the process. Sounds like we are literally
yeah. Okay, you just did the beginning of the process. Sounds like we are literally
yeah. Okay, you just did the beginning of the process. Sounds like we are literally
yeah. Okay, you just did the beginning of the process. Sounds like we are literally
S Speaker 453:00prior to the prior to this, have you raised the capital?
prior to the prior to this, have you raised the capital?
prior to the prior to this, have you raised the capital?
prior to the prior to this, have you raised the capital?
S Speaker 253:03We have Aaron's mom as our first investor. Awesome.
We have Aaron's mom as our first investor. Awesome.
We have Aaron's mom as our first investor. Awesome.
We have Aaron's mom as our first investor. Awesome.
S Speaker 153:18Thanks. So, So Kyle. If you can introduce me to loaded, be great. Also, Aaron man also texted, I like Aaron's Gallery, and we discussed it last time. And it's him and his girlfriend.
Thanks. So, So Kyle. If you can introduce me to loaded, be great. Also, Aaron man also texted, I like Aaron's Gallery, and we discussed it last time. And it's him and his girlfriend.
Thanks. So, So Kyle. If you can introduce me to loaded, be great. Also, Aaron man also texted, I like Aaron's Gallery, and we discussed it last time. And it's him and his girlfriend.
Thanks. So, So Kyle. If you can introduce me to loaded, be great. Also, Aaron man also texted, I like Aaron's Gallery, and we discussed it last time. And it's him and his girlfriend.
S Speaker 353:37She's, she's the UI UX designer, that's what she does professionally. So, yeah, I got, I got one painting back here, but she paints. So
She's, she's the UI UX designer, that's what she does professionally. So, yeah, I got, I got one painting back here, but she paints. So
She's, she's the UI UX designer, that's what she does professionally. So, yeah, I got, I got one painting back here, but she paints. So
She's, she's the UI UX designer, that's what she does professionally. So, yeah, I got, I got one painting back here, but she paints. So
S Speaker 953:49anyways, so thank you guys. And then we'll be in touch and get back to make steps. Sounds good. As meeting you all. Thank you.
anyways, so thank you guys. And then we'll be in touch and get back to make steps. Sounds good. As meeting you all. Thank you.
anyways, so thank you guys. And then we'll be in touch and get back to make steps. Sounds good. As meeting you all. Thank you.
anyways, so thank you guys. And then we'll be in touch and get back to make steps. Sounds good. As meeting you all. Thank you.