Meeting: Perceptron Stage 1 US
Thu, Aug 29, 2024
10:33 AM
4 h
Priyesh P
Introduction to Perceptron AI and Phy
URL: https://otter.ai/u/hZEwwqIgTFY_1qAnFzE6SzLlC9A
Downloaded: 2025-12-22T14:44:41.324579
Method: text_extraction
============================================================

S Speaker 17:11and Yoshi, so in this use case, you talk about this process compliance, or whatever it's called, How does early fusion play in this case? Because the because what's going to happen is think of each line, each step right. Step one put, you know, use a hand sanitizer. Yeah, the text, use the hand sanitizer would have the same embeddings output as an image of someone's hands under a hand sanitizer, got it so it would be the same embeddings output. And that's my understanding of early fusion. And that's extremely powerful, because all the entropy of the world, all the knowledge of the world, is getting embedded in a vector very early in the architecture. And right now, no one is doing this right and do it enables them. Yep.
and Yoshi, so in this use case, you talk about this process compliance, or whatever it's called, How does early fusion play in this case? Because the because what's going to happen is think of each line, each step right. Step one put, you know, use a hand sanitizer. Yeah, the text, use the hand sanitizer would have the same embeddings output as an image of someone's hands under a hand sanitizer, got it so it would be the same embeddings output. And that's my understanding of early fusion. And that's extremely powerful, because all the entropy of the world, all the knowledge of the world, is getting embedded in a vector very early in the architecture. And right now, no one is doing this right and do it enables them. Yep.
and Yoshi, so in this use case, you talk about this process compliance, or whatever it's called, How does early fusion play in this case? Because the because what's going to happen is think of each line, each step right. Step one put, you know, use a hand sanitizer. Yeah, the text, use the hand sanitizer would have the same embeddings output as an image of someone's hands under a hand sanitizer, got it so it would be the same embeddings output. And that's my understanding of early fusion. And that's extremely powerful, because all the entropy of the world, all the knowledge of the world, is getting embedded in a vector very early in the architecture. And right now, no one is doing this right and do it enables them. Yep.
and Yoshi, so in this use case, you talk about this process compliance, or whatever it's called, How does early fusion play in this case? Because the because what's going to happen is think of each line, each step right. Step one put, you know, use a hand sanitizer. Yeah, the text, use the hand sanitizer would have the same embeddings output as an image of someone's hands under a hand sanitizer, got it so it would be the same embeddings output. And that's my understanding of early fusion. And that's extremely powerful, because all the entropy of the world, all the knowledge of the world, is getting embedded in a vector very early in the architecture. And right now, no one is doing this right and do it enables them. Yep.
S Speaker 115:41It's the first. Family of models is going to be ranging from 700 million parameters to 12 million parameters. So family of models, three to four models. This reminds me of the autonomous car accounts driving situation that you have the multi sensor fusion, right? Not multi fusion, and you the when the autonomous driving training situation, you have the early fusion, and the accuracy is much higher. So it is a similar analogy that even though that's a great, yeah, that's a brilliant analogy, yeah, sensors or like, you have the temperature, you have the already light, but you get the early fusion, and then the model size actually smaller, because you capture the most important data, and then the better, and then the output is better and accuracy is higher. That's exactly the situation for Yeah. That's yeah, that, that's a brilliant analogy. I think, I think, you know, like, That's exactly my, my understanding of it so far is that, and it's because aksha, the CTO, his background is at Ji. He worked on the, you know, those Ray Ban glasses at meta, right? Like, he's worked on in resource constrained environments, you know. So he's bringing that, know how in here. So that's what enables them to get that, that real time, low latency, high fidelity performance for these real time kind of physical use cases. Tanuja, you mentioned earlier, we refer a couple of times to the general purpose foundation model. So I so we know for the for the text based foundation model exists, but for visual, base and video related foundational models, this exists is something they have to rely on. I don't quite understand this question. Is there another way, maybe you could phrase it so, so I guess, in a way, is, how do they generalize those visual information like build into a foundation model? Yeah, so my understanding, so I've read the chameleon paper, and I believe a lot of this is based on their open source chameleon paper. Now they're building a company, and they're basically going to redo all the steps, but for these physical AI use cases. So my understanding is this is what they do in what's called pre training. So essentially you have pre training and post training as two different steps of building a foundation model, and in the pre training step, you know, where you have a whole lot of unsupervised learning, is where what you described is going to happen, that that's what I understand right now. And post training which, or it's also called found fine tuning. Or, you know, this is where a lot of what you hear in alignment, a lot of where the alignment work goes, right? That's another step, you know, where you know they they do what you're saying. But I believe most of this will actually happen with pre training. Otherwise, you can't get these kind of unified embeddings right, where a chair will have the same, you know, and I don't know how big these vectors are, but a chair would have the same, you know, 128 you know, float vector as a image of a chair, right? Like a text of a chair, image of a chair. Like, no, I believe that all happens in pre training. Yeah. So, so for pre training, do you get a sense how they actually do the unsupervised or self supervised? Now they, they that I believe this is, this is in the boundaries where they have the really good domain expertise. Because I think this is, this is where they're, you know, trying to keep it a little proprietary. I don't have context at that level into the exact how. Apart from, hey, we have, we're the team that did it, and we're going to do it again. I don't think that a lot of people will have the caliber to the pre trained.
It's the first. Family of models is going to be ranging from 700 million parameters to 12 million parameters. So family of models, three to four models. This reminds me of the autonomous car accounts driving situation that you have the multi sensor fusion, right? Not multi fusion, and you the when the autonomous driving training situation, you have the early fusion, and the accuracy is much higher. So it is a similar analogy that even though that's a great, yeah, that's a brilliant analogy, yeah, sensors or like, you have the temperature, you have the already light, but you get the early fusion, and then the model size actually smaller, because you capture the most important data, and then the better, and then the output is better and accuracy is higher. That's exactly the situation for Yeah. That's yeah, that, that's a brilliant analogy. I think, I think, you know, like, That's exactly my, my understanding of it so far is that, and it's because aksha, the CTO, his background is at Ji. He worked on the, you know, those Ray Ban glasses at meta, right? Like, he's worked on in resource constrained environments, you know. So he's bringing that, know how in here. So that's what enables them to get that, that real time, low latency, high fidelity performance for these real time kind of physical use cases. Tanuja, you mentioned earlier, we refer a couple of times to the general purpose foundation model. So I so we know for the for the text based foundation model exists, but for visual, base and video related foundational models, this exists is something they have to rely on. I don't quite understand this question. Is there another way, maybe you could phrase it so, so I guess, in a way, is, how do they generalize those visual information like build into a foundation model? Yeah, so my understanding, so I've read the chameleon paper, and I believe a lot of this is based on their open source chameleon paper. Now they're building a company, and they're basically going to redo all the steps, but for these physical AI use cases. So my understanding is this is what they do in what's called pre training. So essentially you have pre training and post training as two different steps of building a foundation model, and in the pre training step, you know, where you have a whole lot of unsupervised learning, is where what you described is going to happen, that that's what I understand right now. And post training which, or it's also called found fine tuning. Or, you know, this is where a lot of what you hear in alignment, a lot of where the alignment work goes, right? That's another step, you know, where you know they they do what you're saying. But I believe most of this will actually happen with pre training. Otherwise, you can't get these kind of unified embeddings right, where a chair will have the same, you know, and I don't know how big these vectors are, but a chair would have the same, you know, 128 you know, float vector as a image of a chair, right? Like a text of a chair, image of a chair. Like, no, I believe that all happens in pre training. Yeah. So, so for pre training, do you get a sense how they actually do the unsupervised or self supervised? Now they, they that I believe this is, this is in the boundaries where they have the really good domain expertise. Because I think this is, this is where they're, you know, trying to keep it a little proprietary. I don't have context at that level into the exact how. Apart from, hey, we have, we're the team that did it, and we're going to do it again. I don't think that a lot of people will have the caliber to the pre trained.
It's the first. Family of models is going to be ranging from 700 million parameters to 12 million parameters. So family of models, three to four models. This reminds me of the autonomous car accounts driving situation that you have the multi sensor fusion, right? Not multi fusion, and you the when the autonomous driving training situation, you have the early fusion, and the accuracy is much higher. So it is a similar analogy that even though that's a great, yeah, that's a brilliant analogy, yeah, sensors or like, you have the temperature, you have the already light, but you get the early fusion, and then the model size actually smaller, because you capture the most important data, and then the better, and then the output is better and accuracy is higher. That's exactly the situation for Yeah. That's yeah, that, that's a brilliant analogy. I think, I think, you know, like, That's exactly my, my understanding of it so far is that, and it's because aksha, the CTO, his background is at Ji. He worked on the, you know, those Ray Ban glasses at meta, right? Like, he's worked on in resource constrained environments, you know. So he's bringing that, know how in here. So that's what enables them to get that, that real time, low latency, high fidelity performance for these real time kind of physical use cases. Tanuja, you mentioned earlier, we refer a couple of times to the general purpose foundation model. So I so we know for the for the text based foundation model exists, but for visual, base and video related foundational models, this exists is something they have to rely on. I don't quite understand this question. Is there another way, maybe you could phrase it so, so I guess, in a way, is, how do they generalize those visual information like build into a foundation model? Yeah, so my understanding, so I've read the chameleon paper, and I believe a lot of this is based on their open source chameleon paper. Now they're building a company, and they're basically going to redo all the steps, but for these physical AI use cases. So my understanding is this is what they do in what's called pre training. So essentially you have pre training and post training as two different steps of building a foundation model, and in the pre training step, you know, where you have a whole lot of unsupervised learning, is where what you described is going to happen, that that's what I understand right now. And post training which, or it's also called found fine tuning. Or, you know, this is where a lot of what you hear in alignment, a lot of where the alignment work goes, right? That's another step, you know, where you know they they do what you're saying. But I believe most of this will actually happen with pre training. Otherwise, you can't get these kind of unified embeddings right, where a chair will have the same, you know, and I don't know how big these vectors are, but a chair would have the same, you know, 128 you know, float vector as a image of a chair, right? Like a text of a chair, image of a chair. Like, no, I believe that all happens in pre training. Yeah. So, so for pre training, do you get a sense how they actually do the unsupervised or self supervised? Now they, they that I believe this is, this is in the boundaries where they have the really good domain expertise. Because I think this is, this is where they're, you know, trying to keep it a little proprietary. I don't have context at that level into the exact how. Apart from, hey, we have, we're the team that did it, and we're going to do it again. I don't think that a lot of people will have the caliber to the pre trained.
It's the first. Family of models is going to be ranging from 700 million parameters to 12 million parameters. So family of models, three to four models. This reminds me of the autonomous car accounts driving situation that you have the multi sensor fusion, right? Not multi fusion, and you the when the autonomous driving training situation, you have the early fusion, and the accuracy is much higher. So it is a similar analogy that even though that's a great, yeah, that's a brilliant analogy, yeah, sensors or like, you have the temperature, you have the already light, but you get the early fusion, and then the model size actually smaller, because you capture the most important data, and then the better, and then the output is better and accuracy is higher. That's exactly the situation for Yeah. That's yeah, that, that's a brilliant analogy. I think, I think, you know, like, That's exactly my, my understanding of it so far is that, and it's because aksha, the CTO, his background is at Ji. He worked on the, you know, those Ray Ban glasses at meta, right? Like, he's worked on in resource constrained environments, you know. So he's bringing that, know how in here. So that's what enables them to get that, that real time, low latency, high fidelity performance for these real time kind of physical use cases. Tanuja, you mentioned earlier, we refer a couple of times to the general purpose foundation model. So I so we know for the for the text based foundation model exists, but for visual, base and video related foundational models, this exists is something they have to rely on. I don't quite understand this question. Is there another way, maybe you could phrase it so, so I guess, in a way, is, how do they generalize those visual information like build into a foundation model? Yeah, so my understanding, so I've read the chameleon paper, and I believe a lot of this is based on their open source chameleon paper. Now they're building a company, and they're basically going to redo all the steps, but for these physical AI use cases. So my understanding is this is what they do in what's called pre training. So essentially you have pre training and post training as two different steps of building a foundation model, and in the pre training step, you know, where you have a whole lot of unsupervised learning, is where what you described is going to happen, that that's what I understand right now. And post training which, or it's also called found fine tuning. Or, you know, this is where a lot of what you hear in alignment, a lot of where the alignment work goes, right? That's another step, you know, where you know they they do what you're saying. But I believe most of this will actually happen with pre training. Otherwise, you can't get these kind of unified embeddings right, where a chair will have the same, you know, and I don't know how big these vectors are, but a chair would have the same, you know, 128 you know, float vector as a image of a chair, right? Like a text of a chair, image of a chair. Like, no, I believe that all happens in pre training. Yeah. So, so for pre training, do you get a sense how they actually do the unsupervised or self supervised? Now they, they that I believe this is, this is in the boundaries where they have the really good domain expertise. Because I think this is, this is where they're, you know, trying to keep it a little proprietary. I don't have context at that level into the exact how. Apart from, hey, we have, we're the team that did it, and we're going to do it again. I don't think that a lot of people will have the caliber to the pre trained.
S Speaker 119:47this is our man and and that they don't even talk about it in the chameleon paper,
this is our man and and that they don't even talk about it in the chameleon paper,
this is our man and and that they don't even talk about it in the chameleon paper,
this is our man and and that they don't even talk about it in the chameleon paper,
S Speaker 119:57and, yeah. And Armin also met some members of our team. We have two. We have a pair of Stanford engineers. One of them worked on large scale, you know, AI systems at Microsoft. The other actually worked at Facebook as well before coming here. And they, you know, they had done some diligence on these guys, and they're, they left very, very impressed with, with both of them, that these are highly, highly skilled, competent people. And we've met a bunch of these teams so far because, like, we want an ecosystem for this to exist, right? Like, we want to be these guys, customers and partners, right? So, like, you know, we've talked with a bunch of these folks. This is the first team that these guys have actually said, Hey, these guys are really high caliber. So apart from the people validation point, I we haven't been able to dig into the how on the on the pre training, there's, there's, you know, it's kind of their special sauce. I think so. So without getting them to disclose their secret sauce, like, what evidence is? Can we try to capture, to know, to get kind of some comfort that there? Yeah, because their pre training is indeed scalable. I mean, evidence is a million very dependent ones. Yeah, I would say, So, what are we I'll now answer as a potential customer fee for spot, right? We got really excited by these guys, because, like, you know, we've been, we've been thinking about this stuff for a long time, and, you know, we do think there'll be a GPT moment for these, you know, born multimodal models all that, right? Like, for vision and, you know, for the physical world. So like for us, right? Like we, you know, we looked at chameleon, right? We saw what chameleon was doing. It's an open source version of borough. It's the only viable open source version of borough right now. So, like for us, we have very little downside to get in a partnership with them, start sharing some data, tell them the use cases, where's the revenue coming from, right? Like, where's the where's the consumption coming from, and then work with them to steer these models towards these use cases, right? So, like, for us, there's really high upside, really little downside to partner with them, but we've internally said we're not really going to know until, I think at one to two quarters, kind of that first intermediate checkpoints come out in the model. Because this is one of those things where, yes, they they may need less capital than a traditional, you know, like, you know, some of these other approaches, right? Skilled, you know, brought in 300 million, and depth was at a few 100 million before the million before they got scooped up. Like, you know, yes, they'll mean that's less capital, but we're not going to know for one to two quarters, you know, the real growth in the pudding, but we're willing to give it a shot and give these guys, you know, the best opportunity with our data, right? Because there's so much upside. If you know, if this team can you know, leverage their their expertise here, and when they get your data, is it mostly going to be post training, right? Fine tuning, so, so this is where I don't know yet. So we're just full this. We're an active conversation with them right now. I there was some legal paper replying around this morning on email that that I was, I was looking at, so we're looking to get in some sort of partnership deal with them right now. And this is one of the open points that we need clarification.
and, yeah. And Armin also met some members of our team. We have two. We have a pair of Stanford engineers. One of them worked on large scale, you know, AI systems at Microsoft. The other actually worked at Facebook as well before coming here. And they, you know, they had done some diligence on these guys, and they're, they left very, very impressed with, with both of them, that these are highly, highly skilled, competent people. And we've met a bunch of these teams so far because, like, we want an ecosystem for this to exist, right? Like, we want to be these guys, customers and partners, right? So, like, you know, we've talked with a bunch of these folks. This is the first team that these guys have actually said, Hey, these guys are really high caliber. So apart from the people validation point, I we haven't been able to dig into the how on the on the pre training, there's, there's, you know, it's kind of their special sauce. I think so. So without getting them to disclose their secret sauce, like, what evidence is? Can we try to capture, to know, to get kind of some comfort that there? Yeah, because their pre training is indeed scalable. I mean, evidence is a million very dependent ones. Yeah, I would say, So, what are we I'll now answer as a potential customer fee for spot, right? We got really excited by these guys, because, like, you know, we've been, we've been thinking about this stuff for a long time, and, you know, we do think there'll be a GPT moment for these, you know, born multimodal models all that, right? Like, for vision and, you know, for the physical world. So like for us, right? Like we, you know, we looked at chameleon, right? We saw what chameleon was doing. It's an open source version of borough. It's the only viable open source version of borough right now. So, like for us, we have very little downside to get in a partnership with them, start sharing some data, tell them the use cases, where's the revenue coming from, right? Like, where's the where's the consumption coming from, and then work with them to steer these models towards these use cases, right? So, like, for us, there's really high upside, really little downside to partner with them, but we've internally said we're not really going to know until, I think at one to two quarters, kind of that first intermediate checkpoints come out in the model. Because this is one of those things where, yes, they they may need less capital than a traditional, you know, like, you know, some of these other approaches, right? Skilled, you know, brought in 300 million, and depth was at a few 100 million before the million before they got scooped up. Like, you know, yes, they'll mean that's less capital, but we're not going to know for one to two quarters, you know, the real growth in the pudding, but we're willing to give it a shot and give these guys, you know, the best opportunity with our data, right? Because there's so much upside. If you know, if this team can you know, leverage their their expertise here, and when they get your data, is it mostly going to be post training, right? Fine tuning, so, so this is where I don't know yet. So we're just full this. We're an active conversation with them right now. I there was some legal paper replying around this morning on email that that I was, I was looking at, so we're looking to get in some sort of partnership deal with them right now. And this is one of the open points that we need clarification.
and, yeah. And Armin also met some members of our team. We have two. We have a pair of Stanford engineers. One of them worked on large scale, you know, AI systems at Microsoft. The other actually worked at Facebook as well before coming here. And they, you know, they had done some diligence on these guys, and they're, they left very, very impressed with, with both of them, that these are highly, highly skilled, competent people. And we've met a bunch of these teams so far because, like, we want an ecosystem for this to exist, right? Like, we want to be these guys, customers and partners, right? So, like, you know, we've talked with a bunch of these folks. This is the first team that these guys have actually said, Hey, these guys are really high caliber. So apart from the people validation point, I we haven't been able to dig into the how on the on the pre training, there's, there's, you know, it's kind of their special sauce. I think so. So without getting them to disclose their secret sauce, like, what evidence is? Can we try to capture, to know, to get kind of some comfort that there? Yeah, because their pre training is indeed scalable. I mean, evidence is a million very dependent ones. Yeah, I would say, So, what are we I'll now answer as a potential customer fee for spot, right? We got really excited by these guys, because, like, you know, we've been, we've been thinking about this stuff for a long time, and, you know, we do think there'll be a GPT moment for these, you know, born multimodal models all that, right? Like, for vision and, you know, for the physical world. So like for us, right? Like we, you know, we looked at chameleon, right? We saw what chameleon was doing. It's an open source version of borough. It's the only viable open source version of borough right now. So, like for us, we have very little downside to get in a partnership with them, start sharing some data, tell them the use cases, where's the revenue coming from, right? Like, where's the where's the consumption coming from, and then work with them to steer these models towards these use cases, right? So, like, for us, there's really high upside, really little downside to partner with them, but we've internally said we're not really going to know until, I think at one to two quarters, kind of that first intermediate checkpoints come out in the model. Because this is one of those things where, yes, they they may need less capital than a traditional, you know, like, you know, some of these other approaches, right? Skilled, you know, brought in 300 million, and depth was at a few 100 million before the million before they got scooped up. Like, you know, yes, they'll mean that's less capital, but we're not going to know for one to two quarters, you know, the real growth in the pudding, but we're willing to give it a shot and give these guys, you know, the best opportunity with our data, right? Because there's so much upside. If you know, if this team can you know, leverage their their expertise here, and when they get your data, is it mostly going to be post training, right? Fine tuning, so, so this is where I don't know yet. So we're just full this. We're an active conversation with them right now. I there was some legal paper replying around this morning on email that that I was, I was looking at, so we're looking to get in some sort of partnership deal with them right now. And this is one of the open points that we need clarification.
and, yeah. And Armin also met some members of our team. We have two. We have a pair of Stanford engineers. One of them worked on large scale, you know, AI systems at Microsoft. The other actually worked at Facebook as well before coming here. And they, you know, they had done some diligence on these guys, and they're, they left very, very impressed with, with both of them, that these are highly, highly skilled, competent people. And we've met a bunch of these teams so far because, like, we want an ecosystem for this to exist, right? Like, we want to be these guys, customers and partners, right? So, like, you know, we've talked with a bunch of these folks. This is the first team that these guys have actually said, Hey, these guys are really high caliber. So apart from the people validation point, I we haven't been able to dig into the how on the on the pre training, there's, there's, you know, it's kind of their special sauce. I think so. So without getting them to disclose their secret sauce, like, what evidence is? Can we try to capture, to know, to get kind of some comfort that there? Yeah, because their pre training is indeed scalable. I mean, evidence is a million very dependent ones. Yeah, I would say, So, what are we I'll now answer as a potential customer fee for spot, right? We got really excited by these guys, because, like, you know, we've been, we've been thinking about this stuff for a long time, and, you know, we do think there'll be a GPT moment for these, you know, born multimodal models all that, right? Like, for vision and, you know, for the physical world. So like for us, right? Like we, you know, we looked at chameleon, right? We saw what chameleon was doing. It's an open source version of borough. It's the only viable open source version of borough right now. So, like for us, we have very little downside to get in a partnership with them, start sharing some data, tell them the use cases, where's the revenue coming from, right? Like, where's the where's the consumption coming from, and then work with them to steer these models towards these use cases, right? So, like, for us, there's really high upside, really little downside to partner with them, but we've internally said we're not really going to know until, I think at one to two quarters, kind of that first intermediate checkpoints come out in the model. Because this is one of those things where, yes, they they may need less capital than a traditional, you know, like, you know, some of these other approaches, right? Skilled, you know, brought in 300 million, and depth was at a few 100 million before the million before they got scooped up. Like, you know, yes, they'll mean that's less capital, but we're not going to know for one to two quarters, you know, the real growth in the pudding, but we're willing to give it a shot and give these guys, you know, the best opportunity with our data, right? Because there's so much upside. If you know, if this team can you know, leverage their their expertise here, and when they get your data, is it mostly going to be post training, right? Fine tuning, so, so this is where I don't know yet. So we're just full this. We're an active conversation with them right now. I there was some legal paper replying around this morning on email that that I was, I was looking at, so we're looking to get in some sort of partnership deal with them right now. And this is one of the open points that we need clarification.
S Speaker 123:39says it seems that mostly what sounds to me, reading from their partnership agreement is that a lot of this data, and we'll only know when they drop that version 0.1 to you in December, is alignment. So supposedly this is their so that
says it seems that mostly what sounds to me, reading from their partnership agreement is that a lot of this data, and we'll only know when they drop that version 0.1 to you in December, is alignment. So supposedly this is their so that
says it seems that mostly what sounds to me, reading from their partnership agreement is that a lot of this data, and we'll only know when they drop that version 0.1 to you in December, is alignment. So supposedly this is their so that
says it seems that mostly what sounds to me, reading from their partnership agreement is that a lot of this data, and we'll only know when they drop that version 0.1 to you in December, is alignment. So supposedly this is their so that
S Speaker 123:56And just to be clear, this is a separate dog. So we, we've drafted a separate dog with them right now. So we do have the partnership doc. This is, like, we have to get under NDA, and there's, there are all these other things we need to do, but, but, yeah, maybe it's starting with pro training, post training. And this is, I mean, if I'm being really, like, this is, this was a big risk. Question that we have internally is, you know, a car wash is going to have such bespoke things, right? Like, if a belt doesn't work, or if the brushes don't work, and there's, like, there needs to be some perception, there needs to be some reasoning, and there needs to be some control. And like, I'm like, Where the heck in the public internet is that information could be right? So, like, that's one of those things where, you know, we're open to sharing more with them if it gets these models to, you know, where we can benefit our customers with what they're asking us for. But it's one of those things where, like, I'll, I'll believe it when I when I see it, but I'm really bullish on the team. So, like, I'm not sure it'll only be post training, because, like, I mean, I've tried googling for, you know, a lot of these bespoke use cases that our customers ask us for, but this is such latent, gritty blue collar industry knowledge, like, you're not going to find it very easily online. So maybe another way to ask the same question I asked initially, like, without human in the loop. But if someone get these car wash data, is there, is there a self sufficient way to extract label out of those videos? My understanding is in pre training, a lot of the data that the training modality is unsupervised, right? And post training it'll be supervised, right, where you fine tune in line. And I feel like, you know, going going to your point on the labels. I mean, one way with spawn our customers now use us. What is it like? 75 times a month, every user, right? So we do have a lot of consumption data, right? And you know, we also know the workflows they do after they get our video. So there could be a way, just in them, using our product, that we're actually generating a crap ton of labels, right? That we can just pair with the brains. And I'm now thinking very poor, right? We don't do any of that now, right? But, but, I mean, that's something that we
And just to be clear, this is a separate dog. So we, we've drafted a separate dog with them right now. So we do have the partnership doc. This is, like, we have to get under NDA, and there's, there are all these other things we need to do, but, but, yeah, maybe it's starting with pro training, post training. And this is, I mean, if I'm being really, like, this is, this was a big risk. Question that we have internally is, you know, a car wash is going to have such bespoke things, right? Like, if a belt doesn't work, or if the brushes don't work, and there's, like, there needs to be some perception, there needs to be some reasoning, and there needs to be some control. And like, I'm like, Where the heck in the public internet is that information could be right? So, like, that's one of those things where, you know, we're open to sharing more with them if it gets these models to, you know, where we can benefit our customers with what they're asking us for. But it's one of those things where, like, I'll, I'll believe it when I when I see it, but I'm really bullish on the team. So, like, I'm not sure it'll only be post training, because, like, I mean, I've tried googling for, you know, a lot of these bespoke use cases that our customers ask us for, but this is such latent, gritty blue collar industry knowledge, like, you're not going to find it very easily online. So maybe another way to ask the same question I asked initially, like, without human in the loop. But if someone get these car wash data, is there, is there a self sufficient way to extract label out of those videos? My understanding is in pre training, a lot of the data that the training modality is unsupervised, right? And post training it'll be supervised, right, where you fine tune in line. And I feel like, you know, going going to your point on the labels. I mean, one way with spawn our customers now use us. What is it like? 75 times a month, every user, right? So we do have a lot of consumption data, right? And you know, we also know the workflows they do after they get our video. So there could be a way, just in them, using our product, that we're actually generating a crap ton of labels, right? That we can just pair with the brains. And I'm now thinking very poor, right? We don't do any of that now, right? But, but, I mean, that's something that we
And just to be clear, this is a separate dog. So we, we've drafted a separate dog with them right now. So we do have the partnership doc. This is, like, we have to get under NDA, and there's, there are all these other things we need to do, but, but, yeah, maybe it's starting with pro training, post training. And this is, I mean, if I'm being really, like, this is, this was a big risk. Question that we have internally is, you know, a car wash is going to have such bespoke things, right? Like, if a belt doesn't work, or if the brushes don't work, and there's, like, there needs to be some perception, there needs to be some reasoning, and there needs to be some control. And like, I'm like, Where the heck in the public internet is that information could be right? So, like, that's one of those things where, you know, we're open to sharing more with them if it gets these models to, you know, where we can benefit our customers with what they're asking us for. But it's one of those things where, like, I'll, I'll believe it when I when I see it, but I'm really bullish on the team. So, like, I'm not sure it'll only be post training, because, like, I mean, I've tried googling for, you know, a lot of these bespoke use cases that our customers ask us for, but this is such latent, gritty blue collar industry knowledge, like, you're not going to find it very easily online. So maybe another way to ask the same question I asked initially, like, without human in the loop. But if someone get these car wash data, is there, is there a self sufficient way to extract label out of those videos? My understanding is in pre training, a lot of the data that the training modality is unsupervised, right? And post training it'll be supervised, right, where you fine tune in line. And I feel like, you know, going going to your point on the labels. I mean, one way with spawn our customers now use us. What is it like? 75 times a month, every user, right? So we do have a lot of consumption data, right? And you know, we also know the workflows they do after they get our video. So there could be a way, just in them, using our product, that we're actually generating a crap ton of labels, right? That we can just pair with the brains. And I'm now thinking very poor, right? We don't do any of that now, right? But, but, I mean, that's something that we
And just to be clear, this is a separate dog. So we, we've drafted a separate dog with them right now. So we do have the partnership doc. This is, like, we have to get under NDA, and there's, there are all these other things we need to do, but, but, yeah, maybe it's starting with pro training, post training. And this is, I mean, if I'm being really, like, this is, this was a big risk. Question that we have internally is, you know, a car wash is going to have such bespoke things, right? Like, if a belt doesn't work, or if the brushes don't work, and there's, like, there needs to be some perception, there needs to be some reasoning, and there needs to be some control. And like, I'm like, Where the heck in the public internet is that information could be right? So, like, that's one of those things where, you know, we're open to sharing more with them if it gets these models to, you know, where we can benefit our customers with what they're asking us for. But it's one of those things where, like, I'll, I'll believe it when I when I see it, but I'm really bullish on the team. So, like, I'm not sure it'll only be post training, because, like, I mean, I've tried googling for, you know, a lot of these bespoke use cases that our customers ask us for, but this is such latent, gritty blue collar industry knowledge, like, you're not going to find it very easily online. So maybe another way to ask the same question I asked initially, like, without human in the loop. But if someone get these car wash data, is there, is there a self sufficient way to extract label out of those videos? My understanding is in pre training, a lot of the data that the training modality is unsupervised, right? And post training it'll be supervised, right, where you fine tune in line. And I feel like, you know, going going to your point on the labels. I mean, one way with spawn our customers now use us. What is it like? 75 times a month, every user, right? So we do have a lot of consumption data, right? And you know, we also know the workflows they do after they get our video. So there could be a way, just in them, using our product, that we're actually generating a crap ton of labels, right? That we can just pair with the brains. And I'm now thinking very poor, right? We don't do any of that now, right? But, but, I mean, that's something that we
26:19someone using is still, it's a form of human in the loop. That's exactly
someone using is still, it's a form of human in the loop. That's exactly
someone using is still, it's a form of human in the loop. That's exactly
someone using is still, it's a form of human in the loop. That's exactly
S Speaker 126:24right, yeah, yeah. And maybe these guys do have a synthetic labeling strategy. A lot of these foundation model companies are taking that playbook now, right? So, you know, just, you know, there could be a way to use synthetic data labeling services that are starting to come up to maybe get around the point I brought up.
right, yeah, yeah. And maybe these guys do have a synthetic labeling strategy. A lot of these foundation model companies are taking that playbook now, right? So, you know, just, you know, there could be a way to use synthetic data labeling services that are starting to come up to maybe get around the point I brought up.
right, yeah, yeah. And maybe these guys do have a synthetic labeling strategy. A lot of these foundation model companies are taking that playbook now, right? So, you know, just, you know, there could be a way to use synthetic data labeling services that are starting to come up to maybe get around the point I brought up.
right, yeah, yeah. And maybe these guys do have a synthetic labeling strategy. A lot of these foundation model companies are taking that playbook now, right? So, you know, just, you know, there could be a way to use synthetic data labeling services that are starting to come up to maybe get around the point I brought up.
26:47then you also getting the chicken the egg issue, right? If
then you also getting the chicken the egg issue, right? If
then you also getting the chicken the egg issue, right? If
then you also getting the chicken the egg issue, right? If
S Speaker 128:44me know. And thanks for the introduction. We're pretty excited by that. Certainly, there are questions and risks, but you know, as a customer, you know, there's little downside for us, you know, to engage with them.
me know. And thanks for the introduction. We're pretty excited by that. Certainly, there are questions and risks, but you know, as a customer, you know, there's little downside for us, you know, to engage with them.
me know. And thanks for the introduction. We're pretty excited by that. Certainly, there are questions and risks, but you know, as a customer, you know, there's little downside for us, you know, to engage with them.
me know. And thanks for the introduction. We're pretty excited by that. Certainly, there are questions and risks, but you know, as a customer, you know, there's little downside for us, you know, to engage with them.
28:55Yeah, cool. Thanks, man. Thank you. You. Okay, so
S Speaker 131:29they basically have to apply the same technique, if you will, but for physical stuff, right? That's
they basically have to apply the same technique, if you will, but for physical stuff, right? That's
they basically have to apply the same technique, if you will, but for physical stuff, right? That's
they basically have to apply the same technique, if you will, but for physical stuff, right? That's
S Speaker 131:38So maybe we can touch instead of, I'm not going to talk about product technology in more detail now, unless people have questions, a few things around what we've done is, so this chameleon paper. I wanted to make sure that Armin was the main guy behind the chameleon paper, so I called people at meta. I know enough people at fair. So this guy, Armin is the main guy. He ran the team for chameleon. Akshat actually worked very closely with Timon X Qualcomm guy on this Ray Ban deploying edge AI model. I got really good feedback on Akshat as well. So both of them from up from a technology. And also these guys are not just built models. They've also shipped models. From that perspective, I got good feedback from their former colleagues at meta. Now what we've seen is startups with similar backgrounds, like cartesia, for example, I got feedback again, cartesia is that state space model company. They're starting to do really good. They're eating into I have several customers I talked to their customers that are moving from 11 labs to Cartesian. So cartesia is doing really well. Quinn, if you remember that, Luma AI, the might dauber company, remember, they were going nowhere because they were doing models and everything and everything, yeah, early January this year, they pivoted to doing video generation model. So the key was it was a very, very strong team, and then they pivoted to doing this video generation model right now and then. So they launched literally just two months ago. They're at 14 to 16 million ARR around. So these teams are strong, some of these teams that are strong, they're able to scale well, we don't necessarily get allocations in these early rounds, but if you get allocations, and then some of these can can turn out to be big outcomes eventually. Can you just just quickly understand the word in meta and for the very smart, but how you know what exactly I mean, and also probably quick researchers, but did they mean how similar they were? Do they manage teams. I mean, what was the role? Yeah,
So maybe we can touch instead of, I'm not going to talk about product technology in more detail now, unless people have questions, a few things around what we've done is, so this chameleon paper. I wanted to make sure that Armin was the main guy behind the chameleon paper, so I called people at meta. I know enough people at fair. So this guy, Armin is the main guy. He ran the team for chameleon. Akshat actually worked very closely with Timon X Qualcomm guy on this Ray Ban deploying edge AI model. I got really good feedback on Akshat as well. So both of them from up from a technology. And also these guys are not just built models. They've also shipped models. From that perspective, I got good feedback from their former colleagues at meta. Now what we've seen is startups with similar backgrounds, like cartesia, for example, I got feedback again, cartesia is that state space model company. They're starting to do really good. They're eating into I have several customers I talked to their customers that are moving from 11 labs to Cartesian. So cartesia is doing really well. Quinn, if you remember that, Luma AI, the might dauber company, remember, they were going nowhere because they were doing models and everything and everything, yeah, early January this year, they pivoted to doing video generation model. So the key was it was a very, very strong team, and then they pivoted to doing this video generation model right now and then. So they launched literally just two months ago. They're at 14 to 16 million ARR around. So these teams are strong, some of these teams that are strong, they're able to scale well, we don't necessarily get allocations in these early rounds, but if you get allocations, and then some of these can can turn out to be big outcomes eventually. Can you just just quickly understand the word in meta and for the very smart, but how you know what exactly I mean, and also probably quick researchers, but did they mean how similar they were? Do they manage teams. I mean, what was the role? Yeah,
So maybe we can touch instead of, I'm not going to talk about product technology in more detail now, unless people have questions, a few things around what we've done is, so this chameleon paper. I wanted to make sure that Armin was the main guy behind the chameleon paper, so I called people at meta. I know enough people at fair. So this guy, Armin is the main guy. He ran the team for chameleon. Akshat actually worked very closely with Timon X Qualcomm guy on this Ray Ban deploying edge AI model. I got really good feedback on Akshat as well. So both of them from up from a technology. And also these guys are not just built models. They've also shipped models. From that perspective, I got good feedback from their former colleagues at meta. Now what we've seen is startups with similar backgrounds, like cartesia, for example, I got feedback again, cartesia is that state space model company. They're starting to do really good. They're eating into I have several customers I talked to their customers that are moving from 11 labs to Cartesian. So cartesia is doing really well. Quinn, if you remember that, Luma AI, the might dauber company, remember, they were going nowhere because they were doing models and everything and everything, yeah, early January this year, they pivoted to doing video generation model. So the key was it was a very, very strong team, and then they pivoted to doing this video generation model right now and then. So they launched literally just two months ago. They're at 14 to 16 million ARR around. So these teams are strong, some of these teams that are strong, they're able to scale well, we don't necessarily get allocations in these early rounds, but if you get allocations, and then some of these can can turn out to be big outcomes eventually. Can you just just quickly understand the word in meta and for the very smart, but how you know what exactly I mean, and also probably quick researchers, but did they mean how similar they were? Do they manage teams. I mean, what was the role? Yeah,
So maybe we can touch instead of, I'm not going to talk about product technology in more detail now, unless people have questions, a few things around what we've done is, so this chameleon paper. I wanted to make sure that Armin was the main guy behind the chameleon paper, so I called people at meta. I know enough people at fair. So this guy, Armin is the main guy. He ran the team for chameleon. Akshat actually worked very closely with Timon X Qualcomm guy on this Ray Ban deploying edge AI model. I got really good feedback on Akshat as well. So both of them from up from a technology. And also these guys are not just built models. They've also shipped models. From that perspective, I got good feedback from their former colleagues at meta. Now what we've seen is startups with similar backgrounds, like cartesia, for example, I got feedback again, cartesia is that state space model company. They're starting to do really good. They're eating into I have several customers I talked to their customers that are moving from 11 labs to Cartesian. So cartesia is doing really well. Quinn, if you remember that, Luma AI, the might dauber company, remember, they were going nowhere because they were doing models and everything and everything, yeah, early January this year, they pivoted to doing video generation model. So the key was it was a very, very strong team, and then they pivoted to doing this video generation model right now and then. So they launched literally just two months ago. They're at 14 to 16 million ARR around. So these teams are strong, some of these teams that are strong, they're able to scale well, we don't necessarily get allocations in these early rounds, but if you get allocations, and then some of these can can turn out to be big outcomes eventually. Can you just just quickly understand the word in meta and for the very smart, but how you know what exactly I mean, and also probably quick researchers, but did they mean how similar they were? Do they manage teams. I mean, what was the role? Yeah,
S Speaker 134:10l7 is at meta is principal, and even Akshat was l7 both of them were l sevens. L8 is a director, which is a manager position over there at meta. Director at meta is like SVP from from a seniority. I mean, they have a VP, they don't have SVPs. They have VP and
l7 is at meta is principal, and even Akshat was l7 both of them were l sevens. L8 is a director, which is a manager position over there at meta. Director at meta is like SVP from from a seniority. I mean, they have a VP, they don't have SVPs. They have VP and
l7 is at meta is principal, and even Akshat was l7 both of them were l sevens. L8 is a director, which is a manager position over there at meta. Director at meta is like SVP from from a seniority. I mean, they have a VP, they don't have SVPs. They have VP and
l7 is at meta is principal, and even Akshat was l7 both of them were l sevens. L8 is a director, which is a manager position over there at meta. Director at meta is like SVP from from a seniority. I mean, they have a VP, they don't have SVPs. They have VP and
34:42then and then just report to the C suite the level.
then and then just report to the C suite the level.
then and then just report to the C suite the level.
then and then just report to the C suite the level.
S Speaker 134:49So they're they're senior people. They're l7 both l sevens at Meadow. And Akshat was IC. This guy was a manager as well.
So they're they're senior people. They're l7 both l sevens at Meadow. And Akshat was IC. This guy was a manager as well.
So they're they're senior people. They're l7 both l sevens at Meadow. And Akshat was IC. This guy was a manager as well.
So they're they're senior people. They're l7 both l sevens at Meadow. And Akshat was IC. This guy was a manager as well.
S Speaker 135:08That's the question. Were they more like, look at the principal part of like, very smart guys develop something, or did you really run an operation? So this guy ran the team. Armen ran the team that released chameleon, and also contributed to Lama three, so they shipped it. Akshat worked on the AI models for Ray Ban meta, Ray Ban glasses. So he was responsible for shipping the models that run on Ray Ban meta classes. So I got the names right. Armen is the CEO Akshat. CEO Akshat is the CTO, however, so the other thing is, both of them not PhDs. So these are not PhDs. These are self taught AI guys. So I'm not reading too much into it, but I'm saying is, it's not like they were pure research. Background from when they came, when they joined the company, they were always shipping products.
That's the question. Were they more like, look at the principal part of like, very smart guys develop something, or did you really run an operation? So this guy ran the team. Armen ran the team that released chameleon, and also contributed to Lama three, so they shipped it. Akshat worked on the AI models for Ray Ban meta, Ray Ban glasses. So he was responsible for shipping the models that run on Ray Ban meta classes. So I got the names right. Armen is the CEO Akshat. CEO Akshat is the CTO, however, so the other thing is, both of them not PhDs. So these are not PhDs. These are self taught AI guys. So I'm not reading too much into it, but I'm saying is, it's not like they were pure research. Background from when they came, when they joined the company, they were always shipping products.
That's the question. Were they more like, look at the principal part of like, very smart guys develop something, or did you really run an operation? So this guy ran the team. Armen ran the team that released chameleon, and also contributed to Lama three, so they shipped it. Akshat worked on the AI models for Ray Ban meta, Ray Ban glasses. So he was responsible for shipping the models that run on Ray Ban meta classes. So I got the names right. Armen is the CEO Akshat. CEO Akshat is the CTO, however, so the other thing is, both of them not PhDs. So these are not PhDs. These are self taught AI guys. So I'm not reading too much into it, but I'm saying is, it's not like they were pure research. Background from when they came, when they joined the company, they were always shipping products.
That's the question. Were they more like, look at the principal part of like, very smart guys develop something, or did you really run an operation? So this guy ran the team. Armen ran the team that released chameleon, and also contributed to Lama three, so they shipped it. Akshat worked on the AI models for Ray Ban meta, Ray Ban glasses. So he was responsible for shipping the models that run on Ray Ban meta classes. So I got the names right. Armen is the CEO Akshat. CEO Akshat is the CTO, however, so the other thing is, both of them not PhDs. So these are not PhDs. These are self taught AI guys. So I'm not reading too much into it, but I'm saying is, it's not like they were pure research. Background from when they came, when they joined the company, they were always shipping products.
S Speaker 136:30I think we can talk about, so maybe instead of I got a bunch of slides. What are the key questions that we have we can talk about because we've already learned about the product. It's early. Stage, seed, stage, a few pointers, few messages that I would say is like, why consider investing? So there, I think let's talk about the risk. It's there's product risk, for sure, this is still r&d, but like Mistral was r&d and tropic was r&d, sakhana was r&d, remember as akana as well, the Japan, Japanese company we talked to. So even there now at a billion dollar valuation, but when we talked to them, they didn't have a model, any of that, right? So they were going to release a model in 10 months, which they did, and they released the model, and now they're at $1.5 million valuation.
I think we can talk about, so maybe instead of I got a bunch of slides. What are the key questions that we have we can talk about because we've already learned about the product. It's early. Stage, seed, stage, a few pointers, few messages that I would say is like, why consider investing? So there, I think let's talk about the risk. It's there's product risk, for sure, this is still r&d, but like Mistral was r&d and tropic was r&d, sakhana was r&d, remember as akana as well, the Japan, Japanese company we talked to. So even there now at a billion dollar valuation, but when we talked to them, they didn't have a model, any of that, right? So they were going to release a model in 10 months, which they did, and they released the model, and now they're at $1.5 million valuation.
I think we can talk about, so maybe instead of I got a bunch of slides. What are the key questions that we have we can talk about because we've already learned about the product. It's early. Stage, seed, stage, a few pointers, few messages that I would say is like, why consider investing? So there, I think let's talk about the risk. It's there's product risk, for sure, this is still r&d, but like Mistral was r&d and tropic was r&d, sakhana was r&d, remember as akana as well, the Japan, Japanese company we talked to. So even there now at a billion dollar valuation, but when we talked to them, they didn't have a model, any of that, right? So they were going to release a model in 10 months, which they did, and they released the model, and now they're at $1.5 million valuation.
I think we can talk about, so maybe instead of I got a bunch of slides. What are the key questions that we have we can talk about because we've already learned about the product. It's early. Stage, seed, stage, a few pointers, few messages that I would say is like, why consider investing? So there, I think let's talk about the risk. It's there's product risk, for sure, this is still r&d, but like Mistral was r&d and tropic was r&d, sakhana was r&d, remember as akana as well, the Japan, Japanese company we talked to. So even there now at a billion dollar valuation, but when we talked to them, they didn't have a model, any of that, right? So they were going to release a model in 10 months, which they did, and they released the model, and now they're at $1.5 million valuation.
S Speaker 137:19their capital requirements for this is fine, the first model is going to take $20 million to train. It's all GPU cost. So 2.2 they've negotiated with somebody for 2.2 dollars an hour to rent the GPUs. The second model is going to take $50 million to train. So hence, we need a tier one investor at this stage of this company. We've told them, Carlos, and I would have told them, they have agreed. We don't know their terms yet. They're in the process of finalizing allocations and getting some term sheets and all of that. But they know this too, and they agree with this. One of the risks that Tanuj mentioned, and I agree 100% is that this is not the same as the cognitive AI model, which is you hosted in the cloud and you expose it as an API. You This is a much more involved sales motion than hosting something in the cloud. Having said that, these guys are also going to host something in the cloud, let's say, for example, you want to create YouTube shorts or Tiktok videos, and then they can just host a model which you input, like a 20 minute video, it converts into a 32nd video, of interesting video that you say they're gonna do this. Yes, that's just to get the I mean, essentially, just to get excitement going. What does this have to do with physical world? It has So the example is that today, when you have to create highlights of any sort of video. You don't have a clear understanding of what a good highlight of a video should be in a 20 minute clip, right? So imagine you're trying to build a trailer from a 20 minute clip, right? So the trailer today, the way it works is people handpick interesting parts of those videos. The idea is that, can I just automatic, automate that in some way, shape or form? And so for those, what they'll do is they won't actually make it, make a tool such that the end user will be able to do it end to end. They will make these models available to other companies, like hey, Gen and bid and a bunch of others that are doing this, who can use these models and expose it to their end users to do this. So that's just to get the excitement going. But having said that, the key is physical AI, and this is a much more involved sales motion. So, and they haven't done this, go to market for hardware space where they're selling to, you know, companies like Mercado and spa than all of this before. So basically, so can you clarify the concept physical AI versus cognitive AI? A little bit more this is more about you not just understand recognize the objects in there, but also understand the underlying logic, like what is going on there, so underlying, which is as in, so, for example, the concept of friction or concept of gravity, a vision language model doesn't understand that concept. Vision. Language model understands that, and I can see an apple falling from a tree, but it doesn't understand it's falling from the tree because of gravity. So that's a fundamental understanding and intrinsic relationship between understanding what causality and understanding these concepts of gravity and friction and a lot more detail. And what does that enable this? I um, so for example. So they've got a bunch of different examples, right? So if you just take a look at some like, like temporal event sequences, which is list the steps shown in this cooking video, and then you evolve that for level one, which is, these are all their levels of intelligence, spatial and understanding intelligence. So any of these use cases beyond what people traditionally talk about video, understanding capabilities correct, like understanding what people are fighting someone climbing the wall, and that is primarily done so the accuracy of that, which is the leading company in that space today, is 12 laps. This is what Tanuj was referring to as well. So these guys have tried 12 laps this video, understanding, and it is very rudimentary, which is, it's not able to actually detect, like, the accuracy of even detecting oil spills, which was something that they wanted in a car wash scenario. For that was very, very limited. So video understanding hasn't been solved because of some of these reasons. So you've got a bunch of models today that are doing video understanding, and that's done today. The latest and greatest technology for that is moved from resnets and CNNs to vision language models, which is vision transformers, and also it's mostly case by case. It is very so you have to train it on a task by task basis. Every single one of them, no for perception. Are they going to go beyond video understanding. They're going to have general video understanding, and they will understand the physics behind those events. That's the
their capital requirements for this is fine, the first model is going to take $20 million to train. It's all GPU cost. So 2.2 they've negotiated with somebody for 2.2 dollars an hour to rent the GPUs. The second model is going to take $50 million to train. So hence, we need a tier one investor at this stage of this company. We've told them, Carlos, and I would have told them, they have agreed. We don't know their terms yet. They're in the process of finalizing allocations and getting some term sheets and all of that. But they know this too, and they agree with this. One of the risks that Tanuj mentioned, and I agree 100% is that this is not the same as the cognitive AI model, which is you hosted in the cloud and you expose it as an API. You This is a much more involved sales motion than hosting something in the cloud. Having said that, these guys are also going to host something in the cloud, let's say, for example, you want to create YouTube shorts or Tiktok videos, and then they can just host a model which you input, like a 20 minute video, it converts into a 32nd video, of interesting video that you say they're gonna do this. Yes, that's just to get the I mean, essentially, just to get excitement going. What does this have to do with physical world? It has So the example is that today, when you have to create highlights of any sort of video. You don't have a clear understanding of what a good highlight of a video should be in a 20 minute clip, right? So imagine you're trying to build a trailer from a 20 minute clip, right? So the trailer today, the way it works is people handpick interesting parts of those videos. The idea is that, can I just automatic, automate that in some way, shape or form? And so for those, what they'll do is they won't actually make it, make a tool such that the end user will be able to do it end to end. They will make these models available to other companies, like hey, Gen and bid and a bunch of others that are doing this, who can use these models and expose it to their end users to do this. So that's just to get the excitement going. But having said that, the key is physical AI, and this is a much more involved sales motion. So, and they haven't done this, go to market for hardware space where they're selling to, you know, companies like Mercado and spa than all of this before. So basically, so can you clarify the concept physical AI versus cognitive AI? A little bit more this is more about you not just understand recognize the objects in there, but also understand the underlying logic, like what is going on there, so underlying, which is as in, so, for example, the concept of friction or concept of gravity, a vision language model doesn't understand that concept. Vision. Language model understands that, and I can see an apple falling from a tree, but it doesn't understand it's falling from the tree because of gravity. So that's a fundamental understanding and intrinsic relationship between understanding what causality and understanding these concepts of gravity and friction and a lot more detail. And what does that enable this? I um, so for example. So they've got a bunch of different examples, right? So if you just take a look at some like, like temporal event sequences, which is list the steps shown in this cooking video, and then you evolve that for level one, which is, these are all their levels of intelligence, spatial and understanding intelligence. So any of these use cases beyond what people traditionally talk about video, understanding capabilities correct, like understanding what people are fighting someone climbing the wall, and that is primarily done so the accuracy of that, which is the leading company in that space today, is 12 laps. This is what Tanuj was referring to as well. So these guys have tried 12 laps this video, understanding, and it is very rudimentary, which is, it's not able to actually detect, like, the accuracy of even detecting oil spills, which was something that they wanted in a car wash scenario. For that was very, very limited. So video understanding hasn't been solved because of some of these reasons. So you've got a bunch of models today that are doing video understanding, and that's done today. The latest and greatest technology for that is moved from resnets and CNNs to vision language models, which is vision transformers, and also it's mostly case by case. It is very so you have to train it on a task by task basis. Every single one of them, no for perception. Are they going to go beyond video understanding. They're going to have general video understanding, and they will understand the physics behind those events. That's the
their capital requirements for this is fine, the first model is going to take $20 million to train. It's all GPU cost. So 2.2 they've negotiated with somebody for 2.2 dollars an hour to rent the GPUs. The second model is going to take $50 million to train. So hence, we need a tier one investor at this stage of this company. We've told them, Carlos, and I would have told them, they have agreed. We don't know their terms yet. They're in the process of finalizing allocations and getting some term sheets and all of that. But they know this too, and they agree with this. One of the risks that Tanuj mentioned, and I agree 100% is that this is not the same as the cognitive AI model, which is you hosted in the cloud and you expose it as an API. You This is a much more involved sales motion than hosting something in the cloud. Having said that, these guys are also going to host something in the cloud, let's say, for example, you want to create YouTube shorts or Tiktok videos, and then they can just host a model which you input, like a 20 minute video, it converts into a 32nd video, of interesting video that you say they're gonna do this. Yes, that's just to get the I mean, essentially, just to get excitement going. What does this have to do with physical world? It has So the example is that today, when you have to create highlights of any sort of video. You don't have a clear understanding of what a good highlight of a video should be in a 20 minute clip, right? So imagine you're trying to build a trailer from a 20 minute clip, right? So the trailer today, the way it works is people handpick interesting parts of those videos. The idea is that, can I just automatic, automate that in some way, shape or form? And so for those, what they'll do is they won't actually make it, make a tool such that the end user will be able to do it end to end. They will make these models available to other companies, like hey, Gen and bid and a bunch of others that are doing this, who can use these models and expose it to their end users to do this. So that's just to get the excitement going. But having said that, the key is physical AI, and this is a much more involved sales motion. So, and they haven't done this, go to market for hardware space where they're selling to, you know, companies like Mercado and spa than all of this before. So basically, so can you clarify the concept physical AI versus cognitive AI? A little bit more this is more about you not just understand recognize the objects in there, but also understand the underlying logic, like what is going on there, so underlying, which is as in, so, for example, the concept of friction or concept of gravity, a vision language model doesn't understand that concept. Vision. Language model understands that, and I can see an apple falling from a tree, but it doesn't understand it's falling from the tree because of gravity. So that's a fundamental understanding and intrinsic relationship between understanding what causality and understanding these concepts of gravity and friction and a lot more detail. And what does that enable this? I um, so for example. So they've got a bunch of different examples, right? So if you just take a look at some like, like temporal event sequences, which is list the steps shown in this cooking video, and then you evolve that for level one, which is, these are all their levels of intelligence, spatial and understanding intelligence. So any of these use cases beyond what people traditionally talk about video, understanding capabilities correct, like understanding what people are fighting someone climbing the wall, and that is primarily done so the accuracy of that, which is the leading company in that space today, is 12 laps. This is what Tanuj was referring to as well. So these guys have tried 12 laps this video, understanding, and it is very rudimentary, which is, it's not able to actually detect, like, the accuracy of even detecting oil spills, which was something that they wanted in a car wash scenario. For that was very, very limited. So video understanding hasn't been solved because of some of these reasons. So you've got a bunch of models today that are doing video understanding, and that's done today. The latest and greatest technology for that is moved from resnets and CNNs to vision language models, which is vision transformers, and also it's mostly case by case. It is very so you have to train it on a task by task basis. Every single one of them, no for perception. Are they going to go beyond video understanding. They're going to have general video understanding, and they will understand the physics behind those events. That's the
their capital requirements for this is fine, the first model is going to take $20 million to train. It's all GPU cost. So 2.2 they've negotiated with somebody for 2.2 dollars an hour to rent the GPUs. The second model is going to take $50 million to train. So hence, we need a tier one investor at this stage of this company. We've told them, Carlos, and I would have told them, they have agreed. We don't know their terms yet. They're in the process of finalizing allocations and getting some term sheets and all of that. But they know this too, and they agree with this. One of the risks that Tanuj mentioned, and I agree 100% is that this is not the same as the cognitive AI model, which is you hosted in the cloud and you expose it as an API. You This is a much more involved sales motion than hosting something in the cloud. Having said that, these guys are also going to host something in the cloud, let's say, for example, you want to create YouTube shorts or Tiktok videos, and then they can just host a model which you input, like a 20 minute video, it converts into a 32nd video, of interesting video that you say they're gonna do this. Yes, that's just to get the I mean, essentially, just to get excitement going. What does this have to do with physical world? It has So the example is that today, when you have to create highlights of any sort of video. You don't have a clear understanding of what a good highlight of a video should be in a 20 minute clip, right? So imagine you're trying to build a trailer from a 20 minute clip, right? So the trailer today, the way it works is people handpick interesting parts of those videos. The idea is that, can I just automatic, automate that in some way, shape or form? And so for those, what they'll do is they won't actually make it, make a tool such that the end user will be able to do it end to end. They will make these models available to other companies, like hey, Gen and bid and a bunch of others that are doing this, who can use these models and expose it to their end users to do this. So that's just to get the excitement going. But having said that, the key is physical AI, and this is a much more involved sales motion. So, and they haven't done this, go to market for hardware space where they're selling to, you know, companies like Mercado and spa than all of this before. So basically, so can you clarify the concept physical AI versus cognitive AI? A little bit more this is more about you not just understand recognize the objects in there, but also understand the underlying logic, like what is going on there, so underlying, which is as in, so, for example, the concept of friction or concept of gravity, a vision language model doesn't understand that concept. Vision. Language model understands that, and I can see an apple falling from a tree, but it doesn't understand it's falling from the tree because of gravity. So that's a fundamental understanding and intrinsic relationship between understanding what causality and understanding these concepts of gravity and friction and a lot more detail. And what does that enable this? I um, so for example. So they've got a bunch of different examples, right? So if you just take a look at some like, like temporal event sequences, which is list the steps shown in this cooking video, and then you evolve that for level one, which is, these are all their levels of intelligence, spatial and understanding intelligence. So any of these use cases beyond what people traditionally talk about video, understanding capabilities correct, like understanding what people are fighting someone climbing the wall, and that is primarily done so the accuracy of that, which is the leading company in that space today, is 12 laps. This is what Tanuj was referring to as well. So these guys have tried 12 laps this video, understanding, and it is very rudimentary, which is, it's not able to actually detect, like, the accuracy of even detecting oil spills, which was something that they wanted in a car wash scenario. For that was very, very limited. So video understanding hasn't been solved because of some of these reasons. So you've got a bunch of models today that are doing video understanding, and that's done today. The latest and greatest technology for that is moved from resnets and CNNs to vision language models, which is vision transformers, and also it's mostly case by case. It is very so you have to train it on a task by task basis. Every single one of them, no for perception. Are they going to go beyond video understanding. They're going to have general video understanding, and they will understand the physics behind those events. That's the
S Speaker 144:37can they go and sell to each one of these industries, which, in itself, is a big, big challenge that I'm worried less about. This part is, I think if they can truly build this general purpose foundation model, then adapting to future cases, it's easy, right? But it's assuming you already have the general purpose model. They can adapt. Because otherwise, if you don't, unless you never be exposed to certain industry. Now we're talking about you have a gap in the general foundational model. Then you go back to the case of more like hey, going to individual K verticals and and now you just building one vertical at attack by pre training one vertical attack, not just adapting to it. So let's assume Albert, I think fundamentally, they're going for not pre training for individual tasks. However, the problem is that any mistake that they have during the pre training phase as they embark on this journey is a very costly mistake.
can they go and sell to each one of these industries, which, in itself, is a big, big challenge that I'm worried less about. This part is, I think if they can truly build this general purpose foundation model, then adapting to future cases, it's easy, right? But it's assuming you already have the general purpose model. They can adapt. Because otherwise, if you don't, unless you never be exposed to certain industry. Now we're talking about you have a gap in the general foundational model. Then you go back to the case of more like hey, going to individual K verticals and and now you just building one vertical at attack by pre training one vertical attack, not just adapting to it. So let's assume Albert, I think fundamentally, they're going for not pre training for individual tasks. However, the problem is that any mistake that they have during the pre training phase as they embark on this journey is a very costly mistake.
can they go and sell to each one of these industries, which, in itself, is a big, big challenge that I'm worried less about. This part is, I think if they can truly build this general purpose foundation model, then adapting to future cases, it's easy, right? But it's assuming you already have the general purpose model. They can adapt. Because otherwise, if you don't, unless you never be exposed to certain industry. Now we're talking about you have a gap in the general foundational model. Then you go back to the case of more like hey, going to individual K verticals and and now you just building one vertical at attack by pre training one vertical attack, not just adapting to it. So let's assume Albert, I think fundamentally, they're going for not pre training for individual tasks. However, the problem is that any mistake that they have during the pre training phase as they embark on this journey is a very costly mistake.
can they go and sell to each one of these industries, which, in itself, is a big, big challenge that I'm worried less about. This part is, I think if they can truly build this general purpose foundation model, then adapting to future cases, it's easy, right? But it's assuming you already have the general purpose model. They can adapt. Because otherwise, if you don't, unless you never be exposed to certain industry. Now we're talking about you have a gap in the general foundational model. Then you go back to the case of more like hey, going to individual K verticals and and now you just building one vertical at attack by pre training one vertical attack, not just adapting to it. So let's assume Albert, I think fundamentally, they're going for not pre training for individual tasks. However, the problem is that any mistake that they have during the pre training phase as they embark on this journey is a very costly mistake.
46:51of some of these, but that's how they're defined, which is,
of some of these, but that's how they're defined, which is,
of some of these, but that's how they're defined, which is,
of some of these, but that's how they're defined, which is,
S Speaker 146:59talk to the founder that if their fundamental purpose is to completely replace the visual language model, or to add on that layer as a special intelligence to make, let's say, any specific use cases of the
talk to the founder that if their fundamental purpose is to completely replace the visual language model, or to add on that layer as a special intelligence to make, let's say, any specific use cases of the
talk to the founder that if their fundamental purpose is to completely replace the visual language model, or to add on that layer as a special intelligence to make, let's say, any specific use cases of the
talk to the founder that if their fundamental purpose is to completely replace the visual language model, or to add on that layer as a special intelligence to make, let's say, any specific use cases of the
S Speaker 147:18I think the last thing they're going to replace so gradually, or maybe, maybe there's a middle step that add on that top, or just completely replace that as a final step. So here's the replacement. Yeah, so the time here. So perceptron one is going to get launched in per this timeline, in May next year. That's going to be replacing visual transformers for these types of use cases. That is l1 and l2 over here. And then from 26 and 27 onwards, it starts replacing for other types of use cases, and this copilot is essentially action, which is these models are able to now take action from just fundamentally a model perspective. So you are not going and pressing a button, or you are not going and calling an API to take an action. The model is taking the action for you. So that's the end goal. But right now, like, yeah, they will replace with their idea is to replace vision transformers for each one of these with subsequent models. Hey, Trish, do they have any thoughts on potentially apply that to autonomous driving. Very cool. Yes, they can apply to autonomous driving, but they know that selling into that is not easy. And the other thing, when I talked to him, he said that right now. I mean, they don't think anybody else has solved autonomous driving. And they know people at grok who are at Tesla now that are working on also per diffusion, and they were very bullish on Tesla's effort to go and solve it, autonomous driving.
I think the last thing they're going to replace so gradually, or maybe, maybe there's a middle step that add on that top, or just completely replace that as a final step. So here's the replacement. Yeah, so the time here. So perceptron one is going to get launched in per this timeline, in May next year. That's going to be replacing visual transformers for these types of use cases. That is l1 and l2 over here. And then from 26 and 27 onwards, it starts replacing for other types of use cases, and this copilot is essentially action, which is these models are able to now take action from just fundamentally a model perspective. So you are not going and pressing a button, or you are not going and calling an API to take an action. The model is taking the action for you. So that's the end goal. But right now, like, yeah, they will replace with their idea is to replace vision transformers for each one of these with subsequent models. Hey, Trish, do they have any thoughts on potentially apply that to autonomous driving. Very cool. Yes, they can apply to autonomous driving, but they know that selling into that is not easy. And the other thing, when I talked to him, he said that right now. I mean, they don't think anybody else has solved autonomous driving. And they know people at grok who are at Tesla now that are working on also per diffusion, and they were very bullish on Tesla's effort to go and solve it, autonomous driving.
I think the last thing they're going to replace so gradually, or maybe, maybe there's a middle step that add on that top, or just completely replace that as a final step. So here's the replacement. Yeah, so the time here. So perceptron one is going to get launched in per this timeline, in May next year. That's going to be replacing visual transformers for these types of use cases. That is l1 and l2 over here. And then from 26 and 27 onwards, it starts replacing for other types of use cases, and this copilot is essentially action, which is these models are able to now take action from just fundamentally a model perspective. So you are not going and pressing a button, or you are not going and calling an API to take an action. The model is taking the action for you. So that's the end goal. But right now, like, yeah, they will replace with their idea is to replace vision transformers for each one of these with subsequent models. Hey, Trish, do they have any thoughts on potentially apply that to autonomous driving. Very cool. Yes, they can apply to autonomous driving, but they know that selling into that is not easy. And the other thing, when I talked to him, he said that right now. I mean, they don't think anybody else has solved autonomous driving. And they know people at grok who are at Tesla now that are working on also per diffusion, and they were very bullish on Tesla's effort to go and solve it, autonomous driving.
I think the last thing they're going to replace so gradually, or maybe, maybe there's a middle step that add on that top, or just completely replace that as a final step. So here's the replacement. Yeah, so the time here. So perceptron one is going to get launched in per this timeline, in May next year. That's going to be replacing visual transformers for these types of use cases. That is l1 and l2 over here. And then from 26 and 27 onwards, it starts replacing for other types of use cases, and this copilot is essentially action, which is these models are able to now take action from just fundamentally a model perspective. So you are not going and pressing a button, or you are not going and calling an API to take an action. The model is taking the action for you. So that's the end goal. But right now, like, yeah, they will replace with their idea is to replace vision transformers for each one of these with subsequent models. Hey, Trish, do they have any thoughts on potentially apply that to autonomous driving. Very cool. Yes, they can apply to autonomous driving, but they know that selling into that is not easy. And the other thing, when I talked to him, he said that right now. I mean, they don't think anybody else has solved autonomous driving. And they know people at grok who are at Tesla now that are working on also per diffusion, and they were very bullish on Tesla's effort to go and solve it, autonomous driving.
49:18They're not going to go up against Tesla just yet in
They're not going to go up against Tesla just yet in
They're not going to go up against Tesla just yet in
They're not going to go up against Tesla just yet in
S Speaker 150:19yeah, Maya, I don't see how we know until they actually run this and prove it out Correct. Unless somebody I don't know what work we can do, or somebody can tell me, you're probably one of the smartest guys on the team, Albert, what work we can do to understand this thing will work or not, I don't think we'd be able to figure out. We have to. We have to basically take the lead that they've done this in, in chameleon, that they'll figure this out. Now, if they don't figure this out, then they have to pivot to something else. So Quinn and Albert spot AI guys really have talked to multiple skilled physical intelligence, all of these other physical AI and video intelligence, 12 labs, everybody. They did not get satisfactory answers from any of those teams. They did get satisfactory answers from these teams, and that's it. That's all we can know. And then, of course, their engineering team said, okay, you know what? I'm not committing to anything today. Let's get their first model, and then I'll see. So my comment kosher. I think it doesn't matter. I mean, how much the architecture? I mean, yeah, we can try to figure out if it's going to work. That's that's number one. But at the end of the day, it's a priestly deal. It's all about the team. I mean, we don't have the domain expertise, but the diligence has to be whether they have skills to build a company, which is a very different skill, and they very much, maybe they can. I mean, I don't know, but that's the thing you should clarify. And it's beyond the speaking about there was l7 or l8 question is whether
yeah, Maya, I don't see how we know until they actually run this and prove it out Correct. Unless somebody I don't know what work we can do, or somebody can tell me, you're probably one of the smartest guys on the team, Albert, what work we can do to understand this thing will work or not, I don't think we'd be able to figure out. We have to. We have to basically take the lead that they've done this in, in chameleon, that they'll figure this out. Now, if they don't figure this out, then they have to pivot to something else. So Quinn and Albert spot AI guys really have talked to multiple skilled physical intelligence, all of these other physical AI and video intelligence, 12 labs, everybody. They did not get satisfactory answers from any of those teams. They did get satisfactory answers from these teams, and that's it. That's all we can know. And then, of course, their engineering team said, okay, you know what? I'm not committing to anything today. Let's get their first model, and then I'll see. So my comment kosher. I think it doesn't matter. I mean, how much the architecture? I mean, yeah, we can try to figure out if it's going to work. That's that's number one. But at the end of the day, it's a priestly deal. It's all about the team. I mean, we don't have the domain expertise, but the diligence has to be whether they have skills to build a company, which is a very different skill, and they very much, maybe they can. I mean, I don't know, but that's the thing you should clarify. And it's beyond the speaking about there was l7 or l8 question is whether
yeah, Maya, I don't see how we know until they actually run this and prove it out Correct. Unless somebody I don't know what work we can do, or somebody can tell me, you're probably one of the smartest guys on the team, Albert, what work we can do to understand this thing will work or not, I don't think we'd be able to figure out. We have to. We have to basically take the lead that they've done this in, in chameleon, that they'll figure this out. Now, if they don't figure this out, then they have to pivot to something else. So Quinn and Albert spot AI guys really have talked to multiple skilled physical intelligence, all of these other physical AI and video intelligence, 12 labs, everybody. They did not get satisfactory answers from any of those teams. They did get satisfactory answers from these teams, and that's it. That's all we can know. And then, of course, their engineering team said, okay, you know what? I'm not committing to anything today. Let's get their first model, and then I'll see. So my comment kosher. I think it doesn't matter. I mean, how much the architecture? I mean, yeah, we can try to figure out if it's going to work. That's that's number one. But at the end of the day, it's a priestly deal. It's all about the team. I mean, we don't have the domain expertise, but the diligence has to be whether they have skills to build a company, which is a very different skill, and they very much, maybe they can. I mean, I don't know, but that's the thing you should clarify. And it's beyond the speaking about there was l7 or l8 question is whether
yeah, Maya, I don't see how we know until they actually run this and prove it out Correct. Unless somebody I don't know what work we can do, or somebody can tell me, you're probably one of the smartest guys on the team, Albert, what work we can do to understand this thing will work or not, I don't think we'd be able to figure out. We have to. We have to basically take the lead that they've done this in, in chameleon, that they'll figure this out. Now, if they don't figure this out, then they have to pivot to something else. So Quinn and Albert spot AI guys really have talked to multiple skilled physical intelligence, all of these other physical AI and video intelligence, 12 labs, everybody. They did not get satisfactory answers from any of those teams. They did get satisfactory answers from these teams, and that's it. That's all we can know. And then, of course, their engineering team said, okay, you know what? I'm not committing to anything today. Let's get their first model, and then I'll see. So my comment kosher. I think it doesn't matter. I mean, how much the architecture? I mean, yeah, we can try to figure out if it's going to work. That's that's number one. But at the end of the day, it's a priestly deal. It's all about the team. I mean, we don't have the domain expertise, but the diligence has to be whether they have skills to build a company, which is a very different skill, and they very much, maybe they can. I mean, I don't know, but that's the thing you should clarify. And it's beyond the speaking about there was l7 or l8 question is whether
S Speaker 152:05people that know them, that walk with them, that hire them, or whatever, they left already, right? That left me, they just left a week ago. But I know, so coincidentally, I knew people like some ex Qualcomm people who work directly with them, and some ex Qualcomm people were actually good friends of mine, and I still talk to them once a week. We have a meta and Qualcomm meetup, and they work directly with these guys. So the feedback on these guys was positive, having said that these researcher teams, we know it's mixed bag whether some first time, first time founders, so I think we have enough data points. I think the team trying to get inputs on them, and then trying to get perspective customers feedback on whether this makes sense. I think that, my view, we have, you know, enough sort of
people that know them, that walk with them, that hire them, or whatever, they left already, right? That left me, they just left a week ago. But I know, so coincidentally, I knew people like some ex Qualcomm people who work directly with them, and some ex Qualcomm people were actually good friends of mine, and I still talk to them once a week. We have a meta and Qualcomm meetup, and they work directly with these guys. So the feedback on these guys was positive, having said that these researcher teams, we know it's mixed bag whether some first time, first time founders, so I think we have enough data points. I think the team trying to get inputs on them, and then trying to get perspective customers feedback on whether this makes sense. I think that, my view, we have, you know, enough sort of
people that know them, that walk with them, that hire them, or whatever, they left already, right? That left me, they just left a week ago. But I know, so coincidentally, I knew people like some ex Qualcomm people who work directly with them, and some ex Qualcomm people were actually good friends of mine, and I still talk to them once a week. We have a meta and Qualcomm meetup, and they work directly with these guys. So the feedback on these guys was positive, having said that these researcher teams, we know it's mixed bag whether some first time, first time founders, so I think we have enough data points. I think the team trying to get inputs on them, and then trying to get perspective customers feedback on whether this makes sense. I think that, my view, we have, you know, enough sort of
people that know them, that walk with them, that hire them, or whatever, they left already, right? That left me, they just left a week ago. But I know, so coincidentally, I knew people like some ex Qualcomm people who work directly with them, and some ex Qualcomm people were actually good friends of mine, and I still talk to them once a week. We have a meta and Qualcomm meetup, and they work directly with these guys. So the feedback on these guys was positive, having said that these researcher teams, we know it's mixed bag whether some first time, first time founders, so I think we have enough data points. I think the team trying to get inputs on them, and then trying to get perspective customers feedback on whether this makes sense. I think that, my view, we have, you know, enough sort of
53:09to say, Okay, this kind of makes sense, but we won that we never know all the answers, that's for sure.
to say, Okay, this kind of makes sense, but we won that we never know all the answers, that's for sure.
to say, Okay, this kind of makes sense, but we won that we never know all the answers, that's for sure.
to say, Okay, this kind of makes sense, but we won that we never know all the answers, that's for sure.
S Speaker 153:18So I'll give I agree one more data point is the founders, the type of founder that we're referring to, cartesia as, in fact, less purely research founders. Cartesia turns out doing really well. Anthropic had purely research founders turns out doing really well. Luma, purely research founders, turns out now they're doing well, well, we'll see what the end result is. For us, the success metric is, can they raise at a higher valuation in series A we're not going to know what the eventual outcome is going to be. At this stage of the company, there's another company, you know, the Sakana, I would rephrase that. Can they raise a lot of money at a higher valuation procedure? That's right, because this model requires a lot of money, and all of these Carlos require require that, but they've been able to successfully do that. No, I know. I'm just amplifying your answer.
So I'll give I agree one more data point is the founders, the type of founder that we're referring to, cartesia as, in fact, less purely research founders. Cartesia turns out doing really well. Anthropic had purely research founders turns out doing really well. Luma, purely research founders, turns out now they're doing well, well, we'll see what the end result is. For us, the success metric is, can they raise at a higher valuation in series A we're not going to know what the eventual outcome is going to be. At this stage of the company, there's another company, you know, the Sakana, I would rephrase that. Can they raise a lot of money at a higher valuation procedure? That's right, because this model requires a lot of money, and all of these Carlos require require that, but they've been able to successfully do that. No, I know. I'm just amplifying your answer.
So I'll give I agree one more data point is the founders, the type of founder that we're referring to, cartesia as, in fact, less purely research founders. Cartesia turns out doing really well. Anthropic had purely research founders turns out doing really well. Luma, purely research founders, turns out now they're doing well, well, we'll see what the end result is. For us, the success metric is, can they raise at a higher valuation in series A we're not going to know what the eventual outcome is going to be. At this stage of the company, there's another company, you know, the Sakana, I would rephrase that. Can they raise a lot of money at a higher valuation procedure? That's right, because this model requires a lot of money, and all of these Carlos require require that, but they've been able to successfully do that. No, I know. I'm just amplifying your answer.
So I'll give I agree one more data point is the founders, the type of founder that we're referring to, cartesia as, in fact, less purely research founders. Cartesia turns out doing really well. Anthropic had purely research founders turns out doing really well. Luma, purely research founders, turns out now they're doing well, well, we'll see what the end result is. For us, the success metric is, can they raise at a higher valuation in series A we're not going to know what the eventual outcome is going to be. At this stage of the company, there's another company, you know, the Sakana, I would rephrase that. Can they raise a lot of money at a higher valuation procedure? That's right, because this model requires a lot of money, and all of these Carlos require require that, but they've been able to successfully do that. No, I know. I'm just amplifying your answer.
S Speaker 154:26comment on building the company part? I Yeah, that was ideally, we validated can build companies. But I don't know, like, there's many, many examples of of, you know, zoom, when we earlier, the product was there. It's not clear. Eric can't build a multi billion dollar company either. Mark Zuckerberg, if you, if you talked about Facebook earlier, I don't think he will figure it out. He's in Dropbox from Harvard, right? That he can't build this gigantic company. This is a very hard to figure out. So I think the bet is really on this team, and they from some, you know, data points we get from television so forth, at least they know what they're doing. They've done it before and within Facebook, and they can't figure this out again. So I think that's the I don't know how else we can validate to you. Want them to talk to Jake, because yesterday, after you had Jason, Jason mentioned about special intelligence, is that ideally the visual the visual image model, can iterate the special intelligence part faster, because really need to understand the physical world better, like, for example, go back, what are you trying to say the spatial intelligence part of the peasant language model? Man is asking, remember that company yesterday, right? So, lindens company, yeah. She's asking if we should have them talk to Jason the CTO. Oh, yeah. But So Jason and them are men are going after vision transformers, which is and so what I got is, it seems Jason's vetted to that technique for now, and they want to go build this foundation metal model themselves. Yeah, so I don't think it's a good idea. So right now for this one won't be a good idea, I have introduced them to three other companies and collected feedback from this other company, path robotics as well. That founder is also very good so, but good feedback, I am introducing to collect feedback and to also build a rapport. Because I don't think,
comment on building the company part? I Yeah, that was ideally, we validated can build companies. But I don't know, like, there's many, many examples of of, you know, zoom, when we earlier, the product was there. It's not clear. Eric can't build a multi billion dollar company either. Mark Zuckerberg, if you, if you talked about Facebook earlier, I don't think he will figure it out. He's in Dropbox from Harvard, right? That he can't build this gigantic company. This is a very hard to figure out. So I think the bet is really on this team, and they from some, you know, data points we get from television so forth, at least they know what they're doing. They've done it before and within Facebook, and they can't figure this out again. So I think that's the I don't know how else we can validate to you. Want them to talk to Jake, because yesterday, after you had Jason, Jason mentioned about special intelligence, is that ideally the visual the visual image model, can iterate the special intelligence part faster, because really need to understand the physical world better, like, for example, go back, what are you trying to say the spatial intelligence part of the peasant language model? Man is asking, remember that company yesterday, right? So, lindens company, yeah. She's asking if we should have them talk to Jason the CTO. Oh, yeah. But So Jason and them are men are going after vision transformers, which is and so what I got is, it seems Jason's vetted to that technique for now, and they want to go build this foundation metal model themselves. Yeah, so I don't think it's a good idea. So right now for this one won't be a good idea, I have introduced them to three other companies and collected feedback from this other company, path robotics as well. That founder is also very good so, but good feedback, I am introducing to collect feedback and to also build a rapport. Because I don't think,
comment on building the company part? I Yeah, that was ideally, we validated can build companies. But I don't know, like, there's many, many examples of of, you know, zoom, when we earlier, the product was there. It's not clear. Eric can't build a multi billion dollar company either. Mark Zuckerberg, if you, if you talked about Facebook earlier, I don't think he will figure it out. He's in Dropbox from Harvard, right? That he can't build this gigantic company. This is a very hard to figure out. So I think the bet is really on this team, and they from some, you know, data points we get from television so forth, at least they know what they're doing. They've done it before and within Facebook, and they can't figure this out again. So I think that's the I don't know how else we can validate to you. Want them to talk to Jake, because yesterday, after you had Jason, Jason mentioned about special intelligence, is that ideally the visual the visual image model, can iterate the special intelligence part faster, because really need to understand the physical world better, like, for example, go back, what are you trying to say the spatial intelligence part of the peasant language model? Man is asking, remember that company yesterday, right? So, lindens company, yeah. She's asking if we should have them talk to Jason the CTO. Oh, yeah. But So Jason and them are men are going after vision transformers, which is and so what I got is, it seems Jason's vetted to that technique for now, and they want to go build this foundation metal model themselves. Yeah, so I don't think it's a good idea. So right now for this one won't be a good idea, I have introduced them to three other companies and collected feedback from this other company, path robotics as well. That founder is also very good so, but good feedback, I am introducing to collect feedback and to also build a rapport. Because I don't think,
comment on building the company part? I Yeah, that was ideally, we validated can build companies. But I don't know, like, there's many, many examples of of, you know, zoom, when we earlier, the product was there. It's not clear. Eric can't build a multi billion dollar company either. Mark Zuckerberg, if you, if you talked about Facebook earlier, I don't think he will figure it out. He's in Dropbox from Harvard, right? That he can't build this gigantic company. This is a very hard to figure out. So I think the bet is really on this team, and they from some, you know, data points we get from television so forth, at least they know what they're doing. They've done it before and within Facebook, and they can't figure this out again. So I think that's the I don't know how else we can validate to you. Want them to talk to Jake, because yesterday, after you had Jason, Jason mentioned about special intelligence, is that ideally the visual the visual image model, can iterate the special intelligence part faster, because really need to understand the physical world better, like, for example, go back, what are you trying to say the spatial intelligence part of the peasant language model? Man is asking, remember that company yesterday, right? So, lindens company, yeah. She's asking if we should have them talk to Jason the CTO. Oh, yeah. But So Jason and them are men are going after vision transformers, which is and so what I got is, it seems Jason's vetted to that technique for now, and they want to go build this foundation metal model themselves. Yeah, so I don't think it's a good idea. So right now for this one won't be a good idea, I have introduced them to three other companies and collected feedback from this other company, path robotics as well. That founder is also very good so, but good feedback, I am introducing to collect feedback and to also build a rapport. Because I don't think,
56:49I won't be surprised we don't get allocation. So
S Speaker 11:00:14So because so they're not there. They because Dabur is not going to be able to write the $50 million check, right? Yeah, dauber is a size check is a little smaller, that's fine, but he's a he's got a good ability to find, like, good founders dauber, yeah, these guys are also Seattle, okay, yeah, so these guys are also Seattle, okay, local ecosystem. So then, what do we do from here? Like, what do we do? So I'll get the turn. So the next steps is, wait till they sign the term sheet. I'll get the terms. Let's understand the terms. Yeah, us to invest. I'm saying, like, we have to get a board of zero seats, no, because my experience now has been, yeah, otherwise, you don't have years ago. I'm not doing it. I I'm not doing it. Not worth the energy. So thank you, Carlos, my religion, okay, adopted, good. I wish you would stick to religion more strongly. Carlos, my deals, I have my religion other deals, maybe
So because so they're not there. They because Dabur is not going to be able to write the $50 million check, right? Yeah, dauber is a size check is a little smaller, that's fine, but he's a he's got a good ability to find, like, good founders dauber, yeah, these guys are also Seattle, okay, yeah, so these guys are also Seattle, okay, local ecosystem. So then, what do we do from here? Like, what do we do? So I'll get the turn. So the next steps is, wait till they sign the term sheet. I'll get the terms. Let's understand the terms. Yeah, us to invest. I'm saying, like, we have to get a board of zero seats, no, because my experience now has been, yeah, otherwise, you don't have years ago. I'm not doing it. I I'm not doing it. Not worth the energy. So thank you, Carlos, my religion, okay, adopted, good. I wish you would stick to religion more strongly. Carlos, my deals, I have my religion other deals, maybe
So because so they're not there. They because Dabur is not going to be able to write the $50 million check, right? Yeah, dauber is a size check is a little smaller, that's fine, but he's a he's got a good ability to find, like, good founders dauber, yeah, these guys are also Seattle, okay, yeah, so these guys are also Seattle, okay, local ecosystem. So then, what do we do from here? Like, what do we do? So I'll get the turn. So the next steps is, wait till they sign the term sheet. I'll get the terms. Let's understand the terms. Yeah, us to invest. I'm saying, like, we have to get a board of zero seats, no, because my experience now has been, yeah, otherwise, you don't have years ago. I'm not doing it. I I'm not doing it. Not worth the energy. So thank you, Carlos, my religion, okay, adopted, good. I wish you would stick to religion more strongly. Carlos, my deals, I have my religion other deals, maybe
So because so they're not there. They because Dabur is not going to be able to write the $50 million check, right? Yeah, dauber is a size check is a little smaller, that's fine, but he's a he's got a good ability to find, like, good founders dauber, yeah, these guys are also Seattle, okay, yeah, so these guys are also Seattle, okay, local ecosystem. So then, what do we do from here? Like, what do we do? So I'll get the turn. So the next steps is, wait till they sign the term sheet. I'll get the terms. Let's understand the terms. Yeah, us to invest. I'm saying, like, we have to get a board of zero seats, no, because my experience now has been, yeah, otherwise, you don't have years ago. I'm not doing it. I I'm not doing it. Not worth the energy. So thank you, Carlos, my religion, okay, adopted, good. I wish you would stick to religion more strongly. Carlos, my deals, I have my religion other deals, maybe
S Speaker 11:01:25okay. I think that's a good, I mean, experience now, no, like
okay. I think that's a good, I mean, experience now, no, like
okay. I think that's a good, I mean, experience now, no, like
okay. I think that's a good, I mean, experience now, no, like
1:01:32no board observer did get very little visibility.
S Speaker 11:01:36The only, only time, you know, I think you let this observer thing go, is just saying, like these, these massive rounds, if we really want to do it, and but, but I'm not chasing those these days anyway. So let's talk. So we probably have short time between this and stage two. What should we focus on else we can answer number one. And then we need to decide if we want to do this, what's our check size three, or what is the limitation you have in terms of validation? Let us see right now by the cost. I think you told me you know the big fan of them, and we also know that, right? Who, you know, he has strong opinions. Guys, very smart here in his place in the sun, right? Not an easy guy to work with, but he's been right a bunch of times. So, yeah, okay, still likes it. Gives them whatever 2050 so what is the limitation you pulling yourself for the 249
The only, only time, you know, I think you let this observer thing go, is just saying, like these, these massive rounds, if we really want to do it, and but, but I'm not chasing those these days anyway. So let's talk. So we probably have short time between this and stage two. What should we focus on else we can answer number one. And then we need to decide if we want to do this, what's our check size three, or what is the limitation you have in terms of validation? Let us see right now by the cost. I think you told me you know the big fan of them, and we also know that, right? Who, you know, he has strong opinions. Guys, very smart here in his place in the sun, right? Not an easy guy to work with, but he's been right a bunch of times. So, yeah, okay, still likes it. Gives them whatever 2050 so what is the limitation you pulling yourself for the 249
The only, only time, you know, I think you let this observer thing go, is just saying, like these, these massive rounds, if we really want to do it, and but, but I'm not chasing those these days anyway. So let's talk. So we probably have short time between this and stage two. What should we focus on else we can answer number one. And then we need to decide if we want to do this, what's our check size three, or what is the limitation you have in terms of validation? Let us see right now by the cost. I think you told me you know the big fan of them, and we also know that, right? Who, you know, he has strong opinions. Guys, very smart here in his place in the sun, right? Not an easy guy to work with, but he's been right a bunch of times. So, yeah, okay, still likes it. Gives them whatever 2050 so what is the limitation you pulling yourself for the 249
The only, only time, you know, I think you let this observer thing go, is just saying, like these, these massive rounds, if we really want to do it, and but, but I'm not chasing those these days anyway. So let's talk. So we probably have short time between this and stage two. What should we focus on else we can answer number one. And then we need to decide if we want to do this, what's our check size three, or what is the limitation you have in terms of validation? Let us see right now by the cost. I think you told me you know the big fan of them, and we also know that, right? Who, you know, he has strong opinions. Guys, very smart here in his place in the sun, right? Not an easy guy to work with, but he's been right a bunch of times. So, yeah, okay, still likes it. Gives them whatever 2050 so what is the limitation you pulling yourself for the 249
S Speaker 11:05:55poke holes on their ability to build a business as a team, right? We can take the rosy view, yeah, they'll be successful. They're smart. Or, you know, are there any leading things that says, okay, these guys, you know, not like it. Maybe that's one way to go about it. You can. I don't know if you can, but the indication that I have, all the indication that I have, but introducing them to customers, is one thing that they go in very prepared with the customers, which is prepared these memories. I've seen that. So they're going very prepared with these customers, and then the customer's feedback on them has been positive. That's all I because they've never so short of talking to their shrinks, we won't be able to find any shortcomings. And then they have many, many shrinks either. Yeah, I like, I like some of us, but I think it's more you can trust and be able to build a team eventually. Yes, all right, well, there's that, there's the there's the further you have to go, across, like as a technology founder, to scale into something big, they have to learn the team building part, the business part. And some were able to do it, like Eric, for instance, right? Zuckerberg certainly done it. I don't think Zach Berg knows how to build companies when you start fitting there's many examples the founder could scale, but there's some cases they don't. So, so there's some, probably some traits you can find in these founders, and may have a better, better confidence level that they can they can scale on how to, like, build a business, basically, right? That's me with you casually for dinner. So the R and the menu Carlos, you can check like, that's why meeting them for dinner was showed a different side of them. Yeah, that's right, yeah, so, and we learned that it doesn't take too much wine for them to start talking. So that's good, cheap taste.
poke holes on their ability to build a business as a team, right? We can take the rosy view, yeah, they'll be successful. They're smart. Or, you know, are there any leading things that says, okay, these guys, you know, not like it. Maybe that's one way to go about it. You can. I don't know if you can, but the indication that I have, all the indication that I have, but introducing them to customers, is one thing that they go in very prepared with the customers, which is prepared these memories. I've seen that. So they're going very prepared with these customers, and then the customer's feedback on them has been positive. That's all I because they've never so short of talking to their shrinks, we won't be able to find any shortcomings. And then they have many, many shrinks either. Yeah, I like, I like some of us, but I think it's more you can trust and be able to build a team eventually. Yes, all right, well, there's that, there's the there's the further you have to go, across, like as a technology founder, to scale into something big, they have to learn the team building part, the business part. And some were able to do it, like Eric, for instance, right? Zuckerberg certainly done it. I don't think Zach Berg knows how to build companies when you start fitting there's many examples the founder could scale, but there's some cases they don't. So, so there's some, probably some traits you can find in these founders, and may have a better, better confidence level that they can they can scale on how to, like, build a business, basically, right? That's me with you casually for dinner. So the R and the menu Carlos, you can check like, that's why meeting them for dinner was showed a different side of them. Yeah, that's right, yeah, so, and we learned that it doesn't take too much wine for them to start talking. So that's good, cheap taste.
poke holes on their ability to build a business as a team, right? We can take the rosy view, yeah, they'll be successful. They're smart. Or, you know, are there any leading things that says, okay, these guys, you know, not like it. Maybe that's one way to go about it. You can. I don't know if you can, but the indication that I have, all the indication that I have, but introducing them to customers, is one thing that they go in very prepared with the customers, which is prepared these memories. I've seen that. So they're going very prepared with these customers, and then the customer's feedback on them has been positive. That's all I because they've never so short of talking to their shrinks, we won't be able to find any shortcomings. And then they have many, many shrinks either. Yeah, I like, I like some of us, but I think it's more you can trust and be able to build a team eventually. Yes, all right, well, there's that, there's the there's the further you have to go, across, like as a technology founder, to scale into something big, they have to learn the team building part, the business part. And some were able to do it, like Eric, for instance, right? Zuckerberg certainly done it. I don't think Zach Berg knows how to build companies when you start fitting there's many examples the founder could scale, but there's some cases they don't. So, so there's some, probably some traits you can find in these founders, and may have a better, better confidence level that they can they can scale on how to, like, build a business, basically, right? That's me with you casually for dinner. So the R and the menu Carlos, you can check like, that's why meeting them for dinner was showed a different side of them. Yeah, that's right, yeah, so, and we learned that it doesn't take too much wine for them to start talking. So that's good, cheap taste.
poke holes on their ability to build a business as a team, right? We can take the rosy view, yeah, they'll be successful. They're smart. Or, you know, are there any leading things that says, okay, these guys, you know, not like it. Maybe that's one way to go about it. You can. I don't know if you can, but the indication that I have, all the indication that I have, but introducing them to customers, is one thing that they go in very prepared with the customers, which is prepared these memories. I've seen that. So they're going very prepared with these customers, and then the customer's feedback on them has been positive. That's all I because they've never so short of talking to their shrinks, we won't be able to find any shortcomings. And then they have many, many shrinks either. Yeah, I like, I like some of us, but I think it's more you can trust and be able to build a team eventually. Yes, all right, well, there's that, there's the there's the further you have to go, across, like as a technology founder, to scale into something big, they have to learn the team building part, the business part. And some were able to do it, like Eric, for instance, right? Zuckerberg certainly done it. I don't think Zach Berg knows how to build companies when you start fitting there's many examples the founder could scale, but there's some cases they don't. So, so there's some, probably some traits you can find in these founders, and may have a better, better confidence level that they can they can scale on how to, like, build a business, basically, right? That's me with you casually for dinner. So the R and the menu Carlos, you can check like, that's why meeting them for dinner was showed a different side of them. Yeah, that's right, yeah, so, and we learned that it doesn't take too much wine for them to start talking. So that's good, cheap taste.
S Speaker 11:07:56Carlos pouring wine glasses. Glasses, no, but it was like, the whole thing, what bottle for four of us? It was enough to get the cookies. So, oh, wow, that's good. Yeah, it's cheap date. Okay, so you figured out the like, what do we need to do next? And so forth. I don't know what else we can validate. I can go read chameleon, but I don't know, even after reading chameleon, like, what am I okay? We validated chameleon is good. Chameleon is good. We validated that Armin was the main guy behind chameleon. I mean, it's not even it's publicly people talk about Armin, referring to Armin, whenever they're referring to it was Krishna says these guys, Krishna brought it, took his model guys, spent hours with them. Yeah, he's like, these are legit. So he could say, even because this early fusion, Yeah, nobody's done it. So even his model guy and Krishna didn't know much about this, but all they could say is, these guys know what they're talking about. So good feedback from Krishna, the news is pretty smart guy. Yeah, good feedback, at least from interactions with the team and so forth. They've seen a lot of other companies, right? Any red flags you guys see this shit don't work, but I don't know how we're gonna figure out that. We only know in December. Yeah, exactly any other red flags, you see, guys can't drink red flags, the biggest, the one big risk that I have for them is, like any misstep in app training, this is costly, very costly. Yes, yeah. They did have to spend a lot of money with with the with Nvidia, basically, that was somebody, yeah. My other problem is, you know, they could go and Jensen gets very early with these teams, yeah. I hope they just don't talk to Jensen in times. So if that happens,
Carlos pouring wine glasses. Glasses, no, but it was like, the whole thing, what bottle for four of us? It was enough to get the cookies. So, oh, wow, that's good. Yeah, it's cheap date. Okay, so you figured out the like, what do we need to do next? And so forth. I don't know what else we can validate. I can go read chameleon, but I don't know, even after reading chameleon, like, what am I okay? We validated chameleon is good. Chameleon is good. We validated that Armin was the main guy behind chameleon. I mean, it's not even it's publicly people talk about Armin, referring to Armin, whenever they're referring to it was Krishna says these guys, Krishna brought it, took his model guys, spent hours with them. Yeah, he's like, these are legit. So he could say, even because this early fusion, Yeah, nobody's done it. So even his model guy and Krishna didn't know much about this, but all they could say is, these guys know what they're talking about. So good feedback from Krishna, the news is pretty smart guy. Yeah, good feedback, at least from interactions with the team and so forth. They've seen a lot of other companies, right? Any red flags you guys see this shit don't work, but I don't know how we're gonna figure out that. We only know in December. Yeah, exactly any other red flags, you see, guys can't drink red flags, the biggest, the one big risk that I have for them is, like any misstep in app training, this is costly, very costly. Yes, yeah. They did have to spend a lot of money with with the with Nvidia, basically, that was somebody, yeah. My other problem is, you know, they could go and Jensen gets very early with these teams, yeah. I hope they just don't talk to Jensen in times. So if that happens,
Carlos pouring wine glasses. Glasses, no, but it was like, the whole thing, what bottle for four of us? It was enough to get the cookies. So, oh, wow, that's good. Yeah, it's cheap date. Okay, so you figured out the like, what do we need to do next? And so forth. I don't know what else we can validate. I can go read chameleon, but I don't know, even after reading chameleon, like, what am I okay? We validated chameleon is good. Chameleon is good. We validated that Armin was the main guy behind chameleon. I mean, it's not even it's publicly people talk about Armin, referring to Armin, whenever they're referring to it was Krishna says these guys, Krishna brought it, took his model guys, spent hours with them. Yeah, he's like, these are legit. So he could say, even because this early fusion, Yeah, nobody's done it. So even his model guy and Krishna didn't know much about this, but all they could say is, these guys know what they're talking about. So good feedback from Krishna, the news is pretty smart guy. Yeah, good feedback, at least from interactions with the team and so forth. They've seen a lot of other companies, right? Any red flags you guys see this shit don't work, but I don't know how we're gonna figure out that. We only know in December. Yeah, exactly any other red flags, you see, guys can't drink red flags, the biggest, the one big risk that I have for them is, like any misstep in app training, this is costly, very costly. Yes, yeah. They did have to spend a lot of money with with the with Nvidia, basically, that was somebody, yeah. My other problem is, you know, they could go and Jensen gets very early with these teams, yeah. I hope they just don't talk to Jensen in times. So if that happens,
Carlos pouring wine glasses. Glasses, no, but it was like, the whole thing, what bottle for four of us? It was enough to get the cookies. So, oh, wow, that's good. Yeah, it's cheap date. Okay, so you figured out the like, what do we need to do next? And so forth. I don't know what else we can validate. I can go read chameleon, but I don't know, even after reading chameleon, like, what am I okay? We validated chameleon is good. Chameleon is good. We validated that Armin was the main guy behind chameleon. I mean, it's not even it's publicly people talk about Armin, referring to Armin, whenever they're referring to it was Krishna says these guys, Krishna brought it, took his model guys, spent hours with them. Yeah, he's like, these are legit. So he could say, even because this early fusion, Yeah, nobody's done it. So even his model guy and Krishna didn't know much about this, but all they could say is, these guys know what they're talking about. So good feedback from Krishna, the news is pretty smart guy. Yeah, good feedback, at least from interactions with the team and so forth. They've seen a lot of other companies, right? Any red flags you guys see this shit don't work, but I don't know how we're gonna figure out that. We only know in December. Yeah, exactly any other red flags, you see, guys can't drink red flags, the biggest, the one big risk that I have for them is, like any misstep in app training, this is costly, very costly. Yes, yeah. They did have to spend a lot of money with with the with Nvidia, basically, that was somebody, yeah. My other problem is, you know, they could go and Jensen gets very early with these teams, yeah. I hope they just don't talk to Jensen in times. So if that happens,
1:10:09then they'll have room for only one strategic, Oh, I see we get squeezed out. Okay, got it? I mean, that's happened. We are the leader in aji.
then they'll have room for only one strategic, Oh, I see we get squeezed out. Okay, got it? I mean, that's happened. We are the leader in aji.
then they'll have room for only one strategic, Oh, I see we get squeezed out. Okay, got it? I mean, that's happened. We are the leader in aji.
then they'll have room for only one strategic, Oh, I see we get squeezed out. Okay, got it? I mean, that's happened. We are the leader in aji.
S Speaker 11:10:25and then their memo only talked about Nvidia hardware for AGI. So we had to have to the test for Okay, good. All right, guys, okay, so Okay. And then the other one we should also talk about is this lending company that many of you met. I mean, I think the guy is legit. He's pretty transparent with us. He wasn't right now, whether he can do what he claims he can do is a separate question, but we should talk about it, not now, but yeah, not now. More like, trust in Him today. Yes, it's not more trust. It's just like, transparent. Yeah, he's more transparent. He's telling us to do monastic he's working on, you know, going through all this stuff and and like, and he tells you, like, Okay, I'm gonna push the team very hard to do this, but they're gonna learn by doing it. Basically, you to learn by doing it. Basically, yeah, Jason is much younger, much younger and a pure researcher. Yes, he spent only six months at DeepMind, yeah, and so I talked to him about this early fusion and all this. He wasn't so plugged in, but he was vetted into the technique that he was using with late fusion transformers. But I was just asking him a few questions. So he's He's young. He's like, very young, yeah, this is really betting on this Linden. This is entire bet over there. It is Linden, yeah, the other co founder might be also very capable, yeah.
and then their memo only talked about Nvidia hardware for AGI. So we had to have to the test for Okay, good. All right, guys, okay, so Okay. And then the other one we should also talk about is this lending company that many of you met. I mean, I think the guy is legit. He's pretty transparent with us. He wasn't right now, whether he can do what he claims he can do is a separate question, but we should talk about it, not now, but yeah, not now. More like, trust in Him today. Yes, it's not more trust. It's just like, transparent. Yeah, he's more transparent. He's telling us to do monastic he's working on, you know, going through all this stuff and and like, and he tells you, like, Okay, I'm gonna push the team very hard to do this, but they're gonna learn by doing it. Basically, you to learn by doing it. Basically, yeah, Jason is much younger, much younger and a pure researcher. Yes, he spent only six months at DeepMind, yeah, and so I talked to him about this early fusion and all this. He wasn't so plugged in, but he was vetted into the technique that he was using with late fusion transformers. But I was just asking him a few questions. So he's He's young. He's like, very young, yeah, this is really betting on this Linden. This is entire bet over there. It is Linden, yeah, the other co founder might be also very capable, yeah.
and then their memo only talked about Nvidia hardware for AGI. So we had to have to the test for Okay, good. All right, guys, okay, so Okay. And then the other one we should also talk about is this lending company that many of you met. I mean, I think the guy is legit. He's pretty transparent with us. He wasn't right now, whether he can do what he claims he can do is a separate question, but we should talk about it, not now, but yeah, not now. More like, trust in Him today. Yes, it's not more trust. It's just like, transparent. Yeah, he's more transparent. He's telling us to do monastic he's working on, you know, going through all this stuff and and like, and he tells you, like, Okay, I'm gonna push the team very hard to do this, but they're gonna learn by doing it. Basically, you to learn by doing it. Basically, yeah, Jason is much younger, much younger and a pure researcher. Yes, he spent only six months at DeepMind, yeah, and so I talked to him about this early fusion and all this. He wasn't so plugged in, but he was vetted into the technique that he was using with late fusion transformers. But I was just asking him a few questions. So he's He's young. He's like, very young, yeah, this is really betting on this Linden. This is entire bet over there. It is Linden, yeah, the other co founder might be also very capable, yeah.
and then their memo only talked about Nvidia hardware for AGI. So we had to have to the test for Okay, good. All right, guys, okay, so Okay. And then the other one we should also talk about is this lending company that many of you met. I mean, I think the guy is legit. He's pretty transparent with us. He wasn't right now, whether he can do what he claims he can do is a separate question, but we should talk about it, not now, but yeah, not now. More like, trust in Him today. Yes, it's not more trust. It's just like, transparent. Yeah, he's more transparent. He's telling us to do monastic he's working on, you know, going through all this stuff and and like, and he tells you, like, Okay, I'm gonna push the team very hard to do this, but they're gonna learn by doing it. Basically, you to learn by doing it. Basically, yeah, Jason is much younger, much younger and a pure researcher. Yes, he spent only six months at DeepMind, yeah, and so I talked to him about this early fusion and all this. He wasn't so plugged in, but he was vetted into the technique that he was using with late fusion transformers. But I was just asking him a few questions. So he's He's young. He's like, very young, yeah, this is really betting on this Linden. This is entire bet over there. It is Linden, yeah, the other co founder might be also very capable, yeah.
1:12:15So we could talk to the other co founder with
S Speaker 11:12:19him, yeah, you should talk to York, because York because York is going to be the one that do the engineering stuff, not Jason, yeah, that's right. The systems part Jason is more research. The systems part is all York, yeah, that's right. Okay, okay, okay. Do you have two minutes about for Octo? That's not going to be others can drop, but you should. You should just ask him, right? Just say hey, if you want us to sign anything, we the lead time. You can't just Oh, Saturday morning, send your dog so you gotta turn around this afternoon. It's not gonna happen. We he got, like, too sharp. I gave you all the legal things that we have to sign that binds Qualcomm into things that's just not gonna happen. He can't go. He can't go without us. That's fine. We're just telling him, if he needs any signature out of Qualcomm, we need to get the document. Let me talk to Dwayne as well, because spoke with Dwayne yesterday. So they're also now going back again, because all of a sudden we want on, that's fine. I'm just telling, telling you to tell who is. Basically, you can send us document. Expect us to turn around two hours. That's all right. If we don't, if we don't have to sign anything easier, or the consent, for instance, right? Or you guys have to sign off, then you're going to get a lot of slack from the legal team. And so it's called, that's all,
him, yeah, you should talk to York, because York because York is going to be the one that do the engineering stuff, not Jason, yeah, that's right. The systems part Jason is more research. The systems part is all York, yeah, that's right. Okay, okay, okay. Do you have two minutes about for Octo? That's not going to be others can drop, but you should. You should just ask him, right? Just say hey, if you want us to sign anything, we the lead time. You can't just Oh, Saturday morning, send your dog so you gotta turn around this afternoon. It's not gonna happen. We he got, like, too sharp. I gave you all the legal things that we have to sign that binds Qualcomm into things that's just not gonna happen. He can't go. He can't go without us. That's fine. We're just telling him, if he needs any signature out of Qualcomm, we need to get the document. Let me talk to Dwayne as well, because spoke with Dwayne yesterday. So they're also now going back again, because all of a sudden we want on, that's fine. I'm just telling, telling you to tell who is. Basically, you can send us document. Expect us to turn around two hours. That's all right. If we don't, if we don't have to sign anything easier, or the consent, for instance, right? Or you guys have to sign off, then you're going to get a lot of slack from the legal team. And so it's called, that's all,
him, yeah, you should talk to York, because York because York is going to be the one that do the engineering stuff, not Jason, yeah, that's right. The systems part Jason is more research. The systems part is all York, yeah, that's right. Okay, okay, okay. Do you have two minutes about for Octo? That's not going to be others can drop, but you should. You should just ask him, right? Just say hey, if you want us to sign anything, we the lead time. You can't just Oh, Saturday morning, send your dog so you gotta turn around this afternoon. It's not gonna happen. We he got, like, too sharp. I gave you all the legal things that we have to sign that binds Qualcomm into things that's just not gonna happen. He can't go. He can't go without us. That's fine. We're just telling him, if he needs any signature out of Qualcomm, we need to get the document. Let me talk to Dwayne as well, because spoke with Dwayne yesterday. So they're also now going back again, because all of a sudden we want on, that's fine. I'm just telling, telling you to tell who is. Basically, you can send us document. Expect us to turn around two hours. That's all right. If we don't, if we don't have to sign anything easier, or the consent, for instance, right? Or you guys have to sign off, then you're going to get a lot of slack from the legal team. And so it's called, that's all,
him, yeah, you should talk to York, because York because York is going to be the one that do the engineering stuff, not Jason, yeah, that's right. The systems part Jason is more research. The systems part is all York, yeah, that's right. Okay, okay, okay. Do you have two minutes about for Octo? That's not going to be others can drop, but you should. You should just ask him, right? Just say hey, if you want us to sign anything, we the lead time. You can't just Oh, Saturday morning, send your dog so you gotta turn around this afternoon. It's not gonna happen. We he got, like, too sharp. I gave you all the legal things that we have to sign that binds Qualcomm into things that's just not gonna happen. He can't go. He can't go without us. That's fine. We're just telling him, if he needs any signature out of Qualcomm, we need to get the document. Let me talk to Dwayne as well, because spoke with Dwayne yesterday. So they're also now going back again, because all of a sudden we want on, that's fine. I'm just telling, telling you to tell who is. Basically, you can send us document. Expect us to turn around two hours. That's all right. If we don't, if we don't have to sign anything easier, or the consent, for instance, right? Or you guys have to sign off, then you're going to get a lot of slack from the legal team. And so it's called, that's all,
S Speaker 11:13:50the legal team. I'll just, I'll do my job of telling Louise. I'm afraid of Shannon
the legal team. I'll just, I'll do my job of telling Louise. I'm afraid of Shannon
the legal team. I'll just, I'll do my job of telling Louise. I'm afraid of Shannon
the legal team. I'll just, I'll do my job of telling Louise. I'm afraid of Shannon
S Speaker 11:14:01basically anything we sign off, right? If he doesn't need a signature, then it's fine. He doesn't have to tell us, okay, right? So let me ask him that that if he needs a signature, we need Yes, and tell him we need five days, because our legal team is working on other shit, right? They can't just drop everything else, let me I'm just gonna, yeah, just set the expectation with him. Like, so you know, when he called you say, tucha, I told you, yeah,
basically anything we sign off, right? If he doesn't need a signature, then it's fine. He doesn't have to tell us, okay, right? So let me ask him that that if he needs a signature, we need Yes, and tell him we need five days, because our legal team is working on other shit, right? They can't just drop everything else, let me I'm just gonna, yeah, just set the expectation with him. Like, so you know, when he called you say, tucha, I told you, yeah,
basically anything we sign off, right? If he doesn't need a signature, then it's fine. He doesn't have to tell us, okay, right? So let me ask him that that if he needs a signature, we need Yes, and tell him we need five days, because our legal team is working on other shit, right? They can't just drop everything else, let me I'm just gonna, yeah, just set the expectation with him. Like, so you know, when he called you say, tucha, I told you, yeah,
basically anything we sign off, right? If he doesn't need a signature, then it's fine. He doesn't have to tell us, okay, right? So let me ask him that that if he needs a signature, we need Yes, and tell him we need five days, because our legal team is working on other shit, right? They can't just drop everything else, let me I'm just gonna, yeah, just set the expectation with him. Like, so you know, when he called you say, tucha, I told you, yeah,
1:14:58Have you go back and read? Do we still, if there's
S Speaker 11:15:01any leadership, like non commissioned and stuff like that, we can't sign. It doesn't buy. What kind of Ventures is buying spot? Yeah, agreed. I will just email him, and let's say Louise is a little emotional. What's emotional about this? I'll
any leadership, like non commissioned and stuff like that, we can't sign. It doesn't buy. What kind of Ventures is buying spot? Yeah, agreed. I will just email him, and let's say Louise is a little emotional. What's emotional about this? I'll
any leadership, like non commissioned and stuff like that, we can't sign. It doesn't buy. What kind of Ventures is buying spot? Yeah, agreed. I will just email him, and let's say Louise is a little emotional. What's emotional about this? I'll
any leadership, like non commissioned and stuff like that, we can't sign. It doesn't buy. What kind of Ventures is buying spot? Yeah, agreed. I will just email him, and let's say Louise is a little emotional. What's emotional about this? I'll
S Speaker 11:15:29he got he got very emotional when I called him yesterday. Why emotional? You know, we did the whole song and dance again with him, right? Like this. Oh, yeah. Again. And then all of so then Nicole and Durga said, You know what? No, not interested. Yeah, maybe for yesterday. Durga said, Oh, very interested. That's the one. Give me a compiler talent. Give me the best compiler talent on the planet. I'm like, I just got you the best compiler talent. You guys, go back, go back, go back, go back. I'm doing like two shot. I gave you the chance, so you guys just completely dropped the ball. So I can't say anything. Don't talk to me. Talk to my banker. So
he got he got very emotional when I called him yesterday. Why emotional? You know, we did the whole song and dance again with him, right? Like this. Oh, yeah. Again. And then all of so then Nicole and Durga said, You know what? No, not interested. Yeah, maybe for yesterday. Durga said, Oh, very interested. That's the one. Give me a compiler talent. Give me the best compiler talent on the planet. I'm like, I just got you the best compiler talent. You guys, go back, go back, go back, go back. I'm doing like two shot. I gave you the chance, so you guys just completely dropped the ball. So I can't say anything. Don't talk to me. Talk to my banker. So
he got he got very emotional when I called him yesterday. Why emotional? You know, we did the whole song and dance again with him, right? Like this. Oh, yeah. Again. And then all of so then Nicole and Durga said, You know what? No, not interested. Yeah, maybe for yesterday. Durga said, Oh, very interested. That's the one. Give me a compiler talent. Give me the best compiler talent on the planet. I'm like, I just got you the best compiler talent. You guys, go back, go back, go back, go back. I'm doing like two shot. I gave you the chance, so you guys just completely dropped the ball. So I can't say anything. Don't talk to me. Talk to my banker. So
he got he got very emotional when I called him yesterday. Why emotional? You know, we did the whole song and dance again with him, right? Like this. Oh, yeah. Again. And then all of so then Nicole and Durga said, You know what? No, not interested. Yeah, maybe for yesterday. Durga said, Oh, very interested. That's the one. Give me a compiler talent. Give me the best compiler talent on the planet. I'm like, I just got you the best compiler talent. You guys, go back, go back, go back, go back. I'm doing like two shot. I gave you the chance, so you guys just completely dropped the ball. So I can't say anything. Don't talk to me. Talk to my banker. So
S Speaker 11:16:26Same happened with this. You know, they approach us. They're interested, until she figure out he wants to go with them and be there. I think it's bad in the better that scenario. Just have Dwayne do a talk to me right
Same happened with this. You know, they approach us. They're interested, until she figure out he wants to go with them and be there. I think it's bad in the better that scenario. Just have Dwayne do a talk to me right
Same happened with this. You know, they approach us. They're interested, until she figure out he wants to go with them and be there. I think it's bad in the better that scenario. Just have Dwayne do a talk to me right
Same happened with this. You know, they approach us. They're interested, until she figure out he wants to go with them and be there. I think it's bad in the better that scenario. Just have Dwayne do a talk to me right
S Speaker 11:16:53But, but no, they all. They were all asking me for compiler. And I was surprised. I was like, think just this just happened, like five weeks ago, this whole thing, and then,
But, but no, they all. They were all asking me for compiler. And I was surprised. I was like, think just this just happened, like five weeks ago, this whole thing, and then,
But, but no, they all. They were all asking me for compiler. And I was surprised. I was like, think just this just happened, like five weeks ago, this whole thing, and then,
But, but no, they all. They were all asking me for compiler. And I was surprised. I was like, think just this just happened, like five weeks ago, this whole thing, and then,
S Speaker 11:17:09I don't, I don't know how to stop that above my credit, yeah, but we gotta. I mean, actually, there's a compiler company in Europe, so it's okay, so you got it, just tell me. You say, hey, like, like, anything, we need to sign. We need to heads up. That's all that is simple as that, right? Yeah, I'll just email, yeah, otherwise, we're gonna drag our feet outside. That is gonna be pissed again.
I don't, I don't know how to stop that above my credit, yeah, but we gotta. I mean, actually, there's a compiler company in Europe, so it's okay, so you got it, just tell me. You say, hey, like, like, anything, we need to sign. We need to heads up. That's all that is simple as that, right? Yeah, I'll just email, yeah, otherwise, we're gonna drag our feet outside. That is gonna be pissed again.
I don't, I don't know how to stop that above my credit, yeah, but we gotta. I mean, actually, there's a compiler company in Europe, so it's okay, so you got it, just tell me. You say, hey, like, like, anything, we need to sign. We need to heads up. That's all that is simple as that, right? Yeah, I'll just email, yeah, otherwise, we're gonna drag our feet outside. That is gonna be pissed again.
I don't, I don't know how to stop that above my credit, yeah, but we gotta. I mean, actually, there's a compiler company in Europe, so it's okay, so you got it, just tell me. You say, hey, like, like, anything, we need to sign. We need to heads up. That's all that is simple as that, right? Yeah, I'll just email, yeah, otherwise, we're gonna drag our feet outside. That is gonna be pissed again.
S Speaker 11:17:53Oh, maybe have ck, oh, yeah, maybe car.
S Speaker 11:18:02All right, already told him, we're the nice guys with the good guys. Look at what it turned out to be. So I'm like, I don't have a whole lot of things to do this, but we can try a few years ago.
All right, already told him, we're the nice guys with the good guys. Look at what it turned out to be. So I'm like, I don't have a whole lot of things to do this, but we can try a few years ago.
All right, already told him, we're the nice guys with the good guys. Look at what it turned out to be. So I'm like, I don't have a whole lot of things to do this, but we can try a few years ago.
All right, already told him, we're the nice guys with the good guys. Look at what it turned out to be. So I'm like, I don't have a whole lot of things to do this, but we can try a few years ago.
1:20:12just trying to see where the hell The tempo is. I
S Speaker 11:20:42You okay, hold on, this seems to be of importance. Oh,
You okay, hold on, this seems to be of importance. Oh,
You okay, hold on, this seems to be of importance. Oh,
You okay, hold on, this seems to be of importance. Oh,
1:21:03maximum stamina. Damn. I actually needed that. I feel like that's the one I've been upgrading the least so I've got the least of but I grabbed this too. I Oh
maximum stamina. Damn. I actually needed that. I feel like that's the one I've been upgrading the least so I've got the least of but I grabbed this too. I Oh
maximum stamina. Damn. I actually needed that. I feel like that's the one I've been upgrading the least so I've got the least of but I grabbed this too. I Oh
maximum stamina. Damn. I actually needed that. I feel like that's the one I've been upgrading the least so I've got the least of but I grabbed this too. I Oh
1:21:29no, what happened? Oh no, the focus is, it's a hand. What is this? I
no, what happened? Oh no, the focus is, it's a hand. What is this? I
no, what happened? Oh no, the focus is, it's a hand. What is this? I
no, what happened? Oh no, the focus is, it's a hand. What is this? I
1:24:44supreme inspector, oh, fuck, I'm nervous, bro, oh, My god.
supreme inspector, oh, fuck, I'm nervous, bro, oh, My god.
supreme inspector, oh, fuck, I'm nervous, bro, oh, My god.
supreme inspector, oh, fuck, I'm nervous, bro, oh, My god.
1:24:58Oh, he's hitting that fucking move why? Using holding magic or whatever,
Oh, he's hitting that fucking move why? Using holding magic or whatever,
Oh, he's hitting that fucking move why? Using holding magic or whatever,
Oh, he's hitting that fucking move why? Using holding magic or whatever,
You've hit the transcription limit You've reached the  90 minutes  per conversation transcription limit. Upgrade to Otter Business to get the full transcript. Upgrade to Otter Business
You've hit the transcription limit You've reached the  90 minutes  per conversation transcription limit. Upgrade to Otter Business to get the full transcript. Upgrade to Otter Business