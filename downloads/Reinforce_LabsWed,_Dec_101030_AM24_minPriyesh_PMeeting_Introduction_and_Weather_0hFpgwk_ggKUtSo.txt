Meeting: Reinforce Labs
Wed, Dec 10
10:30 AM
24 min
Priyesh P
Meeting Introduction and Weather Discussion
0:0
URL: https://otter.ai/u/0hFpgwk_ggKUtSorEZ8gWwoTfmE
Downloaded: 2025-12-21T19:18:31.283196
Method: text_extraction
============================================================

0:30Hey, hi, Anish, can
0:32you hear me? Hey, good to see you again. How are you
you hear me? Hey, good to see you again. How are you
you hear me? Hey, good to see you again. How are you
you hear me? Hey, good to see you again. How are you
S Speaker 10:34absolutely Anish, pleasure, pleasure. Speaking. I'm a little bit off weather. But other than then, things, things are great. How about you?
absolutely Anish, pleasure, pleasure. Speaking. I'm a little bit off weather. But other than then, things, things are great. How about you?
absolutely Anish, pleasure, pleasure. Speaking. I'm a little bit off weather. But other than then, things, things are great. How about you?
absolutely Anish, pleasure, pleasure. Speaking. I'm a little bit off weather. But other than then, things, things are great. How about you?
S Speaker 20:43Good, good. Yeah, same, same. We're doing well here, I know the weather is changing, and so it's kind of makes it hard, right?
Good, good. Yeah, same, same. We're doing well here, I know the weather is changing, and so it's kind of makes it hard, right?
Good, good. Yeah, same, same. We're doing well here, I know the weather is changing, and so it's kind of makes it hard, right?
Good, good. Yeah, same, same. We're doing well here, I know the weather is changing, and so it's kind of makes it hard, right?
S Speaker 10:50Yeah, it's really bad. Actually, a lot of team members got stuck by flu. Apparently, there's a new strain going on in Bay Area sometime at this time, so it's hitting
Yeah, it's really bad. Actually, a lot of team members got stuck by flu. Apparently, there's a new strain going on in Bay Area sometime at this time, so it's hitting
Yeah, it's really bad. Actually, a lot of team members got stuck by flu. Apparently, there's a new strain going on in Bay Area sometime at this time, so it's hitting
Yeah, it's really bad. Actually, a lot of team members got stuck by flu. Apparently, there's a new strain going on in Bay Area sometime at this time, so it's hitting
S Speaker 21:00a lot of people hard. I Where are you, gentlemen? Where do you live in the Bay?
a lot of people hard. I Where are you, gentlemen? Where do you live in the Bay?
a lot of people hard. I Where are you, gentlemen? Where do you live in the Bay?
a lot of people hard. I Where are you, gentlemen? Where do you live in the Bay?
S Speaker 11:05I'm in San Mateo, Anish. Most of the Qualcomm ventures team members are here, and then some are in San Diego, where our headquarters is. Okay, Okay, nice. Yeah. Were you at New rips last week? I believe you were
I'm in San Mateo, Anish. Most of the Qualcomm ventures team members are here, and then some are in San Diego, where our headquarters is. Okay, Okay, nice. Yeah. Were you at New rips last week? I believe you were
I'm in San Mateo, Anish. Most of the Qualcomm ventures team members are here, and then some are in San Diego, where our headquarters is. Okay, Okay, nice. Yeah. Were you at New rips last week? I believe you were
I'm in San Mateo, Anish. Most of the Qualcomm ventures team members are here, and then some are in San Diego, where our headquarters is. Okay, Okay, nice. Yeah. Were you at New rips last week? I believe you were
S Speaker 21:17busy, right? Yeah. I was at New rep. Actually. That's what I was traveling. I first went to Columbia University to give a talk there, and then I was at neurodebs as moderating a panel on, like, AI and safety.
busy, right? Yeah. I was at New rep. Actually. That's what I was traveling. I first went to Columbia University to give a talk there, and then I was at neurodebs as moderating a panel on, like, AI and safety.
busy, right? Yeah. I was at New rep. Actually. That's what I was traveling. I first went to Columbia University to give a talk there, and then I was at neurodebs as moderating a panel on, like, AI and safety.
busy, right? Yeah. I was at New rep. Actually. That's what I was traveling. I first went to Columbia University to give a talk there, and then I was at neurodebs as moderating a panel on, like, AI and safety.
S Speaker 11:29Yeah, that's That's amazing. Like, are you sort of trying to do this, to sort of do more word of mouth about reinforce how
Yeah, that's That's amazing. Like, are you sort of trying to do this, to sort of do more word of mouth about reinforce how
Yeah, that's That's amazing. Like, are you sort of trying to do this, to sort of do more word of mouth about reinforce how
Yeah, that's That's amazing. Like, are you sort of trying to do this, to sort of do more word of mouth about reinforce how
S Speaker 21:37that's right? Like, in fact, like, high level, so far, we've tried to stay completely under the radar, like, intentionally, yeah. But our goal is, like, I think maybe early next year, January, February, actually do, like, a proper announcement of the company. We brought, like, we've been super stealth and so on, but so like, doing a little bit of this. But I would say actual proper announcement would be early next year. We lost the company, the through the standard media outlets. I might do a bit more outbound, these kind of events, and then also, like make that's when it will align. Well, because we want to launch our product public. Right now, we have this working with the kind of beta customers designed partnerships, but we'll actually launch the product and make it. Ga also, next year, got it.
that's right? Like, in fact, like, high level, so far, we've tried to stay completely under the radar, like, intentionally, yeah. But our goal is, like, I think maybe early next year, January, February, actually do, like, a proper announcement of the company. We brought, like, we've been super stealth and so on, but so like, doing a little bit of this. But I would say actual proper announcement would be early next year. We lost the company, the through the standard media outlets. I might do a bit more outbound, these kind of events, and then also, like make that's when it will align. Well, because we want to launch our product public. Right now, we have this working with the kind of beta customers designed partnerships, but we'll actually launch the product and make it. Ga also, next year, got it.
that's right? Like, in fact, like, high level, so far, we've tried to stay completely under the radar, like, intentionally, yeah. But our goal is, like, I think maybe early next year, January, February, actually do, like, a proper announcement of the company. We brought, like, we've been super stealth and so on, but so like, doing a little bit of this. But I would say actual proper announcement would be early next year. We lost the company, the through the standard media outlets. I might do a bit more outbound, these kind of events, and then also, like make that's when it will align. Well, because we want to launch our product public. Right now, we have this working with the kind of beta customers designed partnerships, but we'll actually launch the product and make it. Ga also, next year, got it.
that's right? Like, in fact, like, high level, so far, we've tried to stay completely under the radar, like, intentionally, yeah. But our goal is, like, I think maybe early next year, January, February, actually do, like, a proper announcement of the company. We brought, like, we've been super stealth and so on, but so like, doing a little bit of this. But I would say actual proper announcement would be early next year. We lost the company, the through the standard media outlets. I might do a bit more outbound, these kind of events, and then also, like make that's when it will align. Well, because we want to launch our product public. Right now, we have this working with the kind of beta customers designed partnerships, but we'll actually launch the product and make it. Ga also, next year, got it.
S Speaker 12:19That's amazing. Anish, are you also planning to be at CES
That's amazing. Anish, are you also planning to be at CES
That's amazing. Anish, are you also planning to be at CES
That's amazing. Anish, are you also planning to be at CES
S Speaker 22:23No, I wasn't planning to wear the girl. Yeah. When is
No, I wasn't planning to wear the girl. Yeah. When is
No, I wasn't planning to wear the girl. Yeah. When is
No, I wasn't planning to wear the girl. Yeah. When is
S Speaker 12:26it actually early January, the first week of Jan.
it actually early January, the first week of Jan.
it actually early January, the first week of Jan.
it actually early January, the first week of Jan.
2:30Okay, okay, yes, I might.
Okay, okay, yes, I might.
Okay, okay, yes, I might.
Okay, okay, yes, I might.
S Speaker 12:36Are you going to be there or no, we, I'll be there. And we are hosting an event, a very closed dinner with some investors and prospect companies. So in case you were there, I'll ask my team to send you an invite.
Are you going to be there or no, we, I'll be there. And we are hosting an event, a very closed dinner with some investors and prospect companies. So in case you were there, I'll ask my team to send you an invite.
Are you going to be there or no, we, I'll be there. And we are hosting an event, a very closed dinner with some investors and prospect companies. So in case you were there, I'll ask my team to send you an invite.
Are you going to be there or no, we, I'll be there. And we are hosting an event, a very closed dinner with some investors and prospect companies. So in case you were there, I'll ask my team to send you an invite.
S Speaker 22:49Yeah, I let you know I default. I wasn't planning to be there, but I take a look at it. I don't mind. It's like West Coast is easier. It's a short,
Yeah, I let you know I default. I wasn't planning to be there, but I take a look at it. I don't mind. It's like West Coast is easier. It's a short,
Yeah, I let you know I default. I wasn't planning to be there, but I take a look at it. I don't mind. It's like West Coast is easier. It's a short,
Yeah, I let you know I default. I wasn't planning to be there, but I take a look at it. I don't mind. It's like West Coast is easier. It's a short,
S Speaker 13:00yeah, absolutely, absolutely, Anish. Anish. So pleasure meeting again, broadly, what I wanted to do here was have a chat, try to understand, reinforce a little bit better, in the context of the fact that internally at Qualcomm, we are doing a lot of work, sort of, building our own AI systems, onboarding a lot of third party solutions, especially in infra. And then Qualcomm also has a Qualcomm AI hub, which is in partnership with hugging face, where we have a lot of say infra solutions hosted. We have our own developer audience where which build sort of AI applications on top of our hardware. So Qualcomm's AI chips, which go into mobile PCs, a lot of edge solutions, and could be some partnership opportunities there. So I wanted to have a chat about that down the line when you're fundraising. Would love to chat about that as well.
yeah, absolutely, absolutely, Anish. Anish. So pleasure meeting again, broadly, what I wanted to do here was have a chat, try to understand, reinforce a little bit better, in the context of the fact that internally at Qualcomm, we are doing a lot of work, sort of, building our own AI systems, onboarding a lot of third party solutions, especially in infra. And then Qualcomm also has a Qualcomm AI hub, which is in partnership with hugging face, where we have a lot of say infra solutions hosted. We have our own developer audience where which build sort of AI applications on top of our hardware. So Qualcomm's AI chips, which go into mobile PCs, a lot of edge solutions, and could be some partnership opportunities there. So I wanted to have a chat about that down the line when you're fundraising. Would love to chat about that as well.
yeah, absolutely, absolutely, Anish. Anish. So pleasure meeting again, broadly, what I wanted to do here was have a chat, try to understand, reinforce a little bit better, in the context of the fact that internally at Qualcomm, we are doing a lot of work, sort of, building our own AI systems, onboarding a lot of third party solutions, especially in infra. And then Qualcomm also has a Qualcomm AI hub, which is in partnership with hugging face, where we have a lot of say infra solutions hosted. We have our own developer audience where which build sort of AI applications on top of our hardware. So Qualcomm's AI chips, which go into mobile PCs, a lot of edge solutions, and could be some partnership opportunities there. So I wanted to have a chat about that down the line when you're fundraising. Would love to chat about that as well.
yeah, absolutely, absolutely, Anish. Anish. So pleasure meeting again, broadly, what I wanted to do here was have a chat, try to understand, reinforce a little bit better, in the context of the fact that internally at Qualcomm, we are doing a lot of work, sort of, building our own AI systems, onboarding a lot of third party solutions, especially in infra. And then Qualcomm also has a Qualcomm AI hub, which is in partnership with hugging face, where we have a lot of say infra solutions hosted. We have our own developer audience where which build sort of AI applications on top of our hardware. So Qualcomm's AI chips, which go into mobile PCs, a lot of edge solutions, and could be some partnership opportunities there. So I wanted to have a chat about that down the line when you're fundraising. Would love to chat about that as well.
S Speaker 16:32But quick, quickly on that. Anish, so I would say safety is more on protecting outputs, security is more on protecting inputs and compliance is more enterprise focused. And you understand the entire, say, end to end of the application happening there. Interestingly, we, I have spent a lot of time in this space more recently, and we have in done an investment very recently. Now it's still not sort of public yet, but in the company, which is say, in AI governance, and would do a lot of shadow AI protection and then slightly expand into AI security, right? I've also spoken to a lot of AI security companies, the likes of hidden layer Galileo, in observability, a lot of those companies, and this is a broad value prop that they, all of them, sort of say that they provide. My hunch is that it's rather difficult to differentiate the tech behind it, and I'm also not at, say, a very technical person, so it's more difficult for me to understand, but any different approach that you're sort of taking to provide this, yeah.
But quick, quickly on that. Anish, so I would say safety is more on protecting outputs, security is more on protecting inputs and compliance is more enterprise focused. And you understand the entire, say, end to end of the application happening there. Interestingly, we, I have spent a lot of time in this space more recently, and we have in done an investment very recently. Now it's still not sort of public yet, but in the company, which is say, in AI governance, and would do a lot of shadow AI protection and then slightly expand into AI security, right? I've also spoken to a lot of AI security companies, the likes of hidden layer Galileo, in observability, a lot of those companies, and this is a broad value prop that they, all of them, sort of say that they provide. My hunch is that it's rather difficult to differentiate the tech behind it, and I'm also not at, say, a very technical person, so it's more difficult for me to understand, but any different approach that you're sort of taking to provide this, yeah.
But quick, quickly on that. Anish, so I would say safety is more on protecting outputs, security is more on protecting inputs and compliance is more enterprise focused. And you understand the entire, say, end to end of the application happening there. Interestingly, we, I have spent a lot of time in this space more recently, and we have in done an investment very recently. Now it's still not sort of public yet, but in the company, which is say, in AI governance, and would do a lot of shadow AI protection and then slightly expand into AI security, right? I've also spoken to a lot of AI security companies, the likes of hidden layer Galileo, in observability, a lot of those companies, and this is a broad value prop that they, all of them, sort of say that they provide. My hunch is that it's rather difficult to differentiate the tech behind it, and I'm also not at, say, a very technical person, so it's more difficult for me to understand, but any different approach that you're sort of taking to provide this, yeah.
But quick, quickly on that. Anish, so I would say safety is more on protecting outputs, security is more on protecting inputs and compliance is more enterprise focused. And you understand the entire, say, end to end of the application happening there. Interestingly, we, I have spent a lot of time in this space more recently, and we have in done an investment very recently. Now it's still not sort of public yet, but in the company, which is say, in AI governance, and would do a lot of shadow AI protection and then slightly expand into AI security, right? I've also spoken to a lot of AI security companies, the likes of hidden layer Galileo, in observability, a lot of those companies, and this is a broad value prop that they, all of them, sort of say that they provide. My hunch is that it's rather difficult to differentiate the tech behind it, and I'm also not at, say, a very technical person, so it's more difficult for me to understand, but any different approach that you're sort of taking to provide this, yeah.
S Speaker 27:40Yeah. I mean, I think I can fairly quickly jump into it. And then we recently published a blog again, at this beginning to do a bit more outwards on our website, you'll see this blog that we published only one, and we start publishing a bit more, and even do like maybe a paper at some point, but yes, this is a comprehensive benchmark of our techniques on simulation red teaming against all the other published work across a bunch of different chatbots. And it shows a comparison. This is kind of the output, but they're more directly answering why we are doing better, right? Like what high level the technology that we use is extremely comprehensive set of simulations which take on we're looking at this at the application layer for we'll take on many different user personas. So when you have a chat bot, specifically a chat bot, we create a full fledged plan of how a user should interact. There are many different user personnel, and I can show you don't like maybe I just show you some examples of the types of personas. Let me just pull it up, right and that. So this is like an internal kind of tool that we built rightly. But we have a bunch of different chat bots. You have policies, which is what the policy should be. And then we have many different personas. We take this expressive person, somebody seeking mental health, somebody has playful somebody's more, and take many different types of personas. And then for each kind of campaign, campaign is one end to end simulation. We build out a full fledged simulation plan, which is, okay, I'm going to do a conversation with this chat bot through these multi step processes back and forth. And high level the architecture is, there's a simulator which is user creating a message, chatbot responding, and we have an evaluation of the step code. Have we reached the step of the agenda? And we reaching the step of the agenda and so on. And the we have. So there's a simulation engine, the Chatbot environment and the evaluator, these are constantly playing against each other, even as we speak right now. I mean, the model is just fighting against you. Then through self play, all these components are getting better. So there's a kind of simulator or the attacker and the judge, they keep fighting, actually, as a backed by human ops. And ultimately, I think, like, obviously, some of it is bootstrapped by human data, but we feel like the deep that we have, and we similarly made different types of environments, we hopefully will beat the others.
Yeah. I mean, I think I can fairly quickly jump into it. And then we recently published a blog again, at this beginning to do a bit more outwards on our website, you'll see this blog that we published only one, and we start publishing a bit more, and even do like maybe a paper at some point, but yes, this is a comprehensive benchmark of our techniques on simulation red teaming against all the other published work across a bunch of different chatbots. And it shows a comparison. This is kind of the output, but they're more directly answering why we are doing better, right? Like what high level the technology that we use is extremely comprehensive set of simulations which take on we're looking at this at the application layer for we'll take on many different user personas. So when you have a chat bot, specifically a chat bot, we create a full fledged plan of how a user should interact. There are many different user personnel, and I can show you don't like maybe I just show you some examples of the types of personas. Let me just pull it up, right and that. So this is like an internal kind of tool that we built rightly. But we have a bunch of different chat bots. You have policies, which is what the policy should be. And then we have many different personas. We take this expressive person, somebody seeking mental health, somebody has playful somebody's more, and take many different types of personas. And then for each kind of campaign, campaign is one end to end simulation. We build out a full fledged simulation plan, which is, okay, I'm going to do a conversation with this chat bot through these multi step processes back and forth. And high level the architecture is, there's a simulator which is user creating a message, chatbot responding, and we have an evaluation of the step code. Have we reached the step of the agenda? And we reaching the step of the agenda and so on. And the we have. So there's a simulation engine, the Chatbot environment and the evaluator, these are constantly playing against each other, even as we speak right now. I mean, the model is just fighting against you. Then through self play, all these components are getting better. So there's a kind of simulator or the attacker and the judge, they keep fighting, actually, as a backed by human ops. And ultimately, I think, like, obviously, some of it is bootstrapped by human data, but we feel like the deep that we have, and we similarly made different types of environments, we hopefully will beat the others.
Yeah. I mean, I think I can fairly quickly jump into it. And then we recently published a blog again, at this beginning to do a bit more outwards on our website, you'll see this blog that we published only one, and we start publishing a bit more, and even do like maybe a paper at some point, but yes, this is a comprehensive benchmark of our techniques on simulation red teaming against all the other published work across a bunch of different chatbots. And it shows a comparison. This is kind of the output, but they're more directly answering why we are doing better, right? Like what high level the technology that we use is extremely comprehensive set of simulations which take on we're looking at this at the application layer for we'll take on many different user personas. So when you have a chat bot, specifically a chat bot, we create a full fledged plan of how a user should interact. There are many different user personnel, and I can show you don't like maybe I just show you some examples of the types of personas. Let me just pull it up, right and that. So this is like an internal kind of tool that we built rightly. But we have a bunch of different chat bots. You have policies, which is what the policy should be. And then we have many different personas. We take this expressive person, somebody seeking mental health, somebody has playful somebody's more, and take many different types of personas. And then for each kind of campaign, campaign is one end to end simulation. We build out a full fledged simulation plan, which is, okay, I'm going to do a conversation with this chat bot through these multi step processes back and forth. And high level the architecture is, there's a simulator which is user creating a message, chatbot responding, and we have an evaluation of the step code. Have we reached the step of the agenda? And we reaching the step of the agenda and so on. And the we have. So there's a simulation engine, the Chatbot environment and the evaluator, these are constantly playing against each other, even as we speak right now. I mean, the model is just fighting against you. Then through self play, all these components are getting better. So there's a kind of simulator or the attacker and the judge, they keep fighting, actually, as a backed by human ops. And ultimately, I think, like, obviously, some of it is bootstrapped by human data, but we feel like the deep that we have, and we similarly made different types of environments, we hopefully will beat the others.
Yeah. I mean, I think I can fairly quickly jump into it. And then we recently published a blog again, at this beginning to do a bit more outwards on our website, you'll see this blog that we published only one, and we start publishing a bit more, and even do like maybe a paper at some point, but yes, this is a comprehensive benchmark of our techniques on simulation red teaming against all the other published work across a bunch of different chatbots. And it shows a comparison. This is kind of the output, but they're more directly answering why we are doing better, right? Like what high level the technology that we use is extremely comprehensive set of simulations which take on we're looking at this at the application layer for we'll take on many different user personas. So when you have a chat bot, specifically a chat bot, we create a full fledged plan of how a user should interact. There are many different user personnel, and I can show you don't like maybe I just show you some examples of the types of personas. Let me just pull it up, right and that. So this is like an internal kind of tool that we built rightly. But we have a bunch of different chat bots. You have policies, which is what the policy should be. And then we have many different personas. We take this expressive person, somebody seeking mental health, somebody has playful somebody's more, and take many different types of personas. And then for each kind of campaign, campaign is one end to end simulation. We build out a full fledged simulation plan, which is, okay, I'm going to do a conversation with this chat bot through these multi step processes back and forth. And high level the architecture is, there's a simulator which is user creating a message, chatbot responding, and we have an evaluation of the step code. Have we reached the step of the agenda? And we reaching the step of the agenda and so on. And the we have. So there's a simulation engine, the Chatbot environment and the evaluator, these are constantly playing against each other, even as we speak right now. I mean, the model is just fighting against you. Then through self play, all these components are getting better. So there's a kind of simulator or the attacker and the judge, they keep fighting, actually, as a backed by human ops. And ultimately, I think, like, obviously, some of it is bootstrapped by human data, but we feel like the deep that we have, and we similarly made different types of environments, we hopefully will beat the others.
S Speaker 110:14That's super interesting. Anish, that's, that's a very interesting approach simulating user behavior is, a technology wise, something that I've seen in different spaces. I've seen it in generative UI and some some platforms which sort of come before vibe coding and sort of see if some features that someone is developing would work or not, or even in market research, but not in security, as detailed as you were saying. So that's pretty interesting. My follow up question there would be, it's a it's like doing that correctly, and seems like you have very comprehensive set of personas, but it's a long tail problem, right? There are a lot of different personas that that may not seem very obvious. So how are you thinking about sort of making sure that the entire persona, but, yeah, very comprehensive,
That's super interesting. Anish, that's, that's a very interesting approach simulating user behavior is, a technology wise, something that I've seen in different spaces. I've seen it in generative UI and some some platforms which sort of come before vibe coding and sort of see if some features that someone is developing would work or not, or even in market research, but not in security, as detailed as you were saying. So that's pretty interesting. My follow up question there would be, it's a it's like doing that correctly, and seems like you have very comprehensive set of personas, but it's a long tail problem, right? There are a lot of different personas that that may not seem very obvious. So how are you thinking about sort of making sure that the entire persona, but, yeah, very comprehensive,
That's super interesting. Anish, that's, that's a very interesting approach simulating user behavior is, a technology wise, something that I've seen in different spaces. I've seen it in generative UI and some some platforms which sort of come before vibe coding and sort of see if some features that someone is developing would work or not, or even in market research, but not in security, as detailed as you were saying. So that's pretty interesting. My follow up question there would be, it's a it's like doing that correctly, and seems like you have very comprehensive set of personas, but it's a long tail problem, right? There are a lot of different personas that that may not seem very obvious. So how are you thinking about sort of making sure that the entire persona, but, yeah, very comprehensive,
That's super interesting. Anish, that's, that's a very interesting approach simulating user behavior is, a technology wise, something that I've seen in different spaces. I've seen it in generative UI and some some platforms which sort of come before vibe coding and sort of see if some features that someone is developing would work or not, or even in market research, but not in security, as detailed as you were saying. So that's pretty interesting. My follow up question there would be, it's a it's like doing that correctly, and seems like you have very comprehensive set of personas, but it's a long tail problem, right? There are a lot of different personas that that may not seem very obvious. So how are you thinking about sort of making sure that the entire persona, but, yeah, very comprehensive,
S Speaker 211:04that's right. So I think part of it is, I think annuals, he starts a conversation with a while, and these are real conversations with the chat bots. And we do the bunch of these, I think, As for whether it's comprehensive or not, and it's, I think there's like personas, there's different agendas, agenda that, how am I going to try to compromise the system and so on? We have a we have built out, like, actually bootstrapped by humans, right? So we are partnering with, actually a large annotation provider that does a lot of like, highly curated data set generation. Have been doing these kinds of red teaming exercises manually, using that as our starting point, and then we are using our AI models to expand from the seed set itself, As for whether it's the most comprehensive or not. We don't know, right? Like nobody knows what the recall is. Yes, what we're able to show is that here's the gaps we found, compared to everybody else's gaps that we found, and then in this space, like, at least from a red teaming standpoint, our goal is to be the best, like, find the best. But I find everything, to be honest, nobody will ever be able to cover right like, it's going to be evolving, but hopefully we find much more than any other competitor, and go to market motion, as long as long as we can find whatever they're using, compared to that we can find more than this clear, incremental value provided
that's right. So I think part of it is, I think annuals, he starts a conversation with a while, and these are real conversations with the chat bots. And we do the bunch of these, I think, As for whether it's comprehensive or not, and it's, I think there's like personas, there's different agendas, agenda that, how am I going to try to compromise the system and so on? We have a we have built out, like, actually bootstrapped by humans, right? So we are partnering with, actually a large annotation provider that does a lot of like, highly curated data set generation. Have been doing these kinds of red teaming exercises manually, using that as our starting point, and then we are using our AI models to expand from the seed set itself, As for whether it's the most comprehensive or not. We don't know, right? Like nobody knows what the recall is. Yes, what we're able to show is that here's the gaps we found, compared to everybody else's gaps that we found, and then in this space, like, at least from a red teaming standpoint, our goal is to be the best, like, find the best. But I find everything, to be honest, nobody will ever be able to cover right like, it's going to be evolving, but hopefully we find much more than any other competitor, and go to market motion, as long as long as we can find whatever they're using, compared to that we can find more than this clear, incremental value provided
that's right. So I think part of it is, I think annuals, he starts a conversation with a while, and these are real conversations with the chat bots. And we do the bunch of these, I think, As for whether it's comprehensive or not, and it's, I think there's like personas, there's different agendas, agenda that, how am I going to try to compromise the system and so on? We have a we have built out, like, actually bootstrapped by humans, right? So we are partnering with, actually a large annotation provider that does a lot of like, highly curated data set generation. Have been doing these kinds of red teaming exercises manually, using that as our starting point, and then we are using our AI models to expand from the seed set itself, As for whether it's the most comprehensive or not. We don't know, right? Like nobody knows what the recall is. Yes, what we're able to show is that here's the gaps we found, compared to everybody else's gaps that we found, and then in this space, like, at least from a red teaming standpoint, our goal is to be the best, like, find the best. But I find everything, to be honest, nobody will ever be able to cover right like, it's going to be evolving, but hopefully we find much more than any other competitor, and go to market motion, as long as long as we can find whatever they're using, compared to that we can find more than this clear, incremental value provided
that's right. So I think part of it is, I think annuals, he starts a conversation with a while, and these are real conversations with the chat bots. And we do the bunch of these, I think, As for whether it's comprehensive or not, and it's, I think there's like personas, there's different agendas, agenda that, how am I going to try to compromise the system and so on? We have a we have built out, like, actually bootstrapped by humans, right? So we are partnering with, actually a large annotation provider that does a lot of like, highly curated data set generation. Have been doing these kinds of red teaming exercises manually, using that as our starting point, and then we are using our AI models to expand from the seed set itself, As for whether it's the most comprehensive or not. We don't know, right? Like nobody knows what the recall is. Yes, what we're able to show is that here's the gaps we found, compared to everybody else's gaps that we found, and then in this space, like, at least from a red teaming standpoint, our goal is to be the best, like, find the best. But I find everything, to be honest, nobody will ever be able to cover right like, it's going to be evolving, but hopefully we find much more than any other competitor, and go to market motion, as long as long as we can find whatever they're using, compared to that we can find more than this clear, incremental value provided
S Speaker 112:27totally, totally and I'm assuming as you deploy, you are present at inline, during, say, runtime, you're capturing every interaction so your your entire bucket expands as you deploy as your scale,
totally, totally and I'm assuming as you deploy, you are present at inline, during, say, runtime, you're capturing every interaction so your your entire bucket expands as you deploy as your scale,
totally, totally and I'm assuming as you deploy, you are present at inline, during, say, runtime, you're capturing every interaction so your your entire bucket expands as you deploy as your scale,
totally, totally and I'm assuming as you deploy, you are present at inline, during, say, runtime, you're capturing every interaction so your your entire bucket expands as you deploy as your scale,
S Speaker 113:51That's and that's a fair approach Anish, I think, from from my study as well, most of the deployments today are chatbots, and they are expanding into agents. But I think market is still early for that. One question I have for you, and it's, it's a thesis I have, is, say, the total surface area that a security provider covers, and you probably today integrate as an API or an SDK into applications that an enterprise is developing in house. But a big part of problem that I see at Qualcomm as well is the shadow AI usage, which is all the AI that I'm just swiping my credit card at as a SaaS using, which Qualcomm hasn't developed, but Qualcomm hasn't authorized either, and yes, there is a big need to protect that.
That's and that's a fair approach Anish, I think, from from my study as well, most of the deployments today are chatbots, and they are expanding into agents. But I think market is still early for that. One question I have for you, and it's, it's a thesis I have, is, say, the total surface area that a security provider covers, and you probably today integrate as an API or an SDK into applications that an enterprise is developing in house. But a big part of problem that I see at Qualcomm as well is the shadow AI usage, which is all the AI that I'm just swiping my credit card at as a SaaS using, which Qualcomm hasn't developed, but Qualcomm hasn't authorized either, and yes, there is a big need to protect that.
That's and that's a fair approach Anish, I think, from from my study as well, most of the deployments today are chatbots, and they are expanding into agents. But I think market is still early for that. One question I have for you, and it's, it's a thesis I have, is, say, the total surface area that a security provider covers, and you probably today integrate as an API or an SDK into applications that an enterprise is developing in house. But a big part of problem that I see at Qualcomm as well is the shadow AI usage, which is all the AI that I'm just swiping my credit card at as a SaaS using, which Qualcomm hasn't developed, but Qualcomm hasn't authorized either, and yes, there is a big need to protect that.
That's and that's a fair approach Anish, I think, from from my study as well, most of the deployments today are chatbots, and they are expanding into agents. But I think market is still early for that. One question I have for you, and it's, it's a thesis I have, is, say, the total surface area that a security provider covers, and you probably today integrate as an API or an SDK into applications that an enterprise is developing in house. But a big part of problem that I see at Qualcomm as well is the shadow AI usage, which is all the AI that I'm just swiping my credit card at as a SaaS using, which Qualcomm hasn't developed, but Qualcomm hasn't authorized either, and yes, there is a big need to protect that.
S Speaker 214:46I understood this. So when you say, is this like the AI users, you may not realize users of any application,
I understood this. So when you say, is this like the AI users, you may not realize users of any application,
I understood this. So when you say, is this like the AI users, you may not realize users of any application,
I understood this. So when you say, is this like the AI users, you may not realize users of any application,
S Speaker 114:54or, yeah, say, say, a perplexity, a perplexity would be blocked by my Qualcomm's browser. But there's a long team of applications which are out there as a SaaS. And do you sort of, are you thinking of, say, adding a network level protection and doing something like that, or is that not?
or, yeah, say, say, a perplexity, a perplexity would be blocked by my Qualcomm's browser. But there's a long team of applications which are out there as a SaaS. And do you sort of, are you thinking of, say, adding a network level protection and doing something like that, or is that not?
or, yeah, say, say, a perplexity, a perplexity would be blocked by my Qualcomm's browser. But there's a long team of applications which are out there as a SaaS. And do you sort of, are you thinking of, say, adding a network level protection and doing something like that, or is that not?
or, yeah, say, say, a perplexity, a perplexity would be blocked by my Qualcomm's browser. But there's a long team of applications which are out there as a SaaS. And do you sort of, are you thinking of, say, adding a network level protection and doing something like that, or is that not?
S Speaker 215:16I think there is a need for that. We have not gone into that like we what we are seeing is very agnostic to whether the user is an agent, or what we are saying is we have some attributes of the user. The definition of what is allowed or not allowed is by the policies, say of Qualcomm. And we try to simulate, if you say you do want to try to and we are simulating user personas, yeah. If that says, like, no bots are allowed, we can try to simulate bots, right? But it's like, ultimately, our mission here is much more about protecting real individuals, less so on that thing, but we may expand like the market is come up before I can imagine. Yeah, so it's definitely an area that needs solutions. We don't have that right now, retail chat bots, just consumer apps, like dating applications, applications for like neurodivergent people. Like these are the types of examples, even like more large tech companies, they want raise possible AI they have present safety teams. Those are the types of cases where we are already getting, like, material interest from, and that's why we just said, Let's just focus on that. Yes, clear, like you said, there's competition, so we just want to be clearly the best in the business in that Yeah. And then from there,
I think there is a need for that. We have not gone into that like we what we are seeing is very agnostic to whether the user is an agent, or what we are saying is we have some attributes of the user. The definition of what is allowed or not allowed is by the policies, say of Qualcomm. And we try to simulate, if you say you do want to try to and we are simulating user personas, yeah. If that says, like, no bots are allowed, we can try to simulate bots, right? But it's like, ultimately, our mission here is much more about protecting real individuals, less so on that thing, but we may expand like the market is come up before I can imagine. Yeah, so it's definitely an area that needs solutions. We don't have that right now, retail chat bots, just consumer apps, like dating applications, applications for like neurodivergent people. Like these are the types of examples, even like more large tech companies, they want raise possible AI they have present safety teams. Those are the types of cases where we are already getting, like, material interest from, and that's why we just said, Let's just focus on that. Yes, clear, like you said, there's competition, so we just want to be clearly the best in the business in that Yeah. And then from there,
I think there is a need for that. We have not gone into that like we what we are seeing is very agnostic to whether the user is an agent, or what we are saying is we have some attributes of the user. The definition of what is allowed or not allowed is by the policies, say of Qualcomm. And we try to simulate, if you say you do want to try to and we are simulating user personas, yeah. If that says, like, no bots are allowed, we can try to simulate bots, right? But it's like, ultimately, our mission here is much more about protecting real individuals, less so on that thing, but we may expand like the market is come up before I can imagine. Yeah, so it's definitely an area that needs solutions. We don't have that right now, retail chat bots, just consumer apps, like dating applications, applications for like neurodivergent people. Like these are the types of examples, even like more large tech companies, they want raise possible AI they have present safety teams. Those are the types of cases where we are already getting, like, material interest from, and that's why we just said, Let's just focus on that. Yes, clear, like you said, there's competition, so we just want to be clearly the best in the business in that Yeah. And then from there,
I think there is a need for that. We have not gone into that like we what we are seeing is very agnostic to whether the user is an agent, or what we are saying is we have some attributes of the user. The definition of what is allowed or not allowed is by the policies, say of Qualcomm. And we try to simulate, if you say you do want to try to and we are simulating user personas, yeah. If that says, like, no bots are allowed, we can try to simulate bots, right? But it's like, ultimately, our mission here is much more about protecting real individuals, less so on that thing, but we may expand like the market is come up before I can imagine. Yeah, so it's definitely an area that needs solutions. We don't have that right now, retail chat bots, just consumer apps, like dating applications, applications for like neurodivergent people. Like these are the types of examples, even like more large tech companies, they want raise possible AI they have present safety teams. Those are the types of cases where we are already getting, like, material interest from, and that's why we just said, Let's just focus on that. Yes, clear, like you said, there's competition, so we just want to be clearly the best in the business in that Yeah. And then from there,
S Speaker 116:34totally, totally makes sense. Anish. And on the simulation part, Anish, is it, say, static today or, like you have a big bucket of simulations that you want to run, or is it more dynamic, contextual based on
totally, totally makes sense. Anish. And on the simulation part, Anish, is it, say, static today or, like you have a big bucket of simulations that you want to run, or is it more dynamic, contextual based on
totally, totally makes sense. Anish. And on the simulation part, Anish, is it, say, static today or, like you have a big bucket of simulations that you want to run, or is it more dynamic, contextual based on
totally, totally makes sense. Anish. And on the simulation part, Anish, is it, say, static today or, like you have a big bucket of simulations that you want to run, or is it more dynamic, contextual based on
S Speaker 216:45chatbot industry. It's fully, fully customized, dedicated. It's no nothing static. I mean, we will have benefits as we have more customers because we have static, but it's completely based on the Chatbot, the environment, the policies, based on that. We customize the set of agendas, a set of user personas, run them, and even within the same product, if there's new launches, we'll keep adapting to it so, but so there's like, adaptation based on the environment, which is the chat for the policies, and we'll also keep augmenting based on things outside of the control. Like, for example, new language keeps emerging, right? Like Gen Z uses a different language, they get it, so we might populate that and so on.
chatbot industry. It's fully, fully customized, dedicated. It's no nothing static. I mean, we will have benefits as we have more customers because we have static, but it's completely based on the Chatbot, the environment, the policies, based on that. We customize the set of agendas, a set of user personas, run them, and even within the same product, if there's new launches, we'll keep adapting to it so, but so there's like, adaptation based on the environment, which is the chat for the policies, and we'll also keep augmenting based on things outside of the control. Like, for example, new language keeps emerging, right? Like Gen Z uses a different language, they get it, so we might populate that and so on.
chatbot industry. It's fully, fully customized, dedicated. It's no nothing static. I mean, we will have benefits as we have more customers because we have static, but it's completely based on the Chatbot, the environment, the policies, based on that. We customize the set of agendas, a set of user personas, run them, and even within the same product, if there's new launches, we'll keep adapting to it so, but so there's like, adaptation based on the environment, which is the chat for the policies, and we'll also keep augmenting based on things outside of the control. Like, for example, new language keeps emerging, right? Like Gen Z uses a different language, they get it, so we might populate that and so on.
chatbot industry. It's fully, fully customized, dedicated. It's no nothing static. I mean, we will have benefits as we have more customers because we have static, but it's completely based on the Chatbot, the environment, the policies, based on that. We customize the set of agendas, a set of user personas, run them, and even within the same product, if there's new launches, we'll keep adapting to it so, but so there's like, adaptation based on the environment, which is the chat for the policies, and we'll also keep augmenting based on things outside of the control. Like, for example, new language keeps emerging, right? Like Gen Z uses a different language, they get it, so we might populate that and so on.
S Speaker 117:23And how does the policy and guardrail building side for, say, an enterprise look like Anish, like, can I create guardrails based on natural language? How does the system interpret that? It could be also very contextual for different industries, different use cases.
And how does the policy and guardrail building side for, say, an enterprise look like Anish, like, can I create guardrails based on natural language? How does the system interpret that? It could be also very contextual for different industries, different use cases.
And how does the policy and guardrail building side for, say, an enterprise look like Anish, like, can I create guardrails based on natural language? How does the system interpret that? It could be also very contextual for different industries, different use cases.
And how does the policy and guardrail building side for, say, an enterprise look like Anish, like, can I create guardrails based on natural language? How does the system interpret that? It could be also very contextual for different industries, different use cases.
S Speaker 217:39It's extremely nuanced, right? For example, what is a safe for roadblocks? Yeah, is different. Below block is 13 year old kids. What is safe for them is different for work, from what is safe for Reddit or discord and so on. So our input is a text policy. So then many of these policies are just text. They have some language in the text, and optionally a data set. So if you have labeled data set war, and then the key thing is, our guardians keep will keep improving very rapidly, because we will tell you we are. We think we should. We're not making a strong point of view because it's so nice. But based on your policy and any data we have, we said they should be blocked. They should not be blocked. Classify those. And then if you give us more feedback, our models will keep iterating and improving. Yeah. One thing to realize here is that this is a good solution for many companies. For super deep tech companies, I don't think guardrails completely replace internal solution. Like, if you take a Google or somebody, there's a huge amount of internal data as well, right and internal features for specific account. So just looking at a conversation is often not enough to have the best looking at a conversation, but they know about the user, the history of the user connections to other users, and so they, in those cases, we would be an additive layer on top of their internal models.
It's extremely nuanced, right? For example, what is a safe for roadblocks? Yeah, is different. Below block is 13 year old kids. What is safe for them is different for work, from what is safe for Reddit or discord and so on. So our input is a text policy. So then many of these policies are just text. They have some language in the text, and optionally a data set. So if you have labeled data set war, and then the key thing is, our guardians keep will keep improving very rapidly, because we will tell you we are. We think we should. We're not making a strong point of view because it's so nice. But based on your policy and any data we have, we said they should be blocked. They should not be blocked. Classify those. And then if you give us more feedback, our models will keep iterating and improving. Yeah. One thing to realize here is that this is a good solution for many companies. For super deep tech companies, I don't think guardrails completely replace internal solution. Like, if you take a Google or somebody, there's a huge amount of internal data as well, right and internal features for specific account. So just looking at a conversation is often not enough to have the best looking at a conversation, but they know about the user, the history of the user connections to other users, and so they, in those cases, we would be an additive layer on top of their internal models.
It's extremely nuanced, right? For example, what is a safe for roadblocks? Yeah, is different. Below block is 13 year old kids. What is safe for them is different for work, from what is safe for Reddit or discord and so on. So our input is a text policy. So then many of these policies are just text. They have some language in the text, and optionally a data set. So if you have labeled data set war, and then the key thing is, our guardians keep will keep improving very rapidly, because we will tell you we are. We think we should. We're not making a strong point of view because it's so nice. But based on your policy and any data we have, we said they should be blocked. They should not be blocked. Classify those. And then if you give us more feedback, our models will keep iterating and improving. Yeah. One thing to realize here is that this is a good solution for many companies. For super deep tech companies, I don't think guardrails completely replace internal solution. Like, if you take a Google or somebody, there's a huge amount of internal data as well, right and internal features for specific account. So just looking at a conversation is often not enough to have the best looking at a conversation, but they know about the user, the history of the user connections to other users, and so they, in those cases, we would be an additive layer on top of their internal models.
It's extremely nuanced, right? For example, what is a safe for roadblocks? Yeah, is different. Below block is 13 year old kids. What is safe for them is different for work, from what is safe for Reddit or discord and so on. So our input is a text policy. So then many of these policies are just text. They have some language in the text, and optionally a data set. So if you have labeled data set war, and then the key thing is, our guardians keep will keep improving very rapidly, because we will tell you we are. We think we should. We're not making a strong point of view because it's so nice. But based on your policy and any data we have, we said they should be blocked. They should not be blocked. Classify those. And then if you give us more feedback, our models will keep iterating and improving. Yeah. One thing to realize here is that this is a good solution for many companies. For super deep tech companies, I don't think guardrails completely replace internal solution. Like, if you take a Google or somebody, there's a huge amount of internal data as well, right and internal features for specific account. So just looking at a conversation is often not enough to have the best looking at a conversation, but they know about the user, the history of the user connections to other users, and so they, in those cases, we would be an additive layer on top of their internal models.
S Speaker 119:00Got it, got it. And Anish, last question you mentioned, you also sort of provide solutions to fix all the vulnerabilities that you find. How does that part look like and that it's also going on into the entire pre deployment side of things?
Got it, got it. And Anish, last question you mentioned, you also sort of provide solutions to fix all the vulnerabilities that you find. How does that part look like and that it's also going on into the entire pre deployment side of things?
Got it, got it. And Anish, last question you mentioned, you also sort of provide solutions to fix all the vulnerabilities that you find. How does that part look like and that it's also going on into the entire pre deployment side of things?
Got it, got it. And Anish, last question you mentioned, you also sort of provide solutions to fix all the vulnerabilities that you find. How does that part look like and that it's also going on into the entire pre deployment side of things?
S Speaker 219:14Right? So right now, fixing is only two things. So one is garbage, real time fixing. Yeah, that the second is for systematic fixing. What we do is we can provide our data. Often, the gaps in these models, if you have internal models, are there, are you get training it up, and a real escalation happens. When a real escalation happens, then you add that data set, but we'll simulate. We won't just gaps, but we will allow you to download the data set, and then we can either continue your model, or if you want to retrain your model. But code related gaps, we are not yet going into the code and saying bug fixes of the code. What we can improve is your internal model pre deployment.
Right? So right now, fixing is only two things. So one is garbage, real time fixing. Yeah, that the second is for systematic fixing. What we do is we can provide our data. Often, the gaps in these models, if you have internal models, are there, are you get training it up, and a real escalation happens. When a real escalation happens, then you add that data set, but we'll simulate. We won't just gaps, but we will allow you to download the data set, and then we can either continue your model, or if you want to retrain your model. But code related gaps, we are not yet going into the code and saying bug fixes of the code. What we can improve is your internal model pre deployment.
Right? So right now, fixing is only two things. So one is garbage, real time fixing. Yeah, that the second is for systematic fixing. What we do is we can provide our data. Often, the gaps in these models, if you have internal models, are there, are you get training it up, and a real escalation happens. When a real escalation happens, then you add that data set, but we'll simulate. We won't just gaps, but we will allow you to download the data set, and then we can either continue your model, or if you want to retrain your model. But code related gaps, we are not yet going into the code and saying bug fixes of the code. What we can improve is your internal model pre deployment.
Right? So right now, fixing is only two things. So one is garbage, real time fixing. Yeah, that the second is for systematic fixing. What we do is we can provide our data. Often, the gaps in these models, if you have internal models, are there, are you get training it up, and a real escalation happens. When a real escalation happens, then you add that data set, but we'll simulate. We won't just gaps, but we will allow you to download the data set, and then we can either continue your model, or if you want to retrain your model. But code related gaps, we are not yet going into the code and saying bug fixes of the code. What we can improve is your internal model pre deployment.
S Speaker 119:56Got it, got it super interesting and and how does, like, where are you in terms of design partners and all of that, and would you be?
Got it, got it super interesting and and how does, like, where are you in terms of design partners and all of that, and would you be?
Got it, got it super interesting and and how does, like, where are you in terms of design partners and all of that, and would you be?
Got it, got it super interesting and and how does, like, where are you in terms of design partners and all of that, and would you be?
S Speaker 220:06Yeah, design partners, funding. And I actually all of that, really. So we ended up raising the largest round early this year, like we raised 15 million. So again, I have not created a lot of noise out of it, but maybe January, February, we would, because I didn't see a need to announce the funding, but we secured that most of us are in the bank, and they've grown the team to 10 people actually significantly increased over the last three, four months, as they've got full conviction that this is the space. We have a internal prototype, the kind of thing that I showed you ready. We are working with a couple of design partners. One is a joint go to market. The panel at New reps was with scientific they are one of our customers. Is a very large innovation provider. And we they are both a customer of ours, and we are doing a joint AI solution go to market strategy with them, because they have all the max events large enterprises as their customers. And so we are, we have a joint, responsible, AI sort of strategy. So that's one. And then we're working with a couple of early stages, with a couple of consumer apps, right? And these are in, like, dating, retail sort of space, yeah, we are, got some interest from banks. Haven't quite engaged deeply yet, the plan is work with these couple of people. If there's other clear fit with when I say clear fit, if it's chat bots, I would like to engage right away, if a general, broader agent, AI systems, then I'm holding off on those conversations. That is January, launched the product, and then we can get the sales go to market motion right now it's more like the way the mode of interaction is that we have a pilot for a few weeks. Understand the use case, get the policies. Do a pilot, if it's meaningful, then we convert into into a customer. But after January, this
Yeah, design partners, funding. And I actually all of that, really. So we ended up raising the largest round early this year, like we raised 15 million. So again, I have not created a lot of noise out of it, but maybe January, February, we would, because I didn't see a need to announce the funding, but we secured that most of us are in the bank, and they've grown the team to 10 people actually significantly increased over the last three, four months, as they've got full conviction that this is the space. We have a internal prototype, the kind of thing that I showed you ready. We are working with a couple of design partners. One is a joint go to market. The panel at New reps was with scientific they are one of our customers. Is a very large innovation provider. And we they are both a customer of ours, and we are doing a joint AI solution go to market strategy with them, because they have all the max events large enterprises as their customers. And so we are, we have a joint, responsible, AI sort of strategy. So that's one. And then we're working with a couple of early stages, with a couple of consumer apps, right? And these are in, like, dating, retail sort of space, yeah, we are, got some interest from banks. Haven't quite engaged deeply yet, the plan is work with these couple of people. If there's other clear fit with when I say clear fit, if it's chat bots, I would like to engage right away, if a general, broader agent, AI systems, then I'm holding off on those conversations. That is January, launched the product, and then we can get the sales go to market motion right now it's more like the way the mode of interaction is that we have a pilot for a few weeks. Understand the use case, get the policies. Do a pilot, if it's meaningful, then we convert into into a customer. But after January, this
Yeah, design partners, funding. And I actually all of that, really. So we ended up raising the largest round early this year, like we raised 15 million. So again, I have not created a lot of noise out of it, but maybe January, February, we would, because I didn't see a need to announce the funding, but we secured that most of us are in the bank, and they've grown the team to 10 people actually significantly increased over the last three, four months, as they've got full conviction that this is the space. We have a internal prototype, the kind of thing that I showed you ready. We are working with a couple of design partners. One is a joint go to market. The panel at New reps was with scientific they are one of our customers. Is a very large innovation provider. And we they are both a customer of ours, and we are doing a joint AI solution go to market strategy with them, because they have all the max events large enterprises as their customers. And so we are, we have a joint, responsible, AI sort of strategy. So that's one. And then we're working with a couple of early stages, with a couple of consumer apps, right? And these are in, like, dating, retail sort of space, yeah, we are, got some interest from banks. Haven't quite engaged deeply yet, the plan is work with these couple of people. If there's other clear fit with when I say clear fit, if it's chat bots, I would like to engage right away, if a general, broader agent, AI systems, then I'm holding off on those conversations. That is January, launched the product, and then we can get the sales go to market motion right now it's more like the way the mode of interaction is that we have a pilot for a few weeks. Understand the use case, get the policies. Do a pilot, if it's meaningful, then we convert into into a customer. But after January, this
Yeah, design partners, funding. And I actually all of that, really. So we ended up raising the largest round early this year, like we raised 15 million. So again, I have not created a lot of noise out of it, but maybe January, February, we would, because I didn't see a need to announce the funding, but we secured that most of us are in the bank, and they've grown the team to 10 people actually significantly increased over the last three, four months, as they've got full conviction that this is the space. We have a internal prototype, the kind of thing that I showed you ready. We are working with a couple of design partners. One is a joint go to market. The panel at New reps was with scientific they are one of our customers. Is a very large innovation provider. And we they are both a customer of ours, and we are doing a joint AI solution go to market strategy with them, because they have all the max events large enterprises as their customers. And so we are, we have a joint, responsible, AI sort of strategy. So that's one. And then we're working with a couple of early stages, with a couple of consumer apps, right? And these are in, like, dating, retail sort of space, yeah, we are, got some interest from banks. Haven't quite engaged deeply yet, the plan is work with these couple of people. If there's other clear fit with when I say clear fit, if it's chat bots, I would like to engage right away, if a general, broader agent, AI systems, then I'm holding off on those conversations. That is January, launched the product, and then we can get the sales go to market motion right now it's more like the way the mode of interaction is that we have a pilot for a few weeks. Understand the use case, get the policies. Do a pilot, if it's meaningful, then we convert into into a customer. But after January, this
S Speaker 121:58Makes total sense. Anish, and from Qualcomm's end as well, some of the solutions we are generating, some internal tools are definitely more agentic. So we have an internal coding agent. We don't use cursor. Any of those we have developed our own. There's something for support agents. But the AI hub partnership looks pretty interesting for me, just by the thought of it, given that most what our focus there is to have chat bots which would run on your device. So it's it, the entire workload runs on device. And there, again, today, not most of the agentic workloads do that, but a simple chat bot is definitely able to do that. We have had, say, interest coming in from a lot of companion apps, saying the data needs to be on device, and hence my AI workload need to be on device. So when, when? What I'll do internally is have a chat with the AI hub team and see if we can say, sync up with your announcement, or do something like that. Post that,
Makes total sense. Anish, and from Qualcomm's end as well, some of the solutions we are generating, some internal tools are definitely more agentic. So we have an internal coding agent. We don't use cursor. Any of those we have developed our own. There's something for support agents. But the AI hub partnership looks pretty interesting for me, just by the thought of it, given that most what our focus there is to have chat bots which would run on your device. So it's it, the entire workload runs on device. And there, again, today, not most of the agentic workloads do that, but a simple chat bot is definitely able to do that. We have had, say, interest coming in from a lot of companion apps, saying the data needs to be on device, and hence my AI workload need to be on device. So when, when? What I'll do internally is have a chat with the AI hub team and see if we can say, sync up with your announcement, or do something like that. Post that,
Makes total sense. Anish, and from Qualcomm's end as well, some of the solutions we are generating, some internal tools are definitely more agentic. So we have an internal coding agent. We don't use cursor. Any of those we have developed our own. There's something for support agents. But the AI hub partnership looks pretty interesting for me, just by the thought of it, given that most what our focus there is to have chat bots which would run on your device. So it's it, the entire workload runs on device. And there, again, today, not most of the agentic workloads do that, but a simple chat bot is definitely able to do that. We have had, say, interest coming in from a lot of companion apps, saying the data needs to be on device, and hence my AI workload need to be on device. So when, when? What I'll do internally is have a chat with the AI hub team and see if we can say, sync up with your announcement, or do something like that. Post that,
Makes total sense. Anish, and from Qualcomm's end as well, some of the solutions we are generating, some internal tools are definitely more agentic. So we have an internal coding agent. We don't use cursor. Any of those we have developed our own. There's something for support agents. But the AI hub partnership looks pretty interesting for me, just by the thought of it, given that most what our focus there is to have chat bots which would run on your device. So it's it, the entire workload runs on device. And there, again, today, not most of the agentic workloads do that, but a simple chat bot is definitely able to do that. We have had, say, interest coming in from a lot of companion apps, saying the data needs to be on device, and hence my AI workload need to be on device. So when, when? What I'll do internally is have a chat with the AI hub team and see if we can say, sync up with your announcement, or do something like that. Post that,
S Speaker 222:59yeah. Saying, Yeah, that's great.
yeah. Saying, Yeah, that's great.
yeah. Saying, Yeah, that's great.
yeah. Saying, Yeah, that's great.
24:23Awesome, awesome. That sounds terrific. Thanks so much. You.
Awesome, awesome. That sounds terrific. Thanks so much. You.
Awesome, awesome. That sounds terrific. Thanks so much. You.
Awesome, awesome. That sounds terrific. Thanks so much. You.