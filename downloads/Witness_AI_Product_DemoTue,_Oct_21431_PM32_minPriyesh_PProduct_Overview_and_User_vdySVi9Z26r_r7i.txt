Meeting: Witness AI Product Demo
Tue, Oct 21
4:31 PM
32 min
Priyesh P
Product Overview and User Roles
0:12
De
URL: https://otter.ai/u/vdySVi9Z26r_r7i1yQ-tWJle-uU
Downloaded: 2025-12-21T19:57:16.253340
Method: text_extraction
============================================================

S Speaker 10:12Hey, Dad, how are you good? How are you doing good stuff, and thanks for accommodating this. Dan, of course. Of course, yeah, but
Hey, Dad, how are you good? How are you doing good stuff, and thanks for accommodating this. Dan, of course. Of course, yeah, but
Hey, Dad, how are you good? How are you doing good stuff, and thanks for accommodating this. Dan, of course. Of course, yeah, but
Hey, Dad, how are you good? How are you doing good stuff, and thanks for accommodating this. Dan, of course. Of course, yeah, but
S Speaker 20:23I think we've had it on the agenda for a couple calls in a row, but then we ended up talking about the other stuff.
I think we've had it on the agenda for a couple calls in a row, but then we ended up talking about the other stuff.
I think we've had it on the agenda for a couple calls in a row, but then we ended up talking about the other stuff.
I think we've had it on the agenda for a couple calls in a row, but then we ended up talking about the other stuff.
0:53yeah, components of the product, yeah,
yeah, components of the product, yeah,
yeah, components of the product, yeah,
yeah, components of the product, yeah,
1:47window. Think I want to do that.
window. Think I want to do that.
window. Think I want to do that.
window. Think I want to do that.
1:52I'm not super familiar with sharing in
I'm not super familiar with sharing in
I'm not super familiar with sharing in
I'm not super familiar with sharing in
1:54final teams. There's always picky. Thanks.
final teams. There's always picky. Thanks.
final teams. There's always picky. Thanks.
final teams. There's always picky. Thanks.
S Speaker 22:03Let's try that now you probably so if I go here, can you see a demo screen?
Let's try that now you probably so if I go here, can you see a demo screen?
Let's try that now you probably so if I go here, can you see a demo screen?
Let's try that now you probably so if I go here, can you see a demo screen?
2:12Yes, it says debug mode.
Yes, it says debug mode.
Yes, it says debug mode.
Yes, it says debug mode.
S Speaker 22:14Yeah, that's the one. Okay, yeah, so, so this one debug mode means it's an interface that, like an end user would see when they're trying to see more. So, so I'm Rick bottom left, and I'm in open AI, right, yeah, yeah. So put in a prompt where there's sensitive data, there's two social security numbers in here. And so what this is going to show is, we're seeing some filters that were applied. And what we're going to do internally is, again, you wouldn't see this if you weren't in debug mode, but we intercept that prompt, and before it goes up to GPT, we redact the social security number and replace it with it with that, yeah, yeah, and so, but then it goes up and it doesn't. So when it goes up to the GPT, it writes this draft contract, and when it comes back, we stick those socials back in there. Okay, so the user experience is, it was all fine. I just was able to do what I wanted to do. But we stripped out the sensitive data on the way up and put it back in on the way back, so that their experiences. Everything just worked, but we reduced. So here's a different one. Now again, I'm Rick, I'm in I'm in Microsoft, 365 copilot. This is the example I gave you about the pharma where the people were trying to
Yeah, that's the one. Okay, yeah, so, so this one debug mode means it's an interface that, like an end user would see when they're trying to see more. So, so I'm Rick bottom left, and I'm in open AI, right, yeah, yeah. So put in a prompt where there's sensitive data, there's two social security numbers in here. And so what this is going to show is, we're seeing some filters that were applied. And what we're going to do internally is, again, you wouldn't see this if you weren't in debug mode, but we intercept that prompt, and before it goes up to GPT, we redact the social security number and replace it with it with that, yeah, yeah, and so, but then it goes up and it doesn't. So when it goes up to the GPT, it writes this draft contract, and when it comes back, we stick those socials back in there. Okay, so the user experience is, it was all fine. I just was able to do what I wanted to do. But we stripped out the sensitive data on the way up and put it back in on the way back, so that their experiences. Everything just worked, but we reduced. So here's a different one. Now again, I'm Rick, I'm in I'm in Microsoft, 365 copilot. This is the example I gave you about the pharma where the people were trying to
Yeah, that's the one. Okay, yeah, so, so this one debug mode means it's an interface that, like an end user would see when they're trying to see more. So, so I'm Rick bottom left, and I'm in open AI, right, yeah, yeah. So put in a prompt where there's sensitive data, there's two social security numbers in here. And so what this is going to show is, we're seeing some filters that were applied. And what we're going to do internally is, again, you wouldn't see this if you weren't in debug mode, but we intercept that prompt, and before it goes up to GPT, we redact the social security number and replace it with it with that, yeah, yeah, and so, but then it goes up and it doesn't. So when it goes up to the GPT, it writes this draft contract, and when it comes back, we stick those socials back in there. Okay, so the user experience is, it was all fine. I just was able to do what I wanted to do. But we stripped out the sensitive data on the way up and put it back in on the way back, so that their experiences. Everything just worked, but we reduced. So here's a different one. Now again, I'm Rick, I'm in I'm in Microsoft, 365 copilot. This is the example I gave you about the pharma where the people were trying to
Yeah, that's the one. Okay, yeah, so, so this one debug mode means it's an interface that, like an end user would see when they're trying to see more. So, so I'm Rick bottom left, and I'm in open AI, right, yeah, yeah. So put in a prompt where there's sensitive data, there's two social security numbers in here. And so what this is going to show is, we're seeing some filters that were applied. And what we're going to do internally is, again, you wouldn't see this if you weren't in debug mode, but we intercept that prompt, and before it goes up to GPT, we redact the social security number and replace it with it with that, yeah, yeah, and so, but then it goes up and it doesn't. So when it goes up to the GPT, it writes this draft contract, and when it comes back, we stick those socials back in there. Okay, so the user experience is, it was all fine. I just was able to do what I wanted to do. But we stripped out the sensitive data on the way up and put it back in on the way back, so that their experiences. Everything just worked, but we reduced. So here's a different one. Now again, I'm Rick, I'm in I'm in Microsoft, 365 copilot. This is the example I gave you about the pharma where the people were trying to
3:55summarize the research. Yeah.
summarize the research. Yeah.
summarize the research. Yeah.
summarize the research. Yeah.
S Speaker 23:56So, you know, put this thing in there, and what they see back is, Hi, you know, company policy says you're not allowed to do that right in line, like inside of Microsoft co pilot, instead of, like, getting a notice on the side or something like that. And that's we can do that because we're in line.
So, you know, put this thing in there, and what they see back is, Hi, you know, company policy says you're not allowed to do that right in line, like inside of Microsoft co pilot, instead of, like, getting a notice on the side or something like that. And that's we can do that because we're in line.
So, you know, put this thing in there, and what they see back is, Hi, you know, company policy says you're not allowed to do that right in line, like inside of Microsoft co pilot, instead of, like, getting a notice on the side or something like that. And that's we can do that because we're in line.
So, you know, put this thing in there, and what they see back is, Hi, you know, company policy says you're not allowed to do that right in line, like inside of Microsoft co pilot, instead of, like, getting a notice on the side or something like that. And that's we can do that because we're in line.
4:19Another example here is now I'm in chat GPT,
Another example here is now I'm in chat GPT,
Another example here is now I'm in chat GPT,
Another example here is now I'm in chat GPT,
S Speaker 24:25I entered this. And I don't know if you guys have seen these before, there's these, there's these glyphs that get used to confuse LLM protections, because it breaks up verbs and separates the tokens. And so you know, this is going in and, yeah, we can still detect that, you know, do this kind of problem. It's another one. Here's me go past this one. This one's kind of boring. You it. Yeah, this one's interesting. So now I'm in word again. This is Word. Word talks to the Microsoft copilot back end. And let's so it's a little different than a prompt, right? It's like you're trying to edit some document in there, yeah. And so I'm selecting this document and, and use my same drug research example, like try to, in Word, write a summary of this thing, and the same block is going to happen. It's not going to do it. And the reason we can do those cool things like you just saw in any of the clients, like in a co pilot client, or inside of Word. Thick word itself is back to the protocol thing. We're intercepting all of that network traffic and doing our magic independent of which app they're in.
I entered this. And I don't know if you guys have seen these before, there's these, there's these glyphs that get used to confuse LLM protections, because it breaks up verbs and separates the tokens. And so you know, this is going in and, yeah, we can still detect that, you know, do this kind of problem. It's another one. Here's me go past this one. This one's kind of boring. You it. Yeah, this one's interesting. So now I'm in word again. This is Word. Word talks to the Microsoft copilot back end. And let's so it's a little different than a prompt, right? It's like you're trying to edit some document in there, yeah. And so I'm selecting this document and, and use my same drug research example, like try to, in Word, write a summary of this thing, and the same block is going to happen. It's not going to do it. And the reason we can do those cool things like you just saw in any of the clients, like in a co pilot client, or inside of Word. Thick word itself is back to the protocol thing. We're intercepting all of that network traffic and doing our magic independent of which app they're in.
I entered this. And I don't know if you guys have seen these before, there's these, there's these glyphs that get used to confuse LLM protections, because it breaks up verbs and separates the tokens. And so you know, this is going in and, yeah, we can still detect that, you know, do this kind of problem. It's another one. Here's me go past this one. This one's kind of boring. You it. Yeah, this one's interesting. So now I'm in word again. This is Word. Word talks to the Microsoft copilot back end. And let's so it's a little different than a prompt, right? It's like you're trying to edit some document in there, yeah. And so I'm selecting this document and, and use my same drug research example, like try to, in Word, write a summary of this thing, and the same block is going to happen. It's not going to do it. And the reason we can do those cool things like you just saw in any of the clients, like in a co pilot client, or inside of Word. Thick word itself is back to the protocol thing. We're intercepting all of that network traffic and doing our magic independent of which app they're in.
I entered this. And I don't know if you guys have seen these before, there's these, there's these glyphs that get used to confuse LLM protections, because it breaks up verbs and separates the tokens. And so you know, this is going in and, yeah, we can still detect that, you know, do this kind of problem. It's another one. Here's me go past this one. This one's kind of boring. You it. Yeah, this one's interesting. So now I'm in word again. This is Word. Word talks to the Microsoft copilot back end. And let's so it's a little different than a prompt, right? It's like you're trying to edit some document in there, yeah. And so I'm selecting this document and, and use my same drug research example, like try to, in Word, write a summary of this thing, and the same block is going to happen. It's not going to do it. And the reason we can do those cool things like you just saw in any of the clients, like in a co pilot client, or inside of Word. Thick word itself is back to the protocol thing. We're intercepting all of that network traffic and doing our magic independent of which app they're in.
5:54Inside of word. This
S Speaker 19:37search, so you actually capture, capture the prompts as well, all
search, so you actually capture, capture the prompts as well, all
search, so you actually capture, capture the prompts as well, all
search, so you actually capture, capture the prompts as well, all
S Speaker 29:41the prompts and all the responses. Yeah, wow. Okay, if I have identified that, Hey, Rick was a risky user because he seems to be on all these shady AI sites. I want to learn more and go in and like, here's the one that I just showed you, right? Like, Rick had this prompt to write a contract. It got redacted, yeah, then and so on. And then here's the response like it. Analysts can go through, you know, anybody's you know thing that they're doing. And here's the other one from Rick, summarize these bug results. And here's a summary of the study. So that's an example that we sometimes show of like, yeah, if you don't have the guardrail on Yeah, insert right, so you could see, like, kind of a before and after thing.
the prompts and all the responses. Yeah, wow. Okay, if I have identified that, Hey, Rick was a risky user because he seems to be on all these shady AI sites. I want to learn more and go in and like, here's the one that I just showed you, right? Like, Rick had this prompt to write a contract. It got redacted, yeah, then and so on. And then here's the response like it. Analysts can go through, you know, anybody's you know thing that they're doing. And here's the other one from Rick, summarize these bug results. And here's a summary of the study. So that's an example that we sometimes show of like, yeah, if you don't have the guardrail on Yeah, insert right, so you could see, like, kind of a before and after thing.
the prompts and all the responses. Yeah, wow. Okay, if I have identified that, Hey, Rick was a risky user because he seems to be on all these shady AI sites. I want to learn more and go in and like, here's the one that I just showed you, right? Like, Rick had this prompt to write a contract. It got redacted, yeah, then and so on. And then here's the response like it. Analysts can go through, you know, anybody's you know thing that they're doing. And here's the other one from Rick, summarize these bug results. And here's a summary of the study. So that's an example that we sometimes show of like, yeah, if you don't have the guardrail on Yeah, insert right, so you could see, like, kind of a before and after thing.
the prompts and all the responses. Yeah, wow. Okay, if I have identified that, Hey, Rick was a risky user because he seems to be on all these shady AI sites. I want to learn more and go in and like, here's the one that I just showed you, right? Like, Rick had this prompt to write a contract. It got redacted, yeah, then and so on. And then here's the response like it. Analysts can go through, you know, anybody's you know thing that they're doing. And here's the other one from Rick, summarize these bug results. And here's a summary of the study. So that's an example that we sometimes show of like, yeah, if you don't have the guardrail on Yeah, insert right, so you could see, like, kind of a before and after thing.
S Speaker 110:35And then where would you calculate 10? So the intent data that you were getting
And then where would you calculate 10? So the intent data that you were getting
And then where would you calculate 10? So the intent data that you were getting
And then where would you calculate 10? So the intent data that you were getting
10:41on the dashboard,
S Speaker 210:42it. Here's an example of seeing it on the right. So, okay, this is, this is conversations by user. So in the case here, you know, whatever. There anything. So these, these, well, the intents that are determined are listed here on the right, and then you can create policies for them. So these, there's a whole, I'll call it cluster of intentions, where there's, like, a high level thing. It's about programming, and then under programming, you could have different sub clusters and so on, but eventually you're all the way down into the very specific intention of that one or that one congregation. But we summarize it in like a three word phrase, usually to learn to understand. Yeah, and then, you know, you can, you'll learn on different things. So, like, for certain, this prompt, write a prompt, Python function to do X, you know, was right. Python code that's characterized for this customer is high risk, and what's the what's the risk, and what application was it? And off they go. You know what? What happens in practice is this is sort of simple to use when you're when they're getting started, as soon as it gets to the volume of 10s of 1000s of these things. Yeah, customers are pushing them off into their Sims via API, yeah, starting investigations and so on, so. And then you can see there's a set of policies that have been created. You can make a new one, and each of them, you know, has specific guardrail so like the best post policy,
it. Here's an example of seeing it on the right. So, okay, this is, this is conversations by user. So in the case here, you know, whatever. There anything. So these, these, well, the intents that are determined are listed here on the right, and then you can create policies for them. So these, there's a whole, I'll call it cluster of intentions, where there's, like, a high level thing. It's about programming, and then under programming, you could have different sub clusters and so on, but eventually you're all the way down into the very specific intention of that one or that one congregation. But we summarize it in like a three word phrase, usually to learn to understand. Yeah, and then, you know, you can, you'll learn on different things. So, like, for certain, this prompt, write a prompt, Python function to do X, you know, was right. Python code that's characterized for this customer is high risk, and what's the what's the risk, and what application was it? And off they go. You know what? What happens in practice is this is sort of simple to use when you're when they're getting started, as soon as it gets to the volume of 10s of 1000s of these things. Yeah, customers are pushing them off into their Sims via API, yeah, starting investigations and so on, so. And then you can see there's a set of policies that have been created. You can make a new one, and each of them, you know, has specific guardrail so like the best post policy,
it. Here's an example of seeing it on the right. So, okay, this is, this is conversations by user. So in the case here, you know, whatever. There anything. So these, these, well, the intents that are determined are listed here on the right, and then you can create policies for them. So these, there's a whole, I'll call it cluster of intentions, where there's, like, a high level thing. It's about programming, and then under programming, you could have different sub clusters and so on, but eventually you're all the way down into the very specific intention of that one or that one congregation. But we summarize it in like a three word phrase, usually to learn to understand. Yeah, and then, you know, you can, you'll learn on different things. So, like, for certain, this prompt, write a prompt, Python function to do X, you know, was right. Python code that's characterized for this customer is high risk, and what's the what's the risk, and what application was it? And off they go. You know what? What happens in practice is this is sort of simple to use when you're when they're getting started, as soon as it gets to the volume of 10s of 1000s of these things. Yeah, customers are pushing them off into their Sims via API, yeah, starting investigations and so on, so. And then you can see there's a set of policies that have been created. You can make a new one, and each of them, you know, has specific guardrail so like the best post policy,
it. Here's an example of seeing it on the right. So, okay, this is, this is conversations by user. So in the case here, you know, whatever. There anything. So these, these, well, the intents that are determined are listed here on the right, and then you can create policies for them. So these, there's a whole, I'll call it cluster of intentions, where there's, like, a high level thing. It's about programming, and then under programming, you could have different sub clusters and so on, but eventually you're all the way down into the very specific intention of that one or that one congregation. But we summarize it in like a three word phrase, usually to learn to understand. Yeah, and then, you know, you can, you'll learn on different things. So, like, for certain, this prompt, write a prompt, Python function to do X, you know, was right. Python code that's characterized for this customer is high risk, and what's the what's the risk, and what application was it? And off they go. You know what? What happens in practice is this is sort of simple to use when you're when they're getting started, as soon as it gets to the volume of 10s of 1000s of these things. Yeah, customers are pushing them off into their Sims via API, yeah, starting investigations and so on, so. And then you can see there's a set of policies that have been created. You can make a new one, and each of them, you know, has specific guardrail so like the best post policy,
S Speaker 212:49brick swan. I've got a few guardrails that are on behavioral guardrail, the data protection guardrail, model identity and model protection. And what I'm going to do when each of those types of things fires. So those are some of the basics. Now I want to show you a couple of newer things. So this is the newer homepage that going out in like a week,
brick swan. I've got a few guardrails that are on behavioral guardrail, the data protection guardrail, model identity and model protection. And what I'm going to do when each of those types of things fires. So those are some of the basics. Now I want to show you a couple of newer things. So this is the newer homepage that going out in like a week,
brick swan. I've got a few guardrails that are on behavioral guardrail, the data protection guardrail, model identity and model protection. And what I'm going to do when each of those types of things fires. So those are some of the basics. Now I want to show you a couple of newer things. So this is the newer homepage that going out in like a week,
brick swan. I've got a few guardrails that are on behavioral guardrail, the data protection guardrail, model identity and model protection. And what I'm going to do when each of those types of things fires. So those are some of the basics. Now I want to show you a couple of newer things. So this is the newer homepage that going out in like a week,
S Speaker 213:21of a sort of a the first view we we from learning from our users, they wanted to see is sort of what's new, like, what changed since you were last in here. It did these action you can drill down, see what they are. Closed up, what's happening with conversations, trend line, how many heist event side look several alerts are happening. And then this is an intention explorer that's more dynamic, where I can see, like, here's all the things that were happening with coding assistance I want to drill down. Or here's employee conflict stuff, and what's the rate those? And so if, for a given type of thing. If you're worried about like this one, you could go up a new guardrail to say, let's be more refining. Like, if I say, write me a script to do X, that's okay. If I say, here's all of my sensitive source code, please identify bugs. Maybe that's not okay. So that's this one. Another one here. Another alternate view of that is this sort of starboard diagram where people can see, like a slice of pie for the different high level ends of a tent. Yeah, you click on that, you'd go down in and the wheel would open up and you'd look deeper, sort of like zooming in and out. Yeah. Okay. So far, customers really like this view, so we're gonna we're building it now, and then one final new thing that's about to ship is this agentic view. And so here's an example of cloud desktop on the left, talking over MCP to cloud back end and then executing tool calls. So you can see that the way the workflow actually happens is someone would go into Cloud desktop and they would say, I want to accomplish X. They'd give it a prompt, yeah. And up with that, Claude desktop sends the list of tools that it has access to. So that's the middle column. Cloud has access to Atlassian, this other MCP server, GitHub and so on, Google Drive, so. And then what comes back from Cloud. Is, hey, agent, go to Atlassian and do these things. Search JIRA. Search for these papers. Find this JIRA issue, you know, then go here to get cup and find the code related to that issue, and so on. So the list on the right, so think they're trying to do. So what that allows us is a cool example of visibility, like, into what agents are actually doing, which is, you know, kind of a zoom in view, of like, one particular interaction with Cloud desktop, which I just wanted to show you, because all of that information, of like, what are the tool calls. What are they trying to do? And then, like, how risky is that thing? We have access to all that information as soon as you can parse MCP, as well as parsing.
of a sort of a the first view we we from learning from our users, they wanted to see is sort of what's new, like, what changed since you were last in here. It did these action you can drill down, see what they are. Closed up, what's happening with conversations, trend line, how many heist event side look several alerts are happening. And then this is an intention explorer that's more dynamic, where I can see, like, here's all the things that were happening with coding assistance I want to drill down. Or here's employee conflict stuff, and what's the rate those? And so if, for a given type of thing. If you're worried about like this one, you could go up a new guardrail to say, let's be more refining. Like, if I say, write me a script to do X, that's okay. If I say, here's all of my sensitive source code, please identify bugs. Maybe that's not okay. So that's this one. Another one here. Another alternate view of that is this sort of starboard diagram where people can see, like a slice of pie for the different high level ends of a tent. Yeah, you click on that, you'd go down in and the wheel would open up and you'd look deeper, sort of like zooming in and out. Yeah. Okay. So far, customers really like this view, so we're gonna we're building it now, and then one final new thing that's about to ship is this agentic view. And so here's an example of cloud desktop on the left, talking over MCP to cloud back end and then executing tool calls. So you can see that the way the workflow actually happens is someone would go into Cloud desktop and they would say, I want to accomplish X. They'd give it a prompt, yeah. And up with that, Claude desktop sends the list of tools that it has access to. So that's the middle column. Cloud has access to Atlassian, this other MCP server, GitHub and so on, Google Drive, so. And then what comes back from Cloud. Is, hey, agent, go to Atlassian and do these things. Search JIRA. Search for these papers. Find this JIRA issue, you know, then go here to get cup and find the code related to that issue, and so on. So the list on the right, so think they're trying to do. So what that allows us is a cool example of visibility, like, into what agents are actually doing, which is, you know, kind of a zoom in view, of like, one particular interaction with Cloud desktop, which I just wanted to show you, because all of that information, of like, what are the tool calls. What are they trying to do? And then, like, how risky is that thing? We have access to all that information as soon as you can parse MCP, as well as parsing.
of a sort of a the first view we we from learning from our users, they wanted to see is sort of what's new, like, what changed since you were last in here. It did these action you can drill down, see what they are. Closed up, what's happening with conversations, trend line, how many heist event side look several alerts are happening. And then this is an intention explorer that's more dynamic, where I can see, like, here's all the things that were happening with coding assistance I want to drill down. Or here's employee conflict stuff, and what's the rate those? And so if, for a given type of thing. If you're worried about like this one, you could go up a new guardrail to say, let's be more refining. Like, if I say, write me a script to do X, that's okay. If I say, here's all of my sensitive source code, please identify bugs. Maybe that's not okay. So that's this one. Another one here. Another alternate view of that is this sort of starboard diagram where people can see, like a slice of pie for the different high level ends of a tent. Yeah, you click on that, you'd go down in and the wheel would open up and you'd look deeper, sort of like zooming in and out. Yeah. Okay. So far, customers really like this view, so we're gonna we're building it now, and then one final new thing that's about to ship is this agentic view. And so here's an example of cloud desktop on the left, talking over MCP to cloud back end and then executing tool calls. So you can see that the way the workflow actually happens is someone would go into Cloud desktop and they would say, I want to accomplish X. They'd give it a prompt, yeah. And up with that, Claude desktop sends the list of tools that it has access to. So that's the middle column. Cloud has access to Atlassian, this other MCP server, GitHub and so on, Google Drive, so. And then what comes back from Cloud. Is, hey, agent, go to Atlassian and do these things. Search JIRA. Search for these papers. Find this JIRA issue, you know, then go here to get cup and find the code related to that issue, and so on. So the list on the right, so think they're trying to do. So what that allows us is a cool example of visibility, like, into what agents are actually doing, which is, you know, kind of a zoom in view, of like, one particular interaction with Cloud desktop, which I just wanted to show you, because all of that information, of like, what are the tool calls. What are they trying to do? And then, like, how risky is that thing? We have access to all that information as soon as you can parse MCP, as well as parsing.
of a sort of a the first view we we from learning from our users, they wanted to see is sort of what's new, like, what changed since you were last in here. It did these action you can drill down, see what they are. Closed up, what's happening with conversations, trend line, how many heist event side look several alerts are happening. And then this is an intention explorer that's more dynamic, where I can see, like, here's all the things that were happening with coding assistance I want to drill down. Or here's employee conflict stuff, and what's the rate those? And so if, for a given type of thing. If you're worried about like this one, you could go up a new guardrail to say, let's be more refining. Like, if I say, write me a script to do X, that's okay. If I say, here's all of my sensitive source code, please identify bugs. Maybe that's not okay. So that's this one. Another one here. Another alternate view of that is this sort of starboard diagram where people can see, like a slice of pie for the different high level ends of a tent. Yeah, you click on that, you'd go down in and the wheel would open up and you'd look deeper, sort of like zooming in and out. Yeah. Okay. So far, customers really like this view, so we're gonna we're building it now, and then one final new thing that's about to ship is this agentic view. And so here's an example of cloud desktop on the left, talking over MCP to cloud back end and then executing tool calls. So you can see that the way the workflow actually happens is someone would go into Cloud desktop and they would say, I want to accomplish X. They'd give it a prompt, yeah. And up with that, Claude desktop sends the list of tools that it has access to. So that's the middle column. Cloud has access to Atlassian, this other MCP server, GitHub and so on, Google Drive, so. And then what comes back from Cloud. Is, hey, agent, go to Atlassian and do these things. Search JIRA. Search for these papers. Find this JIRA issue, you know, then go here to get cup and find the code related to that issue, and so on. So the list on the right, so think they're trying to do. So what that allows us is a cool example of visibility, like, into what agents are actually doing, which is, you know, kind of a zoom in view, of like, one particular interaction with Cloud desktop, which I just wanted to show you, because all of that information, of like, what are the tool calls. What are they trying to do? And then, like, how risky is that thing? We have access to all that information as soon as you can parse MCP, as well as parsing.
16:34So the thing that most people
So the thing that most people
So the thing that most people
So the thing that most people
16:39don't get right away
S Speaker 216:47there, yeah, the thing that people don't get up right away is, yeah, only a part of the interesting information about what agents are doing is visible via MCP. It's literally just the part where now this agent is talking to some MCP server and like, it's like hitting an API right, take this screenshot, give me this data, search for this thing, and so on. That's sort of too late in many cases, to to secure it, because what happens first is, you know, the agent goes up and says, like, here's all the stuff I have access to, and sends a prompt back to cloud backend. So that's the traditional cloud protocol that we already know how to inspect. And you might want to guardrail on that, saying, don't even try to access this tool. I don't want you to I don't want you to have access to this database. I don't want you to have access to this I don't want you to call the this third party MCP server as part of your tools. So you can just even limit what Claude tells this agent to do before it does anything. Yeah, and you don't get any of that if you're just doing MCP inspection. And so that's why I think it's, you know how I'll call it a great idea, back in the day before I got here, to make sure that we can do this low level network inspection, because we can get so much more information and context from magenta than you can if you're just sitting there at the at the MCP level, yeah,
there, yeah, the thing that people don't get up right away is, yeah, only a part of the interesting information about what agents are doing is visible via MCP. It's literally just the part where now this agent is talking to some MCP server and like, it's like hitting an API right, take this screenshot, give me this data, search for this thing, and so on. That's sort of too late in many cases, to to secure it, because what happens first is, you know, the agent goes up and says, like, here's all the stuff I have access to, and sends a prompt back to cloud backend. So that's the traditional cloud protocol that we already know how to inspect. And you might want to guardrail on that, saying, don't even try to access this tool. I don't want you to I don't want you to have access to this database. I don't want you to have access to this I don't want you to call the this third party MCP server as part of your tools. So you can just even limit what Claude tells this agent to do before it does anything. Yeah, and you don't get any of that if you're just doing MCP inspection. And so that's why I think it's, you know how I'll call it a great idea, back in the day before I got here, to make sure that we can do this low level network inspection, because we can get so much more information and context from magenta than you can if you're just sitting there at the at the MCP level, yeah,
there, yeah, the thing that people don't get up right away is, yeah, only a part of the interesting information about what agents are doing is visible via MCP. It's literally just the part where now this agent is talking to some MCP server and like, it's like hitting an API right, take this screenshot, give me this data, search for this thing, and so on. That's sort of too late in many cases, to to secure it, because what happens first is, you know, the agent goes up and says, like, here's all the stuff I have access to, and sends a prompt back to cloud backend. So that's the traditional cloud protocol that we already know how to inspect. And you might want to guardrail on that, saying, don't even try to access this tool. I don't want you to I don't want you to have access to this database. I don't want you to have access to this I don't want you to call the this third party MCP server as part of your tools. So you can just even limit what Claude tells this agent to do before it does anything. Yeah, and you don't get any of that if you're just doing MCP inspection. And so that's why I think it's, you know how I'll call it a great idea, back in the day before I got here, to make sure that we can do this low level network inspection, because we can get so much more information and context from magenta than you can if you're just sitting there at the at the MCP level, yeah,
there, yeah, the thing that people don't get up right away is, yeah, only a part of the interesting information about what agents are doing is visible via MCP. It's literally just the part where now this agent is talking to some MCP server and like, it's like hitting an API right, take this screenshot, give me this data, search for this thing, and so on. That's sort of too late in many cases, to to secure it, because what happens first is, you know, the agent goes up and says, like, here's all the stuff I have access to, and sends a prompt back to cloud backend. So that's the traditional cloud protocol that we already know how to inspect. And you might want to guardrail on that, saying, don't even try to access this tool. I don't want you to I don't want you to have access to this database. I don't want you to have access to this I don't want you to call the this third party MCP server as part of your tools. So you can just even limit what Claude tells this agent to do before it does anything. Yeah, and you don't get any of that if you're just doing MCP inspection. And so that's why I think it's, you know how I'll call it a great idea, back in the day before I got here, to make sure that we can do this low level network inspection, because we can get so much more information and context from magenta than you can if you're just sitting there at the at the MCP level, yeah,
S Speaker 118:24maybe one, one couple of questions, Dan, is, if the intent is misclassified, or if, as a user, I want to refine some of the ways these are alerted or improved, right? Do you have an option where human inputs can come in and you can probably retrain your system, right? Are you capturing that? That's number one. Number two is on the cost side. Anything that any area where you can save cost for me by redirecting my prompts, right? I know for one of the customers you claim to have you, yeah. Why? Why would it, you know, that's like, immediate ROI, right for the end customer. Shouldn't there be, like, a section where it's like, hey, because of Smarter rerouting, or we, of course, protected your IP or protected, but also we've saved this possible tokens,
maybe one, one couple of questions, Dan, is, if the intent is misclassified, or if, as a user, I want to refine some of the ways these are alerted or improved, right? Do you have an option where human inputs can come in and you can probably retrain your system, right? Are you capturing that? That's number one. Number two is on the cost side. Anything that any area where you can save cost for me by redirecting my prompts, right? I know for one of the customers you claim to have you, yeah. Why? Why would it, you know, that's like, immediate ROI, right for the end customer. Shouldn't there be, like, a section where it's like, hey, because of Smarter rerouting, or we, of course, protected your IP or protected, but also we've saved this possible tokens,
maybe one, one couple of questions, Dan, is, if the intent is misclassified, or if, as a user, I want to refine some of the ways these are alerted or improved, right? Do you have an option where human inputs can come in and you can probably retrain your system, right? Are you capturing that? That's number one. Number two is on the cost side. Anything that any area where you can save cost for me by redirecting my prompts, right? I know for one of the customers you claim to have you, yeah. Why? Why would it, you know, that's like, immediate ROI, right for the end customer. Shouldn't there be, like, a section where it's like, hey, because of Smarter rerouting, or we, of course, protected your IP or protected, but also we've saved this possible tokens,
maybe one, one couple of questions, Dan, is, if the intent is misclassified, or if, as a user, I want to refine some of the ways these are alerted or improved, right? Do you have an option where human inputs can come in and you can probably retrain your system, right? Are you capturing that? That's number one. Number two is on the cost side. Anything that any area where you can save cost for me by redirecting my prompts, right? I know for one of the customers you claim to have you, yeah. Why? Why would it, you know, that's like, immediate ROI, right for the end customer. Shouldn't there be, like, a section where it's like, hey, because of Smarter rerouting, or we, of course, protected your IP or protected, but also we've saved this possible tokens,
S Speaker 219:20yeah, yeah. I'm glad you asked that's in the works. We're going to do basically like an ROI dash,
yeah, yeah. I'm glad you asked that's in the works. We're going to do basically like an ROI dash,
yeah, yeah. I'm glad you asked that's in the works. We're going to do basically like an ROI dash,
yeah, yeah. I'm glad you asked that's in the works. We're going to do basically like an ROI dash,
S Speaker 119:29because ultimately, numbers speak, right? I mean, you can tell people, hey, these many alerts happened, or these many alerts are prevented, but, yeah, if you don't feel dollars, this must be paid by just lead out in
because ultimately, numbers speak, right? I mean, you can tell people, hey, these many alerts happened, or these many alerts are prevented, but, yeah, if you don't feel dollars, this must be paid by just lead out in
because ultimately, numbers speak, right? I mean, you can tell people, hey, these many alerts happened, or these many alerts are prevented, but, yeah, if you don't feel dollars, this must be paid by just lead out in
because ultimately, numbers speak, right? I mean, you can tell people, hey, these many alerts happened, or these many alerts are prevented, but, yeah, if you don't feel dollars, this must be paid by just lead out in
S Speaker 219:41we have one now, but it's not very good, so I didn't show it to you the the next one is pretty cool, but, but, yeah, there's a number of categories of savings that we're representing. So one is, you know, routing like this prompt would have cost this much to execute if you did it in LMA, but because we did it in Lo and be saved this much, so that's a big one. Second one for like, third party protection is, is going to be a whole other thing. Like, you've got customers using your AI chat bot, and by not answering questions that are off topic. You saved this money. And so the interesting thing that we can do there is we can understand what it would have cost if they had let it go through.
we have one now, but it's not very good, so I didn't show it to you the the next one is pretty cool, but, but, yeah, there's a number of categories of savings that we're representing. So one is, you know, routing like this prompt would have cost this much to execute if you did it in LMA, but because we did it in Lo and be saved this much, so that's a big one. Second one for like, third party protection is, is going to be a whole other thing. Like, you've got customers using your AI chat bot, and by not answering questions that are off topic. You saved this money. And so the interesting thing that we can do there is we can understand what it would have cost if they had let it go through.
we have one now, but it's not very good, so I didn't show it to you the the next one is pretty cool, but, but, yeah, there's a number of categories of savings that we're representing. So one is, you know, routing like this prompt would have cost this much to execute if you did it in LMA, but because we did it in Lo and be saved this much, so that's a big one. Second one for like, third party protection is, is going to be a whole other thing. Like, you've got customers using your AI chat bot, and by not answering questions that are off topic. You saved this money. And so the interesting thing that we can do there is we can understand what it would have cost if they had let it go through.
we have one now, but it's not very good, so I didn't show it to you the the next one is pretty cool, but, but, yeah, there's a number of categories of savings that we're representing. So one is, you know, routing like this prompt would have cost this much to execute if you did it in LMA, but because we did it in Lo and be saved this much, so that's a big one. Second one for like, third party protection is, is going to be a whole other thing. Like, you've got customers using your AI chat bot, and by not answering questions that are off topic. You saved this money. And so the interesting thing that we can do there is we can understand what it would have cost if they had let it go through.
S Speaker 120:35That's actually a good one too, because you want AI to be used for corporate purposes only. And there's a lot of you know, you cannot control what the employee is asking, right? So I think that is also an interesting cost, cost benefit analysis.
That's actually a good one too, because you want AI to be used for corporate purposes only. And there's a lot of you know, you cannot control what the employee is asking, right? So I think that is also an interesting cost, cost benefit analysis.
That's actually a good one too, because you want AI to be used for corporate purposes only. And there's a lot of you know, you cannot control what the employee is asking, right? So I think that is also an interesting cost, cost benefit analysis.
That's actually a good one too, because you want AI to be used for corporate purposes only. And there's a lot of you know, you cannot control what the employee is asking, right? So I think that is also an interesting cost, cost benefit analysis.
20:51So those are all those are.
So those are all those are.
So those are all those are.
So those are all those are.
S Speaker 220:56Now that stuff is in my UX team, who are mocking up a better way to look at it. Yeah, yeah. So today, we've done that with customers, but manually, you know, like, we pull data out of the product and we build them a spreadsheet and whatever. But now that we kind of know what they're looking for, we can. We're going to put it straight into the GUI. The other question you asked, though, the first one, there are, there's quite a few different knobs and dials that customers have to tune the model. So the first one, I'll put them into two big buckets. One is, we've got all these pre built intention classifiers, right? They know how to attack. This looks like coding. This looks like drug research. Those like those come out of the box the way we
Now that stuff is in my UX team, who are mocking up a better way to look at it. Yeah, yeah. So today, we've done that with customers, but manually, you know, like, we pull data out of the product and we build them a spreadsheet and whatever. But now that we kind of know what they're looking for, we can. We're going to put it straight into the GUI. The other question you asked, though, the first one, there are, there's quite a few different knobs and dials that customers have to tune the model. So the first one, I'll put them into two big buckets. One is, we've got all these pre built intention classifiers, right? They know how to attack. This looks like coding. This looks like drug research. Those like those come out of the box the way we
Now that stuff is in my UX team, who are mocking up a better way to look at it. Yeah, yeah. So today, we've done that with customers, but manually, you know, like, we pull data out of the product and we build them a spreadsheet and whatever. But now that we kind of know what they're looking for, we can. We're going to put it straight into the GUI. The other question you asked, though, the first one, there are, there's quite a few different knobs and dials that customers have to tune the model. So the first one, I'll put them into two big buckets. One is, we've got all these pre built intention classifiers, right? They know how to attack. This looks like coding. This looks like drug research. Those like those come out of the box the way we
Now that stuff is in my UX team, who are mocking up a better way to look at it. Yeah, yeah. So today, we've done that with customers, but manually, you know, like, we pull data out of the product and we build them a spreadsheet and whatever. But now that we kind of know what they're looking for, we can. We're going to put it straight into the GUI. The other question you asked, though, the first one, there are, there's quite a few different knobs and dials that customers have to tune the model. So the first one, I'll put them into two big buckets. One is, we've got all these pre built intention classifiers, right? They know how to attack. This looks like coding. This looks like drug research. Those like those come out of the box the way we
21:50interesting. Way that we tune those
interesting. Way that we tune those
interesting. Way that we tune those
interesting. Way that we tune those
S Speaker 221:54is if a customer opts in, we see their real prompts on the back end, and our ML team tunes those models with different parameters to to get better results for them. So those kind of at the moment, we have to hand tune for for the customer, but we do. It's part of the services and so on. Yeah, yeah. Second. Second thing is, there's a bucket of there's a new thing where customers can build their own intentions and their own guardrails around intent. Yes, yeah. And that's the thing where we have this new capability called the intention studio, where they say, I want to make a guardrail that controls employees doing research about foreign governments, espionage, okay, whatever. So someone types in that prompt our LLM generates a draft like set of parameters and like a draft program, basically for them. And then you click a button, and you iterate on it, and it makes and asks the customer some questions. Let's refine this aspect of it. Let's refine this aspect of it, so sort of a guided experience. And then what happens is you go into test mode, so it's like, okay, let's run last week some real prompts from your company through that. And here's the results. We found these hits. And then they can they can keep iterating like we analyze it well, we have found these hits. Let's make a variation. Vary that thing a little bit. Now let's run last week through that. So we have a couple models, like an antagonistic one and a protagonistic One, who are like, iterating back and forth with a user in the loop, and eventually out of that, we're like, iteration F was the best one that caught the highest number of hits from this tranche of 10,000 problems from your actual company last week. And then you go and like, let's deploy that one in real life. So it's, it's a, it's a, it's an interactive ml assisted custom intention guardrail.
is if a customer opts in, we see their real prompts on the back end, and our ML team tunes those models with different parameters to to get better results for them. So those kind of at the moment, we have to hand tune for for the customer, but we do. It's part of the services and so on. Yeah, yeah. Second. Second thing is, there's a bucket of there's a new thing where customers can build their own intentions and their own guardrails around intent. Yes, yeah. And that's the thing where we have this new capability called the intention studio, where they say, I want to make a guardrail that controls employees doing research about foreign governments, espionage, okay, whatever. So someone types in that prompt our LLM generates a draft like set of parameters and like a draft program, basically for them. And then you click a button, and you iterate on it, and it makes and asks the customer some questions. Let's refine this aspect of it. Let's refine this aspect of it, so sort of a guided experience. And then what happens is you go into test mode, so it's like, okay, let's run last week some real prompts from your company through that. And here's the results. We found these hits. And then they can they can keep iterating like we analyze it well, we have found these hits. Let's make a variation. Vary that thing a little bit. Now let's run last week through that. So we have a couple models, like an antagonistic one and a protagonistic One, who are like, iterating back and forth with a user in the loop, and eventually out of that, we're like, iteration F was the best one that caught the highest number of hits from this tranche of 10,000 problems from your actual company last week. And then you go and like, let's deploy that one in real life. So it's, it's a, it's a, it's an interactive ml assisted custom intention guardrail.
is if a customer opts in, we see their real prompts on the back end, and our ML team tunes those models with different parameters to to get better results for them. So those kind of at the moment, we have to hand tune for for the customer, but we do. It's part of the services and so on. Yeah, yeah. Second. Second thing is, there's a bucket of there's a new thing where customers can build their own intentions and their own guardrails around intent. Yes, yeah. And that's the thing where we have this new capability called the intention studio, where they say, I want to make a guardrail that controls employees doing research about foreign governments, espionage, okay, whatever. So someone types in that prompt our LLM generates a draft like set of parameters and like a draft program, basically for them. And then you click a button, and you iterate on it, and it makes and asks the customer some questions. Let's refine this aspect of it. Let's refine this aspect of it, so sort of a guided experience. And then what happens is you go into test mode, so it's like, okay, let's run last week some real prompts from your company through that. And here's the results. We found these hits. And then they can they can keep iterating like we analyze it well, we have found these hits. Let's make a variation. Vary that thing a little bit. Now let's run last week through that. So we have a couple models, like an antagonistic one and a protagonistic One, who are like, iterating back and forth with a user in the loop, and eventually out of that, we're like, iteration F was the best one that caught the highest number of hits from this tranche of 10,000 problems from your actual company last week. And then you go and like, let's deploy that one in real life. So it's, it's a, it's a, it's an interactive ml assisted custom intention guardrail.
is if a customer opts in, we see their real prompts on the back end, and our ML team tunes those models with different parameters to to get better results for them. So those kind of at the moment, we have to hand tune for for the customer, but we do. It's part of the services and so on. Yeah, yeah. Second. Second thing is, there's a bucket of there's a new thing where customers can build their own intentions and their own guardrails around intent. Yes, yeah. And that's the thing where we have this new capability called the intention studio, where they say, I want to make a guardrail that controls employees doing research about foreign governments, espionage, okay, whatever. So someone types in that prompt our LLM generates a draft like set of parameters and like a draft program, basically for them. And then you click a button, and you iterate on it, and it makes and asks the customer some questions. Let's refine this aspect of it. Let's refine this aspect of it, so sort of a guided experience. And then what happens is you go into test mode, so it's like, okay, let's run last week some real prompts from your company through that. And here's the results. We found these hits. And then they can they can keep iterating like we analyze it well, we have found these hits. Let's make a variation. Vary that thing a little bit. Now let's run last week through that. So we have a couple models, like an antagonistic one and a protagonistic One, who are like, iterating back and forth with a user in the loop, and eventually out of that, we're like, iteration F was the best one that caught the highest number of hits from this tranche of 10,000 problems from your actual company last week. And then you go and like, let's deploy that one in real life. So it's, it's a, it's a, it's an interactive ml assisted custom intention guardrail.
S Speaker 124:26Okay, I think that that will be interesting to as part of the roadmap. I understand that's
Okay, I think that that will be interesting to as part of the roadmap. I understand that's
Okay, I think that that will be interesting to as part of the roadmap. I understand that's
Okay, I think that that will be interesting to as part of the roadmap. I understand that's
S Speaker 224:31not today deployed. That one's not today, that one's probably November, November. Okay, yeah, yeah, it's pretty far, but it's not done.
not today deployed. That one's not today, that one's probably November, November. Okay, yeah, yeah, it's pretty far, but it's not done.
not today deployed. That one's not today, that one's probably November, November. Okay, yeah, yeah, it's pretty far, but it's not done.
not today deployed. That one's not today, that one's probably November, November. Okay, yeah, yeah, it's pretty far, but it's not done.
S Speaker 124:43Okay, no, that's good. So I think, I think I got a good sense of, you know, where you guys are at one, one more question I have. Do you have entitlements or access categories? Yeah, not, not, not necessarily, RBAC, but let's say this app and this user, you know, he doesn't have access to the Pro Plan, or he has, he or she has access to the Pro Plan, like different fields of planning, and within the plan, what resources they have access to what level. So I saw the human level, right? So you can tell creation access to chat. GPT, but would you have, would you have a little more detail around? Okay, he's subscribed to a Pro Plan. He's, he's used these many tokens, or he's, he's prompting 10 times a day, like we have analytics on we employ,
Okay, no, that's good. So I think, I think I got a good sense of, you know, where you guys are at one, one more question I have. Do you have entitlements or access categories? Yeah, not, not, not necessarily, RBAC, but let's say this app and this user, you know, he doesn't have access to the Pro Plan, or he has, he or she has access to the Pro Plan, like different fields of planning, and within the plan, what resources they have access to what level. So I saw the human level, right? So you can tell creation access to chat. GPT, but would you have, would you have a little more detail around? Okay, he's subscribed to a Pro Plan. He's, he's used these many tokens, or he's, he's prompting 10 times a day, like we have analytics on we employ,
Okay, no, that's good. So I think, I think I got a good sense of, you know, where you guys are at one, one more question I have. Do you have entitlements or access categories? Yeah, not, not, not necessarily, RBAC, but let's say this app and this user, you know, he doesn't have access to the Pro Plan, or he has, he or she has access to the Pro Plan, like different fields of planning, and within the plan, what resources they have access to what level. So I saw the human level, right? So you can tell creation access to chat. GPT, but would you have, would you have a little more detail around? Okay, he's subscribed to a Pro Plan. He's, he's used these many tokens, or he's, he's prompting 10 times a day, like we have analytics on we employ,
Okay, no, that's good. So I think, I think I got a good sense of, you know, where you guys are at one, one more question I have. Do you have entitlements or access categories? Yeah, not, not, not necessarily, RBAC, but let's say this app and this user, you know, he doesn't have access to the Pro Plan, or he has, he or she has access to the Pro Plan, like different fields of planning, and within the plan, what resources they have access to what level. So I saw the human level, right? So you can tell creation access to chat. GPT, but would you have, would you have a little more detail around? Okay, he's subscribed to a Pro Plan. He's, he's used these many tokens, or he's, he's prompting 10 times a day, like we have analytics on we employ,
S Speaker 225:42we do. And the reason is all of that, all those data points that you just described, are in line in the stream. So in the prompt metadata, let's call it the prompt metadata. It has the username, it has the date and time, it has the model that they're going to it has the licensing condition like, all that information is in the metadata on the prompt, and the tokens consumed for like, when it comes back, like that cost me 53 tokens. So that information is in there
we do. And the reason is all of that, all those data points that you just described, are in line in the stream. So in the prompt metadata, let's call it the prompt metadata. It has the username, it has the date and time, it has the model that they're going to it has the licensing condition like, all that information is in the metadata on the prompt, and the tokens consumed for like, when it comes back, like that cost me 53 tokens. So that information is in there
we do. And the reason is all of that, all those data points that you just described, are in line in the stream. So in the prompt metadata, let's call it the prompt metadata. It has the username, it has the date and time, it has the model that they're going to it has the licensing condition like, all that information is in the metadata on the prompt, and the tokens consumed for like, when it comes back, like that cost me 53 tokens. So that information is in there
we do. And the reason is all of that, all those data points that you just described, are in line in the stream. So in the prompt metadata, let's call it the prompt metadata. It has the username, it has the date and time, it has the model that they're going to it has the licensing condition like, all that information is in the metadata on the prompt, and the tokens consumed for like, when it comes back, like that cost me 53 tokens. So that information is in there
26:23interesting. Yeah,
S Speaker 126:26I think that covers, that's most of what I had. Priyesh, any questions from your end?
I think that covers, that's most of what I had. Priyesh, any questions from your end?
I think that covers, that's most of what I had. Priyesh, any questions from your end?
I think that covers, that's most of what I had. Priyesh, any questions from your end?
S Speaker 326:32Just a couple of quick questions. Dan, on the first prompt where you sort of redacted the SSN, how does the model do it like I can assume the model comes off the shelf with SSN, information, but numbers could be anything. So do different customers fine tune the numbers? Could it be employee ID? Could be phone number? Could it be SSN,
Just a couple of quick questions. Dan, on the first prompt where you sort of redacted the SSN, how does the model do it like I can assume the model comes off the shelf with SSN, information, but numbers could be anything. So do different customers fine tune the numbers? Could it be employee ID? Could be phone number? Could it be SSN,
Just a couple of quick questions. Dan, on the first prompt where you sort of redacted the SSN, how does the model do it like I can assume the model comes off the shelf with SSN, information, but numbers could be anything. So do different customers fine tune the numbers? Could it be employee ID? Could be phone number? Could it be SSN,
Just a couple of quick questions. Dan, on the first prompt where you sort of redacted the SSN, how does the model do it like I can assume the model comes off the shelf with SSN, information, but numbers could be anything. So do different customers fine tune the numbers? Could it be employee ID? Could be phone number? Could it be SSN,
S Speaker 226:56okay, got it, yeah. So first step in that is I detecting some data in a prompt that they consider sensitive, right? So running a prompt through a set of data classifiers, there's both regex based classifiers as well as any our classifiers to say that looks like a credit card number that looks like a social security number that looks like my bank's private hospital ID number, because it's this pattern and so on. So you have built in plus extensible classifiers to identify the type of data that you think's sensitive, right? Like in Schwab. We've got a whole bunch built in. They uploaded some of their own that into the tool because they've got special Schwab data types that they care about, right, right? So, so once you've now classified that, you have a couple of choices. You could say, if I see a prompt going with any of that in, I just want to block it, not even let it go through it all. In our case, we should that example was showing it's a tokenization. I called it redaction, but it's really a tokenization where we're replacing that actual social security number with a string, ssn, ssn, 123, for that one, and SSN, 234, for the next one, our tokenized string goes through as the prompt up to the back end. It does its response and leaves those alone. And then when it comes back, we just reverse it. We just look up because we've stored the actual social for SSN, 123, we reverse it, and then in line. When it gets back to the user in their app, they now see the original sensitive data. So we kept it from leaving the building by this tokenization and reverse tokenization maneuver in the middle. Does that make sense?
okay, got it, yeah. So first step in that is I detecting some data in a prompt that they consider sensitive, right? So running a prompt through a set of data classifiers, there's both regex based classifiers as well as any our classifiers to say that looks like a credit card number that looks like a social security number that looks like my bank's private hospital ID number, because it's this pattern and so on. So you have built in plus extensible classifiers to identify the type of data that you think's sensitive, right? Like in Schwab. We've got a whole bunch built in. They uploaded some of their own that into the tool because they've got special Schwab data types that they care about, right, right? So, so once you've now classified that, you have a couple of choices. You could say, if I see a prompt going with any of that in, I just want to block it, not even let it go through it all. In our case, we should that example was showing it's a tokenization. I called it redaction, but it's really a tokenization where we're replacing that actual social security number with a string, ssn, ssn, 123, for that one, and SSN, 234, for the next one, our tokenized string goes through as the prompt up to the back end. It does its response and leaves those alone. And then when it comes back, we just reverse it. We just look up because we've stored the actual social for SSN, 123, we reverse it, and then in line. When it gets back to the user in their app, they now see the original sensitive data. So we kept it from leaving the building by this tokenization and reverse tokenization maneuver in the middle. Does that make sense?
okay, got it, yeah. So first step in that is I detecting some data in a prompt that they consider sensitive, right? So running a prompt through a set of data classifiers, there's both regex based classifiers as well as any our classifiers to say that looks like a credit card number that looks like a social security number that looks like my bank's private hospital ID number, because it's this pattern and so on. So you have built in plus extensible classifiers to identify the type of data that you think's sensitive, right? Like in Schwab. We've got a whole bunch built in. They uploaded some of their own that into the tool because they've got special Schwab data types that they care about, right, right? So, so once you've now classified that, you have a couple of choices. You could say, if I see a prompt going with any of that in, I just want to block it, not even let it go through it all. In our case, we should that example was showing it's a tokenization. I called it redaction, but it's really a tokenization where we're replacing that actual social security number with a string, ssn, ssn, 123, for that one, and SSN, 234, for the next one, our tokenized string goes through as the prompt up to the back end. It does its response and leaves those alone. And then when it comes back, we just reverse it. We just look up because we've stored the actual social for SSN, 123, we reverse it, and then in line. When it gets back to the user in their app, they now see the original sensitive data. So we kept it from leaving the building by this tokenization and reverse tokenization maneuver in the middle. Does that make sense?
okay, got it, yeah. So first step in that is I detecting some data in a prompt that they consider sensitive, right? So running a prompt through a set of data classifiers, there's both regex based classifiers as well as any our classifiers to say that looks like a credit card number that looks like a social security number that looks like my bank's private hospital ID number, because it's this pattern and so on. So you have built in plus extensible classifiers to identify the type of data that you think's sensitive, right? Like in Schwab. We've got a whole bunch built in. They uploaded some of their own that into the tool because they've got special Schwab data types that they care about, right, right? So, so once you've now classified that, you have a couple of choices. You could say, if I see a prompt going with any of that in, I just want to block it, not even let it go through it all. In our case, we should that example was showing it's a tokenization. I called it redaction, but it's really a tokenization where we're replacing that actual social security number with a string, ssn, ssn, 123, for that one, and SSN, 234, for the next one, our tokenized string goes through as the prompt up to the back end. It does its response and leaves those alone. And then when it comes back, we just reverse it. We just look up because we've stored the actual social for SSN, 123, we reverse it, and then in line. When it gets back to the user in their app, they now see the original sensitive data. So we kept it from leaving the building by this tokenization and reverse tokenization maneuver in the middle. Does that make sense?
S Speaker 328:55Yeah, yeah. And one more last question, Dan, you mentioned the app classifies about 4500 apps, and there are different risk categories. What sort of factors do you take into classify different apps on different risk categories?
Yeah, yeah. And one more last question, Dan, you mentioned the app classifies about 4500 apps, and there are different risk categories. What sort of factors do you take into classify different apps on different risk categories?
Yeah, yeah. And one more last question, Dan, you mentioned the app classifies about 4500 apps, and there are different risk categories. What sort of factors do you take into classify different apps on different risk categories?
Yeah, yeah. And one more last question, Dan, you mentioned the app classifies about 4500 apps, and there are different risk categories. What sort of factors do you take into classify different apps on different risk categories?
29:11That's a good question, and that is an ongoing effort. So
That's a good question, and that is an ongoing effort. So
That's a good question, and that is an ongoing effort. So
That's a good question, and that is an ongoing effort. So
S Speaker 229:15you know, we continue to build the app catalog, and we continue to identify various aspects of that app that may be considered risky. So one is the type of data that it would typically have access to, like some apps are image generation, that's so there's a purpose of the app kind of thing. Like, I'm an image generator or an audio generator, or I'm a finance app. So there's verticals, there's types of apps. So it's kind of like the CASB problem, of like, there's a million websites in the world. These are about gambling and these are about medical stuff and these about whatever. So kind of like an industry kind of purpose classification is one bubble second bubble is risk score based on their privacy policies. And so we scrape the privacy policy from those apps and have models that look at them and assess how thorough that privacy policy it's like, are they saying your prompt information? We're never training our models on that. Are they not saying that, you know, things like that that are the customers are worried about that? One's a really popular one, by the way. People seem enterprise customers are much more nervous about external models being trained on their data than external models just using that data to formulate a response. So, so those become different risk factors, and then it becomes, it gets computed as a score and and what we're looking at is additional sources of information that we might ingest into them. So there's starting to be some third party LLM ranking services out there, you know. So we may end up having, like, you know, the witness score for this website is x, but there's a third party score too, and you can see both, and you can use that if you want to see policy and so on, yeah.
you know, we continue to build the app catalog, and we continue to identify various aspects of that app that may be considered risky. So one is the type of data that it would typically have access to, like some apps are image generation, that's so there's a purpose of the app kind of thing. Like, I'm an image generator or an audio generator, or I'm a finance app. So there's verticals, there's types of apps. So it's kind of like the CASB problem, of like, there's a million websites in the world. These are about gambling and these are about medical stuff and these about whatever. So kind of like an industry kind of purpose classification is one bubble second bubble is risk score based on their privacy policies. And so we scrape the privacy policy from those apps and have models that look at them and assess how thorough that privacy policy it's like, are they saying your prompt information? We're never training our models on that. Are they not saying that, you know, things like that that are the customers are worried about that? One's a really popular one, by the way. People seem enterprise customers are much more nervous about external models being trained on their data than external models just using that data to formulate a response. So, so those become different risk factors, and then it becomes, it gets computed as a score and and what we're looking at is additional sources of information that we might ingest into them. So there's starting to be some third party LLM ranking services out there, you know. So we may end up having, like, you know, the witness score for this website is x, but there's a third party score too, and you can see both, and you can use that if you want to see policy and so on, yeah.
you know, we continue to build the app catalog, and we continue to identify various aspects of that app that may be considered risky. So one is the type of data that it would typically have access to, like some apps are image generation, that's so there's a purpose of the app kind of thing. Like, I'm an image generator or an audio generator, or I'm a finance app. So there's verticals, there's types of apps. So it's kind of like the CASB problem, of like, there's a million websites in the world. These are about gambling and these are about medical stuff and these about whatever. So kind of like an industry kind of purpose classification is one bubble second bubble is risk score based on their privacy policies. And so we scrape the privacy policy from those apps and have models that look at them and assess how thorough that privacy policy it's like, are they saying your prompt information? We're never training our models on that. Are they not saying that, you know, things like that that are the customers are worried about that? One's a really popular one, by the way. People seem enterprise customers are much more nervous about external models being trained on their data than external models just using that data to formulate a response. So, so those become different risk factors, and then it becomes, it gets computed as a score and and what we're looking at is additional sources of information that we might ingest into them. So there's starting to be some third party LLM ranking services out there, you know. So we may end up having, like, you know, the witness score for this website is x, but there's a third party score too, and you can see both, and you can use that if you want to see policy and so on, yeah.
you know, we continue to build the app catalog, and we continue to identify various aspects of that app that may be considered risky. So one is the type of data that it would typically have access to, like some apps are image generation, that's so there's a purpose of the app kind of thing. Like, I'm an image generator or an audio generator, or I'm a finance app. So there's verticals, there's types of apps. So it's kind of like the CASB problem, of like, there's a million websites in the world. These are about gambling and these are about medical stuff and these about whatever. So kind of like an industry kind of purpose classification is one bubble second bubble is risk score based on their privacy policies. And so we scrape the privacy policy from those apps and have models that look at them and assess how thorough that privacy policy it's like, are they saying your prompt information? We're never training our models on that. Are they not saying that, you know, things like that that are the customers are worried about that? One's a really popular one, by the way. People seem enterprise customers are much more nervous about external models being trained on their data than external models just using that data to formulate a response. So, so those become different risk factors, and then it becomes, it gets computed as a score and and what we're looking at is additional sources of information that we might ingest into them. So there's starting to be some third party LLM ranking services out there, you know. So we may end up having, like, you know, the witness score for this website is x, but there's a third party score too, and you can see both, and you can use that if you want to see policy and so on, yeah.
S Speaker 331:19And do you give the customer an option to sort of give different weights to the different scoring categories.
And do you give the customer an option to sort of give different weights to the different scoring categories.
And do you give the customer an option to sort of give different weights to the different scoring categories.
And do you give the customer an option to sort of give different weights to the different scoring categories.
S Speaker 131:50okay, this was good. Glad we finally got
okay, this was good. Glad we finally got
okay, this was good. Glad we finally got
okay, this was good. Glad we finally got
31:55to it. Appreciate
S Speaker 231:59it. I've got a draft for my next thing. But thank you guys,
it. I've got a draft for my next thing. But thank you guys,
it. I've got a draft for my next thing. But thank you guys,
it. I've got a draft for my next thing. But thank you guys,
32:03thank you. Thank you. Then bye again. You.
thank you. Thank you. Then bye again. You.
thank you. Thank you. Then bye again. You.
thank you. Thank you. Then bye again. You.