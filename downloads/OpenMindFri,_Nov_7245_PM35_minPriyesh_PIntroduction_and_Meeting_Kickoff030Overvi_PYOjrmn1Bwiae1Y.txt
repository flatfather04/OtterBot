Meeting: OpenMind
Fri, Nov 7
2:45 PM
35 min
Priyesh P
Introduction and Meeting Kickoff
0:30
Overview of Curre
URL: https://otter.ai/u/PYOjrmn1Bwiae1YujcEeHdWgsLI
Downloaded: 2025-12-21T19:41:58.673983
Method: text_extraction
============================================================

0:30Hey, Hi Jan. Hey,
0:34hello, hi Jan. I'm Priyesh. I'm in Deepak steam as well. Wonderful.
hello, hi Jan. I'm Priyesh. I'm in Deepak steam as well. Wonderful.
hello, hi Jan. I'm Priyesh. I'm in Deepak steam as well. Wonderful.
hello, hi Jan. I'm Priyesh. I'm in Deepak steam as well. Wonderful.
S Speaker 10:39Glad to finally join. I was a little bit late for the meeting.
Glad to finally join. I was a little bit late for the meeting.
Glad to finally join. I was a little bit late for the meeting.
Glad to finally join. I was a little bit late for the meeting.
S Speaker 20:46We Hey, we agreed to start at 245 just so, like, everyone is, like, fully briefed and so
We Hey, we agreed to start at 245 just so, like, everyone is, like, fully briefed and so
We Hey, we agreed to start at 245 just so, like, everyone is, like, fully briefed and so
We Hey, we agreed to start at 245 just so, like, everyone is, like, fully briefed and so
S Speaker 30:54forth. Yeah, no. Thanks. Thanks. Thanks, Jan and good to Good to have you join as well. He's been spending some time on the physical AI side of things. Yeah, so yeah, and I connected almost three months ago. Yeah. Now, right. And yeah, we'd love to maybe, if you can start from what you guys are building for. We've read what's publicly available, we kind of have some sense on that. But maybe if we can unpack, and I think there's, there's a difference between what the other humanoid companies or robotics companies are doing, there's an echo. I don't know if it's,
forth. Yeah, no. Thanks. Thanks. Thanks, Jan and good to Good to have you join as well. He's been spending some time on the physical AI side of things. Yeah, so yeah, and I connected almost three months ago. Yeah. Now, right. And yeah, we'd love to maybe, if you can start from what you guys are building for. We've read what's publicly available, we kind of have some sense on that. But maybe if we can unpack, and I think there's, there's a difference between what the other humanoid companies or robotics companies are doing, there's an echo. I don't know if it's,
forth. Yeah, no. Thanks. Thanks. Thanks, Jan and good to Good to have you join as well. He's been spending some time on the physical AI side of things. Yeah, so yeah, and I connected almost three months ago. Yeah. Now, right. And yeah, we'd love to maybe, if you can start from what you guys are building for. We've read what's publicly available, we kind of have some sense on that. But maybe if we can unpack, and I think there's, there's a difference between what the other humanoid companies or robotics companies are doing, there's an echo. I don't know if it's,
forth. Yeah, no. Thanks. Thanks. Thanks, Jan and good to Good to have you join as well. He's been spending some time on the physical AI side of things. Yeah, so yeah, and I connected almost three months ago. Yeah. Now, right. And yeah, we'd love to maybe, if you can start from what you guys are building for. We've read what's publicly available, we kind of have some sense on that. But maybe if we can unpack, and I think there's, there's a difference between what the other humanoid companies or robotics companies are doing, there's an echo. I don't know if it's,
S Speaker 21:34maybe it's, well, let's see if the Echo is goes away. So let's see. Well, there's a lot of parallel threads, but the simple version is that we write software for primarily quadruped and bipedal and but we also support other foreign factors, like six legged dogs, although that's an edge case, and our goal is to write software that is very easy to modify to accommodate many different use cases and many different movement platforms, and there's a there's one thing we don't do, and we don't do anything with hands. There's no hands. And the reason we don't, of course, we have lots of hands in the lab, but in our estimation, hands in particular, are not really ready yet for like US consumer so when robotics companies say, Oh, we will fold your laundry, we will chop your onions or fold Your socks, we say, business wise, it's not so interesting, and it's technically very hard, right? For example, the Inspire hands we use realistically have a mean time between failure of 100 hours
maybe it's, well, let's see if the Echo is goes away. So let's see. Well, there's a lot of parallel threads, but the simple version is that we write software for primarily quadruped and bipedal and but we also support other foreign factors, like six legged dogs, although that's an edge case, and our goal is to write software that is very easy to modify to accommodate many different use cases and many different movement platforms, and there's a there's one thing we don't do, and we don't do anything with hands. There's no hands. And the reason we don't, of course, we have lots of hands in the lab, but in our estimation, hands in particular, are not really ready yet for like US consumer so when robotics companies say, Oh, we will fold your laundry, we will chop your onions or fold Your socks, we say, business wise, it's not so interesting, and it's technically very hard, right? For example, the Inspire hands we use realistically have a mean time between failure of 100 hours
maybe it's, well, let's see if the Echo is goes away. So let's see. Well, there's a lot of parallel threads, but the simple version is that we write software for primarily quadruped and bipedal and but we also support other foreign factors, like six legged dogs, although that's an edge case, and our goal is to write software that is very easy to modify to accommodate many different use cases and many different movement platforms, and there's a there's one thing we don't do, and we don't do anything with hands. There's no hands. And the reason we don't, of course, we have lots of hands in the lab, but in our estimation, hands in particular, are not really ready yet for like US consumer so when robotics companies say, Oh, we will fold your laundry, we will chop your onions or fold Your socks, we say, business wise, it's not so interesting, and it's technically very hard, right? For example, the Inspire hands we use realistically have a mean time between failure of 100 hours
maybe it's, well, let's see if the Echo is goes away. So let's see. Well, there's a lot of parallel threads, but the simple version is that we write software for primarily quadruped and bipedal and but we also support other foreign factors, like six legged dogs, although that's an edge case, and our goal is to write software that is very easy to modify to accommodate many different use cases and many different movement platforms, and there's a there's one thing we don't do, and we don't do anything with hands. There's no hands. And the reason we don't, of course, we have lots of hands in the lab, but in our estimation, hands in particular, are not really ready yet for like US consumer so when robotics companies say, Oh, we will fold your laundry, we will chop your onions or fold Your socks, we say, business wise, it's not so interesting, and it's technically very hard, right? For example, the Inspire hands we use realistically have a mean time between failure of 100 hours
3:17and one of the five fingers breaks.
and one of the five fingers breaks.
and one of the five fingers breaks.
and one of the five fingers breaks.
S Speaker 23:20And so sure. Can we do demos like Instacart, grab grocery, put in basket, and can we do a video,
And so sure. Can we do demos like Instacart, grab grocery, put in basket, and can we do a video,
And so sure. Can we do demos like Instacart, grab grocery, put in basket, and can we do a video,
And so sure. Can we do demos like Instacart, grab grocery, put in basket, and can we do a video,
3:29right? Yeah, we can, right? Do
right? Yeah, we can, right? Do
right? Yeah, we can, right? Do
right? Yeah, we can, right? Do
S Speaker 23:31we feel comfortable selling 1000 of these to us supermarkets? No, because the only thing that would happen is we'd be running a repair company consent technicians.
we feel comfortable selling 1000 of these to us supermarkets? No, because the only thing that would happen is we'd be running a repair company consent technicians.
we feel comfortable selling 1000 of these to us supermarkets? No, because the only thing that would happen is we'd be running a repair company consent technicians.
we feel comfortable selling 1000 of these to us supermarkets? No, because the only thing that would happen is we'd be running a repair company consent technicians.
3:46Because, yeah, I get it. I get it. And
Because, yeah, I get it. I get it. And
Because, yeah, I get it. I get it. And
Because, yeah, I get it. I get it. And
S Speaker 23:48so in the long term, is physical dexterity critical, of course, it is, of course. But right now, if you're trying to sell robots into schools, homes, hospitals, workplaces. In our estimation, the strategic thing to do is go after good verticals that do not require hands and for most robotics companies, that probably sounds crazy, because a lot of people in the humanoid space in their mind, what defines what makes a humanoid useful is like iPhone assembly, or when we have calls with BMW and they say, like the torques bolts they want to insert upside down with blue Loctite and stuff like that. So I get it. Those are use cases for, like, for robots, yeah. But in 2025 the combination of the software, the hardware and the hands, in my estimation, is just not there yet, right? So I don't want to be trying to, like, make hands perfect before we ship. We want to ship now. Now that's why we're going after things like memory care, retirement homes, nurse triage for emergency rooms, handing out water bottles to pilgrims in Saudi Arabia because of heat stroke and the kind of use cases we see over and over again is minimal hand dexterity, and in many cases, you don't even need a hand, right? But what you need is voice. You need to speak. You need to follow humans. You need to recognize humans. You need to remember their preferences, yeah, previous things you've said. And then if I have that kind of memory, then I can say sensible things. I can teach. I can ask you about your health. I can ask you. I can ask your mother, who's lying on the floor. Hey, are you okay? Yeah, human nurse, yeah. And
so in the long term, is physical dexterity critical, of course, it is, of course. But right now, if you're trying to sell robots into schools, homes, hospitals, workplaces. In our estimation, the strategic thing to do is go after good verticals that do not require hands and for most robotics companies, that probably sounds crazy, because a lot of people in the humanoid space in their mind, what defines what makes a humanoid useful is like iPhone assembly, or when we have calls with BMW and they say, like the torques bolts they want to insert upside down with blue Loctite and stuff like that. So I get it. Those are use cases for, like, for robots, yeah. But in 2025 the combination of the software, the hardware and the hands, in my estimation, is just not there yet, right? So I don't want to be trying to, like, make hands perfect before we ship. We want to ship now. Now that's why we're going after things like memory care, retirement homes, nurse triage for emergency rooms, handing out water bottles to pilgrims in Saudi Arabia because of heat stroke and the kind of use cases we see over and over again is minimal hand dexterity, and in many cases, you don't even need a hand, right? But what you need is voice. You need to speak. You need to follow humans. You need to recognize humans. You need to remember their preferences, yeah, previous things you've said. And then if I have that kind of memory, then I can say sensible things. I can teach. I can ask you about your health. I can ask you. I can ask your mother, who's lying on the floor. Hey, are you okay? Yeah, human nurse, yeah. And
so in the long term, is physical dexterity critical, of course, it is, of course. But right now, if you're trying to sell robots into schools, homes, hospitals, workplaces. In our estimation, the strategic thing to do is go after good verticals that do not require hands and for most robotics companies, that probably sounds crazy, because a lot of people in the humanoid space in their mind, what defines what makes a humanoid useful is like iPhone assembly, or when we have calls with BMW and they say, like the torques bolts they want to insert upside down with blue Loctite and stuff like that. So I get it. Those are use cases for, like, for robots, yeah. But in 2025 the combination of the software, the hardware and the hands, in my estimation, is just not there yet, right? So I don't want to be trying to, like, make hands perfect before we ship. We want to ship now. Now that's why we're going after things like memory care, retirement homes, nurse triage for emergency rooms, handing out water bottles to pilgrims in Saudi Arabia because of heat stroke and the kind of use cases we see over and over again is minimal hand dexterity, and in many cases, you don't even need a hand, right? But what you need is voice. You need to speak. You need to follow humans. You need to recognize humans. You need to remember their preferences, yeah, previous things you've said. And then if I have that kind of memory, then I can say sensible things. I can teach. I can ask you about your health. I can ask you. I can ask your mother, who's lying on the floor. Hey, are you okay? Yeah, human nurse, yeah. And
so in the long term, is physical dexterity critical, of course, it is, of course. But right now, if you're trying to sell robots into schools, homes, hospitals, workplaces. In our estimation, the strategic thing to do is go after good verticals that do not require hands and for most robotics companies, that probably sounds crazy, because a lot of people in the humanoid space in their mind, what defines what makes a humanoid useful is like iPhone assembly, or when we have calls with BMW and they say, like the torques bolts they want to insert upside down with blue Loctite and stuff like that. So I get it. Those are use cases for, like, for robots, yeah. But in 2025 the combination of the software, the hardware and the hands, in my estimation, is just not there yet, right? So I don't want to be trying to, like, make hands perfect before we ship. We want to ship now. Now that's why we're going after things like memory care, retirement homes, nurse triage for emergency rooms, handing out water bottles to pilgrims in Saudi Arabia because of heat stroke and the kind of use cases we see over and over again is minimal hand dexterity, and in many cases, you don't even need a hand, right? But what you need is voice. You need to speak. You need to follow humans. You need to recognize humans. You need to remember their preferences, yeah, previous things you've said. And then if I have that kind of memory, then I can say sensible things. I can teach. I can ask you about your health. I can ask you. I can ask your mother, who's lying on the floor. Hey, are you okay? Yeah, human nurse, yeah. And
6:01that's a lot, lot of software
that's a lot, lot of software
that's a lot, lot of software
that's a lot, lot of software
S Speaker 26:02there. Yeah, exactly. And so what we do software wise is we're really one layer above a world model or a foundation model, because we deal with things like tactics or decisions like the humanoid is in a room and there's a kid and a baby and a mom, and the humanoid knows the names of everyone with a ring, given the history of previous interactions with those humans, what should the humanoid be doing? And the answer may well be pick up the coffee. And then there's great news. There's dozens of companies building models to pick up a glass so we don't have to reinvent that. And in fact, there's simulation environments, and there's like billions flowing into assembly giving of coffee. But we don't, we don't care, because we're operating one layer above, which is, you know, the nursing education, security, selling home in Hillsborough tomorrow with Iris. And so the software is modular. Yeah, the modularity of the software makes it very easy for developers to build apps or skill chips that can be run on the humanoid for specific tasks. And one thing that's coming out product wise is the first app store for humanoid where you double click on a skill and then your humanoid has new skill, supports your language, better at math, can detect seizures in kids with epilepsy and detect people lying on the floor and so, yeah, we're kind of different. Like, a year ago, it was fashionable to say, oh, you know, like robots need one universal all capable end to end, AI, and it will be beautiful and awesome and do everything right. Sure, if you have unlimited time of money, but if you have someone says, oh, I need to support Vietnamese, and I need the robot to ask these 10 Questions for intake in the ER. And it would be incredibly expensive and slow to have to tune some vision action model, of course, and then you'd have trade offs, then all of a sudden, you have to test the whole system all over again. And if I improve capability in one area, almost certainly I'm going to mess with capabilities in other areas. And so when we interact with customers who have a list of needs, they're all kind of different, and it would be very difficult commercially to justify tooling building new world models.
there. Yeah, exactly. And so what we do software wise is we're really one layer above a world model or a foundation model, because we deal with things like tactics or decisions like the humanoid is in a room and there's a kid and a baby and a mom, and the humanoid knows the names of everyone with a ring, given the history of previous interactions with those humans, what should the humanoid be doing? And the answer may well be pick up the coffee. And then there's great news. There's dozens of companies building models to pick up a glass so we don't have to reinvent that. And in fact, there's simulation environments, and there's like billions flowing into assembly giving of coffee. But we don't, we don't care, because we're operating one layer above, which is, you know, the nursing education, security, selling home in Hillsborough tomorrow with Iris. And so the software is modular. Yeah, the modularity of the software makes it very easy for developers to build apps or skill chips that can be run on the humanoid for specific tasks. And one thing that's coming out product wise is the first app store for humanoid where you double click on a skill and then your humanoid has new skill, supports your language, better at math, can detect seizures in kids with epilepsy and detect people lying on the floor and so, yeah, we're kind of different. Like, a year ago, it was fashionable to say, oh, you know, like robots need one universal all capable end to end, AI, and it will be beautiful and awesome and do everything right. Sure, if you have unlimited time of money, but if you have someone says, oh, I need to support Vietnamese, and I need the robot to ask these 10 Questions for intake in the ER. And it would be incredibly expensive and slow to have to tune some vision action model, of course, and then you'd have trade offs, then all of a sudden, you have to test the whole system all over again. And if I improve capability in one area, almost certainly I'm going to mess with capabilities in other areas. And so when we interact with customers who have a list of needs, they're all kind of different, and it would be very difficult commercially to justify tooling building new world models.
there. Yeah, exactly. And so what we do software wise is we're really one layer above a world model or a foundation model, because we deal with things like tactics or decisions like the humanoid is in a room and there's a kid and a baby and a mom, and the humanoid knows the names of everyone with a ring, given the history of previous interactions with those humans, what should the humanoid be doing? And the answer may well be pick up the coffee. And then there's great news. There's dozens of companies building models to pick up a glass so we don't have to reinvent that. And in fact, there's simulation environments, and there's like billions flowing into assembly giving of coffee. But we don't, we don't care, because we're operating one layer above, which is, you know, the nursing education, security, selling home in Hillsborough tomorrow with Iris. And so the software is modular. Yeah, the modularity of the software makes it very easy for developers to build apps or skill chips that can be run on the humanoid for specific tasks. And one thing that's coming out product wise is the first app store for humanoid where you double click on a skill and then your humanoid has new skill, supports your language, better at math, can detect seizures in kids with epilepsy and detect people lying on the floor and so, yeah, we're kind of different. Like, a year ago, it was fashionable to say, oh, you know, like robots need one universal all capable end to end, AI, and it will be beautiful and awesome and do everything right. Sure, if you have unlimited time of money, but if you have someone says, oh, I need to support Vietnamese, and I need the robot to ask these 10 Questions for intake in the ER. And it would be incredibly expensive and slow to have to tune some vision action model, of course, and then you'd have trade offs, then all of a sudden, you have to test the whole system all over again. And if I improve capability in one area, almost certainly I'm going to mess with capabilities in other areas. And so when we interact with customers who have a list of needs, they're all kind of different, and it would be very difficult commercially to justify tooling building new world models.
there. Yeah, exactly. And so what we do software wise is we're really one layer above a world model or a foundation model, because we deal with things like tactics or decisions like the humanoid is in a room and there's a kid and a baby and a mom, and the humanoid knows the names of everyone with a ring, given the history of previous interactions with those humans, what should the humanoid be doing? And the answer may well be pick up the coffee. And then there's great news. There's dozens of companies building models to pick up a glass so we don't have to reinvent that. And in fact, there's simulation environments, and there's like billions flowing into assembly giving of coffee. But we don't, we don't care, because we're operating one layer above, which is, you know, the nursing education, security, selling home in Hillsborough tomorrow with Iris. And so the software is modular. Yeah, the modularity of the software makes it very easy for developers to build apps or skill chips that can be run on the humanoid for specific tasks. And one thing that's coming out product wise is the first app store for humanoid where you double click on a skill and then your humanoid has new skill, supports your language, better at math, can detect seizures in kids with epilepsy and detect people lying on the floor and so, yeah, we're kind of different. Like, a year ago, it was fashionable to say, oh, you know, like robots need one universal all capable end to end, AI, and it will be beautiful and awesome and do everything right. Sure, if you have unlimited time of money, but if you have someone says, oh, I need to support Vietnamese, and I need the robot to ask these 10 Questions for intake in the ER. And it would be incredibly expensive and slow to have to tune some vision action model, of course, and then you'd have trade offs, then all of a sudden, you have to test the whole system all over again. And if I improve capability in one area, almost certainly I'm going to mess with capabilities in other areas. And so when we interact with customers who have a list of needs, they're all kind of different, and it would be very difficult commercially to justify tooling building new world models.
S Speaker 39:01Yeah, no, I get it so. So I think maybe another way to put it is, you are the brains behind different systems, right, and you're basically orchestrating, coordinating, right, developing memory, right, doing research.
Yeah, no, I get it so. So I think maybe another way to put it is, you are the brains behind different systems, right, and you're basically orchestrating, coordinating, right, developing memory, right, doing research.
Yeah, no, I get it so. So I think maybe another way to put it is, you are the brains behind different systems, right, and you're basically orchestrating, coordinating, right, developing memory, right, doing research.
Yeah, no, I get it so. So I think maybe another way to put it is, you are the brains behind different systems, right, and you're basically orchestrating, coordinating, right, developing memory, right, doing research.
S Speaker 29:19So everything our robots do is we don't do any manufacturing, we don't do neurosurgery, we don't do easy to automate tasks. Everything we do involves the robot interacting with the human and having to make decisions that involve multiple channels of data, vision, location, machine and memory of the previous interactions with the human. And so that's a little bit like on one. And what's really nice about on one, it's one of the top trending open source things on GitHub right now, which is way cool. And a lot of people really love the idea of, oh, it's something like, I can understand it's something, if I want new capability, I can add it and I can put it on this app store. It's just like a phone. So we totally, yeah, we kind of do have a different perspective in terms of the hardware side, the brain packs that are going for sale. The frustrating thing we found is working with multiple Chinese humanitarian wise companies is they're all kind of different, different voltage power supplies, Zeno, DDS, custom, SDK lockdown, partially locked down mid 360 real sense, a little overall, everything's kind of different. And so this hardware product that's going on sale soon, which is centered around the NVIDIA Thor. It's the NVIDIA Thor, plus all the wires and cables, plus laser scan camera, great microphone, speakers, display for emotion expression and a capacitive touchscreen, and you snap that onto the back of unitary Yuba tech, and it's like it's a modular like computer with sensors that talks to multiple humanoid movement platforms and uses our cloud and our software. The first product that is built around the brain pack is an educational product for us, K through 12 schools and universities with unity and Robo store, and there's already press releases about that, they went out yesterday and today and stuff like that. And that's basically a package consisting of a humanoid plus education materials plus on one, and that together is then makes it easier for people to, like, learn and experience,
So everything our robots do is we don't do any manufacturing, we don't do neurosurgery, we don't do easy to automate tasks. Everything we do involves the robot interacting with the human and having to make decisions that involve multiple channels of data, vision, location, machine and memory of the previous interactions with the human. And so that's a little bit like on one. And what's really nice about on one, it's one of the top trending open source things on GitHub right now, which is way cool. And a lot of people really love the idea of, oh, it's something like, I can understand it's something, if I want new capability, I can add it and I can put it on this app store. It's just like a phone. So we totally, yeah, we kind of do have a different perspective in terms of the hardware side, the brain packs that are going for sale. The frustrating thing we found is working with multiple Chinese humanitarian wise companies is they're all kind of different, different voltage power supplies, Zeno, DDS, custom, SDK lockdown, partially locked down mid 360 real sense, a little overall, everything's kind of different. And so this hardware product that's going on sale soon, which is centered around the NVIDIA Thor. It's the NVIDIA Thor, plus all the wires and cables, plus laser scan camera, great microphone, speakers, display for emotion expression and a capacitive touchscreen, and you snap that onto the back of unitary Yuba tech, and it's like it's a modular like computer with sensors that talks to multiple humanoid movement platforms and uses our cloud and our software. The first product that is built around the brain pack is an educational product for us, K through 12 schools and universities with unity and Robo store, and there's already press releases about that, they went out yesterday and today and stuff like that. And that's basically a package consisting of a humanoid plus education materials plus on one, and that together is then makes it easier for people to, like, learn and experience,
So everything our robots do is we don't do any manufacturing, we don't do neurosurgery, we don't do easy to automate tasks. Everything we do involves the robot interacting with the human and having to make decisions that involve multiple channels of data, vision, location, machine and memory of the previous interactions with the human. And so that's a little bit like on one. And what's really nice about on one, it's one of the top trending open source things on GitHub right now, which is way cool. And a lot of people really love the idea of, oh, it's something like, I can understand it's something, if I want new capability, I can add it and I can put it on this app store. It's just like a phone. So we totally, yeah, we kind of do have a different perspective in terms of the hardware side, the brain packs that are going for sale. The frustrating thing we found is working with multiple Chinese humanitarian wise companies is they're all kind of different, different voltage power supplies, Zeno, DDS, custom, SDK lockdown, partially locked down mid 360 real sense, a little overall, everything's kind of different. And so this hardware product that's going on sale soon, which is centered around the NVIDIA Thor. It's the NVIDIA Thor, plus all the wires and cables, plus laser scan camera, great microphone, speakers, display for emotion expression and a capacitive touchscreen, and you snap that onto the back of unitary Yuba tech, and it's like it's a modular like computer with sensors that talks to multiple humanoid movement platforms and uses our cloud and our software. The first product that is built around the brain pack is an educational product for us, K through 12 schools and universities with unity and Robo store, and there's already press releases about that, they went out yesterday and today and stuff like that. And that's basically a package consisting of a humanoid plus education materials plus on one, and that together is then makes it easier for people to, like, learn and experience,
So everything our robots do is we don't do any manufacturing, we don't do neurosurgery, we don't do easy to automate tasks. Everything we do involves the robot interacting with the human and having to make decisions that involve multiple channels of data, vision, location, machine and memory of the previous interactions with the human. And so that's a little bit like on one. And what's really nice about on one, it's one of the top trending open source things on GitHub right now, which is way cool. And a lot of people really love the idea of, oh, it's something like, I can understand it's something, if I want new capability, I can add it and I can put it on this app store. It's just like a phone. So we totally, yeah, we kind of do have a different perspective in terms of the hardware side, the brain packs that are going for sale. The frustrating thing we found is working with multiple Chinese humanitarian wise companies is they're all kind of different, different voltage power supplies, Zeno, DDS, custom, SDK lockdown, partially locked down mid 360 real sense, a little overall, everything's kind of different. And so this hardware product that's going on sale soon, which is centered around the NVIDIA Thor. It's the NVIDIA Thor, plus all the wires and cables, plus laser scan camera, great microphone, speakers, display for emotion expression and a capacitive touchscreen, and you snap that onto the back of unitary Yuba tech, and it's like it's a modular like computer with sensors that talks to multiple humanoid movement platforms and uses our cloud and our software. The first product that is built around the brain pack is an educational product for us, K through 12 schools and universities with unity and Robo store, and there's already press releases about that, they went out yesterday and today and stuff like that. And that's basically a package consisting of a humanoid plus education materials plus on one, and that together is then makes it easier for people to, like, learn and experience,
S Speaker 312:04of course, of course. So you sell to maybe the OEM manufacturer, or as a software subscription, or, like, audio, wait, yeah.
of course, of course. So you sell to maybe the OEM manufacturer, or as a software subscription, or, like, audio, wait, yeah.
of course, of course. So you sell to maybe the OEM manufacturer, or as a software subscription, or, like, audio, wait, yeah.
of course, of course. So you sell to maybe the OEM manufacturer, or as a software subscription, or, like, audio, wait, yeah.
S Speaker 214:57We have way more people that want humanoids than we could ever sell them so but typically, the people who want humanoids right now, they're either like, rich hackers or they're tech companies like meta and whoever else who like, want lots of humanoids, and then it is so it's still mostly like hackers, developers, tech companies and schools, universities. So that's where the volumes are right now. That's where like the that's like the first wave, and we're trying out different things. So first of all, 100% we work with Chinese humanoid manufacturers, and that's a really easy sell, because for a lot of Chinese humanoid box manufacturers, they know they cannot make money in China. The only way they're going to make money and sell millions of units is us, Middle East and Europe. So every single one of them right now is opening office in San Jose or becoming American, using us software, because that's where they see the money, right? So the connection of us with China's largest company, that's easy. And then there's a completely separate question about how to do the business development on the US side, with possible school districts homes, and that is the unsolved problem, or unself question for us and every single other robotics company in the US right now, exception of the education market, which is much more mature, and things like military, which is different. And then, okay, there's, there's a few things like, you know, pipeline monitoring, drones, agriculture, that are a little bit better developed. But the way we're doing this is, for example, for the humanoid for real estate,
We have way more people that want humanoids than we could ever sell them so but typically, the people who want humanoids right now, they're either like, rich hackers or they're tech companies like meta and whoever else who like, want lots of humanoids, and then it is so it's still mostly like hackers, developers, tech companies and schools, universities. So that's where the volumes are right now. That's where like the that's like the first wave, and we're trying out different things. So first of all, 100% we work with Chinese humanoid manufacturers, and that's a really easy sell, because for a lot of Chinese humanoid box manufacturers, they know they cannot make money in China. The only way they're going to make money and sell millions of units is us, Middle East and Europe. So every single one of them right now is opening office in San Jose or becoming American, using us software, because that's where they see the money, right? So the connection of us with China's largest company, that's easy. And then there's a completely separate question about how to do the business development on the US side, with possible school districts homes, and that is the unsolved problem, or unself question for us and every single other robotics company in the US right now, exception of the education market, which is much more mature, and things like military, which is different. And then, okay, there's, there's a few things like, you know, pipeline monitoring, drones, agriculture, that are a little bit better developed. But the way we're doing this is, for example, for the humanoid for real estate,
We have way more people that want humanoids than we could ever sell them so but typically, the people who want humanoids right now, they're either like, rich hackers or they're tech companies like meta and whoever else who like, want lots of humanoids, and then it is so it's still mostly like hackers, developers, tech companies and schools, universities. So that's where the volumes are right now. That's where like the that's like the first wave, and we're trying out different things. So first of all, 100% we work with Chinese humanoid manufacturers, and that's a really easy sell, because for a lot of Chinese humanoid box manufacturers, they know they cannot make money in China. The only way they're going to make money and sell millions of units is us, Middle East and Europe. So every single one of them right now is opening office in San Jose or becoming American, using us software, because that's where they see the money, right? So the connection of us with China's largest company, that's easy. And then there's a completely separate question about how to do the business development on the US side, with possible school districts homes, and that is the unsolved problem, or unself question for us and every single other robotics company in the US right now, exception of the education market, which is much more mature, and things like military, which is different. And then, okay, there's, there's a few things like, you know, pipeline monitoring, drones, agriculture, that are a little bit better developed. But the way we're doing this is, for example, for the humanoid for real estate,
We have way more people that want humanoids than we could ever sell them so but typically, the people who want humanoids right now, they're either like, rich hackers or they're tech companies like meta and whoever else who like, want lots of humanoids, and then it is so it's still mostly like hackers, developers, tech companies and schools, universities. So that's where the volumes are right now. That's where like the that's like the first wave, and we're trying out different things. So first of all, 100% we work with Chinese humanoid manufacturers, and that's a really easy sell, because for a lot of Chinese humanoid box manufacturers, they know they cannot make money in China. The only way they're going to make money and sell millions of units is us, Middle East and Europe. So every single one of them right now is opening office in San Jose or becoming American, using us software, because that's where they see the money, right? So the connection of us with China's largest company, that's easy. And then there's a completely separate question about how to do the business development on the US side, with possible school districts homes, and that is the unsolved problem, or unself question for us and every single other robotics company in the US right now, exception of the education market, which is much more mature, and things like military, which is different. And then, okay, there's, there's a few things like, you know, pipeline monitoring, drones, agriculture, that are a little bit better developed. But the way we're doing this is, for example, for the humanoid for real estate,
17:08we're partnering with
we're partnering with
we're partnering with
we're partnering with
S Speaker 318:45they did. So let me change the direction of the discussion, right? And, and Priyesh, if you have any questions on any of the sections,
they did. So let me change the direction of the discussion, right? And, and Priyesh, if you have any questions on any of the sections,
they did. So let me change the direction of the discussion, right? And, and Priyesh, if you have any questions on any of the sections,
they did. So let me change the direction of the discussion, right? And, and Priyesh, if you have any questions on any of the sections,
S Speaker 118:56yeah, I wanted to sort of double dive a little bit on the tech stack. Again, you mentioned you are not sort of suggesting hands at the moment. So if I were to break the entire stack, it's perception plus reasoning that you're working on, and not the action module on top of it. And most of the actions that your robots can take today are digital actions. Is that correct?
yeah, I wanted to sort of double dive a little bit on the tech stack. Again, you mentioned you are not sort of suggesting hands at the moment. So if I were to break the entire stack, it's perception plus reasoning that you're working on, and not the action module on top of it. And most of the actions that your robots can take today are digital actions. Is that correct?
yeah, I wanted to sort of double dive a little bit on the tech stack. Again, you mentioned you are not sort of suggesting hands at the moment. So if I were to break the entire stack, it's perception plus reasoning that you're working on, and not the action module on top of it. And most of the actions that your robots can take today are digital actions. Is that correct?
yeah, I wanted to sort of double dive a little bit on the tech stack. Again, you mentioned you are not sort of suggesting hands at the moment. So if I were to break the entire stack, it's perception plus reasoning that you're working on, and not the action module on top of it. And most of the actions that your robots can take today are digital actions. Is that correct?
S Speaker 219:21Well, so we can we have like path planning so they're certainly capable to, like, walk to the kitchen and show you where the living room is, but all the actions are, it's either oil or angle or move to open bracket, three, combable, closed bracket with path planning or elemental actions like shake hand, wave, get up, sit down. But we do not do any like fast, spatially optimal, 23 or 28 degree freedom movement
Well, so we can we have like path planning so they're certainly capable to, like, walk to the kitchen and show you where the living room is, but all the actions are, it's either oil or angle or move to open bracket, three, combable, closed bracket with path planning or elemental actions like shake hand, wave, get up, sit down. But we do not do any like fast, spatially optimal, 23 or 28 degree freedom movement
Well, so we can we have like path planning so they're certainly capable to, like, walk to the kitchen and show you where the living room is, but all the actions are, it's either oil or angle or move to open bracket, three, combable, closed bracket with path planning or elemental actions like shake hand, wave, get up, sit down. But we do not do any like fast, spatially optimal, 23 or 28 degree freedom movement
Well, so we can we have like path planning so they're certainly capable to, like, walk to the kitchen and show you where the living room is, but all the actions are, it's either oil or angle or move to open bracket, three, combable, closed bracket with path planning or elemental actions like shake hand, wave, get up, sit down. But we do not do any like fast, spatially optimal, 23 or 28 degree freedom movement
S Speaker 120:07got it. Got it. And Yan so for the perception and reasoning modules that you have, the models that you use for them are these, your own proprietary models. Are these open source models? How do you compare again? Say, off the shelf Pi Zero or something like that.
got it. Got it. And Yan so for the perception and reasoning modules that you have, the models that you use for them are these, your own proprietary models. Are these open source models? How do you compare again? Say, off the shelf Pi Zero or something like that.
got it. Got it. And Yan so for the perception and reasoning modules that you have, the models that you use for them are these, your own proprietary models. Are these open source models? How do you compare again? Say, off the shelf Pi Zero or something like that.
got it. Got it. And Yan so for the perception and reasoning modules that you have, the models that you use for them are these, your own proprietary models. Are these open source models? How do you compare again? Say, off the shelf Pi Zero or something like that.
S Speaker 220:23Oh, we basically use whatever works best. For example, we really like Nvidia's Villa and Reva for parts of the vision and the audio for the core reasoning, we typically use either anthropic or OpenAI or deeptik. And we also like Gemini from Google, and of course, they have a big robotics effort, partially because of intrinsic which is their own commercially focused, modular operating system approach for robots. And then we build some of our we do some of our own movement policies, and we do some vision models for specific purposes, like detecting dangers in front of the feet, epoxy coated floors, wet floors, incline, swole stare, step shoe, baby. And that's just designed so that robots don't step onto things or trip. And that's running locally, of course, because that we actually need to be very fast.
Oh, we basically use whatever works best. For example, we really like Nvidia's Villa and Reva for parts of the vision and the audio for the core reasoning, we typically use either anthropic or OpenAI or deeptik. And we also like Gemini from Google, and of course, they have a big robotics effort, partially because of intrinsic which is their own commercially focused, modular operating system approach for robots. And then we build some of our we do some of our own movement policies, and we do some vision models for specific purposes, like detecting dangers in front of the feet, epoxy coated floors, wet floors, incline, swole stare, step shoe, baby. And that's just designed so that robots don't step onto things or trip. And that's running locally, of course, because that we actually need to be very fast.
Oh, we basically use whatever works best. For example, we really like Nvidia's Villa and Reva for parts of the vision and the audio for the core reasoning, we typically use either anthropic or OpenAI or deeptik. And we also like Gemini from Google, and of course, they have a big robotics effort, partially because of intrinsic which is their own commercially focused, modular operating system approach for robots. And then we build some of our we do some of our own movement policies, and we do some vision models for specific purposes, like detecting dangers in front of the feet, epoxy coated floors, wet floors, incline, swole stare, step shoe, baby. And that's just designed so that robots don't step onto things or trip. And that's running locally, of course, because that we actually need to be very fast.
Oh, we basically use whatever works best. For example, we really like Nvidia's Villa and Reva for parts of the vision and the audio for the core reasoning, we typically use either anthropic or OpenAI or deeptik. And we also like Gemini from Google, and of course, they have a big robotics effort, partially because of intrinsic which is their own commercially focused, modular operating system approach for robots. And then we build some of our we do some of our own movement policies, and we do some vision models for specific purposes, like detecting dangers in front of the feet, epoxy coated floors, wet floors, incline, swole stare, step shoe, baby. And that's just designed so that robots don't step onto things or trip. And that's running locally, of course, because that we actually need to be very fast.
S Speaker 121:40Got it, got it. And you had one last question when you were suggesting that you have different go to markets that you're targeting, which parts of these tech stacks would you need to fine tune and how to sort of make the robot or the module work better for a realtor versus in healthcare?
Got it, got it. And you had one last question when you were suggesting that you have different go to markets that you're targeting, which parts of these tech stacks would you need to fine tune and how to sort of make the robot or the module work better for a realtor versus in healthcare?
Got it, got it. And you had one last question when you were suggesting that you have different go to markets that you're targeting, which parts of these tech stacks would you need to fine tune and how to sort of make the robot or the module work better for a realtor versus in healthcare?
Got it, got it. And you had one last question when you were suggesting that you have different go to markets that you're targeting, which parts of these tech stacks would you need to fine tune and how to sort of make the robot or the module work better for a realtor versus in healthcare?
S Speaker 221:57Well, we're really focusing on verticals right now that they're all extremely similar. At the core, for example, the difference between a hospital triage robot and a realtor robot is prompts for the different llms, and it's where did the data need to go. So for example, in the hospital use case, you have to work with like Cerner to push data into hospital back ends, whereas for realtors, they use a different system for their mapping and staging, where they need to figure out which furniture goes with which floor plan. So there's differences at the level of who is accessing the data, which computer systems do the data need to be pushed into, and what are the prompts that are facing the human there's one other difference, for example, for the hospital triage, there's an additional sensor which uses the modulation of your face coloration to do remote heart Rate assessment and but that's like a snap on thing just after the head. You know, think that conceptually, like you just add to the head this, of course, is a Deaf camera. Real sense was just here, they're a blast. We had a great time just thinking about what their deaf cameras should actually be doing in terms of the compute that's being done at the camera level, and like internal design of the new, next generation, real sense and yeah. So the hospital robot has another sensor for heart rate estimation, which, of course, the realtor robot has no need for. Yeah. So it's add, subtract, another sense, or maybe change the prompts, figure out where the data needs to flow,
Well, we're really focusing on verticals right now that they're all extremely similar. At the core, for example, the difference between a hospital triage robot and a realtor robot is prompts for the different llms, and it's where did the data need to go. So for example, in the hospital use case, you have to work with like Cerner to push data into hospital back ends, whereas for realtors, they use a different system for their mapping and staging, where they need to figure out which furniture goes with which floor plan. So there's differences at the level of who is accessing the data, which computer systems do the data need to be pushed into, and what are the prompts that are facing the human there's one other difference, for example, for the hospital triage, there's an additional sensor which uses the modulation of your face coloration to do remote heart Rate assessment and but that's like a snap on thing just after the head. You know, think that conceptually, like you just add to the head this, of course, is a Deaf camera. Real sense was just here, they're a blast. We had a great time just thinking about what their deaf cameras should actually be doing in terms of the compute that's being done at the camera level, and like internal design of the new, next generation, real sense and yeah. So the hospital robot has another sensor for heart rate estimation, which, of course, the realtor robot has no need for. Yeah. So it's add, subtract, another sense, or maybe change the prompts, figure out where the data needs to flow,
Well, we're really focusing on verticals right now that they're all extremely similar. At the core, for example, the difference between a hospital triage robot and a realtor robot is prompts for the different llms, and it's where did the data need to go. So for example, in the hospital use case, you have to work with like Cerner to push data into hospital back ends, whereas for realtors, they use a different system for their mapping and staging, where they need to figure out which furniture goes with which floor plan. So there's differences at the level of who is accessing the data, which computer systems do the data need to be pushed into, and what are the prompts that are facing the human there's one other difference, for example, for the hospital triage, there's an additional sensor which uses the modulation of your face coloration to do remote heart Rate assessment and but that's like a snap on thing just after the head. You know, think that conceptually, like you just add to the head this, of course, is a Deaf camera. Real sense was just here, they're a blast. We had a great time just thinking about what their deaf cameras should actually be doing in terms of the compute that's being done at the camera level, and like internal design of the new, next generation, real sense and yeah. So the hospital robot has another sensor for heart rate estimation, which, of course, the realtor robot has no need for. Yeah. So it's add, subtract, another sense, or maybe change the prompts, figure out where the data needs to flow,
Well, we're really focusing on verticals right now that they're all extremely similar. At the core, for example, the difference between a hospital triage robot and a realtor robot is prompts for the different llms, and it's where did the data need to go. So for example, in the hospital use case, you have to work with like Cerner to push data into hospital back ends, whereas for realtors, they use a different system for their mapping and staging, where they need to figure out which furniture goes with which floor plan. So there's differences at the level of who is accessing the data, which computer systems do the data need to be pushed into, and what are the prompts that are facing the human there's one other difference, for example, for the hospital triage, there's an additional sensor which uses the modulation of your face coloration to do remote heart Rate assessment and but that's like a snap on thing just after the head. You know, think that conceptually, like you just add to the head this, of course, is a Deaf camera. Real sense was just here, they're a blast. We had a great time just thinking about what their deaf cameras should actually be doing in terms of the compute that's being done at the camera level, and like internal design of the new, next generation, real sense and yeah. So the hospital robot has another sensor for heart rate estimation, which, of course, the realtor robot has no need for. Yeah. So it's add, subtract, another sense, or maybe change the prompts, figure out where the data needs to flow,
S Speaker 224:16The best thing to do is, if you ask me, send all material is kind of difficult, yeah, but if you, let's just say, if you give me three specific things you're most interested in, then I can tell someone to dig it
The best thing to do is, if you ask me, send all material is kind of difficult, yeah, but if you, let's just say, if you give me three specific things you're most interested in, then I can tell someone to dig it
The best thing to do is, if you ask me, send all material is kind of difficult, yeah, but if you, let's just say, if you give me three specific things you're most interested in, then I can tell someone to dig it
The best thing to do is, if you ask me, send all material is kind of difficult, yeah, but if you, let's just say, if you give me three specific things you're most interested in, then I can tell someone to dig it
S Speaker 324:29up. Sounds good. Sounds good. We can do that. Automotive.
up. Sounds good. Sounds good. We can do that. Automotive.
up. Sounds good. Sounds good. We can do that. Automotive.
up. Sounds good. Sounds good. We can do that. Automotive.
24:33So Automotive is,
S Speaker 224:36there's a few things going on. The first thing is, strategically, who is capable of making a million humans? And my personal answer is car companies. So Tesla Optimus, no brainer. They know I make millions of something, Hyundai, UID, okay, yeah, tell me. Okay, yeah. And then there's cell phone companies that know how to make millions of things with sensors and batteries and screening and connectivity and chips and Bluetooth and security and everything. So an iPhone is really just a humanoid without arms lines, right? So if I had to bet on who's going to make the first million humanoids, it's going to either be a car company or, like, LG, Samsung or Apple, pretty much. Yeah, yeah. And so that means it's interesting for us to go talk to park companies, not because necessarily they want humanoid to do BMW five, ECU Loctite type problems, but because they may be an amazing partner to work with to build an amazing humanoid. I mean,
there's a few things going on. The first thing is, strategically, who is capable of making a million humans? And my personal answer is car companies. So Tesla Optimus, no brainer. They know I make millions of something, Hyundai, UID, okay, yeah, tell me. Okay, yeah. And then there's cell phone companies that know how to make millions of things with sensors and batteries and screening and connectivity and chips and Bluetooth and security and everything. So an iPhone is really just a humanoid without arms lines, right? So if I had to bet on who's going to make the first million humanoids, it's going to either be a car company or, like, LG, Samsung or Apple, pretty much. Yeah, yeah. And so that means it's interesting for us to go talk to park companies, not because necessarily they want humanoid to do BMW five, ECU Loctite type problems, but because they may be an amazing partner to work with to build an amazing humanoid. I mean,
there's a few things going on. The first thing is, strategically, who is capable of making a million humans? And my personal answer is car companies. So Tesla Optimus, no brainer. They know I make millions of something, Hyundai, UID, okay, yeah, tell me. Okay, yeah. And then there's cell phone companies that know how to make millions of things with sensors and batteries and screening and connectivity and chips and Bluetooth and security and everything. So an iPhone is really just a humanoid without arms lines, right? So if I had to bet on who's going to make the first million humanoids, it's going to either be a car company or, like, LG, Samsung or Apple, pretty much. Yeah, yeah. And so that means it's interesting for us to go talk to park companies, not because necessarily they want humanoid to do BMW five, ECU Loctite type problems, but because they may be an amazing partner to work with to build an amazing humanoid. I mean,
there's a few things going on. The first thing is, strategically, who is capable of making a million humans? And my personal answer is car companies. So Tesla Optimus, no brainer. They know I make millions of something, Hyundai, UID, okay, yeah, tell me. Okay, yeah. And then there's cell phone companies that know how to make millions of things with sensors and batteries and screening and connectivity and chips and Bluetooth and security and everything. So an iPhone is really just a humanoid without arms lines, right? So if I had to bet on who's going to make the first million humanoids, it's going to either be a car company or, like, LG, Samsung or Apple, pretty much. Yeah, yeah. And so that means it's interesting for us to go talk to park companies, not because necessarily they want humanoid to do BMW five, ECU Loctite type problems, but because they may be an amazing partner to work with to build an amazing humanoid. I mean,
25:59there's one exception, which is Nvidia botched call.
there's one exception, which is Nvidia botched call.
there's one exception, which is Nvidia botched call.
there's one exception, which is Nvidia botched call.
S Speaker 326:01No, I get that. And they're, they're, you know, the first potential ones to make large scale human rights right. But you mentioned there's an interest from an automotive group for this round. So I was trying to connect, connect the dots. So if you can give some color on what the fundraising is about, who's coming in and you know what? What do you have in mind?
No, I get that. And they're, they're, you know, the first potential ones to make large scale human rights right. But you mentioned there's an interest from an automotive group for this round. So I was trying to connect, connect the dots. So if you can give some color on what the fundraising is about, who's coming in and you know what? What do you have in mind?
No, I get that. And they're, they're, you know, the first potential ones to make large scale human rights right. But you mentioned there's an interest from an automotive group for this round. So I was trying to connect, connect the dots. So if you can give some color on what the fundraising is about, who's coming in and you know what? What do you have in mind?
No, I get that. And they're, they're, you know, the first potential ones to make large scale human rights right. But you mentioned there's an interest from an automotive group for this round. So I was trying to connect, connect the dots. So if you can give some color on what the fundraising is about, who's coming in and you know what? What do you have in mind?
S Speaker 226:24Yeah, sure. So we'll end up raising about 50. Then we have a bunch of stuff today and Monday until Monday night, and then immediately after the dinner with Nvidia ventures, which is Monday night. I then fly to Korea to meet with the Koreans. And that is, I mean, in my estimation, like Korea is pretty much aside from, like China, Taiwan, maybe Japan, maybe the US with Brave limitations, because we really don't have big manufacturing shops here. I think South Korea is one of the few places that still have the manufacturing capability Samsung LG and Hyundai that are interesting to think about from that in terms of the car companies that want to use human there's two main use cases, as you all know, and one use case is assembly tasks that require incredible dexterity, like like cable harnesses and upside down screws behind something else. And then the sort of niche, rare card models that are, like, low volume, that where the volumes just aren't there, they're fully automated, because if the volumes are there, you just gonna fully automate the whole thing. Then you go get a robot. It's already automated, and has been for like, 20 years, right? And so this particular company is, I really can't speak for them, why they're that interested, but,
Yeah, sure. So we'll end up raising about 50. Then we have a bunch of stuff today and Monday until Monday night, and then immediately after the dinner with Nvidia ventures, which is Monday night. I then fly to Korea to meet with the Koreans. And that is, I mean, in my estimation, like Korea is pretty much aside from, like China, Taiwan, maybe Japan, maybe the US with Brave limitations, because we really don't have big manufacturing shops here. I think South Korea is one of the few places that still have the manufacturing capability Samsung LG and Hyundai that are interesting to think about from that in terms of the car companies that want to use human there's two main use cases, as you all know, and one use case is assembly tasks that require incredible dexterity, like like cable harnesses and upside down screws behind something else. And then the sort of niche, rare card models that are, like, low volume, that where the volumes just aren't there, they're fully automated, because if the volumes are there, you just gonna fully automate the whole thing. Then you go get a robot. It's already automated, and has been for like, 20 years, right? And so this particular company is, I really can't speak for them, why they're that interested, but,
Yeah, sure. So we'll end up raising about 50. Then we have a bunch of stuff today and Monday until Monday night, and then immediately after the dinner with Nvidia ventures, which is Monday night. I then fly to Korea to meet with the Koreans. And that is, I mean, in my estimation, like Korea is pretty much aside from, like China, Taiwan, maybe Japan, maybe the US with Brave limitations, because we really don't have big manufacturing shops here. I think South Korea is one of the few places that still have the manufacturing capability Samsung LG and Hyundai that are interesting to think about from that in terms of the car companies that want to use human there's two main use cases, as you all know, and one use case is assembly tasks that require incredible dexterity, like like cable harnesses and upside down screws behind something else. And then the sort of niche, rare card models that are, like, low volume, that where the volumes just aren't there, they're fully automated, because if the volumes are there, you just gonna fully automate the whole thing. Then you go get a robot. It's already automated, and has been for like, 20 years, right? And so this particular company is, I really can't speak for them, why they're that interested, but,
Yeah, sure. So we'll end up raising about 50. Then we have a bunch of stuff today and Monday until Monday night, and then immediately after the dinner with Nvidia ventures, which is Monday night. I then fly to Korea to meet with the Koreans. And that is, I mean, in my estimation, like Korea is pretty much aside from, like China, Taiwan, maybe Japan, maybe the US with Brave limitations, because we really don't have big manufacturing shops here. I think South Korea is one of the few places that still have the manufacturing capability Samsung LG and Hyundai that are interesting to think about from that in terms of the car companies that want to use human there's two main use cases, as you all know, and one use case is assembly tasks that require incredible dexterity, like like cable harnesses and upside down screws behind something else. And then the sort of niche, rare card models that are, like, low volume, that where the volumes just aren't there, they're fully automated, because if the volumes are there, you just gonna fully automate the whole thing. Then you go get a robot. It's already automated, and has been for like, 20 years, right? And so this particular company is, I really can't speak for them, why they're that interested, but,
28:15yeah, I think they're thinking of robotics just as a really,
yeah, I think they're thinking of robotics just as a really,
yeah, I think they're thinking of robotics just as a really,
yeah, I think they're thinking of robotics just as a really,
28:20this is the Korea this is the Korea partner.
this is the Korea this is the Korea partner.
this is the Korea this is the Korea partner.
this is the Korea this is the Korea partner.
S Speaker 328:24That's Korea automotive, right? One of the partners there, Nvidia, is interested. Who else would be around the table?
That's Korea automotive, right? One of the partners there, Nvidia, is interested. Who else would be around the table?
That's Korea automotive, right? One of the partners there, Nvidia, is interested. Who else would be around the table?
That's Korea automotive, right? One of the partners there, Nvidia, is interested. Who else would be around the table?
S Speaker 228:32Well, I think anyone making memory right now? Okay, imagines that memory is going to be useful
Well, I think anyone making memory right now? Okay, imagines that memory is going to be useful
Well, I think anyone making memory right now? Okay, imagines that memory is going to be useful
Well, I think anyone making memory right now? Okay, imagines that memory is going to be useful
S Speaker 328:39for, of course, by including, no, of course, yeah, no. I'm just trying to understand the strategic interest that you have already so of the 50, because if we were to come in, we would be like, at a minimum, $5 million check, right,
for, of course, by including, no, of course, yeah, no. I'm just trying to understand the strategic interest that you have already so of the 50, because if we were to come in, we would be like, at a minimum, $5 million check, right,
for, of course, by including, no, of course, yeah, no. I'm just trying to understand the strategic interest that you have already so of the 50, because if we were to come in, we would be like, at a minimum, $5 million check, right,
for, of course, by including, no, of course, yeah, no. I'm just trying to understand the strategic interest that you have already so of the 50, because if we were to come in, we would be like, at a minimum, $5 million check, right,
S Speaker 228:54precisely. So that's in line with with the numbers that are shaking out. It's like the guidance we've been getting about is like five to 15, sort of range, ish, and then if we have 123, and then maybe one or two smaller ones, just for like, strategic purpose. Here's a funny story. You know, we own open mind.org, yep, the URL. Guess who owns open mind.com?
precisely. So that's in line with with the numbers that are shaking out. It's like the guidance we've been getting about is like five to 15, sort of range, ish, and then if we have 123, and then maybe one or two smaller ones, just for like, strategic purpose. Here's a funny story. You know, we own open mind.org, yep, the URL. Guess who owns open mind.com?
precisely. So that's in line with with the numbers that are shaking out. It's like the guidance we've been getting about is like five to 15, sort of range, ish, and then if we have 123, and then maybe one or two smaller ones, just for like, strategic purpose. Here's a funny story. You know, we own open mind.org, yep, the URL. Guess who owns open mind.com?
precisely. So that's in line with with the numbers that are shaking out. It's like the guidance we've been getting about is like five to 15, sort of range, ish, and then if we have 123, and then maybe one or two smaller ones, just for like, strategic purpose. Here's a funny story. You know, we own open mind.org, yep, the URL. Guess who owns open mind.com?
S Speaker 229:30no, it's owned by Sean, the founder of Tinder. No, he got the URL for a concept that he never quite built out. Okay, I don't think it was in robotics. I think it was in something else, but that's okay. So he was like, guys, you know, I need to be in and I'll also chip in open mind.com so like, okay, Sean, he's very good at the market, by the way,
no, it's owned by Sean, the founder of Tinder. No, he got the URL for a concept that he never quite built out. Okay, I don't think it was in robotics. I think it was in something else, but that's okay. So he was like, guys, you know, I need to be in and I'll also chip in open mind.com so like, okay, Sean, he's very good at the market, by the way,
no, it's owned by Sean, the founder of Tinder. No, he got the URL for a concept that he never quite built out. Okay, I don't think it was in robotics. I think it was in something else, but that's okay. So he was like, guys, you know, I need to be in and I'll also chip in open mind.com so like, okay, Sean, he's very good at the market, by the way,
no, it's owned by Sean, the founder of Tinder. No, he got the URL for a concept that he never quite built out. Okay, I don't think it was in robotics. I think it was in something else, but that's okay. So he was like, guys, you know, I need to be in and I'll also chip in open mind.com so like, okay, Sean, he's very good at the market, by the way,
S Speaker 330:05yeah, also very eclectic, eclectic group of investors there, yeah, but
yeah, also very eclectic, eclectic group of investors there, yeah, but
yeah, also very eclectic, eclectic group of investors there, yeah, but
yeah, also very eclectic, eclectic group of investors there, yeah, but
S Speaker 230:10I think, like each one of them, I think we have a we can articulate pretty good reason.
I think, like each one of them, I think we have a we can articulate pretty good reason.
I think, like each one of them, I think we have a we can articulate pretty good reason.
I think, like each one of them, I think we have a we can articulate pretty good reason.
S Speaker 330:15Of course, it goes without saying. So now maybe if you have couple more minutes, right? So when do you start productionizing it? I know you mentioned you're early and maybe 10 people week is where you're at right now, but I get that, you know, your growth is, you know, kind of dependent thoughts, right? It's not just people using it. So I know you're looking for opportunities where it'll be faster. You're not going down the wrong humanoid route, where you need dexterity and you need all these things, right? So at least. So do you have some projections in mind? So I think a few things that we need is, if you can give some more details on the product architecture,
Of course, it goes without saying. So now maybe if you have couple more minutes, right? So when do you start productionizing it? I know you mentioned you're early and maybe 10 people week is where you're at right now, but I get that, you know, your growth is, you know, kind of dependent thoughts, right? It's not just people using it. So I know you're looking for opportunities where it'll be faster. You're not going down the wrong humanoid route, where you need dexterity and you need all these things, right? So at least. So do you have some projections in mind? So I think a few things that we need is, if you can give some more details on the product architecture,
Of course, it goes without saying. So now maybe if you have couple more minutes, right? So when do you start productionizing it? I know you mentioned you're early and maybe 10 people week is where you're at right now, but I get that, you know, your growth is, you know, kind of dependent thoughts, right? It's not just people using it. So I know you're looking for opportunities where it'll be faster. You're not going down the wrong humanoid route, where you need dexterity and you need all these things, right? So at least. So do you have some projections in mind? So I think a few things that we need is, if you can give some more details on the product architecture,
Of course, it goes without saying. So now maybe if you have couple more minutes, right? So when do you start productionizing it? I know you mentioned you're early and maybe 10 people week is where you're at right now, but I get that, you know, your growth is, you know, kind of dependent thoughts, right? It's not just people using it. So I know you're looking for opportunities where it'll be faster. You're not going down the wrong humanoid route, where you need dexterity and you need all these things, right? So at least. So do you have some projections in mind? So I think a few things that we need is, if you can give some more details on the product architecture,
S Speaker 230:55Sure, let me write this down. So just in the interest of efficiency, let me take
Sure, let me write this down. So just in the interest of efficiency, let me take
Sure, let me write this down. So just in the interest of efficiency, let me take
Sure, let me write this down. So just in the interest of efficiency, let me take
31:01some notes. Yes,
S Speaker 231:43Yeah, yeah, well, yeah. So for each one of these questions, they're typically not binary, yes, no questions. So for example, pipeline wise, of course, what we have right now are basically like all the early adopters, and that's great, but that's not necessarily, like you can't build like a business on, yeah, but yeah, billionaires who, every single one of them want to even own another house. I get
Yeah, yeah, well, yeah. So for each one of these questions, they're typically not binary, yes, no questions. So for example, pipeline wise, of course, what we have right now are basically like all the early adopters, and that's great, but that's not necessarily, like you can't build like a business on, yeah, but yeah, billionaires who, every single one of them want to even own another house. I get
Yeah, yeah, well, yeah. So for each one of these questions, they're typically not binary, yes, no questions. So for example, pipeline wise, of course, what we have right now are basically like all the early adopters, and that's great, but that's not necessarily, like you can't build like a business on, yeah, but yeah, billionaires who, every single one of them want to even own another house. I get
Yeah, yeah, well, yeah. So for each one of these questions, they're typically not binary, yes, no questions. So for example, pipeline wise, of course, what we have right now are basically like all the early adopters, and that's great, but that's not necessarily, like you can't build like a business on, yeah, but yeah, billionaires who, every single one of them want to even own another house. I get
S Speaker 332:12that. So what I'm trying to say is maybe, if you have, you know, more representative set of customers that you think, Hey, this is something that you know, is my long term ideal customer profile. I have a two of those in my pipeline. That's good enough, because the state of PR, I completely get it. And I know the last round was, you already raised quite a bit, Jan, and I remember the last conversation you said, you said you don't need capital. What was the valuation then? And is this not
that. So what I'm trying to say is maybe, if you have, you know, more representative set of customers that you think, Hey, this is something that you know, is my long term ideal customer profile. I have a two of those in my pipeline. That's good enough, because the state of PR, I completely get it. And I know the last round was, you already raised quite a bit, Jan, and I remember the last conversation you said, you said you don't need capital. What was the valuation then? And is this not
that. So what I'm trying to say is maybe, if you have, you know, more representative set of customers that you think, Hey, this is something that you know, is my long term ideal customer profile. I have a two of those in my pipeline. That's good enough, because the state of PR, I completely get it. And I know the last round was, you already raised quite a bit, Jan, and I remember the last conversation you said, you said you don't need capital. What was the valuation then? And is this not
that. So what I'm trying to say is maybe, if you have, you know, more representative set of customers that you think, Hey, this is something that you know, is my long term ideal customer profile. I have a two of those in my pipeline. That's good enough, because the state of PR, I completely get it. And I know the last round was, you already raised quite a bit, Jan, and I remember the last conversation you said, you said you don't need capital. What was the valuation then? And is this not
32:37capture on capital?
32:38This is pressed round. Oh,
This is pressed round. Oh,
This is pressed round. Oh,
This is pressed round. Oh,
32:40this is a price round again. Okay, press round.
this is a price round again. Okay, press round.
this is a price round again. Okay, press round.
this is a price round again. Okay, press round.
S Speaker 232:43It's we're grown up now. We've grown like states and that stuff. Okay, so this is really straightforward, like press round and valuation. The exact valuation was 87 decimal five, okay, that
It's we're grown up now. We've grown like states and that stuff. Okay, so this is really straightforward, like press round and valuation. The exact valuation was 87 decimal five, okay, that
It's we're grown up now. We've grown like states and that stuff. Okay, so this is really straightforward, like press round and valuation. The exact valuation was 87 decimal five, okay, that
It's we're grown up now. We've grown like states and that stuff. Okay, so this is really straightforward, like press round and valuation. The exact valuation was 87 decimal five, okay, that
S Speaker 333:05was the last round, yeah, and this round, where do you expect it to land?
was the last round, yeah, and this round, where do you expect it to land?
was the last round, yeah, and this round, where do you expect it to land?
was the last round, yeah, and this round, where do you expect it to land?
33:10Roughly? Oh, um,
33:20of what? So I don't have an exact
of what? So I don't have an exact
of what? So I don't have an exact
of what? So I don't have an exact
S Speaker 333:26number for you, yes, and that's that's understandable. I was just trying to gage a particular range, right? But I, but I get that fair enough. And anything around the open source adoption metrics. Do you have, like, I know GitHub, we can just go and look at the stars and, you know the frequency, but anything you're tracking there in the open source metrics,
number for you, yes, and that's that's understandable. I was just trying to gage a particular range, right? But I, but I get that fair enough. And anything around the open source adoption metrics. Do you have, like, I know GitHub, we can just go and look at the stars and, you know the frequency, but anything you're tracking there in the open source metrics,
number for you, yes, and that's that's understandable. I was just trying to gage a particular range, right? But I, but I get that fair enough. And anything around the open source adoption metrics. Do you have, like, I know GitHub, we can just go and look at the stars and, you know the frequency, but anything you're tracking there in the open source metrics,
number for you, yes, and that's that's understandable. I was just trying to gage a particular range, right? But I, but I get that fair enough. And anything around the open source adoption metrics. Do you have, like, I know GitHub, we can just go and look at the stars and, you know the frequency, but anything you're tracking there in the open source metrics,
S Speaker 233:49yeah? Well, I mean, GitHub does a pretty good job of tracking that, I think, like, stars have tracked forks, yeah. And then the fact that we're currently overwhelmed by trying to deal with PRs and feature requests. It's like, good and bad. It's like, great that a lot of people are looking at this, but and Well, look, why don't we do this so we have product and features, yes, and then we have actual projections. Financials is the then, like, what's what's business model, yep. And that's, of course, very closely connected with the projections anyway, yeah, because you can't really separate those things. But why don't I, like everyone has been asking for the same thing, so we need to put all this together anyway. So doing this anyway, so super easy, yep, and why don't I focus on getting that to you, and then tomorrow is selling the home in Hillsborough with Iris. It's Bing Crosby's house. If you've heard of Bing Crosby before, it's okay. Yeah, house, yeah. So that's tomorrow, but tomorrow night, I can also spend some time on this as well as Sunday, and then Monday is totally crazy, but everyone wants to see material at least, then you'll have all of that. And then I'm sure there'll be follow ups anywhere
yeah? Well, I mean, GitHub does a pretty good job of tracking that, I think, like, stars have tracked forks, yeah. And then the fact that we're currently overwhelmed by trying to deal with PRs and feature requests. It's like, good and bad. It's like, great that a lot of people are looking at this, but and Well, look, why don't we do this so we have product and features, yes, and then we have actual projections. Financials is the then, like, what's what's business model, yep. And that's, of course, very closely connected with the projections anyway, yeah, because you can't really separate those things. But why don't I, like everyone has been asking for the same thing, so we need to put all this together anyway. So doing this anyway, so super easy, yep, and why don't I focus on getting that to you, and then tomorrow is selling the home in Hillsborough with Iris. It's Bing Crosby's house. If you've heard of Bing Crosby before, it's okay. Yeah, house, yeah. So that's tomorrow, but tomorrow night, I can also spend some time on this as well as Sunday, and then Monday is totally crazy, but everyone wants to see material at least, then you'll have all of that. And then I'm sure there'll be follow ups anywhere
yeah? Well, I mean, GitHub does a pretty good job of tracking that, I think, like, stars have tracked forks, yeah. And then the fact that we're currently overwhelmed by trying to deal with PRs and feature requests. It's like, good and bad. It's like, great that a lot of people are looking at this, but and Well, look, why don't we do this so we have product and features, yes, and then we have actual projections. Financials is the then, like, what's what's business model, yep. And that's, of course, very closely connected with the projections anyway, yeah, because you can't really separate those things. But why don't I, like everyone has been asking for the same thing, so we need to put all this together anyway. So doing this anyway, so super easy, yep, and why don't I focus on getting that to you, and then tomorrow is selling the home in Hillsborough with Iris. It's Bing Crosby's house. If you've heard of Bing Crosby before, it's okay. Yeah, house, yeah. So that's tomorrow, but tomorrow night, I can also spend some time on this as well as Sunday, and then Monday is totally crazy, but everyone wants to see material at least, then you'll have all of that. And then I'm sure there'll be follow ups anywhere
yeah? Well, I mean, GitHub does a pretty good job of tracking that, I think, like, stars have tracked forks, yeah. And then the fact that we're currently overwhelmed by trying to deal with PRs and feature requests. It's like, good and bad. It's like, great that a lot of people are looking at this, but and Well, look, why don't we do this so we have product and features, yes, and then we have actual projections. Financials is the then, like, what's what's business model, yep. And that's, of course, very closely connected with the projections anyway, yeah, because you can't really separate those things. But why don't I, like everyone has been asking for the same thing, so we need to put all this together anyway. So doing this anyway, so super easy, yep, and why don't I focus on getting that to you, and then tomorrow is selling the home in Hillsborough with Iris. It's Bing Crosby's house. If you've heard of Bing Crosby before, it's okay. Yeah, house, yeah. So that's tomorrow, but tomorrow night, I can also spend some time on this as well as Sunday, and then Monday is totally crazy, but everyone wants to see material at least, then you'll have all of that. And then I'm sure there'll be follow ups anywhere
S Speaker 335:23that we can follow from there. So let's take touch on this one. I'll keep you posted on, I'll think of mid next week and let you know how we think about it.
that we can follow from there. So let's take touch on this one. I'll keep you posted on, I'll think of mid next week and let you know how we think about it.
that we can follow from there. So let's take touch on this one. I'll keep you posted on, I'll think of mid next week and let you know how we think about it.
that we can follow from there. So let's take touch on this one. I'll keep you posted on, I'll think of mid next week and let you know how we think about it.
S Speaker 235:32Yeah, that sounds awesome. And thank you. All of this is on the way to you, one way or the other.
Yeah, that sounds awesome. And thank you. All of this is on the way to you, one way or the other.
Yeah, that sounds awesome. And thank you. All of this is on the way to you, one way or the other.
Yeah, that sounds awesome. And thank you. All of this is on the way to you, one way or the other.
S Speaker 335:37Thank you. Yeah, cool. Thanks.
Thank you. Yeah, cool. Thanks.
Thank you. Yeah, cool. Thanks.
Thank you. Yeah, cool. Thanks.