Meeting: Note
Wed, Dec 4, 2024
2:04 PM
38 min
Priyesh P
Introduction and Backgrounds
0:00
Overview of Mobile'
URL: https://otter.ai/u/aQhhKffIA4uWW-I-9Z_f40aPOWk
Downloaded: 2025-12-22T13:35:01.863122
Method: text_extraction
============================================================

Speaker 1
Variances working in product management and QA and really seeing there being a pain point for this, especially because I transitioned from a role where I was pming a very vanilla SaaS app at Palantir, and then I moved into a role where I had to deal with Bluetooth peripherals and portable ultrasounds that plugged into tablets and connected to hospital networks and real hardware and real peripherals, and all of a sudden, I kind of saw that tools that were previously designed for like the perfect CICD software only world didn't really transition well. In a world where I think hardware is fragmenting, there's more physical, real world dependencies, and that's why I started mobile. I will also hand it off to Sam to introduce himself.
Variances working in product management and QA and really seeing there being a pain point for this, especially because I transitioned from a role where I was pming a very vanilla SaaS app at Palantir, and then I moved into a role where I had to deal with Bluetooth peripherals and portable ultrasounds that plugged into tablets and connected to hospital networks and real hardware and real peripherals, and all of a sudden, I kind of saw that tools that were previously designed for like the perfect CICD software only world didn't really transition well. In a world where I think hardware is fragmenting, there's more physical, real world dependencies, and that's why I started mobile. I will also hand it off to Sam to introduce himself.
Variances working in product management and QA and really seeing there being a pain point for this, especially because I transitioned from a role where I was pming a very vanilla SaaS app at Palantir, and then I moved into a role where I had to deal with Bluetooth peripherals and portable ultrasounds that plugged into tablets and connected to hospital networks and real hardware and real peripherals, and all of a sudden, I kind of saw that tools that were previously designed for like the perfect CICD software only world didn't really transition well. In a world where I think hardware is fragmenting, there's more physical, real world dependencies, and that's why I started mobile. I will also hand it off to Sam to introduce himself.
Variances working in product management and QA and really seeing there being a pain point for this, especially because I transitioned from a role where I was pming a very vanilla SaaS app at Palantir, and then I moved into a role where I had to deal with Bluetooth peripherals and portable ultrasounds that plugged into tablets and connected to hospital networks and real hardware and real peripherals, and all of a sudden, I kind of saw that tools that were previously designed for like the perfect CICD software only world didn't really transition well. In a world where I think hardware is fragmenting, there's more physical, real world dependencies, and that's why I started mobile. I will also hand it off to Sam to introduce himself.
Speaker 2
Nice to meet you. My name is Sam. I'm a sales team here, leading the sales team. Been a part of mobile for just over two years. I joined as the first account executive back in 2022 before mobile, I was also in the mobile testing space on the security side. So I'm testing space for over six years, and I'm based in New York.
Nice to meet you. My name is Sam. I'm a sales team here, leading the sales team. Been a part of mobile for just over two years. I joined as the first account executive back in 2022 before mobile, I was also in the mobile testing space on the security side. So I'm testing space for over six years, and I'm based in New York.
Nice to meet you. My name is Sam. I'm a sales team here, leading the sales team. Been a part of mobile for just over two years. I joined as the first account executive back in 2022 before mobile, I was also in the mobile testing space on the security side. So I'm testing space for over six years, and I'm based in New York.
Nice to meet you. My name is Sam. I'm a sales team here, leading the sales team. Been a part of mobile for just over two years. I joined as the first account executive back in 2022 before mobile, I was also in the mobile testing space on the security side. So I'm testing space for over six years, and I'm based in New York.
Are you both based in New York? Yeah, our
Are you both based in New York? Yeah, our
Are you both based in New York? Yeah, our
Are you both based in New York? Yeah, our
Speaker 1
company is headquartered in New York. Our robot fleet is in New York. I would say more than half of our company works out of our New York office. But we do have some kind of like, hybrid or remote employees as well, but everyone's US based we're about
company is headquartered in New York. Our robot fleet is in New York. I would say more than half of our company works out of our New York office. But we do have some kind of like, hybrid or remote employees as well, but everyone's US based we're about
company is headquartered in New York. Our robot fleet is in New York. I would say more than half of our company works out of our New York office. But we do have some kind of like, hybrid or remote employees as well, but everyone's US based we're about
company is headquartered in New York. Our robot fleet is in New York. I would say more than half of our company works out of our New York office. But we do have some kind of like, hybrid or remote employees as well, but everyone's US based we're about
Speaker 3
35 people. I'm based here in the Bay Area with Priyesh ventures for over seven years, investing in a lot of AI. We invest in it also ventures, invests in areas that are, broadly speaking, strategically relevant. And so, of course, a lot of AI, mobile related stuff, IoT related stuff, automotive, networking, PCs, so a bunch of different things and so. And then we people tend to think that we might invest more in hardware. We actually want to invest more in hardware, we actually invest more in software, and we invest off of the balance sheet. So it's about every year, and we we can leave around so we can participate in 75% of them from participate with other investors, but yeah, our check sizes are typically five to seven. The range is to 10, but five to seven, our initial check size is typically. We invest series agnostic, but series A and B is where our sweet spot is so and so we work with a lot of our portfolios. Priyesh told me about mobile exciting enough. I had a bunch of questions, but so I'll let you tell the story, and then. And then, if you have any questions about us, let me know and give you a 10,000 foot overview.
35 people. I'm based here in the Bay Area with Priyesh ventures for over seven years, investing in a lot of AI. We invest in it also ventures, invests in areas that are, broadly speaking, strategically relevant. And so, of course, a lot of AI, mobile related stuff, IoT related stuff, automotive, networking, PCs, so a bunch of different things and so. And then we people tend to think that we might invest more in hardware. We actually want to invest more in hardware, we actually invest more in software, and we invest off of the balance sheet. So it's about every year, and we we can leave around so we can participate in 75% of them from participate with other investors, but yeah, our check sizes are typically five to seven. The range is to 10, but five to seven, our initial check size is typically. We invest series agnostic, but series A and B is where our sweet spot is so and so we work with a lot of our portfolios. Priyesh told me about mobile exciting enough. I had a bunch of questions, but so I'll let you tell the story, and then. And then, if you have any questions about us, let me know and give you a 10,000 foot overview.
35 people. I'm based here in the Bay Area with Priyesh ventures for over seven years, investing in a lot of AI. We invest in it also ventures, invests in areas that are, broadly speaking, strategically relevant. And so, of course, a lot of AI, mobile related stuff, IoT related stuff, automotive, networking, PCs, so a bunch of different things and so. And then we people tend to think that we might invest more in hardware. We actually want to invest more in hardware, we actually invest more in software, and we invest off of the balance sheet. So it's about every year, and we we can leave around so we can participate in 75% of them from participate with other investors, but yeah, our check sizes are typically five to seven. The range is to 10, but five to seven, our initial check size is typically. We invest series agnostic, but series A and B is where our sweet spot is so and so we work with a lot of our portfolios. Priyesh told me about mobile exciting enough. I had a bunch of questions, but so I'll let you tell the story, and then. And then, if you have any questions about us, let me know and give you a 10,000 foot overview.
35 people. I'm based here in the Bay Area with Priyesh ventures for over seven years, investing in a lot of AI. We invest in it also ventures, invests in areas that are, broadly speaking, strategically relevant. And so, of course, a lot of AI, mobile related stuff, IoT related stuff, automotive, networking, PCs, so a bunch of different things and so. And then we people tend to think that we might invest more in hardware. We actually want to invest more in hardware, we actually invest more in software, and we invest off of the balance sheet. So it's about every year, and we we can leave around so we can participate in 75% of them from participate with other investors, but yeah, our check sizes are typically five to seven. The range is to 10, but five to seven, our initial check size is typically. We invest series agnostic, but series A and B is where our sweet spot is so and so we work with a lot of our portfolios. Priyesh told me about mobile exciting enough. I had a bunch of questions, but so I'll let you tell the story, and then. And then, if you have any questions about us, let me know and give you a 10,000 foot overview.
Speaker 1
Yeah, I think Priyesh already answered a few of my questions about Qualcomm ventures last time. So yeah, happy to kind of give you the overview. And then, you know, definitely curious to get your feedback, and would love to go through some of your questions, and then we can kind of circle back to other questions as well. Yeah, um, I will start with just a little demo, which I know, Priyesh, you've seen and heard a bunch of this already, so apologies, but of course, your perspective is also welcome if you have follow up questions. Yeah, so at a high level, what we do at mobot is we build and operate our own complete of commoditized robots that are powered by AI that allow us to automate tasks that historically have to be done manually on actual physical devices. And so a lot of that the use cases typically revolve around yet pre production QA, but we've also seen applicability of Mo bots, technology for other teams, beyond engineering and QA we've done we do post production monitoring. We work with marketing teams. Basically any time that you need a human to pick up a device and poke and interact with a product, a software product on a hardware device, that's where mobile comes in. And so here you can kind of see under the hood how it all works. We have a fleet of, like, 125 robots. They're crammed into a very small closet in their New York office. And we can basically program the robots to perform different tasks by using different prompts. So you can kind of see, like, there's a prompt on the right that sort of tells you, like, you know what, what to expect, open the app, use credentials, log in, complete certain steps, and then you can kind of see the notes on the left is basically we actually are using computer vision on the screen. We've built our own model to do that, where we're interpreting icons and text, and the robot is able to then figure out, okay, based on the semantic context of these icons, this text steps that came before, the steps that I expect to come after, we can have the robot map out a list of robot instructions so it can be clicking on text, clicking on icons, inputting text, dragging and swiping on the screen, and so on, basically anything that a human would do. And so it's kind of mapping those natural language human instructions into robot taps. And the power of using our system is that we can automate things that are historically just un automatable or very difficult to automate with software simulation and emulator frameworks. And so that allows us to cover a wider variety of use cases that typically, you know, are not addressed by popular tools on the market that are typically used for QA. But like I mentioned before, mobile is also useful for other applications beyond QA as well.
Yeah, I think Priyesh already answered a few of my questions about Qualcomm ventures last time. So yeah, happy to kind of give you the overview. And then, you know, definitely curious to get your feedback, and would love to go through some of your questions, and then we can kind of circle back to other questions as well. Yeah, um, I will start with just a little demo, which I know, Priyesh, you've seen and heard a bunch of this already, so apologies, but of course, your perspective is also welcome if you have follow up questions. Yeah, so at a high level, what we do at mobot is we build and operate our own complete of commoditized robots that are powered by AI that allow us to automate tasks that historically have to be done manually on actual physical devices. And so a lot of that the use cases typically revolve around yet pre production QA, but we've also seen applicability of Mo bots, technology for other teams, beyond engineering and QA we've done we do post production monitoring. We work with marketing teams. Basically any time that you need a human to pick up a device and poke and interact with a product, a software product on a hardware device, that's where mobile comes in. And so here you can kind of see under the hood how it all works. We have a fleet of, like, 125 robots. They're crammed into a very small closet in their New York office. And we can basically program the robots to perform different tasks by using different prompts. So you can kind of see, like, there's a prompt on the right that sort of tells you, like, you know what, what to expect, open the app, use credentials, log in, complete certain steps, and then you can kind of see the notes on the left is basically we actually are using computer vision on the screen. We've built our own model to do that, where we're interpreting icons and text, and the robot is able to then figure out, okay, based on the semantic context of these icons, this text steps that came before, the steps that I expect to come after, we can have the robot map out a list of robot instructions so it can be clicking on text, clicking on icons, inputting text, dragging and swiping on the screen, and so on, basically anything that a human would do. And so it's kind of mapping those natural language human instructions into robot taps. And the power of using our system is that we can automate things that are historically just un automatable or very difficult to automate with software simulation and emulator frameworks. And so that allows us to cover a wider variety of use cases that typically, you know, are not addressed by popular tools on the market that are typically used for QA. But like I mentioned before, mobile is also useful for other applications beyond QA as well.
Yeah, I think Priyesh already answered a few of my questions about Qualcomm ventures last time. So yeah, happy to kind of give you the overview. And then, you know, definitely curious to get your feedback, and would love to go through some of your questions, and then we can kind of circle back to other questions as well. Yeah, um, I will start with just a little demo, which I know, Priyesh, you've seen and heard a bunch of this already, so apologies, but of course, your perspective is also welcome if you have follow up questions. Yeah, so at a high level, what we do at mobot is we build and operate our own complete of commoditized robots that are powered by AI that allow us to automate tasks that historically have to be done manually on actual physical devices. And so a lot of that the use cases typically revolve around yet pre production QA, but we've also seen applicability of Mo bots, technology for other teams, beyond engineering and QA we've done we do post production monitoring. We work with marketing teams. Basically any time that you need a human to pick up a device and poke and interact with a product, a software product on a hardware device, that's where mobile comes in. And so here you can kind of see under the hood how it all works. We have a fleet of, like, 125 robots. They're crammed into a very small closet in their New York office. And we can basically program the robots to perform different tasks by using different prompts. So you can kind of see, like, there's a prompt on the right that sort of tells you, like, you know what, what to expect, open the app, use credentials, log in, complete certain steps, and then you can kind of see the notes on the left is basically we actually are using computer vision on the screen. We've built our own model to do that, where we're interpreting icons and text, and the robot is able to then figure out, okay, based on the semantic context of these icons, this text steps that came before, the steps that I expect to come after, we can have the robot map out a list of robot instructions so it can be clicking on text, clicking on icons, inputting text, dragging and swiping on the screen, and so on, basically anything that a human would do. And so it's kind of mapping those natural language human instructions into robot taps. And the power of using our system is that we can automate things that are historically just un automatable or very difficult to automate with software simulation and emulator frameworks. And so that allows us to cover a wider variety of use cases that typically, you know, are not addressed by popular tools on the market that are typically used for QA. But like I mentioned before, mobile is also useful for other applications beyond QA as well.
Yeah, I think Priyesh already answered a few of my questions about Qualcomm ventures last time. So yeah, happy to kind of give you the overview. And then, you know, definitely curious to get your feedback, and would love to go through some of your questions, and then we can kind of circle back to other questions as well. Yeah, um, I will start with just a little demo, which I know, Priyesh, you've seen and heard a bunch of this already, so apologies, but of course, your perspective is also welcome if you have follow up questions. Yeah, so at a high level, what we do at mobot is we build and operate our own complete of commoditized robots that are powered by AI that allow us to automate tasks that historically have to be done manually on actual physical devices. And so a lot of that the use cases typically revolve around yet pre production QA, but we've also seen applicability of Mo bots, technology for other teams, beyond engineering and QA we've done we do post production monitoring. We work with marketing teams. Basically any time that you need a human to pick up a device and poke and interact with a product, a software product on a hardware device, that's where mobile comes in. And so here you can kind of see under the hood how it all works. We have a fleet of, like, 125 robots. They're crammed into a very small closet in their New York office. And we can basically program the robots to perform different tasks by using different prompts. So you can kind of see, like, there's a prompt on the right that sort of tells you, like, you know what, what to expect, open the app, use credentials, log in, complete certain steps, and then you can kind of see the notes on the left is basically we actually are using computer vision on the screen. We've built our own model to do that, where we're interpreting icons and text, and the robot is able to then figure out, okay, based on the semantic context of these icons, this text steps that came before, the steps that I expect to come after, we can have the robot map out a list of robot instructions so it can be clicking on text, clicking on icons, inputting text, dragging and swiping on the screen, and so on, basically anything that a human would do. And so it's kind of mapping those natural language human instructions into robot taps. And the power of using our system is that we can automate things that are historically just un automatable or very difficult to automate with software simulation and emulator frameworks. And so that allows us to cover a wider variety of use cases that typically, you know, are not addressed by popular tools on the market that are typically used for QA. But like I mentioned before, mobile is also useful for other applications beyond QA as well.
Speaker 3
And other applications beyond QA would be,
And other applications beyond QA would be,
And other applications beyond QA would be,
And other applications beyond QA would be,
Speaker 1
yeah. So we see, we see QA and mobile as kind of the springboard to some of these other, other industries. So I think there's a few ways to think about it right now. We do iOS, Android iPad, Android tablet, any flat touch screen, Linux based flat touch screens, you know, so on that has allowed us to extend very naturally into smart watches. So watch OS, which also talks to iOS, Android Auto, Apple CarPlay, which then extends into, you know, we'd like to get to connected peripherals via Bluetooth, gaming smart TVs, yeah, doesn't have to be touch screens. It's just basically like my long term science fiction. Venue for this company is, you know, you have BPOS that have humans that do all sorts of things. Why can't we have a robot fleet in the cloud that you don't have to buy your own robot to put them in your own house, but like the way that you rent, you know, time on servers for a data warehouse, you can rent a remote robot somewhere that will do all the humanoid, human like tasks. But we've seen that we can build a solid, healthy 4 million ARR business with 70% gross margins just doing single taps on cheap, $1,000 robots. And so that's what we've started with. But I think there's a larger $25 million serviceable addressable market doing the tapping labor. And then there's the larger $75 million market around all of those other adjacent industries. But I would say our focus right now is kind of just on these single tap you know, either QA or post production monitoring. And so what we actually have can do is, you know, you ask, what are other use cases beyond QA? There's, we do the pre production stuff, but there's also, for example, LinkedIn is one of our customers. I'm going to jump around a bit for a pretty slide, but we can always go back. LinkedIn actually allows you uses mobile to monitor the health of their application post production. So instead of, normally, when you use Datadog or amplitude, you have to kind of wait for things to fail and customers to run into issues, and then you're like, Oh, why is this? So this happens a lot. For example, with App activations. You've probably personally experienced this at LinkedIn, where you're in an email or you pick up something and it's like, Hey, if you download the app, it's better. But you're like, I already have the app, so let me just click on it. But for some reason, it doesn't take you there. It takes you to the App Store. This is a bug. Yes, this happens all the changing. Facebook keeps changing, world keeps changing. So even though Reddit has deep linked it correctly, they have to keep track of everything else in a production environment. And so marketing teams, product teams, growth teams, also use mobile. But the interesting thing is, it's still just tapping on a screen. It's just we're tapping on post production instead of a pre production QA environment. And it's usually we've noticed that with some of the teams that we've interacted with, interacted with, it's outside of the purview of QA, because it's what actually I'm going to switch to a slightly different slide deck to talk through this. It's what we would consider sort of like an intra an inter app workflow. And so I think a lot of existing the problem with existing solutions you probably heard of, like Browser Stack, lambda, test, tricensus, COVID, on all of those, they focus very much on assuming you're automating things inside your own app. And that used to be the case, like three, 510, years ago. But what we're now seeing is there's a trend where, and I think this lines back up with a bigger trend of why I want to break into fitness and gaming and automotive, is your app doesn't just go by itself. It has to talk to other people's APIs, SDKs, dependencies, and so in a real world scenario, our thesis is it's actually easier to get a human, or, sorry, a robot, to poke the phone like a human would do something, right, some sort of simulated, flaky test that typically works for like an intra app scenario, but not so well for the inter app use case.
yeah. So we see, we see QA and mobile as kind of the springboard to some of these other, other industries. So I think there's a few ways to think about it right now. We do iOS, Android iPad, Android tablet, any flat touch screen, Linux based flat touch screens, you know, so on that has allowed us to extend very naturally into smart watches. So watch OS, which also talks to iOS, Android Auto, Apple CarPlay, which then extends into, you know, we'd like to get to connected peripherals via Bluetooth, gaming smart TVs, yeah, doesn't have to be touch screens. It's just basically like my long term science fiction. Venue for this company is, you know, you have BPOS that have humans that do all sorts of things. Why can't we have a robot fleet in the cloud that you don't have to buy your own robot to put them in your own house, but like the way that you rent, you know, time on servers for a data warehouse, you can rent a remote robot somewhere that will do all the humanoid, human like tasks. But we've seen that we can build a solid, healthy 4 million ARR business with 70% gross margins just doing single taps on cheap, $1,000 robots. And so that's what we've started with. But I think there's a larger $25 million serviceable addressable market doing the tapping labor. And then there's the larger $75 million market around all of those other adjacent industries. But I would say our focus right now is kind of just on these single tap you know, either QA or post production monitoring. And so what we actually have can do is, you know, you ask, what are other use cases beyond QA? There's, we do the pre production stuff, but there's also, for example, LinkedIn is one of our customers. I'm going to jump around a bit for a pretty slide, but we can always go back. LinkedIn actually allows you uses mobile to monitor the health of their application post production. So instead of, normally, when you use Datadog or amplitude, you have to kind of wait for things to fail and customers to run into issues, and then you're like, Oh, why is this? So this happens a lot. For example, with App activations. You've probably personally experienced this at LinkedIn, where you're in an email or you pick up something and it's like, Hey, if you download the app, it's better. But you're like, I already have the app, so let me just click on it. But for some reason, it doesn't take you there. It takes you to the App Store. This is a bug. Yes, this happens all the changing. Facebook keeps changing, world keeps changing. So even though Reddit has deep linked it correctly, they have to keep track of everything else in a production environment. And so marketing teams, product teams, growth teams, also use mobile. But the interesting thing is, it's still just tapping on a screen. It's just we're tapping on post production instead of a pre production QA environment. And it's usually we've noticed that with some of the teams that we've interacted with, interacted with, it's outside of the purview of QA, because it's what actually I'm going to switch to a slightly different slide deck to talk through this. It's what we would consider sort of like an intra an inter app workflow. And so I think a lot of existing the problem with existing solutions you probably heard of, like Browser Stack, lambda, test, tricensus, COVID, on all of those, they focus very much on assuming you're automating things inside your own app. And that used to be the case, like three, 510, years ago. But what we're now seeing is there's a trend where, and I think this lines back up with a bigger trend of why I want to break into fitness and gaming and automotive, is your app doesn't just go by itself. It has to talk to other people's APIs, SDKs, dependencies, and so in a real world scenario, our thesis is it's actually easier to get a human, or, sorry, a robot, to poke the phone like a human would do something, right, some sort of simulated, flaky test that typically works for like an intra app scenario, but not so well for the inter app use case.
yeah. So we see, we see QA and mobile as kind of the springboard to some of these other, other industries. So I think there's a few ways to think about it right now. We do iOS, Android iPad, Android tablet, any flat touch screen, Linux based flat touch screens, you know, so on that has allowed us to extend very naturally into smart watches. So watch OS, which also talks to iOS, Android Auto, Apple CarPlay, which then extends into, you know, we'd like to get to connected peripherals via Bluetooth, gaming smart TVs, yeah, doesn't have to be touch screens. It's just basically like my long term science fiction. Venue for this company is, you know, you have BPOS that have humans that do all sorts of things. Why can't we have a robot fleet in the cloud that you don't have to buy your own robot to put them in your own house, but like the way that you rent, you know, time on servers for a data warehouse, you can rent a remote robot somewhere that will do all the humanoid, human like tasks. But we've seen that we can build a solid, healthy 4 million ARR business with 70% gross margins just doing single taps on cheap, $1,000 robots. And so that's what we've started with. But I think there's a larger $25 million serviceable addressable market doing the tapping labor. And then there's the larger $75 million market around all of those other adjacent industries. But I would say our focus right now is kind of just on these single tap you know, either QA or post production monitoring. And so what we actually have can do is, you know, you ask, what are other use cases beyond QA? There's, we do the pre production stuff, but there's also, for example, LinkedIn is one of our customers. I'm going to jump around a bit for a pretty slide, but we can always go back. LinkedIn actually allows you uses mobile to monitor the health of their application post production. So instead of, normally, when you use Datadog or amplitude, you have to kind of wait for things to fail and customers to run into issues, and then you're like, Oh, why is this? So this happens a lot. For example, with App activations. You've probably personally experienced this at LinkedIn, where you're in an email or you pick up something and it's like, Hey, if you download the app, it's better. But you're like, I already have the app, so let me just click on it. But for some reason, it doesn't take you there. It takes you to the App Store. This is a bug. Yes, this happens all the changing. Facebook keeps changing, world keeps changing. So even though Reddit has deep linked it correctly, they have to keep track of everything else in a production environment. And so marketing teams, product teams, growth teams, also use mobile. But the interesting thing is, it's still just tapping on a screen. It's just we're tapping on post production instead of a pre production QA environment. And it's usually we've noticed that with some of the teams that we've interacted with, interacted with, it's outside of the purview of QA, because it's what actually I'm going to switch to a slightly different slide deck to talk through this. It's what we would consider sort of like an intra an inter app workflow. And so I think a lot of existing the problem with existing solutions you probably heard of, like Browser Stack, lambda, test, tricensus, COVID, on all of those, they focus very much on assuming you're automating things inside your own app. And that used to be the case, like three, 510, years ago. But what we're now seeing is there's a trend where, and I think this lines back up with a bigger trend of why I want to break into fitness and gaming and automotive, is your app doesn't just go by itself. It has to talk to other people's APIs, SDKs, dependencies, and so in a real world scenario, our thesis is it's actually easier to get a human, or, sorry, a robot, to poke the phone like a human would do something, right, some sort of simulated, flaky test that typically works for like an intra app scenario, but not so well for the inter app use case.
yeah. So we see, we see QA and mobile as kind of the springboard to some of these other, other industries. So I think there's a few ways to think about it right now. We do iOS, Android iPad, Android tablet, any flat touch screen, Linux based flat touch screens, you know, so on that has allowed us to extend very naturally into smart watches. So watch OS, which also talks to iOS, Android Auto, Apple CarPlay, which then extends into, you know, we'd like to get to connected peripherals via Bluetooth, gaming smart TVs, yeah, doesn't have to be touch screens. It's just basically like my long term science fiction. Venue for this company is, you know, you have BPOS that have humans that do all sorts of things. Why can't we have a robot fleet in the cloud that you don't have to buy your own robot to put them in your own house, but like the way that you rent, you know, time on servers for a data warehouse, you can rent a remote robot somewhere that will do all the humanoid, human like tasks. But we've seen that we can build a solid, healthy 4 million ARR business with 70% gross margins just doing single taps on cheap, $1,000 robots. And so that's what we've started with. But I think there's a larger $25 million serviceable addressable market doing the tapping labor. And then there's the larger $75 million market around all of those other adjacent industries. But I would say our focus right now is kind of just on these single tap you know, either QA or post production monitoring. And so what we actually have can do is, you know, you ask, what are other use cases beyond QA? There's, we do the pre production stuff, but there's also, for example, LinkedIn is one of our customers. I'm going to jump around a bit for a pretty slide, but we can always go back. LinkedIn actually allows you uses mobile to monitor the health of their application post production. So instead of, normally, when you use Datadog or amplitude, you have to kind of wait for things to fail and customers to run into issues, and then you're like, Oh, why is this? So this happens a lot. For example, with App activations. You've probably personally experienced this at LinkedIn, where you're in an email or you pick up something and it's like, Hey, if you download the app, it's better. But you're like, I already have the app, so let me just click on it. But for some reason, it doesn't take you there. It takes you to the App Store. This is a bug. Yes, this happens all the changing. Facebook keeps changing, world keeps changing. So even though Reddit has deep linked it correctly, they have to keep track of everything else in a production environment. And so marketing teams, product teams, growth teams, also use mobile. But the interesting thing is, it's still just tapping on a screen. It's just we're tapping on post production instead of a pre production QA environment. And it's usually we've noticed that with some of the teams that we've interacted with, interacted with, it's outside of the purview of QA, because it's what actually I'm going to switch to a slightly different slide deck to talk through this. It's what we would consider sort of like an intra an inter app workflow. And so I think a lot of existing the problem with existing solutions you probably heard of, like Browser Stack, lambda, test, tricensus, COVID, on all of those, they focus very much on assuming you're automating things inside your own app. And that used to be the case, like three, 510, years ago. But what we're now seeing is there's a trend where, and I think this lines back up with a bigger trend of why I want to break into fitness and gaming and automotive, is your app doesn't just go by itself. It has to talk to other people's APIs, SDKs, dependencies, and so in a real world scenario, our thesis is it's actually easier to get a human, or, sorry, a robot, to poke the phone like a human would do something, right, some sort of simulated, flaky test that typically works for like an intra app scenario, but not so well for the inter app use case.
Speaker 3
So right now, to what makes you like me, understand this, which is, today, there is nobody else that uses robots to actually test, in this particular case, touch screens, if you will.
So right now, to what makes you like me, understand this, which is, today, there is nobody else that uses robots to actually test, in this particular case, touch screens, if you will.
So right now, to what makes you like me, understand this, which is, today, there is nobody else that uses robots to actually test, in this particular case, touch screens, if you will.
So right now, to what makes you like me, understand this, which is, today, there is nobody else that uses robots to actually test, in this particular case, touch screens, if you will.
Speaker 1
There are, there are touchscreen testing robots. So there are actually companies like Opto fidelity, and I think there's a company called Matt tapster, and they will sell you a robot for like 25 to 50,000 $100,000 and you could, as an engineering team, buy your own robot and write your own Python or C can program it yourself. But that's going to take time, and it's going to take labor and resources, and it's just so outside of the core competency of a lot of these engineering teams that they're not going to do it. And that was the problem I experienced, was I just need someone to solve this problem of labor. For me, I'm not going to, you know, spend time kind of like building my own solution to do it. And so that's basically the opportunity that we kind of see is that there's our direct competitor for the kind of unique work that we do is mostly BPOS and other human labor. It's not actually, if you look at those other tools on the market, they kind of cover a small portion of the use cases that one bot can cover. Also, before we get too into things, I did want to allow Dave, our head of engineering, to introduce himself. He just
There are, there are touchscreen testing robots. So there are actually companies like Opto fidelity, and I think there's a company called Matt tapster, and they will sell you a robot for like 25 to 50,000 $100,000 and you could, as an engineering team, buy your own robot and write your own Python or C can program it yourself. But that's going to take time, and it's going to take labor and resources, and it's just so outside of the core competency of a lot of these engineering teams that they're not going to do it. And that was the problem I experienced, was I just need someone to solve this problem of labor. For me, I'm not going to, you know, spend time kind of like building my own solution to do it. And so that's basically the opportunity that we kind of see is that there's our direct competitor for the kind of unique work that we do is mostly BPOS and other human labor. It's not actually, if you look at those other tools on the market, they kind of cover a small portion of the use cases that one bot can cover. Also, before we get too into things, I did want to allow Dave, our head of engineering, to introduce himself. He just
There are, there are touchscreen testing robots. So there are actually companies like Opto fidelity, and I think there's a company called Matt tapster, and they will sell you a robot for like 25 to 50,000 $100,000 and you could, as an engineering team, buy your own robot and write your own Python or C can program it yourself. But that's going to take time, and it's going to take labor and resources, and it's just so outside of the core competency of a lot of these engineering teams that they're not going to do it. And that was the problem I experienced, was I just need someone to solve this problem of labor. For me, I'm not going to, you know, spend time kind of like building my own solution to do it. And so that's basically the opportunity that we kind of see is that there's our direct competitor for the kind of unique work that we do is mostly BPOS and other human labor. It's not actually, if you look at those other tools on the market, they kind of cover a small portion of the use cases that one bot can cover. Also, before we get too into things, I did want to allow Dave, our head of engineering, to introduce himself. He just
There are, there are touchscreen testing robots. So there are actually companies like Opto fidelity, and I think there's a company called Matt tapster, and they will sell you a robot for like 25 to 50,000 $100,000 and you could, as an engineering team, buy your own robot and write your own Python or C can program it yourself. But that's going to take time, and it's going to take labor and resources, and it's just so outside of the core competency of a lot of these engineering teams that they're not going to do it. And that was the problem I experienced, was I just need someone to solve this problem of labor. For me, I'm not going to, you know, spend time kind of like building my own solution to do it. And so that's basically the opportunity that we kind of see is that there's our direct competitor for the kind of unique work that we do is mostly BPOS and other human labor. It's not actually, if you look at those other tools on the market, they kind of cover a small portion of the use cases that one bot can cover. Also, before we get too into things, I did want to allow Dave, our head of engineering, to introduce himself. He just
joined the call Dave. Sorry, I'm Dave. I
joined the call Dave. Sorry, I'm Dave. I
joined the call Dave. Sorry, I'm Dave. I
joined the call Dave. Sorry, I'm Dave. I
Speaker 2
leave. I've been here for two and a half years. For the past 25 years, I've been in engineering teams in the startup world, particularly focusing on teams going through concierge collection points. So I really enjoyed the time we got here. When
leave. I've been here for two and a half years. For the past 25 years, I've been in engineering teams in the startup world, particularly focusing on teams going through concierge collection points. So I really enjoyed the time we got here. When
leave. I've been here for two and a half years. For the past 25 years, I've been in engineering teams in the startup world, particularly focusing on teams going through concierge collection points. So I really enjoyed the time we got here. When
leave. I've been here for two and a half years. For the past 25 years, I've been in engineering teams in the startup world, particularly focusing on teams going through concierge collection points. So I really enjoyed the time we got here. When
Speaker 1
did you start a company? Started the company six years ago. Coming started company as a solo founder, went through YC Demo Day in winter 19, raised to see brown coming out of that that was led by COVID, by primary Venture Partners and new work. And then a couple of years ago, we raised a Series A with COTA capital, heavy bit and uncorrelated.
did you start a company? Started the company six years ago. Coming started company as a solo founder, went through YC Demo Day in winter 19, raised to see brown coming out of that that was led by COVID, by primary Venture Partners and new work. And then a couple of years ago, we raised a Series A with COTA capital, heavy bit and uncorrelated.
did you start a company? Started the company six years ago. Coming started company as a solo founder, went through YC Demo Day in winter 19, raised to see brown coming out of that that was led by COVID, by primary Venture Partners and new work. And then a couple of years ago, we raised a Series A with COTA capital, heavy bit and uncorrelated.
did you start a company? Started the company six years ago. Coming started company as a solo founder, went through YC Demo Day in winter 19, raised to see brown coming out of that that was led by COVID, by primary Venture Partners and new work. And then a couple of years ago, we raised a Series A with COTA capital, heavy bit and uncorrelated.
And this was last year.
And this was last year.
And this was last year.
And this was last year.
The series A was early 2021.
The series A was early 2021.
The series A was early 2021.
The series A was early 2021.
We raised 17 to date.
We raised 17 to date.
We raised 17 to date.
We raised 17 to date.
Speaker 3
And so even going back to which is so right now, you're competitive. So for most people, most companies, who want to test their apps, they have two options. One is, of course, browser test or lambda test, like platforms, but those are mostly emulation and but if you want to test on physical devices, is like human sending it to people like people who have hired other people to test it out manually? Is that the only option today? But other than move on? Yeah, exactly.
And so even going back to which is so right now, you're competitive. So for most people, most companies, who want to test their apps, they have two options. One is, of course, browser test or lambda test, like platforms, but those are mostly emulation and but if you want to test on physical devices, is like human sending it to people like people who have hired other people to test it out manually? Is that the only option today? But other than move on? Yeah, exactly.
And so even going back to which is so right now, you're competitive. So for most people, most companies, who want to test their apps, they have two options. One is, of course, browser test or lambda test, like platforms, but those are mostly emulation and but if you want to test on physical devices, is like human sending it to people like people who have hired other people to test it out manually? Is that the only option today? But other than move on? Yeah, exactly.
And so even going back to which is so right now, you're competitive. So for most people, most companies, who want to test their apps, they have two options. One is, of course, browser test or lambda test, like platforms, but those are mostly emulation and but if you want to test on physical devices, is like human sending it to people like people who have hired other people to test it out manually? Is that the only option today? But other than move on? Yeah, exactly.
Speaker 1
You're either doing manual testing, or you're not doing the testing at all, or you, yeah, you have your email source into a DPO. It's an in house team that we have couple case studies of customers of what they did before that we can walk through. But this is why, like during the sales process, and Sam can definitely speak to this. Like we make it very clear that we are capable of also doing the things that some of the existing tools can do, like the browser stacks of the world and whatever, but we focus a lot on the things that we can do that are increasingly business critical and complex that your perfect emulator solution just cannot handle. And if you look at this list, you'll see, like, all of these are very common everyday things that a consumer would do. They are absolutely business critical. It's not something that's optional that you can just kind of gloss over, or you can spoof an API call and just like, oh, it kind of worked. I'm not actually sure it worked. I didn't check it with a third party provider, but like, I'm just going to keep moving with my perfect simulated test. And so that's what makes mobile different, is that, because we interact with the mobile app exactly the way that a human would, we can take this black box approach where embedded web views, we can cover those two factor authentication. We can cover that. We can switch from Gmail to the App Store to an Instagram ad to your native app, and that's some of what we actually do for some of our customers is kind of going back to what I was saying with that inter app, where you're kind of bouncing to different apps, but there's dependencies, and you have to be in a certain App State or account state. That is all really important, and it's very, very difficult to automate that. I think depending on who you talk to, if you find the right engineer, someone is always going to argue, oh, if I had enough time, I could totally sit down and perfectly automate this. But I think Sam and I run into a lot of situations in sales where there's business pressure, I needed to ship this feature yesterday. My product team, my marketing team, is AB testing. It's easier and faster to get a robot, especially with AI, to poke the screen and just get the work done. Then to try to, like, simulate things with the right UI selector and the right Map
You're either doing manual testing, or you're not doing the testing at all, or you, yeah, you have your email source into a DPO. It's an in house team that we have couple case studies of customers of what they did before that we can walk through. But this is why, like during the sales process, and Sam can definitely speak to this. Like we make it very clear that we are capable of also doing the things that some of the existing tools can do, like the browser stacks of the world and whatever, but we focus a lot on the things that we can do that are increasingly business critical and complex that your perfect emulator solution just cannot handle. And if you look at this list, you'll see, like, all of these are very common everyday things that a consumer would do. They are absolutely business critical. It's not something that's optional that you can just kind of gloss over, or you can spoof an API call and just like, oh, it kind of worked. I'm not actually sure it worked. I didn't check it with a third party provider, but like, I'm just going to keep moving with my perfect simulated test. And so that's what makes mobile different, is that, because we interact with the mobile app exactly the way that a human would, we can take this black box approach where embedded web views, we can cover those two factor authentication. We can cover that. We can switch from Gmail to the App Store to an Instagram ad to your native app, and that's some of what we actually do for some of our customers is kind of going back to what I was saying with that inter app, where you're kind of bouncing to different apps, but there's dependencies, and you have to be in a certain App State or account state. That is all really important, and it's very, very difficult to automate that. I think depending on who you talk to, if you find the right engineer, someone is always going to argue, oh, if I had enough time, I could totally sit down and perfectly automate this. But I think Sam and I run into a lot of situations in sales where there's business pressure, I needed to ship this feature yesterday. My product team, my marketing team, is AB testing. It's easier and faster to get a robot, especially with AI, to poke the screen and just get the work done. Then to try to, like, simulate things with the right UI selector and the right Map
You're either doing manual testing, or you're not doing the testing at all, or you, yeah, you have your email source into a DPO. It's an in house team that we have couple case studies of customers of what they did before that we can walk through. But this is why, like during the sales process, and Sam can definitely speak to this. Like we make it very clear that we are capable of also doing the things that some of the existing tools can do, like the browser stacks of the world and whatever, but we focus a lot on the things that we can do that are increasingly business critical and complex that your perfect emulator solution just cannot handle. And if you look at this list, you'll see, like, all of these are very common everyday things that a consumer would do. They are absolutely business critical. It's not something that's optional that you can just kind of gloss over, or you can spoof an API call and just like, oh, it kind of worked. I'm not actually sure it worked. I didn't check it with a third party provider, but like, I'm just going to keep moving with my perfect simulated test. And so that's what makes mobile different, is that, because we interact with the mobile app exactly the way that a human would, we can take this black box approach where embedded web views, we can cover those two factor authentication. We can cover that. We can switch from Gmail to the App Store to an Instagram ad to your native app, and that's some of what we actually do for some of our customers is kind of going back to what I was saying with that inter app, where you're kind of bouncing to different apps, but there's dependencies, and you have to be in a certain App State or account state. That is all really important, and it's very, very difficult to automate that. I think depending on who you talk to, if you find the right engineer, someone is always going to argue, oh, if I had enough time, I could totally sit down and perfectly automate this. But I think Sam and I run into a lot of situations in sales where there's business pressure, I needed to ship this feature yesterday. My product team, my marketing team, is AB testing. It's easier and faster to get a robot, especially with AI, to poke the screen and just get the work done. Then to try to, like, simulate things with the right UI selector and the right Map
You're either doing manual testing, or you're not doing the testing at all, or you, yeah, you have your email source into a DPO. It's an in house team that we have couple case studies of customers of what they did before that we can walk through. But this is why, like during the sales process, and Sam can definitely speak to this. Like we make it very clear that we are capable of also doing the things that some of the existing tools can do, like the browser stacks of the world and whatever, but we focus a lot on the things that we can do that are increasingly business critical and complex that your perfect emulator solution just cannot handle. And if you look at this list, you'll see, like, all of these are very common everyday things that a consumer would do. They are absolutely business critical. It's not something that's optional that you can just kind of gloss over, or you can spoof an API call and just like, oh, it kind of worked. I'm not actually sure it worked. I didn't check it with a third party provider, but like, I'm just going to keep moving with my perfect simulated test. And so that's what makes mobile different, is that, because we interact with the mobile app exactly the way that a human would, we can take this black box approach where embedded web views, we can cover those two factor authentication. We can cover that. We can switch from Gmail to the App Store to an Instagram ad to your native app, and that's some of what we actually do for some of our customers is kind of going back to what I was saying with that inter app, where you're kind of bouncing to different apps, but there's dependencies, and you have to be in a certain App State or account state. That is all really important, and it's very, very difficult to automate that. I think depending on who you talk to, if you find the right engineer, someone is always going to argue, oh, if I had enough time, I could totally sit down and perfectly automate this. But I think Sam and I run into a lot of situations in sales where there's business pressure, I needed to ship this feature yesterday. My product team, my marketing team, is AB testing. It's easier and faster to get a robot, especially with AI, to poke the screen and just get the work done. Then to try to, like, simulate things with the right UI selector and the right Map
View Code summary program, which is,
View Code summary program, which is,
View Code summary program, which is,
View Code summary program, which is,
Speaker 3
you get a test. So what is it that you get from what is the ask from the customer? Let's say LinkedIn. What is the Ask from LinkedIn? The Ask from LinkedIn is to test all the mobile flows that a end user can have in a LinkedIn app. Is that, as abstract as that was, do they give you, like, a list of tests themselves to run
you get a test. So what is it that you get from what is the ask from the customer? Let's say LinkedIn. What is the Ask from LinkedIn? The Ask from LinkedIn is to test all the mobile flows that a end user can have in a LinkedIn app. Is that, as abstract as that was, do they give you, like, a list of tests themselves to run
you get a test. So what is it that you get from what is the ask from the customer? Let's say LinkedIn. What is the Ask from LinkedIn? The Ask from LinkedIn is to test all the mobile flows that a end user can have in a LinkedIn app. Is that, as abstract as that was, do they give you, like, a list of tests themselves to run
you get a test. So what is it that you get from what is the ask from the customer? Let's say LinkedIn. What is the Ask from LinkedIn? The Ask from LinkedIn is to test all the mobile flows that a end user can have in a LinkedIn app. Is that, as abstract as that was, do they give you, like, a list of tests themselves to run
Speaker 1
Speaker 3
maybe a little bit about which is, what's your go to market? How do you how do customers find mobile? Is this mostly outbound or inbound, because it seems like most of these teams, so like, is Google, Apple, or anyone of those logos also your customer, because it seems they would want to use a lot of this, right?
maybe a little bit about which is, what's your go to market? How do you how do customers find mobile? Is this mostly outbound or inbound, because it seems like most of these teams, so like, is Google, Apple, or anyone of those logos also your customer, because it seems they would want to use a lot of this, right?
maybe a little bit about which is, what's your go to market? How do you how do customers find mobile? Is this mostly outbound or inbound, because it seems like most of these teams, so like, is Google, Apple, or anyone of those logos also your customer, because it seems they would want to use a lot of this, right?
maybe a little bit about which is, what's your go to market? How do you how do customers find mobile? Is this mostly outbound or inbound, because it seems like most of these teams, so like, is Google, Apple, or anyone of those logos also your customer, because it seems they would want to use a lot of this, right?
Speaker 1
Oh, yeah, just so we're clear. The logos on this slide are examples of we actually had, like, a couple of contacts at our competitors, which are these companies, like applause qualitest Infosys, and they just told us the contract sizes. So we just know that, like, there's an actual $12 million contract Google has with someone like applause or Uber uses EPAM. So that's like, what we're trying to replace. But, yeah, just for context, this is examples of real customer or real contracts we want to displace. And this is the slide of, like, mobile, actual, real customers. Today. I will let Sam talk through our go to market motion.
Oh, yeah, just so we're clear. The logos on this slide are examples of we actually had, like, a couple of contacts at our competitors, which are these companies, like applause qualitest Infosys, and they just told us the contract sizes. So we just know that, like, there's an actual $12 million contract Google has with someone like applause or Uber uses EPAM. So that's like, what we're trying to replace. But, yeah, just for context, this is examples of real customer or real contracts we want to displace. And this is the slide of, like, mobile, actual, real customers. Today. I will let Sam talk through our go to market motion.
Oh, yeah, just so we're clear. The logos on this slide are examples of we actually had, like, a couple of contacts at our competitors, which are these companies, like applause qualitest Infosys, and they just told us the contract sizes. So we just know that, like, there's an actual $12 million contract Google has with someone like applause or Uber uses EPAM. So that's like, what we're trying to replace. But, yeah, just for context, this is examples of real customer or real contracts we want to displace. And this is the slide of, like, mobile, actual, real customers. Today. I will let Sam talk through our go to market motion.
Oh, yeah, just so we're clear. The logos on this slide are examples of we actually had, like, a couple of contacts at our competitors, which are these companies, like applause qualitest Infosys, and they just told us the contract sizes. So we just know that, like, there's an actual $12 million contract Google has with someone like applause or Uber uses EPAM. So that's like, what we're trying to replace. But, yeah, just for context, this is examples of real customer or real contracts we want to displace. And this is the slide of, like, mobile, actual, real customers. Today. I will let Sam talk through our go to market motion.
Speaker 2
Yeah, thanks, Steven. Our go to market motion is mostly outbound at this moment, for the new meetings that we source, the initial conversations that we get, about 75% of them are outbound, and 25% are through inbounds and referrals. So we have a healthy inbound funnel of people that have heard of us, that have come to our website and want to investigate and learn more, but our go to market, I could talk a little bit more about, like, how we go through the sales process, but largely outbound for in a moment. Okay,
Yeah, thanks, Steven. Our go to market motion is mostly outbound at this moment, for the new meetings that we source, the initial conversations that we get, about 75% of them are outbound, and 25% are through inbounds and referrals. So we have a healthy inbound funnel of people that have heard of us, that have come to our website and want to investigate and learn more, but our go to market, I could talk a little bit more about, like, how we go through the sales process, but largely outbound for in a moment. Okay,
Yeah, thanks, Steven. Our go to market motion is mostly outbound at this moment, for the new meetings that we source, the initial conversations that we get, about 75% of them are outbound, and 25% are through inbounds and referrals. So we have a healthy inbound funnel of people that have heard of us, that have come to our website and want to investigate and learn more, but our go to market, I could talk a little bit more about, like, how we go through the sales process, but largely outbound for in a moment. Okay,
Yeah, thanks, Steven. Our go to market motion is mostly outbound at this moment, for the new meetings that we source, the initial conversations that we get, about 75% of them are outbound, and 25% are through inbounds and referrals. So we have a healthy inbound funnel of people that have heard of us, that have come to our website and want to investigate and learn more, but our go to market, I could talk a little bit more about, like, how we go through the sales process, but largely outbound for in a moment. Okay,
Speaker 3
and so typically, like, how long does it take for you to close the customer?
and so typically, like, how long does it take for you to close the customer?
and so typically, like, how long does it take for you to close the customer?
and so typically, like, how long does it take for you to close the customer?
Speaker 2
It depends. We have SMB customers that we can close in three weeks. Yeah, larger customers, like, we have Macy's and Draft Kings right now at the end of the funnel. And procurement that takes six months. So enterprise that six to eight month time period. I think that's pretty typical for the space with some of these companies that are making 15, $20 billion a year. However, we still go after those 50, 100 150 person companies, because it's very low effort on our side for sales and on our Operations Engineering team to get them in, run a quick proof of concept and win them over. And then we are also targeting small companies that we know are going to grow. So we're not just trying to get anyone in, because we have found that you have very good NRR with companies that are small and grow, and with the large companies that get in the door and then end up testing more over time. How do you price it? Our pricing is utilization based, so essentially, how much you're using the robots we price and we do scoping based on how many credits a customer might be using over a given time period. So we're taking the same approach as a snowflake, as an Azure DevOps, where they have a allocation of credits over a month or a year, depending on the payment terms that we're going off of, and they can use those credits to execute tests, to build tests, to use custom services on our end. And all that blends in within that one usage model.
It depends. We have SMB customers that we can close in three weeks. Yeah, larger customers, like, we have Macy's and Draft Kings right now at the end of the funnel. And procurement that takes six months. So enterprise that six to eight month time period. I think that's pretty typical for the space with some of these companies that are making 15, $20 billion a year. However, we still go after those 50, 100 150 person companies, because it's very low effort on our side for sales and on our Operations Engineering team to get them in, run a quick proof of concept and win them over. And then we are also targeting small companies that we know are going to grow. So we're not just trying to get anyone in, because we have found that you have very good NRR with companies that are small and grow, and with the large companies that get in the door and then end up testing more over time. How do you price it? Our pricing is utilization based, so essentially, how much you're using the robots we price and we do scoping based on how many credits a customer might be using over a given time period. So we're taking the same approach as a snowflake, as an Azure DevOps, where they have a allocation of credits over a month or a year, depending on the payment terms that we're going off of, and they can use those credits to execute tests, to build tests, to use custom services on our end. And all that blends in within that one usage model.
It depends. We have SMB customers that we can close in three weeks. Yeah, larger customers, like, we have Macy's and Draft Kings right now at the end of the funnel. And procurement that takes six months. So enterprise that six to eight month time period. I think that's pretty typical for the space with some of these companies that are making 15, $20 billion a year. However, we still go after those 50, 100 150 person companies, because it's very low effort on our side for sales and on our Operations Engineering team to get them in, run a quick proof of concept and win them over. And then we are also targeting small companies that we know are going to grow. So we're not just trying to get anyone in, because we have found that you have very good NRR with companies that are small and grow, and with the large companies that get in the door and then end up testing more over time. How do you price it? Our pricing is utilization based, so essentially, how much you're using the robots we price and we do scoping based on how many credits a customer might be using over a given time period. So we're taking the same approach as a snowflake, as an Azure DevOps, where they have a allocation of credits over a month or a year, depending on the payment terms that we're going off of, and they can use those credits to execute tests, to build tests, to use custom services on our end. And all that blends in within that one usage model.
It depends. We have SMB customers that we can close in three weeks. Yeah, larger customers, like, we have Macy's and Draft Kings right now at the end of the funnel. And procurement that takes six months. So enterprise that six to eight month time period. I think that's pretty typical for the space with some of these companies that are making 15, $20 billion a year. However, we still go after those 50, 100 150 person companies, because it's very low effort on our side for sales and on our Operations Engineering team to get them in, run a quick proof of concept and win them over. And then we are also targeting small companies that we know are going to grow. So we're not just trying to get anyone in, because we have found that you have very good NRR with companies that are small and grow, and with the large companies that get in the door and then end up testing more over time. How do you price it? Our pricing is utilization based, so essentially, how much you're using the robots we price and we do scoping based on how many credits a customer might be using over a given time period. So we're taking the same approach as a snowflake, as an Azure DevOps, where they have a allocation of credits over a month or a year, depending on the payment terms that we're going off of, and they can use those credits to execute tests, to build tests, to use custom services on our end. And all that blends in within that one usage model.
So it's usage based pricing
So it's usage based pricing
So it's usage based pricing
So it's usage based pricing
Speaker 1
contracts, though, so it does set like a subscription floor, but if you incur overages, we you do have to pay for the overages, but if you under utilize your plan, you still have to pay us a subscription floor.
contracts, though, so it does set like a subscription floor, but if you incur overages, we you do have to pay for the overages, but if you under utilize your plan, you still have to pay us a subscription floor.
contracts, though, so it does set like a subscription floor, but if you incur overages, we you do have to pay for the overages, but if you under utilize your plan, you still have to pay us a subscription floor.
contracts, though, so it does set like a subscription floor, but if you incur overages, we you do have to pay for the overages, but if you under utilize your plan, you still have to pay us a subscription floor.
Speaker 3
Got it. Got it. Okay, so, so, and then typically, like these contracts that you have, like, right now, how big are the contracts? Your average contract size?
Got it. Got it. Okay, so, so, and then typically, like these contracts that you have, like, right now, how big are the contracts? Your average contract size?
Got it. Got it. Okay, so, so, and then typically, like these contracts that you have, like, right now, how big are the contracts? Your average contract size?
Got it. Got it. Okay, so, so, and then typically, like these contracts that you have, like, right now, how big are the contracts? Your average contract size?
Yeah, go ahead, Sam.
Speaker 2
Our our initial contracts are starter plans, so the base level that a customer would invest, even the smallest ones, are 25 to $30,000 a year. We have customers that spend over $100,000 with us pretty regularly. The miniscus contract that's in procurement right now, it's going to be somewhere in the range of 100 $150,000 a year. We just signed vivid smart home last month on a $32,000 paid pilot and a $130,000 annual recurring contract post pilot. So quite a large range. A really good story that we have here is chime, where they started out actually pretty small a few years ago, but this is what I was talking about with that NRR, if we can find the right customer, reach out to them. Get them in the sales cycle. Prove our value through the proof of concept. Get them in the door. We see the usage based model doing really well. Where we're working with new engineering teams. Now we're working with the marketing team. Now we're working the product team. They're feeding in more tests. And now you can see, in april 2024 earlier this year, they move forward with a multi year, $400,000 plan. Okay?
Our our initial contracts are starter plans, so the base level that a customer would invest, even the smallest ones, are 25 to $30,000 a year. We have customers that spend over $100,000 with us pretty regularly. The miniscus contract that's in procurement right now, it's going to be somewhere in the range of 100 $150,000 a year. We just signed vivid smart home last month on a $32,000 paid pilot and a $130,000 annual recurring contract post pilot. So quite a large range. A really good story that we have here is chime, where they started out actually pretty small a few years ago, but this is what I was talking about with that NRR, if we can find the right customer, reach out to them. Get them in the sales cycle. Prove our value through the proof of concept. Get them in the door. We see the usage based model doing really well. Where we're working with new engineering teams. Now we're working with the marketing team. Now we're working the product team. They're feeding in more tests. And now you can see, in april 2024 earlier this year, they move forward with a multi year, $400,000 plan. Okay?
Our our initial contracts are starter plans, so the base level that a customer would invest, even the smallest ones, are 25 to $30,000 a year. We have customers that spend over $100,000 with us pretty regularly. The miniscus contract that's in procurement right now, it's going to be somewhere in the range of 100 $150,000 a year. We just signed vivid smart home last month on a $32,000 paid pilot and a $130,000 annual recurring contract post pilot. So quite a large range. A really good story that we have here is chime, where they started out actually pretty small a few years ago, but this is what I was talking about with that NRR, if we can find the right customer, reach out to them. Get them in the sales cycle. Prove our value through the proof of concept. Get them in the door. We see the usage based model doing really well. Where we're working with new engineering teams. Now we're working with the marketing team. Now we're working the product team. They're feeding in more tests. And now you can see, in april 2024 earlier this year, they move forward with a multi year, $400,000 plan. Okay?
Our our initial contracts are starter plans, so the base level that a customer would invest, even the smallest ones, are 25 to $30,000 a year. We have customers that spend over $100,000 with us pretty regularly. The miniscus contract that's in procurement right now, it's going to be somewhere in the range of 100 $150,000 a year. We just signed vivid smart home last month on a $32,000 paid pilot and a $130,000 annual recurring contract post pilot. So quite a large range. A really good story that we have here is chime, where they started out actually pretty small a few years ago, but this is what I was talking about with that NRR, if we can find the right customer, reach out to them. Get them in the sales cycle. Prove our value through the proof of concept. Get them in the door. We see the usage based model doing really well. Where we're working with new engineering teams. Now we're working with the marketing team. Now we're working the product team. They're feeding in more tests. And now you can see, in april 2024 earlier this year, they move forward with a multi year, $400,000 plan. Okay?
Speaker 3
And so, I guess it's varied. How many logos do you have today?
And so, I guess it's varied. How many logos do you have today?
And so, I guess it's varied. How many logos do you have today?
And so, I guess it's varied. How many logos do you have today?
Speaker 1
We have 70 customers today. No more than 70, I think.
We have 70 customers today. No more than 70, I think.
We have 70 customers today. No more than 70, I think.
We have 70 customers today. No more than 70, I think.
Speaker 3
And ACV, if you were to average out across the 70 would be around.
And ACV, if you were to average out across the 70 would be around.
And ACV, if you were to average out across the 70 would be around.
And ACV, if you were to average out across the 70 would be around.
It's just south of $40,000
It's just south of $40,000
It's just south of $40,000
It's just south of $40,000
Speaker 1
yeah. So I think you can kind of see some of the customers stay on kind of that starter tier, but some customers expand and like what we've seen, especially with the enterprises, is they have multiple teams, and each of those teams can essentially be its own, sort of like baby startup with a small contract. And so we see a land and expand motion work very well, because we start off supporting the most painful use cases that they just wanted to get off their plate. But then when they see how easy it is to just add everything into the platform, they naturally expand. From there, they incur a bunch of overages. We reach out to them, and we're like, hey, we can get you better pricing. If you lock into a higher tier, you expand you file a lot of tickets. And part of what mobile does is we integrate with your existing tooling. So, and I didn't have a chance to demo this yet, but that we provide screenshots, telemetry, logging play by plays and so it all the all the information goes back to these teams. And there's almost kind of like an organic word of mouth, where as you see a JIRA ticket from a different team that they tagged you on that needs remediation, you kind of figure out, oh, I want to see if I can get some mobile test coverage of my own. And every one of these teams has their own, you know, devices, features, schedule preferences, and so it allows us to, kind of like, grow within an enterprise organization with all the different use cases. And that's what I was saying earlier. Of like, marketing might have their own list of campaigns they want to validate. QA has their own list of test cases they want to validate. Pre production. Marketing is doing it post production. And those can be, you know, obviously all pulling from the same bucket of credits, but they're consuming at their own schedule, their own use cases.
yeah. So I think you can kind of see some of the customers stay on kind of that starter tier, but some customers expand and like what we've seen, especially with the enterprises, is they have multiple teams, and each of those teams can essentially be its own, sort of like baby startup with a small contract. And so we see a land and expand motion work very well, because we start off supporting the most painful use cases that they just wanted to get off their plate. But then when they see how easy it is to just add everything into the platform, they naturally expand. From there, they incur a bunch of overages. We reach out to them, and we're like, hey, we can get you better pricing. If you lock into a higher tier, you expand you file a lot of tickets. And part of what mobile does is we integrate with your existing tooling. So, and I didn't have a chance to demo this yet, but that we provide screenshots, telemetry, logging play by plays and so it all the all the information goes back to these teams. And there's almost kind of like an organic word of mouth, where as you see a JIRA ticket from a different team that they tagged you on that needs remediation, you kind of figure out, oh, I want to see if I can get some mobile test coverage of my own. And every one of these teams has their own, you know, devices, features, schedule preferences, and so it allows us to, kind of like, grow within an enterprise organization with all the different use cases. And that's what I was saying earlier. Of like, marketing might have their own list of campaigns they want to validate. QA has their own list of test cases they want to validate. Pre production. Marketing is doing it post production. And those can be, you know, obviously all pulling from the same bucket of credits, but they're consuming at their own schedule, their own use cases.
yeah. So I think you can kind of see some of the customers stay on kind of that starter tier, but some customers expand and like what we've seen, especially with the enterprises, is they have multiple teams, and each of those teams can essentially be its own, sort of like baby startup with a small contract. And so we see a land and expand motion work very well, because we start off supporting the most painful use cases that they just wanted to get off their plate. But then when they see how easy it is to just add everything into the platform, they naturally expand. From there, they incur a bunch of overages. We reach out to them, and we're like, hey, we can get you better pricing. If you lock into a higher tier, you expand you file a lot of tickets. And part of what mobile does is we integrate with your existing tooling. So, and I didn't have a chance to demo this yet, but that we provide screenshots, telemetry, logging play by plays and so it all the all the information goes back to these teams. And there's almost kind of like an organic word of mouth, where as you see a JIRA ticket from a different team that they tagged you on that needs remediation, you kind of figure out, oh, I want to see if I can get some mobile test coverage of my own. And every one of these teams has their own, you know, devices, features, schedule preferences, and so it allows us to, kind of like, grow within an enterprise organization with all the different use cases. And that's what I was saying earlier. Of like, marketing might have their own list of campaigns they want to validate. QA has their own list of test cases they want to validate. Pre production. Marketing is doing it post production. And those can be, you know, obviously all pulling from the same bucket of credits, but they're consuming at their own schedule, their own use cases.
yeah. So I think you can kind of see some of the customers stay on kind of that starter tier, but some customers expand and like what we've seen, especially with the enterprises, is they have multiple teams, and each of those teams can essentially be its own, sort of like baby startup with a small contract. And so we see a land and expand motion work very well, because we start off supporting the most painful use cases that they just wanted to get off their plate. But then when they see how easy it is to just add everything into the platform, they naturally expand. From there, they incur a bunch of overages. We reach out to them, and we're like, hey, we can get you better pricing. If you lock into a higher tier, you expand you file a lot of tickets. And part of what mobile does is we integrate with your existing tooling. So, and I didn't have a chance to demo this yet, but that we provide screenshots, telemetry, logging play by plays and so it all the all the information goes back to these teams. And there's almost kind of like an organic word of mouth, where as you see a JIRA ticket from a different team that they tagged you on that needs remediation, you kind of figure out, oh, I want to see if I can get some mobile test coverage of my own. And every one of these teams has their own, you know, devices, features, schedule preferences, and so it allows us to, kind of like, grow within an enterprise organization with all the different use cases. And that's what I was saying earlier. Of like, marketing might have their own list of campaigns they want to validate. QA has their own list of test cases they want to validate. Pre production. Marketing is doing it post production. And those can be, you know, obviously all pulling from the same bucket of credits, but they're consuming at their own schedule, their own use cases.
Speaker 3
And how do you what's the biggest like the value prop to end customer, the the value crop to then customer. Is it cheaper than human labor?
And how do you what's the biggest like the value prop to end customer, the the value crop to then customer. Is it cheaper than human labor?
And how do you what's the biggest like the value prop to end customer, the the value crop to then customer. Is it cheaper than human labor?
And how do you what's the biggest like the value prop to end customer, the the value crop to then customer. Is it cheaper than human labor?
Speaker 1
I think depending on if they had internal resources, were definitely cheaper than internal resources. So in the context of chime, they went through two, three rounds of layoffs. You know, they're trying to be very efficient. I think they're gunning for an IPO at some point. Like they, you know, the cost of mobile doing QA for them, $200,000 a year is cheaper than the team of like five San Francisco based people that they previously
I think depending on if they had internal resources, were definitely cheaper than internal resources. So in the context of chime, they went through two, three rounds of layoffs. You know, they're trying to be very efficient. I think they're gunning for an IPO at some point. Like they, you know, the cost of mobile doing QA for them, $200,000 a year is cheaper than the team of like five San Francisco based people that they previously
I think depending on if they had internal resources, were definitely cheaper than internal resources. So in the context of chime, they went through two, three rounds of layoffs. You know, they're trying to be very efficient. I think they're gunning for an IPO at some point. Like they, you know, the cost of mobile doing QA for them, $200,000 a year is cheaper than the team of like five San Francisco based people that they previously
I think depending on if they had internal resources, were definitely cheaper than internal resources. So in the context of chime, they went through two, three rounds of layoffs. You know, they're trying to be very efficient. I think they're gunning for an IPO at some point. Like they, you know, the cost of mobile doing QA for them, $200,000 a year is cheaper than the team of like five San Francisco based people that they previously
Speaker 3
had talking people were doing this at scale. So people, like the other contracts, that sizes of potential contract size that you had from Infosys and others, which is compared to that, what's the value prop for your end customer?
had talking people were doing this at scale. So people, like the other contracts, that sizes of potential contract size that you had from Infosys and others, which is compared to that, what's the value prop for your end customer?
had talking people were doing this at scale. So people, like the other contracts, that sizes of potential contract size that you had from Infosys and others, which is compared to that, what's the value prop for your end customer?
had talking people were doing this at scale. So people, like the other contracts, that sizes of potential contract size that you had from Infosys and others, which is compared to that, what's the value prop for your end customer?
Speaker 1
Yes, I think given at the volume of work that we would be doing, like looking at like, you know, and fanatics pays applause, $500,000 a year, or whatever we would do that work cheaper than fanatics paying applause for $500,000 a year. And so I think that is the next phase of our growth is we want to be aggressively going after some of these existing manual contracts and actually going head to head and really building out of motion, where we can actually, I think we've our technology has very recently reached a point where, especially with the new AI features, that we can scale up and ramp a lot faster than we could, you know, a couple of years ago. And so I think part of what we've been building up until this point is the training data, the use cases, kind of understanding the motion, seeing a few customers in the journey, but we're now at a point where I think we can confidently say we can take on a $500,000 contract from fanatics, but I think that's a fairly new development for the company, and so that's really what we're looking for in our next round of financing, is to be able To start aggressively going after those kinds of contracts and
Yes, I think given at the volume of work that we would be doing, like looking at like, you know, and fanatics pays applause, $500,000 a year, or whatever we would do that work cheaper than fanatics paying applause for $500,000 a year. And so I think that is the next phase of our growth is we want to be aggressively going after some of these existing manual contracts and actually going head to head and really building out of motion, where we can actually, I think we've our technology has very recently reached a point where, especially with the new AI features, that we can scale up and ramp a lot faster than we could, you know, a couple of years ago. And so I think part of what we've been building up until this point is the training data, the use cases, kind of understanding the motion, seeing a few customers in the journey, but we're now at a point where I think we can confidently say we can take on a $500,000 contract from fanatics, but I think that's a fairly new development for the company, and so that's really what we're looking for in our next round of financing, is to be able To start aggressively going after those kinds of contracts and
Yes, I think given at the volume of work that we would be doing, like looking at like, you know, and fanatics pays applause, $500,000 a year, or whatever we would do that work cheaper than fanatics paying applause for $500,000 a year. And so I think that is the next phase of our growth is we want to be aggressively going after some of these existing manual contracts and actually going head to head and really building out of motion, where we can actually, I think we've our technology has very recently reached a point where, especially with the new AI features, that we can scale up and ramp a lot faster than we could, you know, a couple of years ago. And so I think part of what we've been building up until this point is the training data, the use cases, kind of understanding the motion, seeing a few customers in the journey, but we're now at a point where I think we can confidently say we can take on a $500,000 contract from fanatics, but I think that's a fairly new development for the company, and so that's really what we're looking for in our next round of financing, is to be able To start aggressively going after those kinds of contracts and
Yes, I think given at the volume of work that we would be doing, like looking at like, you know, and fanatics pays applause, $500,000 a year, or whatever we would do that work cheaper than fanatics paying applause for $500,000 a year. And so I think that is the next phase of our growth is we want to be aggressively going after some of these existing manual contracts and actually going head to head and really building out of motion, where we can actually, I think we've our technology has very recently reached a point where, especially with the new AI features, that we can scale up and ramp a lot faster than we could, you know, a couple of years ago. And so I think part of what we've been building up until this point is the training data, the use cases, kind of understanding the motion, seeing a few customers in the journey, but we're now at a point where I think we can confidently say we can take on a $500,000 contract from fanatics, but I think that's a fairly new development for the company, and so that's really what we're looking for in our next round of financing, is to be able To start aggressively going after those kinds of contracts and
but other than the
Speaker 3
So, how are you able to win LinkedIn? LinkedIn might be using these as well. So what was what convinced LinkedIn to use mobile versus these manual labor services.
So, how are you able to win LinkedIn? LinkedIn might be using these as well. So what was what convinced LinkedIn to use mobile versus these manual labor services.
So, how are you able to win LinkedIn? LinkedIn might be using these as well. So what was what convinced LinkedIn to use mobile versus these manual labor services.
So, how are you able to win LinkedIn? LinkedIn might be using these as well. So what was what convinced LinkedIn to use mobile versus these manual labor services.
Speaker 1
I think in the case of LinkedIn, what actually won them over was the the thorough documentation, which maybe I can pivot to for a second to kind of show you, um. So here I'll pull up an example from chime, because that's a pretty easy example to understand. So a typical workflow for mobot, a mobile customer is, we have a lot of folks use teams chime, Slack, whatever it is, there's a bunch of people in this slack channel from chime that they monitor mobile alerts that are coming in, and you see, Hey, there's this alert that came in. I'm on the transfers team. I'm an engineer on that team. I see this alert that came through. And you can see mobile runs a huge volume of test cases that for sending a check with a valid amount, you know, completing the mobile check deposit flow, like doing a direct deposit. Like, there's a whole bunch of stuff that our robots are doing, and you don't really need to scroll through the passing screens. There's a lot of passing stuff here. But I think what won a company like LinkedIn over is the combination of the documentation the telemetry that makes it easy to remediate, and then knowing the consistency of the coverage that like, hey, this bug has occurred six times in the last however many weeks. You just don't get this fidelity of information with with, like manual labor, especially the sort of low quality scale of like BPO type labor. Like, there's the value that LinkedIn got, was the repeatability of this process that made it easy to query for data, and then it could generate insights that their team otherwise didn't have, that they that it was just hard to get the data into the right format. So I think the data availability was a big piece for them. And quite candidly, like LinkedIn within that not actually doing this work, like they did not have a separate contract that we replaced, like we brought in our pilot. We actually proved to them all. I mean, we all know we talked about this earlier, like we've run into those bugs, and there's sort of an anecdotal field feeling that something was wrong. But we went through and we were like, We sampled what happens when you click in a LinkedIn profile from slack, WhatsApp, teams, Gmail, Apple, mail, which ones were failing, which ones were not failing. Compare that to your competitors, and we also can automate workflows for LinkedIn competitors, Reddit, indeed, Facebook, and then compare that like, oh, actually, Facebook found a way to fix to get this deep link to work, and Reddit didn't. This is what they did differently. So there were all of those kind of insights and consolidation that we did for them as well. But yes, theoretically, if someone project planned, you could get a bunch of humans to do the same thing. It's just not feasible. And then, so
I think in the case of LinkedIn, what actually won them over was the the thorough documentation, which maybe I can pivot to for a second to kind of show you, um. So here I'll pull up an example from chime, because that's a pretty easy example to understand. So a typical workflow for mobot, a mobile customer is, we have a lot of folks use teams chime, Slack, whatever it is, there's a bunch of people in this slack channel from chime that they monitor mobile alerts that are coming in, and you see, Hey, there's this alert that came in. I'm on the transfers team. I'm an engineer on that team. I see this alert that came through. And you can see mobile runs a huge volume of test cases that for sending a check with a valid amount, you know, completing the mobile check deposit flow, like doing a direct deposit. Like, there's a whole bunch of stuff that our robots are doing, and you don't really need to scroll through the passing screens. There's a lot of passing stuff here. But I think what won a company like LinkedIn over is the combination of the documentation the telemetry that makes it easy to remediate, and then knowing the consistency of the coverage that like, hey, this bug has occurred six times in the last however many weeks. You just don't get this fidelity of information with with, like manual labor, especially the sort of low quality scale of like BPO type labor. Like, there's the value that LinkedIn got, was the repeatability of this process that made it easy to query for data, and then it could generate insights that their team otherwise didn't have, that they that it was just hard to get the data into the right format. So I think the data availability was a big piece for them. And quite candidly, like LinkedIn within that not actually doing this work, like they did not have a separate contract that we replaced, like we brought in our pilot. We actually proved to them all. I mean, we all know we talked about this earlier, like we've run into those bugs, and there's sort of an anecdotal field feeling that something was wrong. But we went through and we were like, We sampled what happens when you click in a LinkedIn profile from slack, WhatsApp, teams, Gmail, Apple, mail, which ones were failing, which ones were not failing. Compare that to your competitors, and we also can automate workflows for LinkedIn competitors, Reddit, indeed, Facebook, and then compare that like, oh, actually, Facebook found a way to fix to get this deep link to work, and Reddit didn't. This is what they did differently. So there were all of those kind of insights and consolidation that we did for them as well. But yes, theoretically, if someone project planned, you could get a bunch of humans to do the same thing. It's just not feasible. And then, so
I think in the case of LinkedIn, what actually won them over was the the thorough documentation, which maybe I can pivot to for a second to kind of show you, um. So here I'll pull up an example from chime, because that's a pretty easy example to understand. So a typical workflow for mobot, a mobile customer is, we have a lot of folks use teams chime, Slack, whatever it is, there's a bunch of people in this slack channel from chime that they monitor mobile alerts that are coming in, and you see, Hey, there's this alert that came in. I'm on the transfers team. I'm an engineer on that team. I see this alert that came through. And you can see mobile runs a huge volume of test cases that for sending a check with a valid amount, you know, completing the mobile check deposit flow, like doing a direct deposit. Like, there's a whole bunch of stuff that our robots are doing, and you don't really need to scroll through the passing screens. There's a lot of passing stuff here. But I think what won a company like LinkedIn over is the combination of the documentation the telemetry that makes it easy to remediate, and then knowing the consistency of the coverage that like, hey, this bug has occurred six times in the last however many weeks. You just don't get this fidelity of information with with, like manual labor, especially the sort of low quality scale of like BPO type labor. Like, there's the value that LinkedIn got, was the repeatability of this process that made it easy to query for data, and then it could generate insights that their team otherwise didn't have, that they that it was just hard to get the data into the right format. So I think the data availability was a big piece for them. And quite candidly, like LinkedIn within that not actually doing this work, like they did not have a separate contract that we replaced, like we brought in our pilot. We actually proved to them all. I mean, we all know we talked about this earlier, like we've run into those bugs, and there's sort of an anecdotal field feeling that something was wrong. But we went through and we were like, We sampled what happens when you click in a LinkedIn profile from slack, WhatsApp, teams, Gmail, Apple, mail, which ones were failing, which ones were not failing. Compare that to your competitors, and we also can automate workflows for LinkedIn competitors, Reddit, indeed, Facebook, and then compare that like, oh, actually, Facebook found a way to fix to get this deep link to work, and Reddit didn't. This is what they did differently. So there were all of those kind of insights and consolidation that we did for them as well. But yes, theoretically, if someone project planned, you could get a bunch of humans to do the same thing. It's just not feasible. And then, so
I think in the case of LinkedIn, what actually won them over was the the thorough documentation, which maybe I can pivot to for a second to kind of show you, um. So here I'll pull up an example from chime, because that's a pretty easy example to understand. So a typical workflow for mobot, a mobile customer is, we have a lot of folks use teams chime, Slack, whatever it is, there's a bunch of people in this slack channel from chime that they monitor mobile alerts that are coming in, and you see, Hey, there's this alert that came in. I'm on the transfers team. I'm an engineer on that team. I see this alert that came through. And you can see mobile runs a huge volume of test cases that for sending a check with a valid amount, you know, completing the mobile check deposit flow, like doing a direct deposit. Like, there's a whole bunch of stuff that our robots are doing, and you don't really need to scroll through the passing screens. There's a lot of passing stuff here. But I think what won a company like LinkedIn over is the combination of the documentation the telemetry that makes it easy to remediate, and then knowing the consistency of the coverage that like, hey, this bug has occurred six times in the last however many weeks. You just don't get this fidelity of information with with, like manual labor, especially the sort of low quality scale of like BPO type labor. Like, there's the value that LinkedIn got, was the repeatability of this process that made it easy to query for data, and then it could generate insights that their team otherwise didn't have, that they that it was just hard to get the data into the right format. So I think the data availability was a big piece for them. And quite candidly, like LinkedIn within that not actually doing this work, like they did not have a separate contract that we replaced, like we brought in our pilot. We actually proved to them all. I mean, we all know we talked about this earlier, like we've run into those bugs, and there's sort of an anecdotal field feeling that something was wrong. But we went through and we were like, We sampled what happens when you click in a LinkedIn profile from slack, WhatsApp, teams, Gmail, Apple, mail, which ones were failing, which ones were not failing. Compare that to your competitors, and we also can automate workflows for LinkedIn competitors, Reddit, indeed, Facebook, and then compare that like, oh, actually, Facebook found a way to fix to get this deep link to work, and Reddit didn't. This is what they did differently. So there were all of those kind of insights and consolidation that we did for them as well. But yes, theoretically, if someone project planned, you could get a bunch of humans to do the same thing. It's just not feasible. And then, so
Speaker 3
for companies like Google and Apple, who were heavy on automation, Don't they have any like I would imagine, because, just because the volume that they have, and they're so heavy on automation, like Apple's automated everything about testing their devices, they don't have anything internally, and which is fine. I mean, they could have it for their own apps, which is different from providing it as a service to everybody else.
for companies like Google and Apple, who were heavy on automation, Don't they have any like I would imagine, because, just because the volume that they have, and they're so heavy on automation, like Apple's automated everything about testing their devices, they don't have anything internally, and which is fine. I mean, they could have it for their own apps, which is different from providing it as a service to everybody else.
for companies like Google and Apple, who were heavy on automation, Don't they have any like I would imagine, because, just because the volume that they have, and they're so heavy on automation, like Apple's automated everything about testing their devices, they don't have anything internally, and which is fine. I mean, they could have it for their own apps, which is different from providing it as a service to everybody else.
for companies like Google and Apple, who were heavy on automation, Don't they have any like I would imagine, because, just because the volume that they have, and they're so heavy on automation, like Apple's automated everything about testing their devices, they don't have anything internally, and which is fine. I mean, they could have it for their own apps, which is different from providing it as a service to everybody else.
Speaker 1
Well, I will say, I know Apple, yes, they the testing and automation frameworks they released. Everybody else are limited, like you. It's very difficult to automate a push notification because that uses Apple's proprietary Push Notification Service. They actually make it very difficult for you to automate push notification testing, for example. But I would not I'm pretty sure, like iOS, they probably have their own internal secret override system that does everything. But based on what I know before, for example, iOS 18 was released, they still had all employees in the company manually dog fooding and using iOS 18 internally for several months. So No, all the automation in the world still doesn't replace like having it on a bunch of old iPhones, new iPhones, good. Wi Fi, bad. Wi Fi, AirPods connecting. The AirPods not connected. Third party, something else connected. Apple Watch is connected. Oh, did I lost internet? Did it sync my GPS location for my Door Dash delivery is here, or stuff like that. Or, Oh, I have Uber driver, Uber, you know, rider connecting and making sure that like two apps can talk to each other and message each other, all that sort of stuff is still really complicated, and there's no emulator framework that can support those use cases. So even Apple is doing it manually, but they're just dogfooding it internally, because Apple doesn't use third party contractors.
Well, I will say, I know Apple, yes, they the testing and automation frameworks they released. Everybody else are limited, like you. It's very difficult to automate a push notification because that uses Apple's proprietary Push Notification Service. They actually make it very difficult for you to automate push notification testing, for example. But I would not I'm pretty sure, like iOS, they probably have their own internal secret override system that does everything. But based on what I know before, for example, iOS 18 was released, they still had all employees in the company manually dog fooding and using iOS 18 internally for several months. So No, all the automation in the world still doesn't replace like having it on a bunch of old iPhones, new iPhones, good. Wi Fi, bad. Wi Fi, AirPods connecting. The AirPods not connected. Third party, something else connected. Apple Watch is connected. Oh, did I lost internet? Did it sync my GPS location for my Door Dash delivery is here, or stuff like that. Or, Oh, I have Uber driver, Uber, you know, rider connecting and making sure that like two apps can talk to each other and message each other, all that sort of stuff is still really complicated, and there's no emulator framework that can support those use cases. So even Apple is doing it manually, but they're just dogfooding it internally, because Apple doesn't use third party contractors.
Well, I will say, I know Apple, yes, they the testing and automation frameworks they released. Everybody else are limited, like you. It's very difficult to automate a push notification because that uses Apple's proprietary Push Notification Service. They actually make it very difficult for you to automate push notification testing, for example. But I would not I'm pretty sure, like iOS, they probably have their own internal secret override system that does everything. But based on what I know before, for example, iOS 18 was released, they still had all employees in the company manually dog fooding and using iOS 18 internally for several months. So No, all the automation in the world still doesn't replace like having it on a bunch of old iPhones, new iPhones, good. Wi Fi, bad. Wi Fi, AirPods connecting. The AirPods not connected. Third party, something else connected. Apple Watch is connected. Oh, did I lost internet? Did it sync my GPS location for my Door Dash delivery is here, or stuff like that. Or, Oh, I have Uber driver, Uber, you know, rider connecting and making sure that like two apps can talk to each other and message each other, all that sort of stuff is still really complicated, and there's no emulator framework that can support those use cases. So even Apple is doing it manually, but they're just dogfooding it internally, because Apple doesn't use third party contractors.
Well, I will say, I know Apple, yes, they the testing and automation frameworks they released. Everybody else are limited, like you. It's very difficult to automate a push notification because that uses Apple's proprietary Push Notification Service. They actually make it very difficult for you to automate push notification testing, for example. But I would not I'm pretty sure, like iOS, they probably have their own internal secret override system that does everything. But based on what I know before, for example, iOS 18 was released, they still had all employees in the company manually dog fooding and using iOS 18 internally for several months. So No, all the automation in the world still doesn't replace like having it on a bunch of old iPhones, new iPhones, good. Wi Fi, bad. Wi Fi, AirPods connecting. The AirPods not connected. Third party, something else connected. Apple Watch is connected. Oh, did I lost internet? Did it sync my GPS location for my Door Dash delivery is here, or stuff like that. Or, Oh, I have Uber driver, Uber, you know, rider connecting and making sure that like two apps can talk to each other and message each other, all that sort of stuff is still really complicated, and there's no emulator framework that can support those use cases. So even Apple is doing it manually, but they're just dogfooding it internally, because Apple doesn't use third party contractors.
Thank you. And so, so in terms of
Thank you. And so, so in terms of
Thank you. And so, so in terms of
Thank you. And so, so in terms of
ARR, where were you last year?
ARR, where were you last year?
ARR, where were you last year?
ARR, where were you last year?
Speaker 1
I think coming out of last year, we were a little less than, I think, like two point something million arr. And I think some of that has been a lot of small customers that we pivoted away from that, you know, stopped existing. And so I think what we're really focused on this year, and where we've seen the most growth in terms of cohorts of mobile customers has been on the enterprise side. So basically, we've seen that like with our best customers, like chime, Best Buy health, you know, rapid. Sorry, I'm gonna jump to this slide here like we're seeing the enterprise cohort. There's like 161% net revenue retention, like Sam was saying, and we're seeing 3x growth in the enterprise cohort. But overall, arr growth has been a little bit slower because there's been some churn from smaller customers.
I think coming out of last year, we were a little less than, I think, like two point something million arr. And I think some of that has been a lot of small customers that we pivoted away from that, you know, stopped existing. And so I think what we're really focused on this year, and where we've seen the most growth in terms of cohorts of mobile customers has been on the enterprise side. So basically, we've seen that like with our best customers, like chime, Best Buy health, you know, rapid. Sorry, I'm gonna jump to this slide here like we're seeing the enterprise cohort. There's like 161% net revenue retention, like Sam was saying, and we're seeing 3x growth in the enterprise cohort. But overall, arr growth has been a little bit slower because there's been some churn from smaller customers.
I think coming out of last year, we were a little less than, I think, like two point something million arr. And I think some of that has been a lot of small customers that we pivoted away from that, you know, stopped existing. And so I think what we're really focused on this year, and where we've seen the most growth in terms of cohorts of mobile customers has been on the enterprise side. So basically, we've seen that like with our best customers, like chime, Best Buy health, you know, rapid. Sorry, I'm gonna jump to this slide here like we're seeing the enterprise cohort. There's like 161% net revenue retention, like Sam was saying, and we're seeing 3x growth in the enterprise cohort. But overall, arr growth has been a little bit slower because there's been some churn from smaller customers.
I think coming out of last year, we were a little less than, I think, like two point something million arr. And I think some of that has been a lot of small customers that we pivoted away from that, you know, stopped existing. And so I think what we're really focused on this year, and where we've seen the most growth in terms of cohorts of mobile customers has been on the enterprise side. So basically, we've seen that like with our best customers, like chime, Best Buy health, you know, rapid. Sorry, I'm gonna jump to this slide here like we're seeing the enterprise cohort. There's like 161% net revenue retention, like Sam was saying, and we're seeing 3x growth in the enterprise cohort. But overall, arr growth has been a little bit slower because there's been some churn from smaller customers.
How? Are you thinking about next year? Yeah,
How? Are you thinking about next year? Yeah,
How? Are you thinking about next year? Yeah,
How? Are you thinking about next year? Yeah,
Speaker 1
we'd like to be able to double revenue next year, and I think we can do that through a combination of I think the improvement in AI that Dave has been building with his team is going to allow us to onboard customers faster. We didn't even talk about the tech part, we can get back to that. And then I think we also have this proven playbook of direct sales where outbound is working. We'd like to also increase inbound as well. I think we're working to experiment with that and figuring out messaging in the market that lands. And then Sam and I are definitely starting to facilitate more channel partnerships so that we can scale more exponentially. So I think that is going to be a key part of it. But I think there's a combination of like, product readiness that we now have fueled by a lot of the AI improvements that we've made this year, and being able to actually confidently go and take on a contract that's like half a million of labor, which is a huge volume of manual labor, and I think we only very recently, in the last couple of quarters, kind of achieved a product maturity that's enabling us to do that. Yeah, thank you. This
we'd like to be able to double revenue next year, and I think we can do that through a combination of I think the improvement in AI that Dave has been building with his team is going to allow us to onboard customers faster. We didn't even talk about the tech part, we can get back to that. And then I think we also have this proven playbook of direct sales where outbound is working. We'd like to also increase inbound as well. I think we're working to experiment with that and figuring out messaging in the market that lands. And then Sam and I are definitely starting to facilitate more channel partnerships so that we can scale more exponentially. So I think that is going to be a key part of it. But I think there's a combination of like, product readiness that we now have fueled by a lot of the AI improvements that we've made this year, and being able to actually confidently go and take on a contract that's like half a million of labor, which is a huge volume of manual labor, and I think we only very recently, in the last couple of quarters, kind of achieved a product maturity that's enabling us to do that. Yeah, thank you. This
we'd like to be able to double revenue next year, and I think we can do that through a combination of I think the improvement in AI that Dave has been building with his team is going to allow us to onboard customers faster. We didn't even talk about the tech part, we can get back to that. And then I think we also have this proven playbook of direct sales where outbound is working. We'd like to also increase inbound as well. I think we're working to experiment with that and figuring out messaging in the market that lands. And then Sam and I are definitely starting to facilitate more channel partnerships so that we can scale more exponentially. So I think that is going to be a key part of it. But I think there's a combination of like, product readiness that we now have fueled by a lot of the AI improvements that we've made this year, and being able to actually confidently go and take on a contract that's like half a million of labor, which is a huge volume of manual labor, and I think we only very recently, in the last couple of quarters, kind of achieved a product maturity that's enabling us to do that. Yeah, thank you. This
we'd like to be able to double revenue next year, and I think we can do that through a combination of I think the improvement in AI that Dave has been building with his team is going to allow us to onboard customers faster. We didn't even talk about the tech part, we can get back to that. And then I think we also have this proven playbook of direct sales where outbound is working. We'd like to also increase inbound as well. I think we're working to experiment with that and figuring out messaging in the market that lands. And then Sam and I are definitely starting to facilitate more channel partnerships so that we can scale more exponentially. So I think that is going to be a key part of it. But I think there's a combination of like, product readiness that we now have fueled by a lot of the AI improvements that we've made this year, and being able to actually confidently go and take on a contract that's like half a million of labor, which is a huge volume of manual labor, and I think we only very recently, in the last couple of quarters, kind of achieved a product maturity that's enabling us to do that. Yeah, thank you. This
is definitely very interesting.
is definitely very interesting.
is definitely very interesting.
is definitely very interesting.
We are investors. I
don't think it's an overlap we are investors in lambda test.
don't think it's an overlap we are investors in lambda test.
don't think it's an overlap we are investors in lambda test.
don't think it's an overlap we are investors in lambda test.
actually, don't know if it was public yet, but
actually, don't know if it was public yet, but
actually, don't know if it was public yet, but
actually, don't know if it was public yet, but
as of last month,
Speaker 3
lambda test, I don't think, do you think there's a conflict at all with
lambda test, I don't think, do you think there's a conflict at all with
lambda test, I don't think, do you think there's a conflict at all with
lambda test, I don't think, do you think there's a conflict at all with
Speaker 1
them? I think most of lambda test is focused on web and kind of like what we were talking about earlier, like the browser based software emulator side of things. Mo bot is more focused, and our broader long term vision is more on you know, we're building infrastructure as a service that we think will like allow us to scale all these other form factors in the other industries that I was talking about. So I think sometimes we compete for the same budget in an engineering department for customers, but we're not functionally doing the same thing, like the correct engineering team, like the right way to do things is you should be buying lambda test for your web testing and any like, easy mobile coverage, but you should be using mobile for everything else that lambda test
them? I think most of lambda test is focused on web and kind of like what we were talking about earlier, like the browser based software emulator side of things. Mo bot is more focused, and our broader long term vision is more on you know, we're building infrastructure as a service that we think will like allow us to scale all these other form factors in the other industries that I was talking about. So I think sometimes we compete for the same budget in an engineering department for customers, but we're not functionally doing the same thing, like the correct engineering team, like the right way to do things is you should be buying lambda test for your web testing and any like, easy mobile coverage, but you should be using mobile for everything else that lambda test
them? I think most of lambda test is focused on web and kind of like what we were talking about earlier, like the browser based software emulator side of things. Mo bot is more focused, and our broader long term vision is more on you know, we're building infrastructure as a service that we think will like allow us to scale all these other form factors in the other industries that I was talking about. So I think sometimes we compete for the same budget in an engineering department for customers, but we're not functionally doing the same thing, like the correct engineering team, like the right way to do things is you should be buying lambda test for your web testing and any like, easy mobile coverage, but you should be using mobile for everything else that lambda test
them? I think most of lambda test is focused on web and kind of like what we were talking about earlier, like the browser based software emulator side of things. Mo bot is more focused, and our broader long term vision is more on you know, we're building infrastructure as a service that we think will like allow us to scale all these other form factors in the other industries that I was talking about. So I think sometimes we compete for the same budget in an engineering department for customers, but we're not functionally doing the same thing, like the correct engineering team, like the right way to do things is you should be buying lambda test for your web testing and any like, easy mobile coverage, but you should be using mobile for everything else that lambda test
Speaker 3
doesn't do. Yeah. I mean, that's what I thought. Mobile testing is such a big industry, and it remains to be not just mobile and everything else that is that screen. Why is this like? Why like? Why would you not grow at a much faster pace than what you're growing at? I think we a lot
doesn't do. Yeah. I mean, that's what I thought. Mobile testing is such a big industry, and it remains to be not just mobile and everything else that is that screen. Why is this like? Why like? Why would you not grow at a much faster pace than what you're growing at? I think we a lot
doesn't do. Yeah. I mean, that's what I thought. Mobile testing is such a big industry, and it remains to be not just mobile and everything else that is that screen. Why is this like? Why like? Why would you not grow at a much faster pace than what you're growing at? I think we a lot
doesn't do. Yeah. I mean, that's what I thought. Mobile testing is such a big industry, and it remains to be not just mobile and everything else that is that screen. Why is this like? Why like? Why would you not grow at a much faster pace than what you're growing at? I think we a lot
Speaker 1
of that has been product readiness, like I was mentioning like it previously, mapping, you know, the customer's intentions, of like, the test plans to actually, like, getting the robot to execute everything consistently on three, 400 devices, daily, weekly, delivering results consistently and reliably. All of that is quite challenging. And I think for definitely, some of the bottleneck has been, you know, our ability to onboard customers and sustain that kind of like that throughput. But I think that we've been very focused on kind of getting the technology right, and I think now we're at a point,
of that has been product readiness, like I was mentioning like it previously, mapping, you know, the customer's intentions, of like, the test plans to actually, like, getting the robot to execute everything consistently on three, 400 devices, daily, weekly, delivering results consistently and reliably. All of that is quite challenging. And I think for definitely, some of the bottleneck has been, you know, our ability to onboard customers and sustain that kind of like that throughput. But I think that we've been very focused on kind of getting the technology right, and I think now we're at a point,
of that has been product readiness, like I was mentioning like it previously, mapping, you know, the customer's intentions, of like, the test plans to actually, like, getting the robot to execute everything consistently on three, 400 devices, daily, weekly, delivering results consistently and reliably. All of that is quite challenging. And I think for definitely, some of the bottleneck has been, you know, our ability to onboard customers and sustain that kind of like that throughput. But I think that we've been very focused on kind of getting the technology right, and I think now we're at a point,
of that has been product readiness, like I was mentioning like it previously, mapping, you know, the customer's intentions, of like, the test plans to actually, like, getting the robot to execute everything consistently on three, 400 devices, daily, weekly, delivering results consistently and reliably. All of that is quite challenging. And I think for definitely, some of the bottleneck has been, you know, our ability to onboard customers and sustain that kind of like that throughput. But I think that we've been very focused on kind of getting the technology right, and I think now we're at a point,
Speaker 3
because clearly, yes, so all the other stuff that you're providing, testing, yeah, this deep lane, testing. Yeah, failed six times, and that's
because clearly, yes, so all the other stuff that you're providing, testing, yeah, this deep lane, testing. Yeah, failed six times, and that's
because clearly, yes, so all the other stuff that you're providing, testing, yeah, this deep lane, testing. Yeah, failed six times, and that's
because clearly, yes, so all the other stuff that you're providing, testing, yeah, this deep lane, testing. Yeah, failed six times, and that's
medical information. So essentially, that means that it's happening.
medical information. So essentially, that means that it's happening.
medical information. So essentially, that means that it's happening.
medical information. So essentially, that means that it's happening.
Speaker 1
I think fundamentally, what we've built is very hard to put together. It's the combination of we can collect data and we can automate things that nobody else can do because we have these robots that are doing it. Where we built this data model, we've built a pipeline that allows us to feed the data back to retrain our machine learning and AI model, and Dave can talk more about that, and like piecing it all together and operationalizing it with customers, I think that it's definitely taken us some time to figure it out and also build the technology and get to this stage. But I think there's a lot that we've learned, and I think some of the validation that we've gotten from customers that have been with robot for 234, years, that I think makes it easier for us now to go to market and approach these large companies. And I think we talked about the deal that we're doing with Macy's, they would not have talked to us if we didn't have a case study saying, here's all the research we did with rapid and with LinkedIn. And that, I think, was a compelling part of what sold them was seeing that we've actually done this with other reputable names, and I think that's a combination of like, go to market bottleneck, but also product readiness bottleneck. And I think we figured out a lot of that for sure. And as a startup, I think
I think fundamentally, what we've built is very hard to put together. It's the combination of we can collect data and we can automate things that nobody else can do because we have these robots that are doing it. Where we built this data model, we've built a pipeline that allows us to feed the data back to retrain our machine learning and AI model, and Dave can talk more about that, and like piecing it all together and operationalizing it with customers, I think that it's definitely taken us some time to figure it out and also build the technology and get to this stage. But I think there's a lot that we've learned, and I think some of the validation that we've gotten from customers that have been with robot for 234, years, that I think makes it easier for us now to go to market and approach these large companies. And I think we talked about the deal that we're doing with Macy's, they would not have talked to us if we didn't have a case study saying, here's all the research we did with rapid and with LinkedIn. And that, I think, was a compelling part of what sold them was seeing that we've actually done this with other reputable names, and I think that's a combination of like, go to market bottleneck, but also product readiness bottleneck. And I think we figured out a lot of that for sure. And as a startup, I think
I think fundamentally, what we've built is very hard to put together. It's the combination of we can collect data and we can automate things that nobody else can do because we have these robots that are doing it. Where we built this data model, we've built a pipeline that allows us to feed the data back to retrain our machine learning and AI model, and Dave can talk more about that, and like piecing it all together and operationalizing it with customers, I think that it's definitely taken us some time to figure it out and also build the technology and get to this stage. But I think there's a lot that we've learned, and I think some of the validation that we've gotten from customers that have been with robot for 234, years, that I think makes it easier for us now to go to market and approach these large companies. And I think we talked about the deal that we're doing with Macy's, they would not have talked to us if we didn't have a case study saying, here's all the research we did with rapid and with LinkedIn. And that, I think, was a compelling part of what sold them was seeing that we've actually done this with other reputable names, and I think that's a combination of like, go to market bottleneck, but also product readiness bottleneck. And I think we figured out a lot of that for sure. And as a startup, I think
I think fundamentally, what we've built is very hard to put together. It's the combination of we can collect data and we can automate things that nobody else can do because we have these robots that are doing it. Where we built this data model, we've built a pipeline that allows us to feed the data back to retrain our machine learning and AI model, and Dave can talk more about that, and like piecing it all together and operationalizing it with customers, I think that it's definitely taken us some time to figure it out and also build the technology and get to this stage. But I think there's a lot that we've learned, and I think some of the validation that we've gotten from customers that have been with robot for 234, years, that I think makes it easier for us now to go to market and approach these large companies. And I think we talked about the deal that we're doing with Macy's, they would not have talked to us if we didn't have a case study saying, here's all the research we did with rapid and with LinkedIn. And that, I think, was a compelling part of what sold them was seeing that we've actually done this with other reputable names, and I think that's a combination of like, go to market bottleneck, but also product readiness bottleneck. And I think we figured out a lot of that for sure. And as a startup, I think
how much are you raising now?
how much are you raising now?
how much are you raising now?
how much are you raising now?
Speaker 1
Yeah, I think it might have Priyesh I mentioned to you that we are considering sort of like a series a extension right now, but we're doing a larger, you know, planning for a larger amount next year. Our existing investors understand that, like I basically told them, I need to front load some hires. I need to add a couple people for Dave's team, and they'd like to be a little bit more aggressive on the go to market side. So, you know, I think, you know, somewhere in the realm of, like, a three to 5 million series, a extension, but then potentially a larger round of financing as well next year.
Yeah, I think it might have Priyesh I mentioned to you that we are considering sort of like a series a extension right now, but we're doing a larger, you know, planning for a larger amount next year. Our existing investors understand that, like I basically told them, I need to front load some hires. I need to add a couple people for Dave's team, and they'd like to be a little bit more aggressive on the go to market side. So, you know, I think, you know, somewhere in the realm of, like, a three to 5 million series, a extension, but then potentially a larger round of financing as well next year.
Yeah, I think it might have Priyesh I mentioned to you that we are considering sort of like a series a extension right now, but we're doing a larger, you know, planning for a larger amount next year. Our existing investors understand that, like I basically told them, I need to front load some hires. I need to add a couple people for Dave's team, and they'd like to be a little bit more aggressive on the go to market side. So, you know, I think, you know, somewhere in the realm of, like, a three to 5 million series, a extension, but then potentially a larger round of financing as well next year.
Yeah, I think it might have Priyesh I mentioned to you that we are considering sort of like a series a extension right now, but we're doing a larger, you know, planning for a larger amount next year. Our existing investors understand that, like I basically told them, I need to front load some hires. I need to add a couple people for Dave's team, and they'd like to be a little bit more aggressive on the go to market side. So, you know, I think, you know, somewhere in the realm of, like, a three to 5 million series, a extension, but then potentially a larger round of financing as well next year.
What was the valuation of last round?
What was the valuation of last round?
What was the valuation of last round?
What was the valuation of last round?
Speaker 1
The last round was 47 I mean, you know, I trust investors to kind of make the right assessment of the company and what is inappropriate, or that's something that we can definitely talk about. I think the existing investors are supportive, and want to make sure we get the right new investors on board. So, yeah, it was 47
The last round was 47 I mean, you know, I trust investors to kind of make the right assessment of the company and what is inappropriate, or that's something that we can definitely talk about. I think the existing investors are supportive, and want to make sure we get the right new investors on board. So, yeah, it was 47
The last round was 47 I mean, you know, I trust investors to kind of make the right assessment of the company and what is inappropriate, or that's something that we can definitely talk about. I think the existing investors are supportive, and want to make sure we get the right new investors on board. So, yeah, it was 47
The last round was 47 I mean, you know, I trust investors to kind of make the right assessment of the company and what is inappropriate, or that's something that we can definitely talk about. I think the existing investors are supportive, and want to make sure we get the right new investors on board. So, yeah, it was 47
Speaker 3
So here's the thing,
Speaker 3
so we'll discuss. We'll get back, but the truth is that we will seriously get back by January. The reason why is we're going through a bunch of deals that were in the pipeline, and then we're current close by, and then the last week, close by, December, 18 and 19th. So the teams are powering through that. The bandwidth right now is limited to the end of the year to discuss something new. So I would say, I think probably this is definitely interesting. I'd like to spend more time, but January is, realistically, we'd be able to spend more time. Yeah, I
so we'll discuss. We'll get back, but the truth is that we will seriously get back by January. The reason why is we're going through a bunch of deals that were in the pipeline, and then we're current close by, and then the last week, close by, December, 18 and 19th. So the teams are powering through that. The bandwidth right now is limited to the end of the year to discuss something new. So I would say, I think probably this is definitely interesting. I'd like to spend more time, but January is, realistically, we'd be able to spend more time. Yeah, I
so we'll discuss. We'll get back, but the truth is that we will seriously get back by January. The reason why is we're going through a bunch of deals that were in the pipeline, and then we're current close by, and then the last week, close by, December, 18 and 19th. So the teams are powering through that. The bandwidth right now is limited to the end of the year to discuss something new. So I would say, I think probably this is definitely interesting. I'd like to spend more time, but January is, realistically, we'd be able to spend more time. Yeah, I
so we'll discuss. We'll get back, but the truth is that we will seriously get back by January. The reason why is we're going through a bunch of deals that were in the pipeline, and then we're current close by, and then the last week, close by, December, 18 and 19th. So the teams are powering through that. The bandwidth right now is limited to the end of the year to discuss something new. So I would say, I think probably this is definitely interesting. I'd like to spend more time, but January is, realistically, we'd be able to spend more time. Yeah, I
know you're trying to raise a extension now, and so
know you're trying to raise a extension now, and so
know you're trying to raise a extension now, and so
know you're trying to raise a extension now, and so
I want to make sure
that we have the right
that we have the right
that we have the right
that we have the right
Speaker 1
expectations. I'm definitely going to keep the ball moving on our side. I will keep you posted if any of the timing changes. I think there is certainly some flexibility here, because it is, like, mostly insiders that are, you know, I think we're strategically only thinking about, like, one or two external investors that would be appropriate to bring into the round anyway. And I think specifically with Qualcomm, I think there's a huge strategic part of why we would, yeah, so it's like, for the right investor, let's, let's make sure I make the timing in the terms of whatever reasonable, like, I understand what you're saying that, like, you're just trying to get all the other deals through pipeline right now.
expectations. I'm definitely going to keep the ball moving on our side. I will keep you posted if any of the timing changes. I think there is certainly some flexibility here, because it is, like, mostly insiders that are, you know, I think we're strategically only thinking about, like, one or two external investors that would be appropriate to bring into the round anyway. And I think specifically with Qualcomm, I think there's a huge strategic part of why we would, yeah, so it's like, for the right investor, let's, let's make sure I make the timing in the terms of whatever reasonable, like, I understand what you're saying that, like, you're just trying to get all the other deals through pipeline right now.
expectations. I'm definitely going to keep the ball moving on our side. I will keep you posted if any of the timing changes. I think there is certainly some flexibility here, because it is, like, mostly insiders that are, you know, I think we're strategically only thinking about, like, one or two external investors that would be appropriate to bring into the round anyway. And I think specifically with Qualcomm, I think there's a huge strategic part of why we would, yeah, so it's like, for the right investor, let's, let's make sure I make the timing in the terms of whatever reasonable, like, I understand what you're saying that, like, you're just trying to get all the other deals through pipeline right now.
expectations. I'm definitely going to keep the ball moving on our side. I will keep you posted if any of the timing changes. I think there is certainly some flexibility here, because it is, like, mostly insiders that are, you know, I think we're strategically only thinking about, like, one or two external investors that would be appropriate to bring into the round anyway. And I think specifically with Qualcomm, I think there's a huge strategic part of why we would, yeah, so it's like, for the right investor, let's, let's make sure I make the timing in the terms of whatever reasonable, like, I understand what you're saying that, like, you're just trying to get all the other deals through pipeline right now.
I think that's something that we can work through if
I think that's something that we can work through if
I think that's something that we can work through if
I think that's something that we can work through if
the timing needs to change or any team with faster,
the timing needs to change or any team with faster,
the timing needs to change or any team with faster,
the timing needs to change or any team with faster,
I completely understand what I'll keep you posted.
I completely understand what I'll keep you posted.
I completely understand what I'll keep you posted.
I completely understand what I'll keep you posted.
That sounds good. Thank you. Join us mute.
That sounds good. Thank you. Join us mute.
That sounds good. Thank you. Join us mute.
That sounds good. Thank you. Join us mute.
Speaker 1
Variances working in product management and QA and really seeing there being a pain point for this, especially because I transitioned from a role where I was pming a very vanilla SaaS app at Palantir, and then I moved into a role where I had to deal with Bluetooth peripherals and portable ultrasounds that plugged into tablets and connected to hospital networks and real hardware and real peripherals, and all of a sudden, I kind of saw that tools that were previously designed for like the perfect CICD software only world didn't really transition well. In a world where I think hardware is fragmenting, there's more physical, real world dependencies, and that's why I started mobile. I will also hand it off to Sam to introduce himself.
Speaker 2
Nice to meet you. My name is Sam. I'm a sales team here, leading the sales team. Been a part of mobile for just over two years. I joined as the first account executive back in 2022 before mobile, I was also in the mobile testing space on the security side. So I'm testing space for over six years, and I'm based in New York.
Are you both based in New York? Yeah, our
Speaker 1
company is headquartered in New York. Our robot fleet is in New York. I would say more than half of our company works out of our New York office. But we do have some kind of like, hybrid or remote employees as well, but everyone's US based we're about
Speaker 3
35 people. I'm based here in the Bay Area with Priyesh ventures for over seven years, investing in a lot of AI. We invest in it also ventures, invests in areas that are, broadly speaking, strategically relevant. And so, of course, a lot of AI, mobile related stuff, IoT related stuff, automotive, networking, PCs, so a bunch of different things and so. And then we people tend to think that we might invest more in hardware. We actually want to invest more in hardware, we actually invest more in software, and we invest off of the balance sheet. So it's about every year, and we we can leave around so we can participate in 75% of them from participate with other investors, but yeah, our check sizes are typically five to seven. The range is to 10, but five to seven, our initial check size is typically. We invest series agnostic, but series A and B is where our sweet spot is so and so we work with a lot of our portfolios. Priyesh told me about mobile exciting enough. I had a bunch of questions, but so I'll let you tell the story, and then. And then, if you have any questions about us, let me know and give you a 10,000 foot overview.
Speaker 1
Yeah, I think Priyesh already answered a few of my questions about Qualcomm ventures last time. So yeah, happy to kind of give you the overview. And then, you know, definitely curious to get your feedback, and would love to go through some of your questions, and then we can kind of circle back to other questions as well. Yeah, um, I will start with just a little demo, which I know, Priyesh, you've seen and heard a bunch of this already, so apologies, but of course, your perspective is also welcome if you have follow up questions. Yeah, so at a high level, what we do at mobot is we build and operate our own complete of commoditized robots that are powered by AI that allow us to automate tasks that historically have to be done manually on actual physical devices. And so a lot of that the use cases typically revolve around yet pre production QA, but we've also seen applicability of Mo bots, technology for other teams, beyond engineering and QA we've done we do post production monitoring. We work with marketing teams. Basically any time that you need a human to pick up a device and poke and interact with a product, a software product on a hardware device, that's where mobile comes in. And so here you can kind of see under the hood how it all works. We have a fleet of, like, 125 robots. They're crammed into a very small closet in their New York office. And we can basically program the robots to perform different tasks by using different prompts. So you can kind of see, like, there's a prompt on the right that sort of tells you, like, you know what, what to expect, open the app, use credentials, log in, complete certain steps, and then you can kind of see the notes on the left is basically we actually are using computer vision on the screen. We've built our own model to do that, where we're interpreting icons and text, and the robot is able to then figure out, okay, based on the semantic context of these icons, this text steps that came before, the steps that I expect to come after, we can have the robot map out a list of robot instructions so it can be clicking on text, clicking on icons, inputting text, dragging and swiping on the screen, and so on, basically anything that a human would do. And so it's kind of mapping those natural language human instructions into robot taps. And the power of using our system is that we can automate things that are historically just un automatable or very difficult to automate with software simulation and emulator frameworks. And so that allows us to cover a wider variety of use cases that typically, you know, are not addressed by popular tools on the market that are typically used for QA. But like I mentioned before, mobile is also useful for other applications beyond QA as well.
Speaker 3
And other applications beyond QA would be,
Speaker 1
yeah. So we see, we see QA and mobile as kind of the springboard to some of these other, other industries. So I think there's a few ways to think about it right now. We do iOS, Android iPad, Android tablet, any flat touch screen, Linux based flat touch screens, you know, so on that has allowed us to extend very naturally into smart watches. So watch OS, which also talks to iOS, Android Auto, Apple CarPlay, which then extends into, you know, we'd like to get to connected peripherals via Bluetooth, gaming smart TVs, yeah, doesn't have to be touch screens. It's just basically like my long term science fiction. Venue for this company is, you know, you have BPOS that have humans that do all sorts of things. Why can't we have a robot fleet in the cloud that you don't have to buy your own robot to put them in your own house, but like the way that you rent, you know, time on servers for a data warehouse, you can rent a remote robot somewhere that will do all the humanoid, human like tasks. But we've seen that we can build a solid, healthy 4 million ARR business with 70% gross margins just doing single taps on cheap, $1,000 robots. And so that's what we've started with. But I think there's a larger $25 million serviceable addressable market doing the tapping labor. And then there's the larger $75 million market around all of those other adjacent industries. But I would say our focus right now is kind of just on these single tap you know, either QA or post production monitoring. And so what we actually have can do is, you know, you ask, what are other use cases beyond QA? There's, we do the pre production stuff, but there's also, for example, LinkedIn is one of our customers. I'm going to jump around a bit for a pretty slide, but we can always go back. LinkedIn actually allows you uses mobile to monitor the health of their application post production. So instead of, normally, when you use Datadog or amplitude, you have to kind of wait for things to fail and customers to run into issues, and then you're like, Oh, why is this? So this happens a lot. For example, with App activations. You've probably personally experienced this at LinkedIn, where you're in an email or you pick up something and it's like, Hey, if you download the app, it's better. But you're like, I already have the app, so let me just click on it. But for some reason, it doesn't take you there. It takes you to the App Store. This is a bug. Yes, this happens all the changing. Facebook keeps changing, world keeps changing. So even though Reddit has deep linked it correctly, they have to keep track of everything else in a production environment. And so marketing teams, product teams, growth teams, also use mobile. But the interesting thing is, it's still just tapping on a screen. It's just we're tapping on post production instead of a pre production QA environment. And it's usually we've noticed that with some of the teams that we've interacted with, interacted with, it's outside of the purview of QA, because it's what actually I'm going to switch to a slightly different slide deck to talk through this. It's what we would consider sort of like an intra an inter app workflow. And so I think a lot of existing the problem with existing solutions you probably heard of, like Browser Stack, lambda, test, tricensus, COVID, on all of those, they focus very much on assuming you're automating things inside your own app. And that used to be the case, like three, 510, years ago. But what we're now seeing is there's a trend where, and I think this lines back up with a bigger trend of why I want to break into fitness and gaming and automotive, is your app doesn't just go by itself. It has to talk to other people's APIs, SDKs, dependencies, and so in a real world scenario, our thesis is it's actually easier to get a human, or, sorry, a robot, to poke the phone like a human would do something, right, some sort of simulated, flaky test that typically works for like an intra app scenario, but not so well for the inter app use case.
Speaker 3
So right now, to what makes you like me, understand this, which is, today, there is nobody else that uses robots to actually test, in this particular case, touch screens, if you will.
Speaker 1
There are, there are touchscreen testing robots. So there are actually companies like Opto fidelity, and I think there's a company called Matt tapster, and they will sell you a robot for like 25 to 50,000 $100,000 and you could, as an engineering team, buy your own robot and write your own Python or C can program it yourself. But that's going to take time, and it's going to take labor and resources, and it's just so outside of the core competency of a lot of these engineering teams that they're not going to do it. And that was the problem I experienced, was I just need someone to solve this problem of labor. For me, I'm not going to, you know, spend time kind of like building my own solution to do it. And so that's basically the opportunity that we kind of see is that there's our direct competitor for the kind of unique work that we do is mostly BPOS and other human labor. It's not actually, if you look at those other tools on the market, they kind of cover a small portion of the use cases that one bot can cover. Also, before we get too into things, I did want to allow Dave, our head of engineering, to introduce himself. He just
joined the call Dave. Sorry, I'm Dave. I
Speaker 2
leave. I've been here for two and a half years. For the past 25 years, I've been in engineering teams in the startup world, particularly focusing on teams going through concierge collection points. So I really enjoyed the time we got here. When
Speaker 1
did you start a company? Started the company six years ago. Coming started company as a solo founder, went through YC Demo Day in winter 19, raised to see brown coming out of that that was led by COVID, by primary Venture Partners and new work. And then a couple of years ago, we raised a Series A with COTA capital, heavy bit and uncorrelated.
And this was last year.
The series A was early 2021.
We raised 17 to date.
Speaker 3
And so even going back to which is so right now, you're competitive. So for most people, most companies, who want to test their apps, they have two options. One is, of course, browser test or lambda test, like platforms, but those are mostly emulation and but if you want to test on physical devices, is like human sending it to people like people who have hired other people to test it out manually? Is that the only option today? But other than move on? Yeah, exactly.
Speaker 1
You're either doing manual testing, or you're not doing the testing at all, or you, yeah, you have your email source into a DPO. It's an in house team that we have couple case studies of customers of what they did before that we can walk through. But this is why, like during the sales process, and Sam can definitely speak to this. Like we make it very clear that we are capable of also doing the things that some of the existing tools can do, like the browser stacks of the world and whatever, but we focus a lot on the things that we can do that are increasingly business critical and complex that your perfect emulator solution just cannot handle. And if you look at this list, you'll see, like, all of these are very common everyday things that a consumer would do. They are absolutely business critical. It's not something that's optional that you can just kind of gloss over, or you can spoof an API call and just like, oh, it kind of worked. I'm not actually sure it worked. I didn't check it with a third party provider, but like, I'm just going to keep moving with my perfect simulated test. And so that's what makes mobile different, is that, because we interact with the mobile app exactly the way that a human would, we can take this black box approach where embedded web views, we can cover those two factor authentication. We can cover that. We can switch from Gmail to the App Store to an Instagram ad to your native app, and that's some of what we actually do for some of our customers is kind of going back to what I was saying with that inter app, where you're kind of bouncing to different apps, but there's dependencies, and you have to be in a certain App State or account state. That is all really important, and it's very, very difficult to automate that. I think depending on who you talk to, if you find the right engineer, someone is always going to argue, oh, if I had enough time, I could totally sit down and perfectly automate this. But I think Sam and I run into a lot of situations in sales where there's business pressure, I needed to ship this feature yesterday. My product team, my marketing team, is AB testing. It's easier and faster to get a robot, especially with AI, to poke the screen and just get the work done. Then to try to, like, simulate things with the right UI selector and the right Map
View Code summary program, which is,
Speaker 3
you get a test. So what is it that you get from what is the ask from the customer? Let's say LinkedIn. What is the Ask from LinkedIn? The Ask from LinkedIn is to test all the mobile flows that a end user can have in a LinkedIn app. Is that, as abstract as that was, do they give you, like, a list of tests themselves to run
Speaker 1
And so
Speaker 3
maybe a little bit about which is, what's your go to market? How do you how do customers find mobile? Is this mostly outbound or inbound, because it seems like most of these teams, so like, is Google, Apple, or anyone of those logos also your customer, because it seems they would want to use a lot of this, right?
Speaker 1
Oh, yeah, just so we're clear. The logos on this slide are examples of we actually had, like, a couple of contacts at our competitors, which are these companies, like applause qualitest Infosys, and they just told us the contract sizes. So we just know that, like, there's an actual $12 million contract Google has with someone like applause or Uber uses EPAM. So that's like, what we're trying to replace. But, yeah, just for context, this is examples of real customer or real contracts we want to displace. And this is the slide of, like, mobile, actual, real customers. Today. I will let Sam talk through our go to market motion.
Speaker 2
Yeah, thanks, Steven. Our go to market motion is mostly outbound at this moment, for the new meetings that we source, the initial conversations that we get, about 75% of them are outbound, and 25% are through inbounds and referrals. So we have a healthy inbound funnel of people that have heard of us, that have come to our website and want to investigate and learn more, but our go to market, I could talk a little bit more about, like, how we go through the sales process, but largely outbound for in a moment. Okay,
Speaker 3
and so typically, like, how long does it take for you to close the customer?
Speaker 2
It depends. We have SMB customers that we can close in three weeks. Yeah, larger customers, like, we have Macy's and Draft Kings right now at the end of the funnel. And procurement that takes six months. So enterprise that six to eight month time period. I think that's pretty typical for the space with some of these companies that are making 15, $20 billion a year. However, we still go after those 50, 100 150 person companies, because it's very low effort on our side for sales and on our Operations Engineering team to get them in, run a quick proof of concept and win them over. And then we are also targeting small companies that we know are going to grow. So we're not just trying to get anyone in, because we have found that you have very good NRR with companies that are small and grow, and with the large companies that get in the door and then end up testing more over time. How do you price it? Our pricing is utilization based, so essentially, how much you're using the robots we price and we do scoping based on how many credits a customer might be using over a given time period. So we're taking the same approach as a snowflake, as an Azure DevOps, where they have a allocation of credits over a month or a year, depending on the payment terms that we're going off of, and they can use those credits to execute tests, to build tests, to use custom services on our end. And all that blends in within that one usage model.
So it's usage based pricing
Speaker 1
contracts, though, so it does set like a subscription floor, but if you incur overages, we you do have to pay for the overages, but if you under utilize your plan, you still have to pay us a subscription floor.
Speaker 3
Got it. Got it. Okay, so, so, and then typically, like these contracts that you have, like, right now, how big are the contracts? Your average contract size?
Yeah, go ahead, Sam.
Speaker 2
Our our initial contracts are starter plans, so the base level that a customer would invest, even the smallest ones, are 25 to $30,000 a year. We have customers that spend over $100,000 with us pretty regularly. The miniscus contract that's in procurement right now, it's going to be somewhere in the range of 100 $150,000 a year. We just signed vivid smart home last month on a $32,000 paid pilot and a $130,000 annual recurring contract post pilot. So quite a large range. A really good story that we have here is chime, where they started out actually pretty small a few years ago, but this is what I was talking about with that NRR, if we can find the right customer, reach out to them. Get them in the sales cycle. Prove our value through the proof of concept. Get them in the door. We see the usage based model doing really well. Where we're working with new engineering teams. Now we're working with the marketing team. Now we're working the product team. They're feeding in more tests. And now you can see, in april 2024 earlier this year, they move forward with a multi year, $400,000 plan. Okay?
Speaker 3
And so, I guess it's varied. How many logos do you have today?
Speaker 1
We have 70 customers today. No more than 70, I think.
Speaker 3
And ACV, if you were to average out across the 70 would be around.
It's just south of $40,000
Speaker 1
yeah. So I think you can kind of see some of the customers stay on kind of that starter tier, but some customers expand and like what we've seen, especially with the enterprises, is they have multiple teams, and each of those teams can essentially be its own, sort of like baby startup with a small contract. And so we see a land and expand motion work very well, because we start off supporting the most painful use cases that they just wanted to get off their plate. But then when they see how easy it is to just add everything into the platform, they naturally expand. From there, they incur a bunch of overages. We reach out to them, and we're like, hey, we can get you better pricing. If you lock into a higher tier, you expand you file a lot of tickets. And part of what mobile does is we integrate with your existing tooling. So, and I didn't have a chance to demo this yet, but that we provide screenshots, telemetry, logging play by plays and so it all the all the information goes back to these teams. And there's almost kind of like an organic word of mouth, where as you see a JIRA ticket from a different team that they tagged you on that needs remediation, you kind of figure out, oh, I want to see if I can get some mobile test coverage of my own. And every one of these teams has their own, you know, devices, features, schedule preferences, and so it allows us to, kind of like, grow within an enterprise organization with all the different use cases. And that's what I was saying earlier. Of like, marketing might have their own list of campaigns they want to validate. QA has their own list of test cases they want to validate. Pre production. Marketing is doing it post production. And those can be, you know, obviously all pulling from the same bucket of credits, but they're consuming at their own schedule, their own use cases.
Speaker 3
And how do you what's the biggest like the value prop to end customer, the the value crop to then customer. Is it cheaper than human labor?
Speaker 1
I think depending on if they had internal resources, were definitely cheaper than internal resources. So in the context of chime, they went through two, three rounds of layoffs. You know, they're trying to be very efficient. I think they're gunning for an IPO at some point. Like they, you know, the cost of mobile doing QA for them, $200,000 a year is cheaper than the team of like five San Francisco based people that they previously
Speaker 3
had talking people were doing this at scale. So people, like the other contracts, that sizes of potential contract size that you had from Infosys and others, which is compared to that, what's the value prop for your end customer?
Speaker 1
Yes, I think given at the volume of work that we would be doing, like looking at like, you know, and fanatics pays applause, $500,000 a year, or whatever we would do that work cheaper than fanatics paying applause for $500,000 a year. And so I think that is the next phase of our growth is we want to be aggressively going after some of these existing manual contracts and actually going head to head and really building out of motion, where we can actually, I think we've our technology has very recently reached a point where, especially with the new AI features, that we can scale up and ramp a lot faster than we could, you know, a couple of years ago. And so I think part of what we've been building up until this point is the training data, the use cases, kind of understanding the motion, seeing a few customers in the journey, but we're now at a point where I think we can confidently say we can take on a $500,000 contract from fanatics, but I think that's a fairly new development for the company, and so that's really what we're looking for in our next round of financing, is to be able To start aggressively going after those kinds of contracts and
but other than the
Speaker 3
So, how are you able to win LinkedIn? LinkedIn might be using these as well. So what was what convinced LinkedIn to use mobile versus these manual labor services.
Speaker 1
I think in the case of LinkedIn, what actually won them over was the the thorough documentation, which maybe I can pivot to for a second to kind of show you, um. So here I'll pull up an example from chime, because that's a pretty easy example to understand. So a typical workflow for mobot, a mobile customer is, we have a lot of folks use teams chime, Slack, whatever it is, there's a bunch of people in this slack channel from chime that they monitor mobile alerts that are coming in, and you see, Hey, there's this alert that came in. I'm on the transfers team. I'm an engineer on that team. I see this alert that came through. And you can see mobile runs a huge volume of test cases that for sending a check with a valid amount, you know, completing the mobile check deposit flow, like doing a direct deposit. Like, there's a whole bunch of stuff that our robots are doing, and you don't really need to scroll through the passing screens. There's a lot of passing stuff here. But I think what won a company like LinkedIn over is the combination of the documentation the telemetry that makes it easy to remediate, and then knowing the consistency of the coverage that like, hey, this bug has occurred six times in the last however many weeks. You just don't get this fidelity of information with with, like manual labor, especially the sort of low quality scale of like BPO type labor. Like, there's the value that LinkedIn got, was the repeatability of this process that made it easy to query for data, and then it could generate insights that their team otherwise didn't have, that they that it was just hard to get the data into the right format. So I think the data availability was a big piece for them. And quite candidly, like LinkedIn within that not actually doing this work, like they did not have a separate contract that we replaced, like we brought in our pilot. We actually proved to them all. I mean, we all know we talked about this earlier, like we've run into those bugs, and there's sort of an anecdotal field feeling that something was wrong. But we went through and we were like, We sampled what happens when you click in a LinkedIn profile from slack, WhatsApp, teams, Gmail, Apple, mail, which ones were failing, which ones were not failing. Compare that to your competitors, and we also can automate workflows for LinkedIn competitors, Reddit, indeed, Facebook, and then compare that like, oh, actually, Facebook found a way to fix to get this deep link to work, and Reddit didn't. This is what they did differently. So there were all of those kind of insights and consolidation that we did for them as well. But yes, theoretically, if someone project planned, you could get a bunch of humans to do the same thing. It's just not feasible. And then, so
Speaker 3
for companies like Google and Apple, who were heavy on automation, Don't they have any like I would imagine, because, just because the volume that they have, and they're so heavy on automation, like Apple's automated everything about testing their devices, they don't have anything internally, and which is fine. I mean, they could have it for their own apps, which is different from providing it as a service to everybody else.
Speaker 1
Well, I will say, I know Apple, yes, they the testing and automation frameworks they released. Everybody else are limited, like you. It's very difficult to automate a push notification because that uses Apple's proprietary Push Notification Service. They actually make it very difficult for you to automate push notification testing, for example. But I would not I'm pretty sure, like iOS, they probably have their own internal secret override system that does everything. But based on what I know before, for example, iOS 18 was released, they still had all employees in the company manually dog fooding and using iOS 18 internally for several months. So No, all the automation in the world still doesn't replace like having it on a bunch of old iPhones, new iPhones, good. Wi Fi, bad. Wi Fi, AirPods connecting. The AirPods not connected. Third party, something else connected. Apple Watch is connected. Oh, did I lost internet? Did it sync my GPS location for my Door Dash delivery is here, or stuff like that. Or, Oh, I have Uber driver, Uber, you know, rider connecting and making sure that like two apps can talk to each other and message each other, all that sort of stuff is still really complicated, and there's no emulator framework that can support those use cases. So even Apple is doing it manually, but they're just dogfooding it internally, because Apple doesn't use third party contractors.
Thank you. And so, so in terms of
ARR, where were you last year?
Speaker 1
I think coming out of last year, we were a little less than, I think, like two point something million arr. And I think some of that has been a lot of small customers that we pivoted away from that, you know, stopped existing. And so I think what we're really focused on this year, and where we've seen the most growth in terms of cohorts of mobile customers has been on the enterprise side. So basically, we've seen that like with our best customers, like chime, Best Buy health, you know, rapid. Sorry, I'm gonna jump to this slide here like we're seeing the enterprise cohort. There's like 161% net revenue retention, like Sam was saying, and we're seeing 3x growth in the enterprise cohort. But overall, arr growth has been a little bit slower because there's been some churn from smaller customers.
How? Are you thinking about next year? Yeah,
Speaker 1
we'd like to be able to double revenue next year, and I think we can do that through a combination of I think the improvement in AI that Dave has been building with his team is going to allow us to onboard customers faster. We didn't even talk about the tech part, we can get back to that. And then I think we also have this proven playbook of direct sales where outbound is working. We'd like to also increase inbound as well. I think we're working to experiment with that and figuring out messaging in the market that lands. And then Sam and I are definitely starting to facilitate more channel partnerships so that we can scale more exponentially. So I think that is going to be a key part of it. But I think there's a combination of like, product readiness that we now have fueled by a lot of the AI improvements that we've made this year, and being able to actually confidently go and take on a contract that's like half a million of labor, which is a huge volume of manual labor, and I think we only very recently, in the last couple of quarters, kind of achieved a product maturity that's enabling us to do that. Yeah, thank you. This
is definitely very interesting.
We are investors. I
don't think it's an overlap we are investors in lambda test.
Just recently,
actually, don't know if it was public yet, but
as of last month,
Speaker 3
lambda test, I don't think, do you think there's a conflict at all with
Speaker 1
them? I think most of lambda test is focused on web and kind of like what we were talking about earlier, like the browser based software emulator side of things. Mo bot is more focused, and our broader long term vision is more on you know, we're building infrastructure as a service that we think will like allow us to scale all these other form factors in the other industries that I was talking about. So I think sometimes we compete for the same budget in an engineering department for customers, but we're not functionally doing the same thing, like the correct engineering team, like the right way to do things is you should be buying lambda test for your web testing and any like, easy mobile coverage, but you should be using mobile for everything else that lambda test
Speaker 3
doesn't do. Yeah. I mean, that's what I thought. Mobile testing is such a big industry, and it remains to be not just mobile and everything else that is that screen. Why is this like? Why like? Why would you not grow at a much faster pace than what you're growing at? I think we a lot
Speaker 1
of that has been product readiness, like I was mentioning like it previously, mapping, you know, the customer's intentions, of like, the test plans to actually, like, getting the robot to execute everything consistently on three, 400 devices, daily, weekly, delivering results consistently and reliably. All of that is quite challenging. And I think for definitely, some of the bottleneck has been, you know, our ability to onboard customers and sustain that kind of like that throughput. But I think that we've been very focused on kind of getting the technology right, and I think now we're at a point,
Speaker 3
because clearly, yes, so all the other stuff that you're providing, testing, yeah, this deep lane, testing. Yeah, failed six times, and that's
medical information. So essentially, that means that it's happening.
Speaker 1
I think fundamentally, what we've built is very hard to put together. It's the combination of we can collect data and we can automate things that nobody else can do because we have these robots that are doing it. Where we built this data model, we've built a pipeline that allows us to feed the data back to retrain our machine learning and AI model, and Dave can talk more about that, and like piecing it all together and operationalizing it with customers, I think that it's definitely taken us some time to figure it out and also build the technology and get to this stage. But I think there's a lot that we've learned, and I think some of the validation that we've gotten from customers that have been with robot for 234, years, that I think makes it easier for us now to go to market and approach these large companies. And I think we talked about the deal that we're doing with Macy's, they would not have talked to us if we didn't have a case study saying, here's all the research we did with rapid and with LinkedIn. And that, I think, was a compelling part of what sold them was seeing that we've actually done this with other reputable names, and I think that's a combination of like, go to market bottleneck, but also product readiness bottleneck. And I think we figured out a lot of that for sure. And as a startup, I think
how much are you raising now?
Speaker 1
Yeah, I think it might have Priyesh I mentioned to you that we are considering sort of like a series a extension right now, but we're doing a larger, you know, planning for a larger amount next year. Our existing investors understand that, like I basically told them, I need to front load some hires. I need to add a couple people for Dave's team, and they'd like to be a little bit more aggressive on the go to market side. So, you know, I think, you know, somewhere in the realm of, like, a three to 5 million series, a extension, but then potentially a larger round of financing as well next year.
What was the valuation of last round?
Speaker 1
The last round was 47 I mean, you know, I trust investors to kind of make the right assessment of the company and what is inappropriate, or that's something that we can definitely talk about. I think the existing investors are supportive, and want to make sure we get the right new investors on board. So, yeah, it was 47
Speaker 3
So here's the thing,
Speaker 3
so we'll discuss. We'll get back, but the truth is that we will seriously get back by January. The reason why is we're going through a bunch of deals that were in the pipeline, and then we're current close by, and then the last week, close by, December, 18 and 19th. So the teams are powering through that. The bandwidth right now is limited to the end of the year to discuss something new. So I would say, I think probably this is definitely interesting. I'd like to spend more time, but January is, realistically, we'd be able to spend more time. Yeah, I
know you're trying to raise a extension now, and so
I want to make sure
that we have the right
Speaker 1
expectations. I'm definitely going to keep the ball moving on our side. I will keep you posted if any of the timing changes. I think there is certainly some flexibility here, because it is, like, mostly insiders that are, you know, I think we're strategically only thinking about, like, one or two external investors that would be appropriate to bring into the round anyway. And I think specifically with Qualcomm, I think there's a huge strategic part of why we would, yeah, so it's like, for the right investor, let's, let's make sure I make the timing in the terms of whatever reasonable, like, I understand what you're saying that, like, you're just trying to get all the other deals through pipeline right now.
I think that's something that we can work through if
the timing needs to change or any team with faster,
I completely understand what I'll keep you posted.
That sounds good. Thank you. Join us mute.
How accurate was this transcription?