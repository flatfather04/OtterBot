Meeting: Mobot - Call 2
Fri, Nov 22, 2024
12:01 PM
36 min
Priyesh P
Post-Production Monitoring and Customer E
URL: https://otter.ai/u/XlWe4lut_hy4QNhMMpTtBys-pqQ
Downloaded: 2025-12-22T13:38:42.863828
Method: text_extraction
============================================================

0:13hey, hi. Then, how are you? I'm good. How are you,
hey, hi. Then, how are you? I'm good. How are you,
hey, hi. Then, how are you? I'm good. How are you,
hey, hi. Then, how are you? I'm good. How are you,
0:17I'm good. Thanks a lot for taking the time again.
I'm good. Thanks a lot for taking the time again.
I'm good. Thanks a lot for taking the time again.
I'm good. Thanks a lot for taking the time again.
S Speaker 10:20Yeah, I mean, I know some of these questions are pretty quick, so I figured, look, let's have, let's just knock them out, and then obviously, anything that needs more data and follow up, we're happy to put that together and send that to you, but appreciate you taking the time as well. For
Yeah, I mean, I know some of these questions are pretty quick, so I figured, look, let's have, let's just knock them out, and then obviously, anything that needs more data and follow up, we're happy to put that together and send that to you, but appreciate you taking the time as well. For
Yeah, I mean, I know some of these questions are pretty quick, so I figured, look, let's have, let's just knock them out, and then obviously, anything that needs more data and follow up, we're happy to put that together and send that to you, but appreciate you taking the time as well. For
Yeah, I mean, I know some of these questions are pretty quick, so I figured, look, let's have, let's just knock them out, and then obviously, anything that needs more data and follow up, we're happy to put that together and send that to you, but appreciate you taking the time as well. For
S Speaker 10:59yeah, okay, I have your questions pulled up on my other screen. Do you want to just go through them in order? Or you have other as
yeah, okay, I have your questions pulled up on my other screen. Do you want to just go through them in order? Or you have other as
yeah, okay, I have your questions pulled up on my other screen. Do you want to just go through them in order? Or you have other as
yeah, okay, I have your questions pulled up on my other screen. Do you want to just go through them in order? Or you have other as
S Speaker 21:07you feel fit, as you feel fit, I think a lot of those could be combined into one. So whatever you prefer. Okay, yeah, so
you feel fit, as you feel fit, I think a lot of those could be combined into one. So whatever you prefer. Okay, yeah, so
you feel fit, as you feel fit, I think a lot of those could be combined into one. So whatever you prefer. Okay, yeah, so
you feel fit, as you feel fit, I think a lot of those could be combined into one. So whatever you prefer. Okay, yeah, so
S Speaker 11:16first one about post production monitoring, I would say, like, it's actually the technology, the use case, the way we set things up is very similar, both pre and post production. I'll actually show you an example. So one of the customers that we're in a proof of concept with is Macy's. And so did I show you this interface the last time? No,
first one about post production monitoring, I would say, like, it's actually the technology, the use case, the way we set things up is very similar, both pre and post production. I'll actually show you an example. So one of the customers that we're in a proof of concept with is Macy's. And so did I show you this interface the last time? No,
first one about post production monitoring, I would say, like, it's actually the technology, the use case, the way we set things up is very similar, both pre and post production. I'll actually show you an example. So one of the customers that we're in a proof of concept with is Macy's. And so did I show you this interface the last time? No,
first one about post production monitoring, I would say, like, it's actually the technology, the use case, the way we set things up is very similar, both pre and post production. I'll actually show you an example. So one of the customers that we're in a proof of concept with is Macy's. And so did I show you this interface the last time? No,
1:39we didn't go through a demo. Now,
we didn't go through a demo. Now,
we didn't go through a demo. Now,
we didn't go through a demo. Now,
S Speaker 11:42okay, yeah, so basically, like, at a high level, how it works is, we have a number of we have 70 something plus customers, and a lot of our customers work with us on Slack, so they get these slack alerts. This is the example of, like, chime. You know, they have a bunch of engineers who are in this channel, yeah. And they get these alerts that sort of show, oh, okay, you know, this is, this is a bug that this is pre production. So every Wednesday, chime runs this battery of tests, and they get, you know, an alert. And if you're the the transfers team, you get an alert that's like, Okay, I'm going to click on this report. I can see screenshot by screenshot, like, what happened it was on this version of the app on this phone. And all of these are test cases that are executed by mobile they are mapped to chimes internal systems. But you can kind of see like, okay, backwards and forwards. Like, what did the robot actually tap and then see? So when we talk about the 15 million screenshots, we have 15 million of these screenshots, right? Yeah. And so here's a bug, oops, inbound transfer error. Like, this is what you normally expect to see. This is what we saw instead. AI can write a comment explaining based on we know the steps that came before, we know the steps that came after. We know the purpose of the test step or the test case. There's a lot of semantic context, and so mobat can open the JIRA ticket. I can't show you the ticket because this is in time system, but it integrates with their Jira, GitHub, circle CI test flight. We integrate with a number of systems, and then the engineer can come in and they can see this issue, they can also view logs, and they can actually see, like, what was it? What was displayed on the screen at different points, what was being passed through. And so that's how, like, the normal QA and pre production use case works. Yeah,
okay, yeah, so basically, like, at a high level, how it works is, we have a number of we have 70 something plus customers, and a lot of our customers work with us on Slack, so they get these slack alerts. This is the example of, like, chime. You know, they have a bunch of engineers who are in this channel, yeah. And they get these alerts that sort of show, oh, okay, you know, this is, this is a bug that this is pre production. So every Wednesday, chime runs this battery of tests, and they get, you know, an alert. And if you're the the transfers team, you get an alert that's like, Okay, I'm going to click on this report. I can see screenshot by screenshot, like, what happened it was on this version of the app on this phone. And all of these are test cases that are executed by mobile they are mapped to chimes internal systems. But you can kind of see like, okay, backwards and forwards. Like, what did the robot actually tap and then see? So when we talk about the 15 million screenshots, we have 15 million of these screenshots, right? Yeah. And so here's a bug, oops, inbound transfer error. Like, this is what you normally expect to see. This is what we saw instead. AI can write a comment explaining based on we know the steps that came before, we know the steps that came after. We know the purpose of the test step or the test case. There's a lot of semantic context, and so mobat can open the JIRA ticket. I can't show you the ticket because this is in time system, but it integrates with their Jira, GitHub, circle CI test flight. We integrate with a number of systems, and then the engineer can come in and they can see this issue, they can also view logs, and they can actually see, like, what was it? What was displayed on the screen at different points, what was being passed through. And so that's how, like, the normal QA and pre production use case works. Yeah,
okay, yeah, so basically, like, at a high level, how it works is, we have a number of we have 70 something plus customers, and a lot of our customers work with us on Slack, so they get these slack alerts. This is the example of, like, chime. You know, they have a bunch of engineers who are in this channel, yeah. And they get these alerts that sort of show, oh, okay, you know, this is, this is a bug that this is pre production. So every Wednesday, chime runs this battery of tests, and they get, you know, an alert. And if you're the the transfers team, you get an alert that's like, Okay, I'm going to click on this report. I can see screenshot by screenshot, like, what happened it was on this version of the app on this phone. And all of these are test cases that are executed by mobile they are mapped to chimes internal systems. But you can kind of see like, okay, backwards and forwards. Like, what did the robot actually tap and then see? So when we talk about the 15 million screenshots, we have 15 million of these screenshots, right? Yeah. And so here's a bug, oops, inbound transfer error. Like, this is what you normally expect to see. This is what we saw instead. AI can write a comment explaining based on we know the steps that came before, we know the steps that came after. We know the purpose of the test step or the test case. There's a lot of semantic context, and so mobat can open the JIRA ticket. I can't show you the ticket because this is in time system, but it integrates with their Jira, GitHub, circle CI test flight. We integrate with a number of systems, and then the engineer can come in and they can see this issue, they can also view logs, and they can actually see, like, what was it? What was displayed on the screen at different points, what was being passed through. And so that's how, like, the normal QA and pre production use case works. Yeah,
okay, yeah, so basically, like, at a high level, how it works is, we have a number of we have 70 something plus customers, and a lot of our customers work with us on Slack, so they get these slack alerts. This is the example of, like, chime. You know, they have a bunch of engineers who are in this channel, yeah. And they get these alerts that sort of show, oh, okay, you know, this is, this is a bug that this is pre production. So every Wednesday, chime runs this battery of tests, and they get, you know, an alert. And if you're the the transfers team, you get an alert that's like, Okay, I'm going to click on this report. I can see screenshot by screenshot, like, what happened it was on this version of the app on this phone. And all of these are test cases that are executed by mobile they are mapped to chimes internal systems. But you can kind of see like, okay, backwards and forwards. Like, what did the robot actually tap and then see? So when we talk about the 15 million screenshots, we have 15 million of these screenshots, right? Yeah. And so here's a bug, oops, inbound transfer error. Like, this is what you normally expect to see. This is what we saw instead. AI can write a comment explaining based on we know the steps that came before, we know the steps that came after. We know the purpose of the test step or the test case. There's a lot of semantic context, and so mobat can open the JIRA ticket. I can't show you the ticket because this is in time system, but it integrates with their Jira, GitHub, circle CI test flight. We integrate with a number of systems, and then the engineer can come in and they can see this issue, they can also view logs, and they can actually see, like, what was it? What was displayed on the screen at different points, what was being passed through. And so that's how, like, the normal QA and pre production use case works. Yeah,
S Speaker 23:42just one follow up there. Eden, who sets these tests. Do you have a template of tests that you usually run? Are these tests given to you by customers?
just one follow up there. Eden, who sets these tests. Do you have a template of tests that you usually run? Are these tests given to you by customers?
just one follow up there. Eden, who sets these tests. Do you have a template of tests that you usually run? Are these tests given to you by customers?
just one follow up there. Eden, who sets these tests. Do you have a template of tests that you usually run? Are these tests given to you by customers?
S Speaker 26:42Got it, got it. Eden, I think it's a good segue to sort of get into the data mode question. I am assuming the mode itself isn't on the screenshots, because that's a very replicable data pattern. But the context and the metadata that you have behind that, what's the thinking there. How do you see the differentiation sort of play out in the long term? And you just mentioned the llms. And the CNNs are used to sort of evaluate whether the test was a pass or a fail. I would assume, just evaluating whether a test is a pass or fail, llms,
Got it, got it. Eden, I think it's a good segue to sort of get into the data mode question. I am assuming the mode itself isn't on the screenshots, because that's a very replicable data pattern. But the context and the metadata that you have behind that, what's the thinking there. How do you see the differentiation sort of play out in the long term? And you just mentioned the llms. And the CNNs are used to sort of evaluate whether the test was a pass or a fail. I would assume, just evaluating whether a test is a pass or fail, llms,
Got it, got it. Eden, I think it's a good segue to sort of get into the data mode question. I am assuming the mode itself isn't on the screenshots, because that's a very replicable data pattern. But the context and the metadata that you have behind that, what's the thinking there. How do you see the differentiation sort of play out in the long term? And you just mentioned the llms. And the CNNs are used to sort of evaluate whether the test was a pass or a fail. I would assume, just evaluating whether a test is a pass or fail, llms,
Got it, got it. Eden, I think it's a good segue to sort of get into the data mode question. I am assuming the mode itself isn't on the screenshots, because that's a very replicable data pattern. But the context and the metadata that you have behind that, what's the thinking there. How do you see the differentiation sort of play out in the long term? And you just mentioned the llms. And the CNNs are used to sort of evaluate whether the test was a pass or a fail. I would assume, just evaluating whether a test is a pass or fail, llms,
S Speaker 17:20sorry, the llms are for interpreting the screen right? The pass or fail is a traditional, more like convolutional neural network based model. Got
sorry, the llms are for interpreting the screen right? The pass or fail is a traditional, more like convolutional neural network based model. Got
sorry, the llms are for interpreting the screen right? The pass or fail is a traditional, more like convolutional neural network based model. Got
sorry, the llms are for interpreting the screen right? The pass or fail is a traditional, more like convolutional neural network based model. Got
S Speaker 27:29it. Got it. Is the secret sauce in evaluating the test. Is the secret sauce in conducting the test? Where do you think your technology stands
it. Got it. Is the secret sauce in evaluating the test. Is the secret sauce in conducting the test? Where do you think your technology stands
it. Got it. Is the secret sauce in evaluating the test. Is the secret sauce in conducting the test? Where do you think your technology stands
it. Got it. Is the secret sauce in evaluating the test. Is the secret sauce in conducting the test? Where do you think your technology stands
7:38out? I think there's a few different pieces
out? I think there's a few different pieces
out? I think there's a few different pieces
out? I think there's a few different pieces
S Speaker 210:16It's a very interesting analogy. Even I've been talking to a couple of AI native software engineer agents, I'd say, and they, there's a very interesting parallel that I can see, and they are, right now from identifying the bugs to triaging them, was, I would say, the level two of software engineer automation. Right now they are writing AI codes to fix the bugs. And I think, yeah, it makes sense with what you're trying to do. That's interesting. I'd love to understand the competition piece a little bit better. I think we had, I had a few questions around that. And how does it compare to some traditional software, software based,
It's a very interesting analogy. Even I've been talking to a couple of AI native software engineer agents, I'd say, and they, there's a very interesting parallel that I can see, and they are, right now from identifying the bugs to triaging them, was, I would say, the level two of software engineer automation. Right now they are writing AI codes to fix the bugs. And I think, yeah, it makes sense with what you're trying to do. That's interesting. I'd love to understand the competition piece a little bit better. I think we had, I had a few questions around that. And how does it compare to some traditional software, software based,
It's a very interesting analogy. Even I've been talking to a couple of AI native software engineer agents, I'd say, and they, there's a very interesting parallel that I can see, and they are, right now from identifying the bugs to triaging them, was, I would say, the level two of software engineer automation. Right now they are writing AI codes to fix the bugs. And I think, yeah, it makes sense with what you're trying to do. That's interesting. I'd love to understand the competition piece a little bit better. I think we had, I had a few questions around that. And how does it compare to some traditional software, software based,
It's a very interesting analogy. Even I've been talking to a couple of AI native software engineer agents, I'd say, and they, there's a very interesting parallel that I can see, and they are, right now from identifying the bugs to triaging them, was, I would say, the level two of software engineer automation. Right now they are writing AI codes to fix the bugs. And I think, yeah, it makes sense with what you're trying to do. That's interesting. I'd love to understand the competition piece a little bit better. I think we had, I had a few questions around that. And how does it compare to some traditional software, software based,
S Speaker 110:58yep, oh, one thing I want to make sure I address is, I think you said in your email, MOBA was founded in 2016 that's not correct. We were I think maybe some the internet or pitch book might be incorrect. We were founded in late 2018 and we went through Y Combinator in 2019 so we've basically been generating revenue since the beginning of the company. Yeah? Like, I'm not actually sure where you got that, but actually, if you could let me know, I want to make sure I correct that. Yeah,
yep, oh, one thing I want to make sure I address is, I think you said in your email, MOBA was founded in 2016 that's not correct. We were I think maybe some the internet or pitch book might be incorrect. We were founded in late 2018 and we went through Y Combinator in 2019 so we've basically been generating revenue since the beginning of the company. Yeah? Like, I'm not actually sure where you got that, but actually, if you could let me know, I want to make sure I correct that. Yeah,
yep, oh, one thing I want to make sure I address is, I think you said in your email, MOBA was founded in 2016 that's not correct. We were I think maybe some the internet or pitch book might be incorrect. We were founded in late 2018 and we went through Y Combinator in 2019 so we've basically been generating revenue since the beginning of the company. Yeah? Like, I'm not actually sure where you got that, but actually, if you could let me know, I want to make sure I correct that. Yeah,
yep, oh, one thing I want to make sure I address is, I think you said in your email, MOBA was founded in 2016 that's not correct. We were I think maybe some the internet or pitch book might be incorrect. We were founded in late 2018 and we went through Y Combinator in 2019 so we've basically been generating revenue since the beginning of the company. Yeah? Like, I'm not actually sure where you got that, but actually, if you could let me know, I want to make sure I correct that. Yeah,
S Speaker 211:29I probably got it from Facebook if I didn't make a typo error. But, yeah, okay,
I probably got it from Facebook if I didn't make a typo error. But, yeah, okay,
I probably got it from Facebook if I didn't make a typo error. But, yeah, okay,
I probably got it from Facebook if I didn't make a typo error. But, yeah, okay,
S Speaker 111:33no worries. But yeah. So we were founded in late 2018 and then we went through Y Combinator in 2019 got
no worries. But yeah. So we were founded in late 2018 and then we went through Y Combinator in 2019 got
no worries. But yeah. So we were founded in late 2018 and then we went through Y Combinator in 2019 got
no worries. But yeah. So we were founded in late 2018 and then we went through Y Combinator in 2019 got
S Speaker 211:40it. That's there's a very interesting like, I saw the traction graph Eden, and it's a very interesting ramp up since 2020, I'd say, anything specific that led to it.
it. That's there's a very interesting like, I saw the traction graph Eden, and it's a very interesting ramp up since 2020, I'd say, anything specific that led to it.
it. That's there's a very interesting like, I saw the traction graph Eden, and it's a very interesting ramp up since 2020, I'd say, anything specific that led to it.
it. That's there's a very interesting like, I saw the traction graph Eden, and it's a very interesting ramp up since 2020, I'd say, anything specific that led to it.
S Speaker 111:53The main thing was, we actually hired like an account executive, was not me. Because in, I would say the early years of the business, like as solo founder, it was like seed stage company, trying to get product market fit, trying to understand, like, from a technical perspective, how customers wanted to use mobile. And so I did a lot of the early sales by myself. And I think the key difference was in 2020 we hired our first sales rep,
The main thing was, we actually hired like an account executive, was not me. Because in, I would say the early years of the business, like as solo founder, it was like seed stage company, trying to get product market fit, trying to understand, like, from a technical perspective, how customers wanted to use mobile. And so I did a lot of the early sales by myself. And I think the key difference was in 2020 we hired our first sales rep,
The main thing was, we actually hired like an account executive, was not me. Because in, I would say the early years of the business, like as solo founder, it was like seed stage company, trying to get product market fit, trying to understand, like, from a technical perspective, how customers wanted to use mobile. And so I did a lot of the early sales by myself. And I think the key difference was in 2020 we hired our first sales rep,
The main thing was, we actually hired like an account executive, was not me. Because in, I would say the early years of the business, like as solo founder, it was like seed stage company, trying to get product market fit, trying to understand, like, from a technical perspective, how customers wanted to use mobile. And so I did a lot of the early sales by myself. And I think the key difference was in 2020 we hired our first sales rep,
S Speaker 212:21got it, got it. That's where the sales engine was built. That makes sense. Understood, understood, okay. Oh,
got it, got it. That's where the sales engine was built. That makes sense. Understood, understood, okay. Oh,
got it, got it. That's where the sales engine was built. That makes sense. Understood, understood, okay. Oh,
got it, got it. That's where the sales engine was built. That makes sense. Understood, understood, okay. Oh,
S Speaker 112:29yeah. One more thing before we segue to competitive landscape. I didn't you had a question about post production monitoring? Yeah. So this is an example of it's the exact same product, right? But for Macy's, which is a pilot that we have, basically, they want us to go to like Rakuten. And this is in real production, like real racket and data real like, the robot is actually going to Rakuten and is like, Okay, I'm activating, like, 18% cash back. And we want to make sure that it actually goes into the Macy's app. And we're validating on the real production Macy's app that like, yes, the Rakuten campaign, which is constantly changing, right? The promotions are changing hourly, making sure that it opens the Macy's app in the correct space. And we're doing that on the real app. We're making sure that beforehand the app was installed, and we can provide them with like, the link of like, this is what the robot clicked on. And so all of that's happening on production. And so it is the same product, like what you're seeing, but it's just testing on real production environments. And the reason we can do that is because you can see the robot can switch between, you know, the Macy's app, backgrounding Safari. We can be even automating things in Rakuten, which is not controlled by Macy's. And that's why they're interested in this, is because the end to end automation of someone else's website is actually very challenging,
yeah. One more thing before we segue to competitive landscape. I didn't you had a question about post production monitoring? Yeah. So this is an example of it's the exact same product, right? But for Macy's, which is a pilot that we have, basically, they want us to go to like Rakuten. And this is in real production, like real racket and data real like, the robot is actually going to Rakuten and is like, Okay, I'm activating, like, 18% cash back. And we want to make sure that it actually goes into the Macy's app. And we're validating on the real production Macy's app that like, yes, the Rakuten campaign, which is constantly changing, right? The promotions are changing hourly, making sure that it opens the Macy's app in the correct space. And we're doing that on the real app. We're making sure that beforehand the app was installed, and we can provide them with like, the link of like, this is what the robot clicked on. And so all of that's happening on production. And so it is the same product, like what you're seeing, but it's just testing on real production environments. And the reason we can do that is because you can see the robot can switch between, you know, the Macy's app, backgrounding Safari. We can be even automating things in Rakuten, which is not controlled by Macy's. And that's why they're interested in this, is because the end to end automation of someone else's website is actually very challenging,
yeah. One more thing before we segue to competitive landscape. I didn't you had a question about post production monitoring? Yeah. So this is an example of it's the exact same product, right? But for Macy's, which is a pilot that we have, basically, they want us to go to like Rakuten. And this is in real production, like real racket and data real like, the robot is actually going to Rakuten and is like, Okay, I'm activating, like, 18% cash back. And we want to make sure that it actually goes into the Macy's app. And we're validating on the real production Macy's app that like, yes, the Rakuten campaign, which is constantly changing, right? The promotions are changing hourly, making sure that it opens the Macy's app in the correct space. And we're doing that on the real app. We're making sure that beforehand the app was installed, and we can provide them with like, the link of like, this is what the robot clicked on. And so all of that's happening on production. And so it is the same product, like what you're seeing, but it's just testing on real production environments. And the reason we can do that is because you can see the robot can switch between, you know, the Macy's app, backgrounding Safari. We can be even automating things in Rakuten, which is not controlled by Macy's. And that's why they're interested in this, is because the end to end automation of someone else's website is actually very challenging,
yeah. One more thing before we segue to competitive landscape. I didn't you had a question about post production monitoring? Yeah. So this is an example of it's the exact same product, right? But for Macy's, which is a pilot that we have, basically, they want us to go to like Rakuten. And this is in real production, like real racket and data real like, the robot is actually going to Rakuten and is like, Okay, I'm activating, like, 18% cash back. And we want to make sure that it actually goes into the Macy's app. And we're validating on the real production Macy's app that like, yes, the Rakuten campaign, which is constantly changing, right? The promotions are changing hourly, making sure that it opens the Macy's app in the correct space. And we're doing that on the real app. We're making sure that beforehand the app was installed, and we can provide them with like, the link of like, this is what the robot clicked on. And so all of that's happening on production. And so it is the same product, like what you're seeing, but it's just testing on real production environments. And the reason we can do that is because you can see the robot can switch between, you know, the Macy's app, backgrounding Safari. We can be even automating things in Rakuten, which is not controlled by Macy's. And that's why they're interested in this, is because the end to end automation of someone else's website is actually very challenging,
S Speaker 213:59right? That's interesting, and that's definitely a competitive differentiation from more traditional lambda test browser stacks of the world. Eden, what fraction of I'd say your customers usage currently comes from pre production versus post production? Roughly, if you can, if you have an estimation, I would say it's still,
right? That's interesting, and that's definitely a competitive differentiation from more traditional lambda test browser stacks of the world. Eden, what fraction of I'd say your customers usage currently comes from pre production versus post production? Roughly, if you can, if you have an estimation, I would say it's still,
right? That's interesting, and that's definitely a competitive differentiation from more traditional lambda test browser stacks of the world. Eden, what fraction of I'd say your customers usage currently comes from pre production versus post production? Roughly, if you can, if you have an estimation, I would say it's still,
right? That's interesting, and that's definitely a competitive differentiation from more traditional lambda test browser stacks of the world. Eden, what fraction of I'd say your customers usage currently comes from pre production versus post production? Roughly, if you can, if you have an estimation, I would say it's still,
S Speaker 118:52So, yeah, I think going back to, like the competitive piece, the way to think about it is, I think you're kind of already clear that Browser Stack, like Sauce Labs, you know, lens tests, all those other existing solutions. They don't do a lot of the complex stuff that is historically unautomatable on mobile camera, two factor all this stuff, like, if it's if it's really hard, like, there's no actual like, library call that exists in xe UI or espresso or Appium that will actually do these things, and so they end up being manually tested. So there's that piece,
So, yeah, I think going back to, like the competitive piece, the way to think about it is, I think you're kind of already clear that Browser Stack, like Sauce Labs, you know, lens tests, all those other existing solutions. They don't do a lot of the complex stuff that is historically unautomatable on mobile camera, two factor all this stuff, like, if it's if it's really hard, like, there's no actual like, library call that exists in xe UI or espresso or Appium that will actually do these things, and so they end up being manually tested. So there's that piece,
So, yeah, I think going back to, like the competitive piece, the way to think about it is, I think you're kind of already clear that Browser Stack, like Sauce Labs, you know, lens tests, all those other existing solutions. They don't do a lot of the complex stuff that is historically unautomatable on mobile camera, two factor all this stuff, like, if it's if it's really hard, like, there's no actual like, library call that exists in xe UI or espresso or Appium that will actually do these things, and so they end up being manually tested. So there's that piece,
So, yeah, I think going back to, like the competitive piece, the way to think about it is, I think you're kind of already clear that Browser Stack, like Sauce Labs, you know, lens tests, all those other existing solutions. They don't do a lot of the complex stuff that is historically unautomatable on mobile camera, two factor all this stuff, like, if it's if it's really hard, like, there's no actual like, library call that exists in xe UI or espresso or Appium that will actually do these things, and so they end up being manually tested. So there's that piece,
S Speaker 219:29even deep links. So I would I'm surprised that deep links exist in there. Yeah,
even deep links. So I would I'm surprised that deep links exist in there. Yeah,
even deep links. So I would I'm surprised that deep links exist in there. Yeah,
even deep links. So I would I'm surprised that deep links exist in there. Yeah,
S Speaker 119:34deep links technically work, but the problem kind of, like, what I'm showing you is like the racket in screen is changing like all the time. So you can use Appium to write a racket in test, but it might not work tomorrow. And the problem is, because you don't work at Rakuten, you don't know how it changed, right? So, yeah, it's actually harder to rely on that, and there is complexity, especially if you're doing app installs. Appium is not great at handling app reinstalling, uninstalling, clean, installing, backgrounding, because what we're talking about here with the marketing use case is you have to make sure the parameters are being passed through correctly, as the app is in different states, if there's a push notification saying there was a promotion that stuff is really hard to do with Appium. I'm not going to say it's like totally impossible, because if there was a smart engineer, they could probably do it. But what we have seen is with the volume that most of these enterprises are dealing with, it's not like you have 10 test cases and like 10 weeks to automate it, right? We're talking hundreds of use cases, and the engineers are frantically working, and it's just actually more reliable to get a robot to poke the screen like a human. Some people find this thesis very offensive an engineer who wants to control everything with code, they find that fundamentally appalling. But honestly, that's just what we've seen, is the reliability is higher with our system.
deep links technically work, but the problem kind of, like, what I'm showing you is like the racket in screen is changing like all the time. So you can use Appium to write a racket in test, but it might not work tomorrow. And the problem is, because you don't work at Rakuten, you don't know how it changed, right? So, yeah, it's actually harder to rely on that, and there is complexity, especially if you're doing app installs. Appium is not great at handling app reinstalling, uninstalling, clean, installing, backgrounding, because what we're talking about here with the marketing use case is you have to make sure the parameters are being passed through correctly, as the app is in different states, if there's a push notification saying there was a promotion that stuff is really hard to do with Appium. I'm not going to say it's like totally impossible, because if there was a smart engineer, they could probably do it. But what we have seen is with the volume that most of these enterprises are dealing with, it's not like you have 10 test cases and like 10 weeks to automate it, right? We're talking hundreds of use cases, and the engineers are frantically working, and it's just actually more reliable to get a robot to poke the screen like a human. Some people find this thesis very offensive an engineer who wants to control everything with code, they find that fundamentally appalling. But honestly, that's just what we've seen, is the reliability is higher with our system.
deep links technically work, but the problem kind of, like, what I'm showing you is like the racket in screen is changing like all the time. So you can use Appium to write a racket in test, but it might not work tomorrow. And the problem is, because you don't work at Rakuten, you don't know how it changed, right? So, yeah, it's actually harder to rely on that, and there is complexity, especially if you're doing app installs. Appium is not great at handling app reinstalling, uninstalling, clean, installing, backgrounding, because what we're talking about here with the marketing use case is you have to make sure the parameters are being passed through correctly, as the app is in different states, if there's a push notification saying there was a promotion that stuff is really hard to do with Appium. I'm not going to say it's like totally impossible, because if there was a smart engineer, they could probably do it. But what we have seen is with the volume that most of these enterprises are dealing with, it's not like you have 10 test cases and like 10 weeks to automate it, right? We're talking hundreds of use cases, and the engineers are frantically working, and it's just actually more reliable to get a robot to poke the screen like a human. Some people find this thesis very offensive an engineer who wants to control everything with code, they find that fundamentally appalling. But honestly, that's just what we've seen, is the reliability is higher with our system.
deep links technically work, but the problem kind of, like, what I'm showing you is like the racket in screen is changing like all the time. So you can use Appium to write a racket in test, but it might not work tomorrow. And the problem is, because you don't work at Rakuten, you don't know how it changed, right? So, yeah, it's actually harder to rely on that, and there is complexity, especially if you're doing app installs. Appium is not great at handling app reinstalling, uninstalling, clean, installing, backgrounding, because what we're talking about here with the marketing use case is you have to make sure the parameters are being passed through correctly, as the app is in different states, if there's a push notification saying there was a promotion that stuff is really hard to do with Appium. I'm not going to say it's like totally impossible, because if there was a smart engineer, they could probably do it. But what we have seen is with the volume that most of these enterprises are dealing with, it's not like you have 10 test cases and like 10 weeks to automate it, right? We're talking hundreds of use cases, and the engineers are frantically working, and it's just actually more reliable to get a robot to poke the screen like a human. Some people find this thesis very offensive an engineer who wants to control everything with code, they find that fundamentally appalling. But honestly, that's just what we've seen, is the reliability is higher with our system.
S Speaker 221:04No, totally. That's that's quite logical, if you think about it one way, the closer you get to the fidelity of user experience, the better your testing would be. So yeah, that makes a lot of sense. Yeah.
No, totally. That's that's quite logical, if you think about it one way, the closer you get to the fidelity of user experience, the better your testing would be. So yeah, that makes a lot of sense. Yeah.
No, totally. That's that's quite logical, if you think about it one way, the closer you get to the fidelity of user experience, the better your testing would be. So yeah, that makes a lot of sense. Yeah.
No, totally. That's that's quite logical, if you think about it one way, the closer you get to the fidelity of user experience, the better your testing would be. So yeah, that makes a lot of sense. Yeah.
S Speaker 121:16And so long term, like my vision is we will also want to do the things that lambda test and head spin and Browser Stack are doing, but that is one corner of the market, and I think it's very constrained to like simulators, emulators, the web stuff. At some point in the future, we can either expand our roadmap to cover those features, or we can acquire one of those companies, but like our differentiator is the fact that we can do all those use cases in pre and post production monitoring, and the way that we're presenting the data and interpreting the data, I think, is very unique and different than a lot of those other solutions out there. They don't provide you with the AI. I mean, there's more that can be done, right? I think there's like, you know, you mentioned, like, actually, literally, actually, literally suggesting where in the code to change. We have not touched that yet. That's also not our focus. We could maybe acquire one of those companies that are working on that. Our bread and butter is, like, piecing everything together and actually delivering the execution. I think that operationalizing it is the hard part like I think, of course, we are modifying and developing our own AI models when, when it makes sense to but the differentiating piece for it is the fact that we've been able to build this software infrastructure that can run on hundreds of robots and orchestrate work scalably on all of these different devices. And I think, like that piece is compelling, the data moat is also compelling. And then everything else, like we can either integrate with or collaborate with other tools. We're not necessarily competitive, interesting,
And so long term, like my vision is we will also want to do the things that lambda test and head spin and Browser Stack are doing, but that is one corner of the market, and I think it's very constrained to like simulators, emulators, the web stuff. At some point in the future, we can either expand our roadmap to cover those features, or we can acquire one of those companies, but like our differentiator is the fact that we can do all those use cases in pre and post production monitoring, and the way that we're presenting the data and interpreting the data, I think, is very unique and different than a lot of those other solutions out there. They don't provide you with the AI. I mean, there's more that can be done, right? I think there's like, you know, you mentioned, like, actually, literally, actually, literally suggesting where in the code to change. We have not touched that yet. That's also not our focus. We could maybe acquire one of those companies that are working on that. Our bread and butter is, like, piecing everything together and actually delivering the execution. I think that operationalizing it is the hard part like I think, of course, we are modifying and developing our own AI models when, when it makes sense to but the differentiating piece for it is the fact that we've been able to build this software infrastructure that can run on hundreds of robots and orchestrate work scalably on all of these different devices. And I think, like that piece is compelling, the data moat is also compelling. And then everything else, like we can either integrate with or collaborate with other tools. We're not necessarily competitive, interesting,
And so long term, like my vision is we will also want to do the things that lambda test and head spin and Browser Stack are doing, but that is one corner of the market, and I think it's very constrained to like simulators, emulators, the web stuff. At some point in the future, we can either expand our roadmap to cover those features, or we can acquire one of those companies, but like our differentiator is the fact that we can do all those use cases in pre and post production monitoring, and the way that we're presenting the data and interpreting the data, I think, is very unique and different than a lot of those other solutions out there. They don't provide you with the AI. I mean, there's more that can be done, right? I think there's like, you know, you mentioned, like, actually, literally, actually, literally suggesting where in the code to change. We have not touched that yet. That's also not our focus. We could maybe acquire one of those companies that are working on that. Our bread and butter is, like, piecing everything together and actually delivering the execution. I think that operationalizing it is the hard part like I think, of course, we are modifying and developing our own AI models when, when it makes sense to but the differentiating piece for it is the fact that we've been able to build this software infrastructure that can run on hundreds of robots and orchestrate work scalably on all of these different devices. And I think, like that piece is compelling, the data moat is also compelling. And then everything else, like we can either integrate with or collaborate with other tools. We're not necessarily competitive, interesting,
And so long term, like my vision is we will also want to do the things that lambda test and head spin and Browser Stack are doing, but that is one corner of the market, and I think it's very constrained to like simulators, emulators, the web stuff. At some point in the future, we can either expand our roadmap to cover those features, or we can acquire one of those companies, but like our differentiator is the fact that we can do all those use cases in pre and post production monitoring, and the way that we're presenting the data and interpreting the data, I think, is very unique and different than a lot of those other solutions out there. They don't provide you with the AI. I mean, there's more that can be done, right? I think there's like, you know, you mentioned, like, actually, literally, actually, literally suggesting where in the code to change. We have not touched that yet. That's also not our focus. We could maybe acquire one of those companies that are working on that. Our bread and butter is, like, piecing everything together and actually delivering the execution. I think that operationalizing it is the hard part like I think, of course, we are modifying and developing our own AI models when, when it makes sense to but the differentiating piece for it is the fact that we've been able to build this software infrastructure that can run on hundreds of robots and orchestrate work scalably on all of these different devices. And I think, like that piece is compelling, the data moat is also compelling. And then everything else, like we can either integrate with or collaborate with other tools. We're not necessarily competitive, interesting,
S Speaker 222:56and so Eden, if we talk about the product roadmap. What's next in line? Where do you see expanding first?
and so Eden, if we talk about the product roadmap. What's next in line? Where do you see expanding first?
and so Eden, if we talk about the product roadmap. What's next in line? Where do you see expanding first?
and so Eden, if we talk about the product roadmap. What's next in line? Where do you see expanding first?
23:07Yeah, so I think the next thing
Yeah, so I think the next thing
Yeah, so I think the next thing
Yeah, so I think the next thing
S Speaker 123:09we want to do is we want to expand beyond iOS and Android and mobile, right? I think the market is much larger. We see any device with a touch screen, the first thing is like, Okay, if we can have one robot that pokes things, let's do all the poking in the world. I think there's a $25 billion immediate market with mobile and there's a larger $75 billion market of just robot fingers poking things in AR, VR headsets, Smart TV remotes, Roku, like connected devices, all of that. And then I think there's a separate market to, you know, even add on top of that around other, obviously form factors of the like lifting the device, pressing buttons, doing other things. And we will have to add other kinds of robots to our system. So you can actually, there's open source robot arms that you can build and set up for like three $5,000 per arm, probably less. And our robots are commoditized, basically gutted out 3d printers that we assemble each for $1,000 per robot. And we think each robot can generate 330,000 in ARR when we operate it as infrastructure, as a service. Because, again, we don't sell robots. We don't ship robots to anybody else. It's about we have this cloud hosted fleet that our customers can rent time one day you're going to rent time on, you know, a robot that does the single task you might rent time tomorrow on the robot that's testing the smartwatch or the AR VR headset. And so I'm basically, like the long, long term vision of the company
we want to do is we want to expand beyond iOS and Android and mobile, right? I think the market is much larger. We see any device with a touch screen, the first thing is like, Okay, if we can have one robot that pokes things, let's do all the poking in the world. I think there's a $25 billion immediate market with mobile and there's a larger $75 billion market of just robot fingers poking things in AR, VR headsets, Smart TV remotes, Roku, like connected devices, all of that. And then I think there's a separate market to, you know, even add on top of that around other, obviously form factors of the like lifting the device, pressing buttons, doing other things. And we will have to add other kinds of robots to our system. So you can actually, there's open source robot arms that you can build and set up for like three $5,000 per arm, probably less. And our robots are commoditized, basically gutted out 3d printers that we assemble each for $1,000 per robot. And we think each robot can generate 330,000 in ARR when we operate it as infrastructure, as a service. Because, again, we don't sell robots. We don't ship robots to anybody else. It's about we have this cloud hosted fleet that our customers can rent time one day you're going to rent time on, you know, a robot that does the single task you might rent time tomorrow on the robot that's testing the smartwatch or the AR VR headset. And so I'm basically, like the long, long term vision of the company
we want to do is we want to expand beyond iOS and Android and mobile, right? I think the market is much larger. We see any device with a touch screen, the first thing is like, Okay, if we can have one robot that pokes things, let's do all the poking in the world. I think there's a $25 billion immediate market with mobile and there's a larger $75 billion market of just robot fingers poking things in AR, VR headsets, Smart TV remotes, Roku, like connected devices, all of that. And then I think there's a separate market to, you know, even add on top of that around other, obviously form factors of the like lifting the device, pressing buttons, doing other things. And we will have to add other kinds of robots to our system. So you can actually, there's open source robot arms that you can build and set up for like three $5,000 per arm, probably less. And our robots are commoditized, basically gutted out 3d printers that we assemble each for $1,000 per robot. And we think each robot can generate 330,000 in ARR when we operate it as infrastructure, as a service. Because, again, we don't sell robots. We don't ship robots to anybody else. It's about we have this cloud hosted fleet that our customers can rent time one day you're going to rent time on, you know, a robot that does the single task you might rent time tomorrow on the robot that's testing the smartwatch or the AR VR headset. And so I'm basically, like the long, long term vision of the company
we want to do is we want to expand beyond iOS and Android and mobile, right? I think the market is much larger. We see any device with a touch screen, the first thing is like, Okay, if we can have one robot that pokes things, let's do all the poking in the world. I think there's a $25 billion immediate market with mobile and there's a larger $75 billion market of just robot fingers poking things in AR, VR headsets, Smart TV remotes, Roku, like connected devices, all of that. And then I think there's a separate market to, you know, even add on top of that around other, obviously form factors of the like lifting the device, pressing buttons, doing other things. And we will have to add other kinds of robots to our system. So you can actually, there's open source robot arms that you can build and set up for like three $5,000 per arm, probably less. And our robots are commoditized, basically gutted out 3d printers that we assemble each for $1,000 per robot. And we think each robot can generate 330,000 in ARR when we operate it as infrastructure, as a service. Because, again, we don't sell robots. We don't ship robots to anybody else. It's about we have this cloud hosted fleet that our customers can rent time one day you're going to rent time on, you know, a robot that does the single task you might rent time tomorrow on the robot that's testing the smartwatch or the AR VR headset. And so I'm basically, like the long, long term vision of the company
24:48is I want to build
S Speaker 124:52a Accenture, but it's a bunch of robots. Like any work that you are doing manually that you would farm out to Deloitte or Accenture or a PTO, you have a real robot that's like an actual human that does the work in the cloud. And you don't need to have them live at your house. They live at our house like a data center.
a Accenture, but it's a bunch of robots. Like any work that you are doing manually that you would farm out to Deloitte or Accenture or a PTO, you have a real robot that's like an actual human that does the work in the cloud. And you don't need to have them live at your house. They live at our house like a data center.
a Accenture, but it's a bunch of robots. Like any work that you are doing manually that you would farm out to Deloitte or Accenture or a PTO, you have a real robot that's like an actual human that does the work in the cloud. And you don't need to have them live at your house. They live at our house like a data center.
a Accenture, but it's a bunch of robots. Like any work that you are doing manually that you would farm out to Deloitte or Accenture or a PTO, you have a real robot that's like an actual human that does the work in the cloud. And you don't need to have them live at your house. They live at our house like a data center.
S Speaker 225:10Absolutely. So in terms of expansion, are there any of these specific markets that you're targeting first? And would the expansion be first on the robot fidelity, or on the form factor end.
Absolutely. So in terms of expansion, are there any of these specific markets that you're targeting first? And would the expansion be first on the robot fidelity, or on the form factor end.
Absolutely. So in terms of expansion, are there any of these specific markets that you're targeting first? And would the expansion be first on the robot fidelity, or on the form factor end.
Absolutely. So in terms of expansion, are there any of these specific markets that you're targeting first? And would the expansion be first on the robot fidelity, or on the form factor end.
S Speaker 125:24I think we've seen right now that the most easy expansions come from IoT and medical devices that have mobile adjacent platforms because, like, they're already using iOS and Android, and they have a smart watch, or it's a Bluetooth peripheral, kind of like what you saw. I think we talked about best by health last time. And so that's kind of our springboard. Is okay. If we can do those devices, then we can also do basically any other Linux based touch screen or device or flat point of sale kiosk, you know, Android Auto, Apple CarPlay, aviation, cockpit touch screen. That's, that's another, you know, goal. And so I am, like, the first goal is, like, I think we can honestly spend the next three to five years going after every touch screen in what, no matter what, operating system like, operating system agnostic, every single touch screen. And that's a huge, you know, market as it is. But yes, I think that also gives us the time to develop our technology to be also, you know, adding other kinds of robotics as well. Got
I think we've seen right now that the most easy expansions come from IoT and medical devices that have mobile adjacent platforms because, like, they're already using iOS and Android, and they have a smart watch, or it's a Bluetooth peripheral, kind of like what you saw. I think we talked about best by health last time. And so that's kind of our springboard. Is okay. If we can do those devices, then we can also do basically any other Linux based touch screen or device or flat point of sale kiosk, you know, Android Auto, Apple CarPlay, aviation, cockpit touch screen. That's, that's another, you know, goal. And so I am, like, the first goal is, like, I think we can honestly spend the next three to five years going after every touch screen in what, no matter what, operating system like, operating system agnostic, every single touch screen. And that's a huge, you know, market as it is. But yes, I think that also gives us the time to develop our technology to be also, you know, adding other kinds of robotics as well. Got
I think we've seen right now that the most easy expansions come from IoT and medical devices that have mobile adjacent platforms because, like, they're already using iOS and Android, and they have a smart watch, or it's a Bluetooth peripheral, kind of like what you saw. I think we talked about best by health last time. And so that's kind of our springboard. Is okay. If we can do those devices, then we can also do basically any other Linux based touch screen or device or flat point of sale kiosk, you know, Android Auto, Apple CarPlay, aviation, cockpit touch screen. That's, that's another, you know, goal. And so I am, like, the first goal is, like, I think we can honestly spend the next three to five years going after every touch screen in what, no matter what, operating system like, operating system agnostic, every single touch screen. And that's a huge, you know, market as it is. But yes, I think that also gives us the time to develop our technology to be also, you know, adding other kinds of robotics as well. Got
I think we've seen right now that the most easy expansions come from IoT and medical devices that have mobile adjacent platforms because, like, they're already using iOS and Android, and they have a smart watch, or it's a Bluetooth peripheral, kind of like what you saw. I think we talked about best by health last time. And so that's kind of our springboard. Is okay. If we can do those devices, then we can also do basically any other Linux based touch screen or device or flat point of sale kiosk, you know, Android Auto, Apple CarPlay, aviation, cockpit touch screen. That's, that's another, you know, goal. And so I am, like, the first goal is, like, I think we can honestly spend the next three to five years going after every touch screen in what, no matter what, operating system like, operating system agnostic, every single touch screen. And that's a huge, you know, market as it is. But yes, I think that also gives us the time to develop our technology to be also, you know, adding other kinds of robotics as well. Got
S Speaker 226:32it. Got it. Iran would like to spend a few minutes on the pipeline. I think you mentioned you plan to be doubling next year. How is that looking up? Do you have a robust power client? How is the sales process going things like that? Yeah. So
it. Got it. Iran would like to spend a few minutes on the pipeline. I think you mentioned you plan to be doubling next year. How is that looking up? Do you have a robust power client? How is the sales process going things like that? Yeah. So
it. Got it. Iran would like to spend a few minutes on the pipeline. I think you mentioned you plan to be doubling next year. How is that looking up? Do you have a robust power client? How is the sales process going things like that? Yeah. So
it. Got it. Iran would like to spend a few minutes on the pipeline. I think you mentioned you plan to be doubling next year. How is that looking up? Do you have a robust power client? How is the sales process going things like that? Yeah. So
27:17think that's kind of what, what,
think that's kind of what, what,
think that's kind of what, what,
think that's kind of what, what,
S Speaker 127:18what will allow us to scale is like they they're very regulated, so they need to have a very thorough paper trail. They're willing to pay a premium for it. They already have a lot of manual labor that we can displace, and so those are the kinds of companies that we're targeting. But you also saw like we are expanding more into like E commerce. So for example, we have this pilot that we just kicked off with Macy's, and so that is a proof of concept for, you know, this quarter, and we're hoping that will convert into a real customer in 2025
what will allow us to scale is like they they're very regulated, so they need to have a very thorough paper trail. They're willing to pay a premium for it. They already have a lot of manual labor that we can displace, and so those are the kinds of companies that we're targeting. But you also saw like we are expanding more into like E commerce. So for example, we have this pilot that we just kicked off with Macy's, and so that is a proof of concept for, you know, this quarter, and we're hoping that will convert into a real customer in 2025
what will allow us to scale is like they they're very regulated, so they need to have a very thorough paper trail. They're willing to pay a premium for it. They already have a lot of manual labor that we can displace, and so those are the kinds of companies that we're targeting. But you also saw like we are expanding more into like E commerce. So for example, we have this pilot that we just kicked off with Macy's, and so that is a proof of concept for, you know, this quarter, and we're hoping that will convert into a real customer in 2025
what will allow us to scale is like they they're very regulated, so they need to have a very thorough paper trail. They're willing to pay a premium for it. They already have a lot of manual labor that we can displace, and so those are the kinds of companies that we're targeting. But you also saw like we are expanding more into like E commerce. So for example, we have this pilot that we just kicked off with Macy's, and so that is a proof of concept for, you know, this quarter, and we're hoping that will convert into a real customer in 2025
S Speaker 227:50got it so, financial services and healthcare, seems like a couple of ICP markets. Roughly what fraction of your revenue comes from those sectors.
got it so, financial services and healthcare, seems like a couple of ICP markets. Roughly what fraction of your revenue comes from those sectors.
got it so, financial services and healthcare, seems like a couple of ICP markets. Roughly what fraction of your revenue comes from those sectors.
got it so, financial services and healthcare, seems like a couple of ICP markets. Roughly what fraction of your revenue comes from those sectors.
S Speaker 128:02Um, I can get the exact but I would say chime and Best Buy health are two of our biggest customers. But I would Yeah, like, I can definitely get you a distribution if probably, like, half of our our customers come from FinTech and medical devices and regular regulated industries. And then I think the other half kind of comes from, like, your consumer apps. Like, we have a couple dating apps that use mobile like, you know, rappy is the Super App, right? Like, a Door Dash types, type app. The Olympic channel is, you know, like you watch sports. Like, I don't know if that's not, that's not ICP, but it is like mobile first so I would say that's the third segment, right? It's like FinTech, medical devices and anything where, like, it's social media or mobile first focus, like, LinkedIn has a very mobile focused approach. That's why they also use mobile.
Um, I can get the exact but I would say chime and Best Buy health are two of our biggest customers. But I would Yeah, like, I can definitely get you a distribution if probably, like, half of our our customers come from FinTech and medical devices and regular regulated industries. And then I think the other half kind of comes from, like, your consumer apps. Like, we have a couple dating apps that use mobile like, you know, rappy is the Super App, right? Like, a Door Dash types, type app. The Olympic channel is, you know, like you watch sports. Like, I don't know if that's not, that's not ICP, but it is like mobile first so I would say that's the third segment, right? It's like FinTech, medical devices and anything where, like, it's social media or mobile first focus, like, LinkedIn has a very mobile focused approach. That's why they also use mobile.
Um, I can get the exact but I would say chime and Best Buy health are two of our biggest customers. But I would Yeah, like, I can definitely get you a distribution if probably, like, half of our our customers come from FinTech and medical devices and regular regulated industries. And then I think the other half kind of comes from, like, your consumer apps. Like, we have a couple dating apps that use mobile like, you know, rappy is the Super App, right? Like, a Door Dash types, type app. The Olympic channel is, you know, like you watch sports. Like, I don't know if that's not, that's not ICP, but it is like mobile first so I would say that's the third segment, right? It's like FinTech, medical devices and anything where, like, it's social media or mobile first focus, like, LinkedIn has a very mobile focused approach. That's why they also use mobile.
Um, I can get the exact but I would say chime and Best Buy health are two of our biggest customers. But I would Yeah, like, I can definitely get you a distribution if probably, like, half of our our customers come from FinTech and medical devices and regular regulated industries. And then I think the other half kind of comes from, like, your consumer apps. Like, we have a couple dating apps that use mobile like, you know, rappy is the Super App, right? Like, a Door Dash types, type app. The Olympic channel is, you know, like you watch sports. Like, I don't know if that's not, that's not ICP, but it is like mobile first so I would say that's the third segment, right? It's like FinTech, medical devices and anything where, like, it's social media or mobile first focus, like, LinkedIn has a very mobile focused approach. That's why they also use mobile.
S Speaker 129:19I think predominantly like, we've definitely seen consistent land and expand like, I think you probably talked about like last time, our net revenue retention for our enterprise cohort is 161% but I think most of our pipeline is from new deals, especially because we're trying to expand very aggressively. But I think, you know, like, we usually account for 20 to 25% of our pipeline being
I think predominantly like, we've definitely seen consistent land and expand like, I think you probably talked about like last time, our net revenue retention for our enterprise cohort is 161% but I think most of our pipeline is from new deals, especially because we're trying to expand very aggressively. But I think, you know, like, we usually account for 20 to 25% of our pipeline being
I think predominantly like, we've definitely seen consistent land and expand like, I think you probably talked about like last time, our net revenue retention for our enterprise cohort is 161% but I think most of our pipeline is from new deals, especially because we're trying to expand very aggressively. But I think, you know, like, we usually account for 20 to 25% of our pipeline being
I think predominantly like, we've definitely seen consistent land and expand like, I think you probably talked about like last time, our net revenue retention for our enterprise cohort is 161% but I think most of our pipeline is from new deals, especially because we're trying to expand very aggressively. But I think, you know, like, we usually account for 20 to 25% of our pipeline being
S Speaker 229:47from up to got it and how's the sales motion like, how do you sell today? What part of it is outbound, what part of it is inbound? Things like that,
from up to got it and how's the sales motion like, how do you sell today? What part of it is outbound, what part of it is inbound? Things like that,
from up to got it and how's the sales motion like, how do you sell today? What part of it is outbound, what part of it is inbound? Things like that,
from up to got it and how's the sales motion like, how do you sell today? What part of it is outbound, what part of it is inbound? Things like that,
S Speaker 129:5880% of our sales are are outbound. 20% is inbound. We have two AES. We have two SDRs that are doing prospecting, and exactly the ICP that we mentioned. And then, you know, we do, like an initial discovery call, we do a demo on their app. And then we'll, usually, you know, go through procurement and they'll convert into a paid pilot for, usually one to three months. They get to use the platform. We define metrics for success, and then they they convert into into an initial annual contract. We'll usually do that with one team, and then we gradually expand across other teams and other use cases after we calculate how many credits you need based on the number of devices, number of features, and that's going to be different for each team. So there's also that piece, and then our pricing model is basically credits, where every robot tap that you execute consumes one credit. If you use our AI to generate new robot sequences. It's five credits consumed per one generated action. And then you basically can, can you purchase buckets quarterly or annually, or you can also monthly, but it's an annual contract. Even if you're paying monthly, you just get a better discount if you pay annually.
80% of our sales are are outbound. 20% is inbound. We have two AES. We have two SDRs that are doing prospecting, and exactly the ICP that we mentioned. And then, you know, we do, like an initial discovery call, we do a demo on their app. And then we'll, usually, you know, go through procurement and they'll convert into a paid pilot for, usually one to three months. They get to use the platform. We define metrics for success, and then they they convert into into an initial annual contract. We'll usually do that with one team, and then we gradually expand across other teams and other use cases after we calculate how many credits you need based on the number of devices, number of features, and that's going to be different for each team. So there's also that piece, and then our pricing model is basically credits, where every robot tap that you execute consumes one credit. If you use our AI to generate new robot sequences. It's five credits consumed per one generated action. And then you basically can, can you purchase buckets quarterly or annually, or you can also monthly, but it's an annual contract. Even if you're paying monthly, you just get a better discount if you pay annually.
80% of our sales are are outbound. 20% is inbound. We have two AES. We have two SDRs that are doing prospecting, and exactly the ICP that we mentioned. And then, you know, we do, like an initial discovery call, we do a demo on their app. And then we'll, usually, you know, go through procurement and they'll convert into a paid pilot for, usually one to three months. They get to use the platform. We define metrics for success, and then they they convert into into an initial annual contract. We'll usually do that with one team, and then we gradually expand across other teams and other use cases after we calculate how many credits you need based on the number of devices, number of features, and that's going to be different for each team. So there's also that piece, and then our pricing model is basically credits, where every robot tap that you execute consumes one credit. If you use our AI to generate new robot sequences. It's five credits consumed per one generated action. And then you basically can, can you purchase buckets quarterly or annually, or you can also monthly, but it's an annual contract. Even if you're paying monthly, you just get a better discount if you pay annually.
80% of our sales are are outbound. 20% is inbound. We have two AES. We have two SDRs that are doing prospecting, and exactly the ICP that we mentioned. And then, you know, we do, like an initial discovery call, we do a demo on their app. And then we'll, usually, you know, go through procurement and they'll convert into a paid pilot for, usually one to three months. They get to use the platform. We define metrics for success, and then they they convert into into an initial annual contract. We'll usually do that with one team, and then we gradually expand across other teams and other use cases after we calculate how many credits you need based on the number of devices, number of features, and that's going to be different for each team. So there's also that piece, and then our pricing model is basically credits, where every robot tap that you execute consumes one credit. If you use our AI to generate new robot sequences. It's five credits consumed per one generated action. And then you basically can, can you purchase buckets quarterly or annually, or you can also monthly, but it's an annual contract. Even if you're paying monthly, you just get a better discount if you pay annually.
S Speaker 231:19I don't think got it, got it. I don't think I understand the difference between a and b here, steps executed versus generated. A very quick answer there, please.
I don't think got it, got it. I don't think I understand the difference between a and b here, steps executed versus generated. A very quick answer there, please.
I don't think got it, got it. I don't think I understand the difference between a and b here, steps executed versus generated. A very quick answer there, please.
I don't think got it, got it. I don't think I understand the difference between a and b here, steps executed versus generated. A very quick answer there, please.
S Speaker 131:32is when we're running something that was previously generated. So the demo that I showed you where we were creating the skirt, the script that happens, you know, separately from the running of something that was already previously created. So the ongoing monitoring, like, that's faster, like you don't because what we don't want right now is, like, the AI has to stop and interpret every screen that's going to be very slow during run time. So there's, like, the setup and the generation process, and you set it up and do it once, and then we run it. And then as you run it, we're maintaining it, but running is sort of a separate process, and that's a, and then B is the generation process that happens during initial setup. Understood.
is when we're running something that was previously generated. So the demo that I showed you where we were creating the skirt, the script that happens, you know, separately from the running of something that was already previously created. So the ongoing monitoring, like, that's faster, like you don't because what we don't want right now is, like, the AI has to stop and interpret every screen that's going to be very slow during run time. So there's, like, the setup and the generation process, and you set it up and do it once, and then we run it. And then as you run it, we're maintaining it, but running is sort of a separate process, and that's a, and then B is the generation process that happens during initial setup. Understood.
is when we're running something that was previously generated. So the demo that I showed you where we were creating the skirt, the script that happens, you know, separately from the running of something that was already previously created. So the ongoing monitoring, like, that's faster, like you don't because what we don't want right now is, like, the AI has to stop and interpret every screen that's going to be very slow during run time. So there's, like, the setup and the generation process, and you set it up and do it once, and then we run it. And then as you run it, we're maintaining it, but running is sort of a separate process, and that's a, and then B is the generation process that happens during initial setup. Understood.
is when we're running something that was previously generated. So the demo that I showed you where we were creating the skirt, the script that happens, you know, separately from the running of something that was already previously created. So the ongoing monitoring, like, that's faster, like you don't because what we don't want right now is, like, the AI has to stop and interpret every screen that's going to be very slow during run time. So there's, like, the setup and the generation process, and you set it up and do it once, and then we run it. And then as you run it, we're maintaining it, but running is sort of a separate process, and that's a, and then B is the generation process that happens during initial setup. Understood.
S Speaker 232:12Last question, Eden, how long does the typical average sales cycle look like from the discovery call to finally signing the contracts. And do you come across some of these traditional testing players when you are competing with some of these new especially in the enterprise segment,
Last question, Eden, how long does the typical average sales cycle look like from the discovery call to finally signing the contracts. And do you come across some of these traditional testing players when you are competing with some of these new especially in the enterprise segment,
Last question, Eden, how long does the typical average sales cycle look like from the discovery call to finally signing the contracts. And do you come across some of these traditional testing players when you are competing with some of these new especially in the enterprise segment,
Last question, Eden, how long does the typical average sales cycle look like from the discovery call to finally signing the contracts. And do you come across some of these traditional testing players when you are competing with some of these new especially in the enterprise segment,
S Speaker 132:32we're definitely competing for the same budget. But I think usually the sales process is pretty simple, where we show them, hey, you're using lambda test. Like, okay, do they do any of these things? And everyone's like, No. And I'm like, that's where we're focused. Like, we're not here to replace lambda test. We're here to do these things first, and then they get into our platform and they use it for these things, and then they end up realizing we're actually better. And sometimes some companies will switch. Some companies will continue to use both, and that's kind of the way that we navigate with them. What was your other question? Oh, yes, sales cycle, it is. As we move up market, we expect it to take longer, you know, I think it's been, on average, about 100 something days, sometimes less. The reason is that we keep the contract sizes on the smaller side right. Our average starting ACV, is about 35,000 kind of what you see here. And then, because we expect there to be a larger expansion, you know, afterwards. So we would prefer to kind of lock them in one use case, one project, and then we kind of expanded
we're definitely competing for the same budget. But I think usually the sales process is pretty simple, where we show them, hey, you're using lambda test. Like, okay, do they do any of these things? And everyone's like, No. And I'm like, that's where we're focused. Like, we're not here to replace lambda test. We're here to do these things first, and then they get into our platform and they use it for these things, and then they end up realizing we're actually better. And sometimes some companies will switch. Some companies will continue to use both, and that's kind of the way that we navigate with them. What was your other question? Oh, yes, sales cycle, it is. As we move up market, we expect it to take longer, you know, I think it's been, on average, about 100 something days, sometimes less. The reason is that we keep the contract sizes on the smaller side right. Our average starting ACV, is about 35,000 kind of what you see here. And then, because we expect there to be a larger expansion, you know, afterwards. So we would prefer to kind of lock them in one use case, one project, and then we kind of expanded
we're definitely competing for the same budget. But I think usually the sales process is pretty simple, where we show them, hey, you're using lambda test. Like, okay, do they do any of these things? And everyone's like, No. And I'm like, that's where we're focused. Like, we're not here to replace lambda test. We're here to do these things first, and then they get into our platform and they use it for these things, and then they end up realizing we're actually better. And sometimes some companies will switch. Some companies will continue to use both, and that's kind of the way that we navigate with them. What was your other question? Oh, yes, sales cycle, it is. As we move up market, we expect it to take longer, you know, I think it's been, on average, about 100 something days, sometimes less. The reason is that we keep the contract sizes on the smaller side right. Our average starting ACV, is about 35,000 kind of what you see here. And then, because we expect there to be a larger expansion, you know, afterwards. So we would prefer to kind of lock them in one use case, one project, and then we kind of expanded
we're definitely competing for the same budget. But I think usually the sales process is pretty simple, where we show them, hey, you're using lambda test. Like, okay, do they do any of these things? And everyone's like, No. And I'm like, that's where we're focused. Like, we're not here to replace lambda test. We're here to do these things first, and then they get into our platform and they use it for these things, and then they end up realizing we're actually better. And sometimes some companies will switch. Some companies will continue to use both, and that's kind of the way that we navigate with them. What was your other question? Oh, yes, sales cycle, it is. As we move up market, we expect it to take longer, you know, I think it's been, on average, about 100 something days, sometimes less. The reason is that we keep the contract sizes on the smaller side right. Our average starting ACV, is about 35,000 kind of what you see here. And then, because we expect there to be a larger expansion, you know, afterwards. So we would prefer to kind of lock them in one use case, one project, and then we kind of expanded
S Speaker 134:13okay, yeah, we basically, the main way to think about mobile, though, is we're we're trying to replace labor. We're not trying to replace tools. And that's kind of what, where you see, for example, this case study, like chime didn't I mean, chime has detox, like they still run those tests. They have all these other tests that they are not mobile, is not replacing but we replaced five people. That was who we replaced. Like our direct competitors, are not Browser Stack. So I also, and I want to be mindful of that, because I see the ceiling and I, you know, Browser Stack, I think, is not actually as large as of a company as I would think it could be. You know, they're obviously tremendously successful, but they are constrained with certain types of tests they can run on web, and they're constrained by the inherent scaffolding of the document object model and selenium and even other kind of scripting tools. And we are trying to play in the market where we replace labor and not and services. And so we're replacing an Accenture contract, we're replacing Deloitte, we're replacing internal team members, and that inherently is in this in this case study, because chime had three rounds of layoffs and consolidated their
okay, yeah, we basically, the main way to think about mobile, though, is we're we're trying to replace labor. We're not trying to replace tools. And that's kind of what, where you see, for example, this case study, like chime didn't I mean, chime has detox, like they still run those tests. They have all these other tests that they are not mobile, is not replacing but we replaced five people. That was who we replaced. Like our direct competitors, are not Browser Stack. So I also, and I want to be mindful of that, because I see the ceiling and I, you know, Browser Stack, I think, is not actually as large as of a company as I would think it could be. You know, they're obviously tremendously successful, but they are constrained with certain types of tests they can run on web, and they're constrained by the inherent scaffolding of the document object model and selenium and even other kind of scripting tools. And we are trying to play in the market where we replace labor and not and services. And so we're replacing an Accenture contract, we're replacing Deloitte, we're replacing internal team members, and that inherently is in this in this case study, because chime had three rounds of layoffs and consolidated their
okay, yeah, we basically, the main way to think about mobile, though, is we're we're trying to replace labor. We're not trying to replace tools. And that's kind of what, where you see, for example, this case study, like chime didn't I mean, chime has detox, like they still run those tests. They have all these other tests that they are not mobile, is not replacing but we replaced five people. That was who we replaced. Like our direct competitors, are not Browser Stack. So I also, and I want to be mindful of that, because I see the ceiling and I, you know, Browser Stack, I think, is not actually as large as of a company as I would think it could be. You know, they're obviously tremendously successful, but they are constrained with certain types of tests they can run on web, and they're constrained by the inherent scaffolding of the document object model and selenium and even other kind of scripting tools. And we are trying to play in the market where we replace labor and not and services. And so we're replacing an Accenture contract, we're replacing Deloitte, we're replacing internal team members, and that inherently is in this in this case study, because chime had three rounds of layoffs and consolidated their
okay, yeah, we basically, the main way to think about mobile, though, is we're we're trying to replace labor. We're not trying to replace tools. And that's kind of what, where you see, for example, this case study, like chime didn't I mean, chime has detox, like they still run those tests. They have all these other tests that they are not mobile, is not replacing but we replaced five people. That was who we replaced. Like our direct competitors, are not Browser Stack. So I also, and I want to be mindful of that, because I see the ceiling and I, you know, Browser Stack, I think, is not actually as large as of a company as I would think it could be. You know, they're obviously tremendously successful, but they are constrained with certain types of tests they can run on web, and they're constrained by the inherent scaffolding of the document object model and selenium and even other kind of scripting tools. And we are trying to play in the market where we replace labor and not and services. And so we're replacing an Accenture contract, we're replacing Deloitte, we're replacing internal team members, and that inherently is in this in this case study, because chime had three rounds of layoffs and consolidated their
35:31QA team and they expanded their robot coverage. Yeah, that's
QA team and they expanded their robot coverage. Yeah, that's
QA team and they expanded their robot coverage. Yeah, that's
QA team and they expanded their robot coverage. Yeah, that's
S Speaker 235:35fair. Thanks a lot for the clarification again. Eden, yeah, absolutely, yeah,
fair. Thanks a lot for the clarification again. Eden, yeah, absolutely, yeah,
fair. Thanks a lot for the clarification again. Eden, yeah, absolutely, yeah,
fair. Thanks a lot for the clarification again. Eden, yeah, absolutely, yeah,
S Speaker 235:48Yeah, I'd love to schedule a follow up calls with probably one of the partners sometime mid next week, but I'll come back to you with those details. Give me some time by the end of Monday to come back. Okay, yeah that sounds very good thank
Yeah, I'd love to schedule a follow up calls with probably one of the partners sometime mid next week, but I'll come back to you with those details. Give me some time by the end of Monday to come back. Okay, yeah that sounds very good thank
Yeah, I'd love to schedule a follow up calls with probably one of the partners sometime mid next week, but I'll come back to you with those details. Give me some time by the end of Monday to come back. Okay, yeah that sounds very good thank
Yeah, I'd love to schedule a follow up calls with probably one of the partners sometime mid next week, but I'll come back to you with those details. Give me some time by the end of Monday to come back. Okay, yeah that sounds very good thank
36:04you. Absolutely. Thanks, Eden Thanks. Appreciate your time.
you. Absolutely. Thanks, Eden Thanks. Appreciate your time.
you. Absolutely. Thanks, Eden Thanks. Appreciate your time.
you. Absolutely. Thanks, Eden Thanks. Appreciate your time.
36:06All right, talk to you, bye.
All right, talk to you, bye.
All right, talk to you, bye.
All right, talk to you, bye.