Meeting: Sanctum AI
Tue, Nov 18
1:00 PM
23 min
Priyesh P
Introduction and Meeting Purpose
0:01
Speaker 1's Ba
URL: https://otter.ai/u/mTUQgilLZJjNzlMDCjXWM-L9WRs
Downloaded: 2025-12-21T19:34:42.115088
Method: text_extraction
============================================================

S Speaker 10:01Thanks Hey, Rushan, can you hear me? Yeah, I can. Can you hear me? Hey, yes, hi, rushank, how you doing, man?
Thanks Hey, Rushan, can you hear me? Yeah, I can. Can you hear me? Hey, yes, hi, rushank, how you doing, man?
Thanks Hey, Rushan, can you hear me? Yeah, I can. Can you hear me? Hey, yes, hi, rushank, how you doing, man?
Thanks Hey, Rushan, can you hear me? Yeah, I can. Can you hear me? Hey, yes, hi, rushank, how you doing, man?
S Speaker 20:33I'm doing well, thanks for taking the time, by the way. Sorry, no,
I'm doing well, thanks for taking the time, by the way. Sorry, no,
I'm doing well, thanks for taking the time, by the way. Sorry, no,
I'm doing well, thanks for taking the time, by the way. Sorry, no,
S Speaker 10:37absolutely, we had scheduled it. I wanted to stick with it. There's like, a bunch of things going and I'm traveling the next few days, so I wanted to sort of put some things together before I leave. But totally okay, would love to chat. This is, this is a thesis I've been following. I've met one more company in this space. Really interesting. Say, I would say the vision I strongly believe in. I've gone through the demo video. I have a little bit of understanding of what you do. Would love to sort of talk further about the tech stack, how you expose yourself and all of that. But before we start, happy to give you a background about myself and the fund, how we how we decide, and key point there being rushank. Our check sizes are two to $15 million so I'm just thinking maybe this round is a round early for us, but but on the flip side, a lot of strategic partnership opportunity that I can see. So I'd still have a chat with the team and try to bring this up and see where we stand. Eventually, I'll come back to you by early next week on the entire discussion, but very quickly about myself. I am Priyesh, currently a senior associate here in the team, been been with the Fund for two years, been in venture for four worked with Menlo Ventures in Bay for some time, and then with Morpheus ventures in LA before that. And then, originally from India, did my undergrad over there, worked with a lot of early stage startups in the last stint of my career, phase the fund itself has been around for 25 years. So we have deployed 3 billion in capital, 400 plus portfolio companies being been there for for a long time. We have seen cycles. And currently, I would say check sizes is two to 15. Very stage agnostic, investing in a lot of industries, AI being a very big focus area, especially rushon, because corporate Qualcomm as a corporate is expanding its product line across multiple platforms. So we were earlier into mobiles and Network Connectivity. Now there's a chip which goes into PCs, there's a cloud inferencing chip. There's there are chips for wearables and xr and multiple something going into smart cars and all of those areas, right? And we feel through these silicon platforms, we can enable a strong go to market opportunity for a lot of prospects and companies that we invest in. So that's broadly, say, the strategic angle here, and particularly for your use case, I understand you take in a lot of information from screen recordings and other other materials to simulate user behavior. A lot of that can be done on edge. Eventually, you would like to have some of those screen recordings private, and some of these models running on edge because of privacy, cost, latency and all of those reasons. So that's some some angles that we can work together on. Yeah,
absolutely, we had scheduled it. I wanted to stick with it. There's like, a bunch of things going and I'm traveling the next few days, so I wanted to sort of put some things together before I leave. But totally okay, would love to chat. This is, this is a thesis I've been following. I've met one more company in this space. Really interesting. Say, I would say the vision I strongly believe in. I've gone through the demo video. I have a little bit of understanding of what you do. Would love to sort of talk further about the tech stack, how you expose yourself and all of that. But before we start, happy to give you a background about myself and the fund, how we how we decide, and key point there being rushank. Our check sizes are two to $15 million so I'm just thinking maybe this round is a round early for us, but but on the flip side, a lot of strategic partnership opportunity that I can see. So I'd still have a chat with the team and try to bring this up and see where we stand. Eventually, I'll come back to you by early next week on the entire discussion, but very quickly about myself. I am Priyesh, currently a senior associate here in the team, been been with the Fund for two years, been in venture for four worked with Menlo Ventures in Bay for some time, and then with Morpheus ventures in LA before that. And then, originally from India, did my undergrad over there, worked with a lot of early stage startups in the last stint of my career, phase the fund itself has been around for 25 years. So we have deployed 3 billion in capital, 400 plus portfolio companies being been there for for a long time. We have seen cycles. And currently, I would say check sizes is two to 15. Very stage agnostic, investing in a lot of industries, AI being a very big focus area, especially rushon, because corporate Qualcomm as a corporate is expanding its product line across multiple platforms. So we were earlier into mobiles and Network Connectivity. Now there's a chip which goes into PCs, there's a cloud inferencing chip. There's there are chips for wearables and xr and multiple something going into smart cars and all of those areas, right? And we feel through these silicon platforms, we can enable a strong go to market opportunity for a lot of prospects and companies that we invest in. So that's broadly, say, the strategic angle here, and particularly for your use case, I understand you take in a lot of information from screen recordings and other other materials to simulate user behavior. A lot of that can be done on edge. Eventually, you would like to have some of those screen recordings private, and some of these models running on edge because of privacy, cost, latency and all of those reasons. So that's some some angles that we can work together on. Yeah,
absolutely, we had scheduled it. I wanted to stick with it. There's like, a bunch of things going and I'm traveling the next few days, so I wanted to sort of put some things together before I leave. But totally okay, would love to chat. This is, this is a thesis I've been following. I've met one more company in this space. Really interesting. Say, I would say the vision I strongly believe in. I've gone through the demo video. I have a little bit of understanding of what you do. Would love to sort of talk further about the tech stack, how you expose yourself and all of that. But before we start, happy to give you a background about myself and the fund, how we how we decide, and key point there being rushank. Our check sizes are two to $15 million so I'm just thinking maybe this round is a round early for us, but but on the flip side, a lot of strategic partnership opportunity that I can see. So I'd still have a chat with the team and try to bring this up and see where we stand. Eventually, I'll come back to you by early next week on the entire discussion, but very quickly about myself. I am Priyesh, currently a senior associate here in the team, been been with the Fund for two years, been in venture for four worked with Menlo Ventures in Bay for some time, and then with Morpheus ventures in LA before that. And then, originally from India, did my undergrad over there, worked with a lot of early stage startups in the last stint of my career, phase the fund itself has been around for 25 years. So we have deployed 3 billion in capital, 400 plus portfolio companies being been there for for a long time. We have seen cycles. And currently, I would say check sizes is two to 15. Very stage agnostic, investing in a lot of industries, AI being a very big focus area, especially rushon, because corporate Qualcomm as a corporate is expanding its product line across multiple platforms. So we were earlier into mobiles and Network Connectivity. Now there's a chip which goes into PCs, there's a cloud inferencing chip. There's there are chips for wearables and xr and multiple something going into smart cars and all of those areas, right? And we feel through these silicon platforms, we can enable a strong go to market opportunity for a lot of prospects and companies that we invest in. So that's broadly, say, the strategic angle here, and particularly for your use case, I understand you take in a lot of information from screen recordings and other other materials to simulate user behavior. A lot of that can be done on edge. Eventually, you would like to have some of those screen recordings private, and some of these models running on edge because of privacy, cost, latency and all of those reasons. So that's some some angles that we can work together on. Yeah,
absolutely, we had scheduled it. I wanted to stick with it. There's like, a bunch of things going and I'm traveling the next few days, so I wanted to sort of put some things together before I leave. But totally okay, would love to chat. This is, this is a thesis I've been following. I've met one more company in this space. Really interesting. Say, I would say the vision I strongly believe in. I've gone through the demo video. I have a little bit of understanding of what you do. Would love to sort of talk further about the tech stack, how you expose yourself and all of that. But before we start, happy to give you a background about myself and the fund, how we how we decide, and key point there being rushank. Our check sizes are two to $15 million so I'm just thinking maybe this round is a round early for us, but but on the flip side, a lot of strategic partnership opportunity that I can see. So I'd still have a chat with the team and try to bring this up and see where we stand. Eventually, I'll come back to you by early next week on the entire discussion, but very quickly about myself. I am Priyesh, currently a senior associate here in the team, been been with the Fund for two years, been in venture for four worked with Menlo Ventures in Bay for some time, and then with Morpheus ventures in LA before that. And then, originally from India, did my undergrad over there, worked with a lot of early stage startups in the last stint of my career, phase the fund itself has been around for 25 years. So we have deployed 3 billion in capital, 400 plus portfolio companies being been there for for a long time. We have seen cycles. And currently, I would say check sizes is two to 15. Very stage agnostic, investing in a lot of industries, AI being a very big focus area, especially rushon, because corporate Qualcomm as a corporate is expanding its product line across multiple platforms. So we were earlier into mobiles and Network Connectivity. Now there's a chip which goes into PCs, there's a cloud inferencing chip. There's there are chips for wearables and xr and multiple something going into smart cars and all of those areas, right? And we feel through these silicon platforms, we can enable a strong go to market opportunity for a lot of prospects and companies that we invest in. So that's broadly, say, the strategic angle here, and particularly for your use case, I understand you take in a lot of information from screen recordings and other other materials to simulate user behavior. A lot of that can be done on edge. Eventually, you would like to have some of those screen recordings private, and some of these models running on edge because of privacy, cost, latency and all of those reasons. So that's some some angles that we can work together on. Yeah,
S Speaker 33:32totally. I totally agree with that as well. I mean, when I was back in college, a lot of the work that I was doing was on, like, zero knowledge proof, specifically to put the work on edge devices and then communicate just the results to servers, and how we could make that more efficient for things like zero knowledge, login, proof of identity and stuff. But it's like, super cool, definitely something we've thought of for our current space as well.
totally. I totally agree with that as well. I mean, when I was back in college, a lot of the work that I was doing was on, like, zero knowledge proof, specifically to put the work on edge devices and then communicate just the results to servers, and how we could make that more efficient for things like zero knowledge, login, proof of identity and stuff. But it's like, super cool, definitely something we've thought of for our current space as well.
totally. I totally agree with that as well. I mean, when I was back in college, a lot of the work that I was doing was on, like, zero knowledge proof, specifically to put the work on edge devices and then communicate just the results to servers, and how we could make that more efficient for things like zero knowledge, login, proof of identity and stuff. But it's like, super cool, definitely something we've thought of for our current space as well.
totally. I totally agree with that as well. I mean, when I was back in college, a lot of the work that I was doing was on, like, zero knowledge proof, specifically to put the work on edge devices and then communicate just the results to servers, and how we could make that more efficient for things like zero knowledge, login, proof of identity and stuff. But it's like, super cool, definitely something we've thought of for our current space as well.
S Speaker 13:52100% yes, yes, totally agree. Krishna would love to get a little bit background about yourself, and then, yeah, we'll jump in.
100% yes, yes, totally agree. Krishna would love to get a little bit background about yourself, and then, yeah, we'll jump in.
100% yes, yes, totally agree. Krishna would love to get a little bit background about yourself, and then, yeah, we'll jump in.
100% yes, yes, totally agree. Krishna would love to get a little bit background about yourself, and then, yeah, we'll jump in.
4:39So maybe it'd be nice for you to
So maybe it'd be nice for you to
So maybe it'd be nice for you to
So maybe it'd be nice for you to
4:40just see the product. So let's go to
just see the product. So let's go to
just see the product. So let's go to
just see the product. So let's go to
4:48sorry my computer has been really slow today,
sorry my computer has been really slow today,
sorry my computer has been really slow today,
sorry my computer has been really slow today,
4:52lot of workload on it.
lot of workload on it.
lot of workload on it.
lot of workload on it.
4:58Oh, man, here we go.
S Speaker 35:02Okay, so I think this is not what it looked like before. And so basically the core functionality is still pretty similar. Here we're still doing user simulations. So just as a recap, like we build AI agents to simulate real users the you might be wondering, I guess, like, what the initial use case or wedge might be, the thing that we found has been the most impactful to people that we've talked to right now is with QA testing specifically. And there's, like, a lot of room there we can move in the future. But for right now, we're focused specifically on that. And our main differentiation is the fact that it's, it's super, super, super easy to get up and running with us. As opposed to other platforms where you have to write plain English tests that then get turned into playwright scripts or agent instructions, or you need to handle drift and maintain tests and do all of this stuff for us, the workflow basically looks like this. We ingest your postdoc recordings. This is some seeded data right now. So I mean, it looks a little too clean, I know, but one of these lines represents like one user's recording. So here they went from adding a team member to recording an expense to searching a transaction to creating an invoice, for example. And you can see that play out in their actual session recording. And then you can go over here and manage those auto extracted flows to see, like, Oh, these are, these are the things we think your users are doing, like, actually approve them and say, this is something you want to track once you've set that stuff up. Should just be a few clicks after we ingest your stuff, you can come over here and then click on any of those approved flows and then select, you know, any number of agents, really. You could do, like, hundreds, if you want, and then you can just hit Run simulation. This will take like, two and a half minutes or so, and then you'll get, not only the bugs that it found, we seeded some errors, and so we'd expect it to fail here, but it also has end to end observability, so we have an SDK that sits on top they can integrate with open telemetry or century, or whatever you're using there. And hopefully in the future, we're going to create our own version of that that's open source, and so once the simulation finds errors, you could trace, not only console logs, network messages, you know what, what the spans were on the back end associated with this agent, and a lot more rich debugging context that you could feed directly back into Your coding tools. So this is kind of what users are using right now. So does that make sense? Any questions about that?
Okay, so I think this is not what it looked like before. And so basically the core functionality is still pretty similar. Here we're still doing user simulations. So just as a recap, like we build AI agents to simulate real users the you might be wondering, I guess, like, what the initial use case or wedge might be, the thing that we found has been the most impactful to people that we've talked to right now is with QA testing specifically. And there's, like, a lot of room there we can move in the future. But for right now, we're focused specifically on that. And our main differentiation is the fact that it's, it's super, super, super easy to get up and running with us. As opposed to other platforms where you have to write plain English tests that then get turned into playwright scripts or agent instructions, or you need to handle drift and maintain tests and do all of this stuff for us, the workflow basically looks like this. We ingest your postdoc recordings. This is some seeded data right now. So I mean, it looks a little too clean, I know, but one of these lines represents like one user's recording. So here they went from adding a team member to recording an expense to searching a transaction to creating an invoice, for example. And you can see that play out in their actual session recording. And then you can go over here and manage those auto extracted flows to see, like, Oh, these are, these are the things we think your users are doing, like, actually approve them and say, this is something you want to track once you've set that stuff up. Should just be a few clicks after we ingest your stuff, you can come over here and then click on any of those approved flows and then select, you know, any number of agents, really. You could do, like, hundreds, if you want, and then you can just hit Run simulation. This will take like, two and a half minutes or so, and then you'll get, not only the bugs that it found, we seeded some errors, and so we'd expect it to fail here, but it also has end to end observability, so we have an SDK that sits on top they can integrate with open telemetry or century, or whatever you're using there. And hopefully in the future, we're going to create our own version of that that's open source, and so once the simulation finds errors, you could trace, not only console logs, network messages, you know what, what the spans were on the back end associated with this agent, and a lot more rich debugging context that you could feed directly back into Your coding tools. So this is kind of what users are using right now. So does that make sense? Any questions about that?
Okay, so I think this is not what it looked like before. And so basically the core functionality is still pretty similar. Here we're still doing user simulations. So just as a recap, like we build AI agents to simulate real users the you might be wondering, I guess, like, what the initial use case or wedge might be, the thing that we found has been the most impactful to people that we've talked to right now is with QA testing specifically. And there's, like, a lot of room there we can move in the future. But for right now, we're focused specifically on that. And our main differentiation is the fact that it's, it's super, super, super easy to get up and running with us. As opposed to other platforms where you have to write plain English tests that then get turned into playwright scripts or agent instructions, or you need to handle drift and maintain tests and do all of this stuff for us, the workflow basically looks like this. We ingest your postdoc recordings. This is some seeded data right now. So I mean, it looks a little too clean, I know, but one of these lines represents like one user's recording. So here they went from adding a team member to recording an expense to searching a transaction to creating an invoice, for example. And you can see that play out in their actual session recording. And then you can go over here and manage those auto extracted flows to see, like, Oh, these are, these are the things we think your users are doing, like, actually approve them and say, this is something you want to track once you've set that stuff up. Should just be a few clicks after we ingest your stuff, you can come over here and then click on any of those approved flows and then select, you know, any number of agents, really. You could do, like, hundreds, if you want, and then you can just hit Run simulation. This will take like, two and a half minutes or so, and then you'll get, not only the bugs that it found, we seeded some errors, and so we'd expect it to fail here, but it also has end to end observability, so we have an SDK that sits on top they can integrate with open telemetry or century, or whatever you're using there. And hopefully in the future, we're going to create our own version of that that's open source, and so once the simulation finds errors, you could trace, not only console logs, network messages, you know what, what the spans were on the back end associated with this agent, and a lot more rich debugging context that you could feed directly back into Your coding tools. So this is kind of what users are using right now. So does that make sense? Any questions about that?
Okay, so I think this is not what it looked like before. And so basically the core functionality is still pretty similar. Here we're still doing user simulations. So just as a recap, like we build AI agents to simulate real users the you might be wondering, I guess, like, what the initial use case or wedge might be, the thing that we found has been the most impactful to people that we've talked to right now is with QA testing specifically. And there's, like, a lot of room there we can move in the future. But for right now, we're focused specifically on that. And our main differentiation is the fact that it's, it's super, super, super easy to get up and running with us. As opposed to other platforms where you have to write plain English tests that then get turned into playwright scripts or agent instructions, or you need to handle drift and maintain tests and do all of this stuff for us, the workflow basically looks like this. We ingest your postdoc recordings. This is some seeded data right now. So I mean, it looks a little too clean, I know, but one of these lines represents like one user's recording. So here they went from adding a team member to recording an expense to searching a transaction to creating an invoice, for example. And you can see that play out in their actual session recording. And then you can go over here and manage those auto extracted flows to see, like, Oh, these are, these are the things we think your users are doing, like, actually approve them and say, this is something you want to track once you've set that stuff up. Should just be a few clicks after we ingest your stuff, you can come over here and then click on any of those approved flows and then select, you know, any number of agents, really. You could do, like, hundreds, if you want, and then you can just hit Run simulation. This will take like, two and a half minutes or so, and then you'll get, not only the bugs that it found, we seeded some errors, and so we'd expect it to fail here, but it also has end to end observability, so we have an SDK that sits on top they can integrate with open telemetry or century, or whatever you're using there. And hopefully in the future, we're going to create our own version of that that's open source, and so once the simulation finds errors, you could trace, not only console logs, network messages, you know what, what the spans were on the back end associated with this agent, and a lot more rich debugging context that you could feed directly back into Your coding tools. So this is kind of what users are using right now. So does that make sense? Any questions about that?
S Speaker 17:27Totally, totally rishanka, I get that. Maybe I'd also love to take a step back and discuss, say, from a macro perspective, the first screen where you have session recordings is just session recordings, the input data. Do you that you need for it? Do you also take in logs? What sort of quantum of data would you actually require for your simulations to run perfectly? How does that accuracy level change over time, things like that.
Totally, totally rishanka, I get that. Maybe I'd also love to take a step back and discuss, say, from a macro perspective, the first screen where you have session recordings is just session recordings, the input data. Do you that you need for it? Do you also take in logs? What sort of quantum of data would you actually require for your simulations to run perfectly? How does that accuracy level change over time, things like that.
Totally, totally rishanka, I get that. Maybe I'd also love to take a step back and discuss, say, from a macro perspective, the first screen where you have session recordings is just session recordings, the input data. Do you that you need for it? Do you also take in logs? What sort of quantum of data would you actually require for your simulations to run perfectly? How does that accuracy level change over time, things like that.
Totally, totally rishanka, I get that. Maybe I'd also love to take a step back and discuss, say, from a macro perspective, the first screen where you have session recordings is just session recordings, the input data. Do you that you need for it? Do you also take in logs? What sort of quantum of data would you actually require for your simulations to run perfectly? How does that accuracy level change over time, things like that.
S Speaker 18:53Yes, I think, I think, like you earlier said, you're getting a lot of market pull from QA, but I certainly, personally would believe in the UX story as well. I think it's just that that's more of a market creation opportunity. QA already has, say, autonomous QA has been going on for long. Ai native QA has been there for some time now. So that's that's like, I think market is educated over there. But down the line, the story around UX and essentially, then making it a part of CICD pipelines for a lot of autonomous coding applications is something that I personally believe in quite a lot, that makes a lot of sense. Rushand, so what kind of companies are you currently working with, and where say, are they in their development pipeline, and how are they using Sanctum today?
Yes, I think, I think, like you earlier said, you're getting a lot of market pull from QA, but I certainly, personally would believe in the UX story as well. I think it's just that that's more of a market creation opportunity. QA already has, say, autonomous QA has been going on for long. Ai native QA has been there for some time now. So that's that's like, I think market is educated over there. But down the line, the story around UX and essentially, then making it a part of CICD pipelines for a lot of autonomous coding applications is something that I personally believe in quite a lot, that makes a lot of sense. Rushand, so what kind of companies are you currently working with, and where say, are they in their development pipeline, and how are they using Sanctum today?
Yes, I think, I think, like you earlier said, you're getting a lot of market pull from QA, but I certainly, personally would believe in the UX story as well. I think it's just that that's more of a market creation opportunity. QA already has, say, autonomous QA has been going on for long. Ai native QA has been there for some time now. So that's that's like, I think market is educated over there. But down the line, the story around UX and essentially, then making it a part of CICD pipelines for a lot of autonomous coding applications is something that I personally believe in quite a lot, that makes a lot of sense. Rushand, so what kind of companies are you currently working with, and where say, are they in their development pipeline, and how are they using Sanctum today?
Yes, I think, I think, like you earlier said, you're getting a lot of market pull from QA, but I certainly, personally would believe in the UX story as well. I think it's just that that's more of a market creation opportunity. QA already has, say, autonomous QA has been going on for long. Ai native QA has been there for some time now. So that's that's like, I think market is educated over there. But down the line, the story around UX and essentially, then making it a part of CICD pipelines for a lot of autonomous coding applications is something that I personally believe in quite a lot, that makes a lot of sense. Rushand, so what kind of companies are you currently working with, and where say, are they in their development pipeline, and how are they using Sanctum today?
S Speaker 39:46Yeah, those are all great points. Like, I think we totally agree with you, in the sense that the UX creation is the real like new market opportunity here. But we also felt, after talking to a lot of these people, that the tech is not quite there at the stage that they would trust it. Yet, there's a lot of people trying to do it right now as well. Like, you know, I collect personas. You like run, even like run rehearsals. There's, like, a decent amount of companies that try to do that. The problem I hear from people, especially at larger companies that have piloted these products, they don't have the level of trust right now that's necessary to tie this to real users and have, like, not much of a discrepancy there. I think, like one of the issues they find is this is a good model of what the users used to believe at this point in time. But looking forward, if I'm trying to release, like, a new feature, a new product, predict purchase intent and on new types of things, that is not quite there right now, but we think it will be, and we want to be well positioned to capture that when it
Yeah, those are all great points. Like, I think we totally agree with you, in the sense that the UX creation is the real like new market opportunity here. But we also felt, after talking to a lot of these people, that the tech is not quite there at the stage that they would trust it. Yet, there's a lot of people trying to do it right now as well. Like, you know, I collect personas. You like run, even like run rehearsals. There's, like, a decent amount of companies that try to do that. The problem I hear from people, especially at larger companies that have piloted these products, they don't have the level of trust right now that's necessary to tie this to real users and have, like, not much of a discrepancy there. I think, like one of the issues they find is this is a good model of what the users used to believe at this point in time. But looking forward, if I'm trying to release, like, a new feature, a new product, predict purchase intent and on new types of things, that is not quite there right now, but we think it will be, and we want to be well positioned to capture that when it
Yeah, those are all great points. Like, I think we totally agree with you, in the sense that the UX creation is the real like new market opportunity here. But we also felt, after talking to a lot of these people, that the tech is not quite there at the stage that they would trust it. Yet, there's a lot of people trying to do it right now as well. Like, you know, I collect personas. You like run, even like run rehearsals. There's, like, a decent amount of companies that try to do that. The problem I hear from people, especially at larger companies that have piloted these products, they don't have the level of trust right now that's necessary to tie this to real users and have, like, not much of a discrepancy there. I think, like one of the issues they find is this is a good model of what the users used to believe at this point in time. But looking forward, if I'm trying to release, like, a new feature, a new product, predict purchase intent and on new types of things, that is not quite there right now, but we think it will be, and we want to be well positioned to capture that when it
Yeah, those are all great points. Like, I think we totally agree with you, in the sense that the UX creation is the real like new market opportunity here. But we also felt, after talking to a lot of these people, that the tech is not quite there at the stage that they would trust it. Yet, there's a lot of people trying to do it right now as well. Like, you know, I collect personas. You like run, even like run rehearsals. There's, like, a decent amount of companies that try to do that. The problem I hear from people, especially at larger companies that have piloted these products, they don't have the level of trust right now that's necessary to tie this to real users and have, like, not much of a discrepancy there. I think, like one of the issues they find is this is a good model of what the users used to believe at this point in time. But looking forward, if I'm trying to release, like, a new feature, a new product, predict purchase intent and on new types of things, that is not quite there right now, but we think it will be, and we want to be well positioned to capture that when it
S Speaker 110:46is, and just following that line. So what do you think are the technological barriers to get there? I totally agree with what you're saying. So what are the blockers and how are you planning to address that?
is, and just following that line. So what do you think are the technological barriers to get there? I totally agree with what you're saying. So what are the blockers and how are you planning to address that?
is, and just following that line. So what do you think are the technological barriers to get there? I totally agree with what you're saying. So what are the blockers and how are you planning to address that?
is, and just following that line. So what do you think are the technological barriers to get there? I totally agree with what you're saying. So what are the blockers and how are you planning to address that?
S Speaker 311:00Yeah, I think, like at a high level, it's basically, how can browser agents, or agents of any like, using any application, interact most like humans? Because if agents are interacting differently than humans, like they're doing like weird actions, or they have to take weird shortcut tricks to do the same things, then you're not going to get the same experience as a human would, and that's like a major blocker, because you can't really determine things like UX and how things feel without that. You also just need a richer data set, and you also need studies that tie these two things together, that builds trust. And I think all of those things are on a great trajectory. I think even the Gemini three model that the model card is leaked today, and like the screen understanding and multimodal understanding, and if it's true, has jumped from 11% on benchmarks to 70% and in terms of the research associated with this stuff, even in the past two months, there have been so many research papers that have gotten hundreds of citations that have really blown up. And that was one of the reasons that we even felt confident in this space. But yeah, if that makes sense, got
Yeah, I think, like at a high level, it's basically, how can browser agents, or agents of any like, using any application, interact most like humans? Because if agents are interacting differently than humans, like they're doing like weird actions, or they have to take weird shortcut tricks to do the same things, then you're not going to get the same experience as a human would, and that's like a major blocker, because you can't really determine things like UX and how things feel without that. You also just need a richer data set, and you also need studies that tie these two things together, that builds trust. And I think all of those things are on a great trajectory. I think even the Gemini three model that the model card is leaked today, and like the screen understanding and multimodal understanding, and if it's true, has jumped from 11% on benchmarks to 70% and in terms of the research associated with this stuff, even in the past two months, there have been so many research papers that have gotten hundreds of citations that have really blown up. And that was one of the reasons that we even felt confident in this space. But yeah, if that makes sense, got
Yeah, I think, like at a high level, it's basically, how can browser agents, or agents of any like, using any application, interact most like humans? Because if agents are interacting differently than humans, like they're doing like weird actions, or they have to take weird shortcut tricks to do the same things, then you're not going to get the same experience as a human would, and that's like a major blocker, because you can't really determine things like UX and how things feel without that. You also just need a richer data set, and you also need studies that tie these two things together, that builds trust. And I think all of those things are on a great trajectory. I think even the Gemini three model that the model card is leaked today, and like the screen understanding and multimodal understanding, and if it's true, has jumped from 11% on benchmarks to 70% and in terms of the research associated with this stuff, even in the past two months, there have been so many research papers that have gotten hundreds of citations that have really blown up. And that was one of the reasons that we even felt confident in this space. But yeah, if that makes sense, got
Yeah, I think, like at a high level, it's basically, how can browser agents, or agents of any like, using any application, interact most like humans? Because if agents are interacting differently than humans, like they're doing like weird actions, or they have to take weird shortcut tricks to do the same things, then you're not going to get the same experience as a human would, and that's like a major blocker, because you can't really determine things like UX and how things feel without that. You also just need a richer data set, and you also need studies that tie these two things together, that builds trust. And I think all of those things are on a great trajectory. I think even the Gemini three model that the model card is leaked today, and like the screen understanding and multimodal understanding, and if it's true, has jumped from 11% on benchmarks to 70% and in terms of the research associated with this stuff, even in the past two months, there have been so many research papers that have gotten hundreds of citations that have really blown up. And that was one of the reasons that we even felt confident in this space. But yeah, if that makes sense, got
S Speaker 112:05it got it mishandled. Agreed, agreed. Coming, coming back to the original problem. I think. What kind of customers are you working with today? Where are they in the entire cycle?
it got it mishandled. Agreed, agreed. Coming, coming back to the original problem. I think. What kind of customers are you working with today? Where are they in the entire cycle?
it got it mishandled. Agreed, agreed. Coming, coming back to the original problem. I think. What kind of customers are you working with today? Where are they in the entire cycle?
it got it mishandled. Agreed, agreed. Coming, coming back to the original problem. I think. What kind of customers are you working with today? Where are they in the entire cycle?
S Speaker 115:58Yeah. Yeah. Makes sense. Makes sense. So Prasanna from from, say, developing a moat on this perspective, going from where today, the essential technological problems and correct me if I'm wrong or maybe I don't have the entire understanding, but you know this better, the way to go about it is one have better simulation, so that you one build a trust between actual users using the platform, versus simulating them, simulating those behaviors to also expanding vertically, or say horizontally, to an extent that you cover long tail sort of user behaviors. Or is that really not a problem?
Yeah. Yeah. Makes sense. Makes sense. So Prasanna from from, say, developing a moat on this perspective, going from where today, the essential technological problems and correct me if I'm wrong or maybe I don't have the entire understanding, but you know this better, the way to go about it is one have better simulation, so that you one build a trust between actual users using the platform, versus simulating them, simulating those behaviors to also expanding vertically, or say horizontally, to an extent that you cover long tail sort of user behaviors. Or is that really not a problem?
Yeah. Yeah. Makes sense. Makes sense. So Prasanna from from, say, developing a moat on this perspective, going from where today, the essential technological problems and correct me if I'm wrong or maybe I don't have the entire understanding, but you know this better, the way to go about it is one have better simulation, so that you one build a trust between actual users using the platform, versus simulating them, simulating those behaviors to also expanding vertically, or say horizontally, to an extent that you cover long tail sort of user behaviors. Or is that really not a problem?
Yeah. Yeah. Makes sense. Makes sense. So Prasanna from from, say, developing a moat on this perspective, going from where today, the essential technological problems and correct me if I'm wrong or maybe I don't have the entire understanding, but you know this better, the way to go about it is one have better simulation, so that you one build a trust between actual users using the platform, versus simulating them, simulating those behaviors to also expanding vertically, or say horizontally, to an extent that you cover long tail sort of user behaviors. Or is that really not a problem?
S Speaker 118:53100% 100% get that. So rushank, from fundraising perspective, you're raising 2 million right now. Where do you think this capital would go? And you're a two member team, right? Yeah, so plans on hiring and things like that. Yeah.
100% 100% get that. So rushank, from fundraising perspective, you're raising 2 million right now. Where do you think this capital would go? And you're a two member team, right? Yeah, so plans on hiring and things like that. Yeah.
100% 100% get that. So rushank, from fundraising perspective, you're raising 2 million right now. Where do you think this capital would go? And you're a two member team, right? Yeah, so plans on hiring and things like that. Yeah.
100% 100% get that. So rushank, from fundraising perspective, you're raising 2 million right now. Where do you think this capital would go? And you're a two member team, right? Yeah, so plans on hiring and things like that. Yeah.
S Speaker 319:09We need to expand pretty rapidly, but we're kind of wary, because we want to make sure that our core product offering right now has enough of immediate addressable market that we would be comfortable like taking on a bunch of hires right now, though, we just have, like, way too much, like, interest and stuff and feature requests and things to do. So it seems like the one of the first things that we would want to spend this money on is hiring more engineers to make our core product much better, and once we can handle and service our customers and they're super happy with it, we want to transition to more of an initial outbound sales phase, but hopefully our go to market strategy, after we start getting a bit of initial adoption, we want it to be more like plg, because our strength here is that it's super easy to set up. So something like post hog in the way that it grew with small startups, it grows with the company as net over time, and then, as you get a bunch of strong trust base with smaller and mid sized companies and larger companies are catching on.
We need to expand pretty rapidly, but we're kind of wary, because we want to make sure that our core product offering right now has enough of immediate addressable market that we would be comfortable like taking on a bunch of hires right now, though, we just have, like, way too much, like, interest and stuff and feature requests and things to do. So it seems like the one of the first things that we would want to spend this money on is hiring more engineers to make our core product much better, and once we can handle and service our customers and they're super happy with it, we want to transition to more of an initial outbound sales phase, but hopefully our go to market strategy, after we start getting a bit of initial adoption, we want it to be more like plg, because our strength here is that it's super easy to set up. So something like post hog in the way that it grew with small startups, it grows with the company as net over time, and then, as you get a bunch of strong trust base with smaller and mid sized companies and larger companies are catching on.
We need to expand pretty rapidly, but we're kind of wary, because we want to make sure that our core product offering right now has enough of immediate addressable market that we would be comfortable like taking on a bunch of hires right now, though, we just have, like, way too much, like, interest and stuff and feature requests and things to do. So it seems like the one of the first things that we would want to spend this money on is hiring more engineers to make our core product much better, and once we can handle and service our customers and they're super happy with it, we want to transition to more of an initial outbound sales phase, but hopefully our go to market strategy, after we start getting a bit of initial adoption, we want it to be more like plg, because our strength here is that it's super easy to set up. So something like post hog in the way that it grew with small startups, it grows with the company as net over time, and then, as you get a bunch of strong trust base with smaller and mid sized companies and larger companies are catching on.
We need to expand pretty rapidly, but we're kind of wary, because we want to make sure that our core product offering right now has enough of immediate addressable market that we would be comfortable like taking on a bunch of hires right now, though, we just have, like, way too much, like, interest and stuff and feature requests and things to do. So it seems like the one of the first things that we would want to spend this money on is hiring more engineers to make our core product much better, and once we can handle and service our customers and they're super happy with it, we want to transition to more of an initial outbound sales phase, but hopefully our go to market strategy, after we start getting a bit of initial adoption, we want it to be more like plg, because our strength here is that it's super easy to set up. So something like post hog in the way that it grew with small startups, it grows with the company as net over time, and then, as you get a bunch of strong trust base with smaller and mid sized companies and larger companies are catching on.
S Speaker 120:07Makes sense. Makes sense. Rashank, totally.
Makes sense. Makes sense. Rashank, totally.
Makes sense. Makes sense. Rashank, totally.
Makes sense. Makes sense. Rashank, totally.
20:14And are you in the current YC,
And are you in the current YC,
And are you in the current YC,
And are you in the current YC,
20:18YC batch, or have you already demoed and
YC batch, or have you already demoed and
YC batch, or have you already demoed and
YC batch, or have you already demoed and
S Speaker 320:22we were in the current batch. So Demo Day is December 4. And, yeah, the first day that they said that we should start fundraising was literally, like a day ago. So yeah, that's that's where we are right now.
we were in the current batch. So Demo Day is December 4. And, yeah, the first day that they said that we should start fundraising was literally, like a day ago. So yeah, that's that's where we are right now.
we were in the current batch. So Demo Day is December 4. And, yeah, the first day that they said that we should start fundraising was literally, like a day ago. So yeah, that's that's where we are right now.
we were in the current batch. So Demo Day is December 4. And, yeah, the first day that they said that we should start fundraising was literally, like a day ago. So yeah, that's that's where we are right now.
S Speaker 120:35Got it. Got it, and rushed. So do you have you? You mentioned you plan to close it pretty quickly? Do you have, say, a timeline in mind
Got it. Got it, and rushed. So do you have you? You mentioned you plan to close it pretty quickly? Do you have, say, a timeline in mind
Got it. Got it, and rushed. So do you have you? You mentioned you plan to close it pretty quickly? Do you have, say, a timeline in mind
Got it. Got it, and rushed. So do you have you? You mentioned you plan to close it pretty quickly? Do you have, say, a timeline in mind
S Speaker 320:46we're hopefully planning? I mean, obviously, as early as possible, I think, like, a reasonable timeline would be like, like a week and a half to two weeks,
we're hopefully planning? I mean, obviously, as early as possible, I think, like, a reasonable timeline would be like, like a week and a half to two weeks,
we're hopefully planning? I mean, obviously, as early as possible, I think, like, a reasonable timeline would be like, like a week and a half to two weeks,
we're hopefully planning? I mean, obviously, as early as possible, I think, like, a reasonable timeline would be like, like a week and a half to two weeks,
S Speaker 120:55got it, got it. So I think, I think it's really interesting for us. We'd love to dig deeper, full candor. I think my main problem is around the round size and just the round stage. At the moment, we haven't done a check smaller than 1.5 so far, so I'm just thinking from that perspective. But let me have a chat with the team. I would really appreciate if you can send me the deck and I will get back to you by early Tuesday next week.
got it, got it. So I think, I think it's really interesting for us. We'd love to dig deeper, full candor. I think my main problem is around the round size and just the round stage. At the moment, we haven't done a check smaller than 1.5 so far, so I'm just thinking from that perspective. But let me have a chat with the team. I would really appreciate if you can send me the deck and I will get back to you by early Tuesday next week.
got it, got it. So I think, I think it's really interesting for us. We'd love to dig deeper, full candor. I think my main problem is around the round size and just the round stage. At the moment, we haven't done a check smaller than 1.5 so far, so I'm just thinking from that perspective. But let me have a chat with the team. I would really appreciate if you can send me the deck and I will get back to you by early Tuesday next week.
got it, got it. So I think, I think it's really interesting for us. We'd love to dig deeper, full candor. I think my main problem is around the round size and just the round stage. At the moment, we haven't done a check smaller than 1.5 so far, so I'm just thinking from that perspective. But let me have a chat with the team. I would really appreciate if you can send me the deck and I will get back to you by early Tuesday next week.
S Speaker 321:27Yeah, that sounds good to me. I'll definitely send over the deck. I can send over a memo as well and a recording of that demo that I just showed you. Yeah, again, I just want to reiterate that we like could potentially be down to raise with a larger check size that are at a larger, you know, valuation cap. It's we're still in the calibration phase right now, so open to hearing like any offer, if there's an interest or if there's a fit. So yeah, yes,
Yeah, that sounds good to me. I'll definitely send over the deck. I can send over a memo as well and a recording of that demo that I just showed you. Yeah, again, I just want to reiterate that we like could potentially be down to raise with a larger check size that are at a larger, you know, valuation cap. It's we're still in the calibration phase right now, so open to hearing like any offer, if there's an interest or if there's a fit. So yeah, yes,
Yeah, that sounds good to me. I'll definitely send over the deck. I can send over a memo as well and a recording of that demo that I just showed you. Yeah, again, I just want to reiterate that we like could potentially be down to raise with a larger check size that are at a larger, you know, valuation cap. It's we're still in the calibration phase right now, so open to hearing like any offer, if there's an interest or if there's a fit. So yeah, yes,
Yeah, that sounds good to me. I'll definitely send over the deck. I can send over a memo as well and a recording of that demo that I just showed you. Yeah, again, I just want to reiterate that we like could potentially be down to raise with a larger check size that are at a larger, you know, valuation cap. It's we're still in the calibration phase right now, so open to hearing like any offer, if there's an interest or if there's a fit. So yeah, yes,
S Speaker 121:54100% I'll keep it. I'll keep the conversation open as well. I'll get back to you quickly on some things as well on where we are leaning and, yeah, get your point.
100% I'll keep it. I'll keep the conversation open as well. I'll get back to you quickly on some things as well on where we are leaning and, yeah, get your point.
100% I'll keep it. I'll keep the conversation open as well. I'll get back to you quickly on some things as well on where we are leaning and, yeah, get your point.
100% I'll keep it. I'll keep the conversation open as well. I'll get back to you quickly on some things as well on where we are leaning and, yeah, get your point.
22:04Yeah, it would be, it would be
Yeah, it would be, it would be
Yeah, it would be, it would be
Yeah, it would be, it would be
S Speaker 322:06just great to have as much information as early as possible so we could plan the rest around it. But, I mean, would obviously be very excited by our partnership there
just great to have as much information as early as possible so we could plan the rest around it. But, I mean, would obviously be very excited by our partnership there
just great to have as much information as early as possible so we could plan the rest around it. But, I mean, would obviously be very excited by our partnership there
just great to have as much information as early as possible so we could plan the rest around it. But, I mean, would obviously be very excited by our partnership there
S Speaker 122:14absolutely let me like, I think once, once you have a little bit more, say, traction, that would also be a good time to initiate a few partnership discussions. We from, from our platform perspective, we have enabled a few, say, infra companies, or maybe, if you have time, I'll just drop a link back to you over email. There's a Qualcomm AI hub, where we host a lot of models and infra tools that we have our own developer audience, which build platforms on top of our silicon, across mobile PCs and all of that. So this AI hub is in partnership with hugging face, and we expose a lot of software and infra tools over there as well. Could be some good, interesting opportunities on that side of things, so I'll keep you posted on the other side. Yeah, awesome. Sounds great. Thanks. Rushan, really appreciate the time. Great conversation. I believe in a lot of things that you mentioned. Wish you all the best. I'll come back quick.
absolutely let me like, I think once, once you have a little bit more, say, traction, that would also be a good time to initiate a few partnership discussions. We from, from our platform perspective, we have enabled a few, say, infra companies, or maybe, if you have time, I'll just drop a link back to you over email. There's a Qualcomm AI hub, where we host a lot of models and infra tools that we have our own developer audience, which build platforms on top of our silicon, across mobile PCs and all of that. So this AI hub is in partnership with hugging face, and we expose a lot of software and infra tools over there as well. Could be some good, interesting opportunities on that side of things, so I'll keep you posted on the other side. Yeah, awesome. Sounds great. Thanks. Rushan, really appreciate the time. Great conversation. I believe in a lot of things that you mentioned. Wish you all the best. I'll come back quick.
absolutely let me like, I think once, once you have a little bit more, say, traction, that would also be a good time to initiate a few partnership discussions. We from, from our platform perspective, we have enabled a few, say, infra companies, or maybe, if you have time, I'll just drop a link back to you over email. There's a Qualcomm AI hub, where we host a lot of models and infra tools that we have our own developer audience, which build platforms on top of our silicon, across mobile PCs and all of that. So this AI hub is in partnership with hugging face, and we expose a lot of software and infra tools over there as well. Could be some good, interesting opportunities on that side of things, so I'll keep you posted on the other side. Yeah, awesome. Sounds great. Thanks. Rushan, really appreciate the time. Great conversation. I believe in a lot of things that you mentioned. Wish you all the best. I'll come back quick.
absolutely let me like, I think once, once you have a little bit more, say, traction, that would also be a good time to initiate a few partnership discussions. We from, from our platform perspective, we have enabled a few, say, infra companies, or maybe, if you have time, I'll just drop a link back to you over email. There's a Qualcomm AI hub, where we host a lot of models and infra tools that we have our own developer audience, which build platforms on top of our silicon, across mobile PCs and all of that. So this AI hub is in partnership with hugging face, and we expose a lot of software and infra tools over there as well. Could be some good, interesting opportunities on that side of things, so I'll keep you posted on the other side. Yeah, awesome. Sounds great. Thanks. Rushan, really appreciate the time. Great conversation. I believe in a lot of things that you mentioned. Wish you all the best. I'll come back quick.
S Speaker 323:14Yeah, thank you so much for your time. Have a good rest of your day. You too. Bye. Bye. You.
Yeah, thank you so much for your time. Have a good rest of your day. You too. Bye. Bye. You.
Yeah, thank you so much for your time. Have a good rest of your day. You too. Bye. Bye. You.
Yeah, thank you so much for your time. Have a good rest of your day. You too. Bye. Bye. You.