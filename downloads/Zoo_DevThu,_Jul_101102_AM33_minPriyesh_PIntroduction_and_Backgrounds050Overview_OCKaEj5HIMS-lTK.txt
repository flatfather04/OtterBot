Meeting: Zoo Dev
Thu, Jul 10
11:02 AM
33 min
Priyesh P
Introduction and Backgrounds
0:50
Overview of Zoo's Pr
URL: https://otter.ai/u/OCKaEj5HIMS-lTKWikBOiSkhz3M
Downloaded: 2025-12-21T21:40:04.747819
Method: text_extraction
============================================================

S Speaker 10:50Priyesh just joined. Hey, hi, Jordan Nico, sorry, I was late. Had some technical difficulties.
Priyesh just joined. Hey, hi, Jordan Nico, sorry, I was late. Had some technical difficulties.
Priyesh just joined. Hey, hi, Jordan Nico, sorry, I was late. Had some technical difficulties.
Priyesh just joined. Hey, hi, Jordan Nico, sorry, I was late. Had some technical difficulties.
0:58How you guys doing today? Good, good. And I
How you guys doing today? Good, good. And I
How you guys doing today? Good, good. And I
How you guys doing today? Good, good. And I
S Speaker 21:02think Nico, you have a decent amount of background noise. You don't mind? I do sorry about that. Yeah, but no, it's good to meet you. Good to meet you. We're fine
think Nico, you have a decent amount of background noise. You don't mind? I do sorry about that. Yeah, but no, it's good to meet you. Good to meet you. We're fine
think Nico, you have a decent amount of background noise. You don't mind? I do sorry about that. Yeah, but no, it's good to meet you. Good to meet you. We're fine
think Nico, you have a decent amount of background noise. You don't mind? I do sorry about that. Yeah, but no, it's good to meet you. Good to meet you. We're fine
S Speaker 33:20Would love to sort of get a quick background about yourself as well as background about yourself as well and the team, and
Would love to sort of get a quick background about yourself as well as background about yourself as well and the team, and
Would love to sort of get a quick background about yourself as well as background about yourself as well and the team, and
Would love to sort of get a quick background about yourself as well as background about yourself as well and the team, and
3:25then we can jump in discussing
then we can jump in discussing
then we can jump in discussing
then we can jump in discussing
3:28too. Yeah. How about Nico,
too. Yeah. How about Nico,
too. Yeah. How about Nico,
too. Yeah. How about Nico,
S Speaker 43:33if you start and then I can hop in and today, financial strategy, console, dive
if you start and then I can hop in and today, financial strategy, console, dive
if you start and then I can hop in and today, financial strategy, console, dive
if you start and then I can hop in and today, financial strategy, console, dive
S Speaker 35:05Probably one course during my engineering time, but I'm not as familiar.
Probably one course during my engineering time, but I'm not as familiar.
Probably one course during my engineering time, but I'm not as familiar.
Probably one course during my engineering time, but I'm not as familiar.
S Speaker 38:07And Jordan, a couple of questions here. So the reason, I assume, why you're able to create a feature tree and other players cannot is that you have done extensive work on the data pipelines, and then you probably would have created a data pipeline for each of your generation in specific sub features is that, is that also a restricting factor? Like, do you see yourself not having enough data for a lot of issues, and then that becomes a hindrance?
And Jordan, a couple of questions here. So the reason, I assume, why you're able to create a feature tree and other players cannot is that you have done extensive work on the data pipelines, and then you probably would have created a data pipeline for each of your generation in specific sub features is that, is that also a restricting factor? Like, do you see yourself not having enough data for a lot of issues, and then that becomes a hindrance?
And Jordan, a couple of questions here. So the reason, I assume, why you're able to create a feature tree and other players cannot is that you have done extensive work on the data pipelines, and then you probably would have created a data pipeline for each of your generation in specific sub features is that, is that also a restricting factor? Like, do you see yourself not having enough data for a lot of issues, and then that becomes a hindrance?
And Jordan, a couple of questions here. So the reason, I assume, why you're able to create a feature tree and other players cannot is that you have done extensive work on the data pipelines, and then you probably would have created a data pipeline for each of your generation in specific sub features is that, is that also a restricting factor? Like, do you see yourself not having enough data for a lot of issues, and then that becomes a hindrance?
S Speaker 311:56this is very interesting. Have a few questions here, but let me start from the top,
this is very interesting. Have a few questions here, but let me start from the top,
this is very interesting. Have a few questions here, but let me start from the top,
this is very interesting. Have a few questions here, but let me start from the top,
S Speaker 215:53Great question, great question. So starting with the first one on like a direction for the AI direction for text to CAD then. Today we solely train on CAD data then, and we solely, as far as offer public in designs, give you what's a one way interface where you give it a prompt, it gives you a geometry back where we have seen desire, and also be more like a pleasurable experience, you know, kind of like better work there, like a doable experience, is that agent interface where the ability to edit CAD is one of multiple functions that an agent interface can offer. Then we have that internally. We've been demoing it. We'll ship that publicly, probably by end of the year. But the intent of that is more of a co pilot, where, if you want to get a cat edit, just like you would have cursor, make a code edit for you, you can if you wanted to be a thought partner, you wanted to review a PDF specification and pull some numbers out, you wanted to look at a website and figure out what's going on, then you want to track requirements for you, or break down a larger change into a set of smaller steps that are more cohesive. Then that's where our agent interface is going. It's something where the CAD edits are a huge part of it, but there's a huge amount of engineering around that. Whether that's like reading an engineering specification, pulling a number from it and making a cat edit based on that, reviewing a specification and confirming that your CAD file needs that specification in an automatic design review process, then that's where that agent interface is going, so that it's, again, not just one way, prompts to geometry, then you have multimedia to, you know, CAD changes, amongst other functionality. And so that's kind of the underlying evolution of text to cat on the front end side. Your second question was on Data Training direction. The enterprises, generally, almost entirely, are extremely protective of their data, as you would expect. So there is no like backflow of data from the base model to the fine tuning versions of it. But generally, the fine tunings, like, we're not at the level yet where that's like an automated self serve process, then there's a lot where, you know, we go to train on something new data set we haven't interacted before. There's a new kind of metadata that's not being well, it's hallucinating in a new way. Those lessons on how to train the models do go big. Flow on improvements for the base model, on my training strategy, not necessarily data. And some of those enterprises as well will add and they have, like an aerospace company that says 2 million files, they're a Creo user, creo formerly known as um pro eptc, um, they were our first company providing our first customer providing Creo data. We so we built the pipeline to turn Creo into our language internally, which what gets trained on top of um that does unlock um, the ability for us to access public Creo data that in public Creo available files. So it unlocks um kind of parallel, certain data cohorts that we wouldn't have otherwise done that Creo specific training. So they're paying us to unlock data with their data, whether it's on third party data that we can access as a kind of secondary type of building conversion pipelines. So that's moving. And then one of the areas behind the scenes of where Vesica is evolving, this is our roadmap for this year on what we're working on now, everything on the right hand side that was the previous chart you just saw. We are expanding downstream into two areas, one of which is toolpathing, generation CNC machine instruction based on the design data. And the intent of that is that if you can start congealing these data sets, where you have design data and manufacturing data side by side, then your generative AI product is one of the critiques you'll hear. And we, you know, I believe answer this well as well. Then is engineering is more than geometry, it's more than design. It's manufacturing, it's supply chain, it's finance, it's engineering analysis. And we agree, and that's where we're going next then is once you start congealing those data sets together, that's when now your AI should pick up on manufacture ability, nuance of a certain design. And if you want to, let's say this change the manufacturing process. Can you do a prompt like, change this part to be out of sheet metal, or simplify this part to be made on a three axis CNC machine instead of a five axis CNC machine. Things like that are the expected emergent behavior. So we have a team on the mapping today, and we are doing downstream work into more of a what we call a one click Checkout manufacturing flow is if you have the design data, you have the tool pathing data, just send the right machine, cut out the engineering drawing, cut out the machinist, cut out getting the quote from the machine shop, and and you get a large amount of data as well from this of how did that part turn out versus design intent? So basically, building out like our strategic growth run out step by step, is based on how you get more data. How do you get a stronger feedback loop into that generative AI model, which involves going into those downstream adjacent engineering areas?
Great question, great question. So starting with the first one on like a direction for the AI direction for text to CAD then. Today we solely train on CAD data then, and we solely, as far as offer public in designs, give you what's a one way interface where you give it a prompt, it gives you a geometry back where we have seen desire, and also be more like a pleasurable experience, you know, kind of like better work there, like a doable experience, is that agent interface where the ability to edit CAD is one of multiple functions that an agent interface can offer. Then we have that internally. We've been demoing it. We'll ship that publicly, probably by end of the year. But the intent of that is more of a co pilot, where, if you want to get a cat edit, just like you would have cursor, make a code edit for you, you can if you wanted to be a thought partner, you wanted to review a PDF specification and pull some numbers out, you wanted to look at a website and figure out what's going on, then you want to track requirements for you, or break down a larger change into a set of smaller steps that are more cohesive. Then that's where our agent interface is going. It's something where the CAD edits are a huge part of it, but there's a huge amount of engineering around that. Whether that's like reading an engineering specification, pulling a number from it and making a cat edit based on that, reviewing a specification and confirming that your CAD file needs that specification in an automatic design review process, then that's where that agent interface is going, so that it's, again, not just one way, prompts to geometry, then you have multimedia to, you know, CAD changes, amongst other functionality. And so that's kind of the underlying evolution of text to cat on the front end side. Your second question was on Data Training direction. The enterprises, generally, almost entirely, are extremely protective of their data, as you would expect. So there is no like backflow of data from the base model to the fine tuning versions of it. But generally, the fine tunings, like, we're not at the level yet where that's like an automated self serve process, then there's a lot where, you know, we go to train on something new data set we haven't interacted before. There's a new kind of metadata that's not being well, it's hallucinating in a new way. Those lessons on how to train the models do go big. Flow on improvements for the base model, on my training strategy, not necessarily data. And some of those enterprises as well will add and they have, like an aerospace company that says 2 million files, they're a Creo user, creo formerly known as um pro eptc, um, they were our first company providing our first customer providing Creo data. We so we built the pipeline to turn Creo into our language internally, which what gets trained on top of um that does unlock um, the ability for us to access public Creo data that in public Creo available files. So it unlocks um kind of parallel, certain data cohorts that we wouldn't have otherwise done that Creo specific training. So they're paying us to unlock data with their data, whether it's on third party data that we can access as a kind of secondary type of building conversion pipelines. So that's moving. And then one of the areas behind the scenes of where Vesica is evolving, this is our roadmap for this year on what we're working on now, everything on the right hand side that was the previous chart you just saw. We are expanding downstream into two areas, one of which is toolpathing, generation CNC machine instruction based on the design data. And the intent of that is that if you can start congealing these data sets, where you have design data and manufacturing data side by side, then your generative AI product is one of the critiques you'll hear. And we, you know, I believe answer this well as well. Then is engineering is more than geometry, it's more than design. It's manufacturing, it's supply chain, it's finance, it's engineering analysis. And we agree, and that's where we're going next then is once you start congealing those data sets together, that's when now your AI should pick up on manufacture ability, nuance of a certain design. And if you want to, let's say this change the manufacturing process. Can you do a prompt like, change this part to be out of sheet metal, or simplify this part to be made on a three axis CNC machine instead of a five axis CNC machine. Things like that are the expected emergent behavior. So we have a team on the mapping today, and we are doing downstream work into more of a what we call a one click Checkout manufacturing flow is if you have the design data, you have the tool pathing data, just send the right machine, cut out the engineering drawing, cut out the machinist, cut out getting the quote from the machine shop, and and you get a large amount of data as well from this of how did that part turn out versus design intent? So basically, building out like our strategic growth run out step by step, is based on how you get more data. How do you get a stronger feedback loop into that generative AI model, which involves going into those downstream adjacent engineering areas?
Great question, great question. So starting with the first one on like a direction for the AI direction for text to CAD then. Today we solely train on CAD data then, and we solely, as far as offer public in designs, give you what's a one way interface where you give it a prompt, it gives you a geometry back where we have seen desire, and also be more like a pleasurable experience, you know, kind of like better work there, like a doable experience, is that agent interface where the ability to edit CAD is one of multiple functions that an agent interface can offer. Then we have that internally. We've been demoing it. We'll ship that publicly, probably by end of the year. But the intent of that is more of a co pilot, where, if you want to get a cat edit, just like you would have cursor, make a code edit for you, you can if you wanted to be a thought partner, you wanted to review a PDF specification and pull some numbers out, you wanted to look at a website and figure out what's going on, then you want to track requirements for you, or break down a larger change into a set of smaller steps that are more cohesive. Then that's where our agent interface is going. It's something where the CAD edits are a huge part of it, but there's a huge amount of engineering around that. Whether that's like reading an engineering specification, pulling a number from it and making a cat edit based on that, reviewing a specification and confirming that your CAD file needs that specification in an automatic design review process, then that's where that agent interface is going, so that it's, again, not just one way, prompts to geometry, then you have multimedia to, you know, CAD changes, amongst other functionality. And so that's kind of the underlying evolution of text to cat on the front end side. Your second question was on Data Training direction. The enterprises, generally, almost entirely, are extremely protective of their data, as you would expect. So there is no like backflow of data from the base model to the fine tuning versions of it. But generally, the fine tunings, like, we're not at the level yet where that's like an automated self serve process, then there's a lot where, you know, we go to train on something new data set we haven't interacted before. There's a new kind of metadata that's not being well, it's hallucinating in a new way. Those lessons on how to train the models do go big. Flow on improvements for the base model, on my training strategy, not necessarily data. And some of those enterprises as well will add and they have, like an aerospace company that says 2 million files, they're a Creo user, creo formerly known as um pro eptc, um, they were our first company providing our first customer providing Creo data. We so we built the pipeline to turn Creo into our language internally, which what gets trained on top of um that does unlock um, the ability for us to access public Creo data that in public Creo available files. So it unlocks um kind of parallel, certain data cohorts that we wouldn't have otherwise done that Creo specific training. So they're paying us to unlock data with their data, whether it's on third party data that we can access as a kind of secondary type of building conversion pipelines. So that's moving. And then one of the areas behind the scenes of where Vesica is evolving, this is our roadmap for this year on what we're working on now, everything on the right hand side that was the previous chart you just saw. We are expanding downstream into two areas, one of which is toolpathing, generation CNC machine instruction based on the design data. And the intent of that is that if you can start congealing these data sets, where you have design data and manufacturing data side by side, then your generative AI product is one of the critiques you'll hear. And we, you know, I believe answer this well as well. Then is engineering is more than geometry, it's more than design. It's manufacturing, it's supply chain, it's finance, it's engineering analysis. And we agree, and that's where we're going next then is once you start congealing those data sets together, that's when now your AI should pick up on manufacture ability, nuance of a certain design. And if you want to, let's say this change the manufacturing process. Can you do a prompt like, change this part to be out of sheet metal, or simplify this part to be made on a three axis CNC machine instead of a five axis CNC machine. Things like that are the expected emergent behavior. So we have a team on the mapping today, and we are doing downstream work into more of a what we call a one click Checkout manufacturing flow is if you have the design data, you have the tool pathing data, just send the right machine, cut out the engineering drawing, cut out the machinist, cut out getting the quote from the machine shop, and and you get a large amount of data as well from this of how did that part turn out versus design intent? So basically, building out like our strategic growth run out step by step, is based on how you get more data. How do you get a stronger feedback loop into that generative AI model, which involves going into those downstream adjacent engineering areas?
Great question, great question. So starting with the first one on like a direction for the AI direction for text to CAD then. Today we solely train on CAD data then, and we solely, as far as offer public in designs, give you what's a one way interface where you give it a prompt, it gives you a geometry back where we have seen desire, and also be more like a pleasurable experience, you know, kind of like better work there, like a doable experience, is that agent interface where the ability to edit CAD is one of multiple functions that an agent interface can offer. Then we have that internally. We've been demoing it. We'll ship that publicly, probably by end of the year. But the intent of that is more of a co pilot, where, if you want to get a cat edit, just like you would have cursor, make a code edit for you, you can if you wanted to be a thought partner, you wanted to review a PDF specification and pull some numbers out, you wanted to look at a website and figure out what's going on, then you want to track requirements for you, or break down a larger change into a set of smaller steps that are more cohesive. Then that's where our agent interface is going. It's something where the CAD edits are a huge part of it, but there's a huge amount of engineering around that. Whether that's like reading an engineering specification, pulling a number from it and making a cat edit based on that, reviewing a specification and confirming that your CAD file needs that specification in an automatic design review process, then that's where that agent interface is going, so that it's, again, not just one way, prompts to geometry, then you have multimedia to, you know, CAD changes, amongst other functionality. And so that's kind of the underlying evolution of text to cat on the front end side. Your second question was on Data Training direction. The enterprises, generally, almost entirely, are extremely protective of their data, as you would expect. So there is no like backflow of data from the base model to the fine tuning versions of it. But generally, the fine tunings, like, we're not at the level yet where that's like an automated self serve process, then there's a lot where, you know, we go to train on something new data set we haven't interacted before. There's a new kind of metadata that's not being well, it's hallucinating in a new way. Those lessons on how to train the models do go big. Flow on improvements for the base model, on my training strategy, not necessarily data. And some of those enterprises as well will add and they have, like an aerospace company that says 2 million files, they're a Creo user, creo formerly known as um pro eptc, um, they were our first company providing our first customer providing Creo data. We so we built the pipeline to turn Creo into our language internally, which what gets trained on top of um that does unlock um, the ability for us to access public Creo data that in public Creo available files. So it unlocks um kind of parallel, certain data cohorts that we wouldn't have otherwise done that Creo specific training. So they're paying us to unlock data with their data, whether it's on third party data that we can access as a kind of secondary type of building conversion pipelines. So that's moving. And then one of the areas behind the scenes of where Vesica is evolving, this is our roadmap for this year on what we're working on now, everything on the right hand side that was the previous chart you just saw. We are expanding downstream into two areas, one of which is toolpathing, generation CNC machine instruction based on the design data. And the intent of that is that if you can start congealing these data sets, where you have design data and manufacturing data side by side, then your generative AI product is one of the critiques you'll hear. And we, you know, I believe answer this well as well. Then is engineering is more than geometry, it's more than design. It's manufacturing, it's supply chain, it's finance, it's engineering analysis. And we agree, and that's where we're going next then is once you start congealing those data sets together, that's when now your AI should pick up on manufacture ability, nuance of a certain design. And if you want to, let's say this change the manufacturing process. Can you do a prompt like, change this part to be out of sheet metal, or simplify this part to be made on a three axis CNC machine instead of a five axis CNC machine. Things like that are the expected emergent behavior. So we have a team on the mapping today, and we are doing downstream work into more of a what we call a one click Checkout manufacturing flow is if you have the design data, you have the tool pathing data, just send the right machine, cut out the engineering drawing, cut out the machinist, cut out getting the quote from the machine shop, and and you get a large amount of data as well from this of how did that part turn out versus design intent? So basically, building out like our strategic growth run out step by step, is based on how you get more data. How do you get a stronger feedback loop into that generative AI model, which involves going into those downstream adjacent engineering areas?
S Speaker 319:32John great job at sort of starting at a smaller problem than expanding vertically integrating into a lot of different spaces, and understand getting closer to the customer is probably the only mode that would emerge out of generative AI, a lot of applications. So great to see that model very quickly is other plans to sort of create a image to card, video to card model. Or is that not necessary? I'm not, I'm not sure
John great job at sort of starting at a smaller problem than expanding vertically integrating into a lot of different spaces, and understand getting closer to the customer is probably the only mode that would emerge out of generative AI, a lot of applications. So great to see that model very quickly is other plans to sort of create a image to card, video to card model. Or is that not necessary? I'm not, I'm not sure
John great job at sort of starting at a smaller problem than expanding vertically integrating into a lot of different spaces, and understand getting closer to the customer is probably the only mode that would emerge out of generative AI, a lot of applications. So great to see that model very quickly is other plans to sort of create a image to card, video to card model. Or is that not necessary? I'm not, I'm not sure
John great job at sort of starting at a smaller problem than expanding vertically integrating into a lot of different spaces, and understand getting closer to the customer is probably the only mode that would emerge out of generative AI, a lot of applications. So great to see that model very quickly is other plans to sort of create a image to card, video to card model. Or is that not necessary? I'm not, I'm not sure
S Speaker 219:53necessary. Necessary is the right I don't know if the answer, is it necessary? Are we going to do it? Yes, it seems necessary on two fronts, one which is a naming we're going to eventually have to rename it. It's going to be more than text. And that's a big, good problem. Today we have a kind of breaking that. Then we've toyed with some image to CAD work, which we have really liked, and some customers have really wanted, like some of the older like European engineering companies, like hundreds of years of data, carrying so much data in the archives, so much data that's stuck on a draft print that was never digitized. Then that kind of like drawing the CAD workflow, or reverse engineering, a part that they take a picture of workflow then extremely advantageous for them to do. So we've done image to CAD work, preliminary work. We probably won't kick it off into a full series, a it doesn't deserve a full team to work on. Then image to Cat side has been in demand, and we have to wait with that as well. Kind of what we call an agent feedback loop on my pay grade, something like that, and all specifics on what exactly the industry calls it. Then put things like, when you get AI generation, let's say it has the two features that are supposed to be connected but are not, then a whole pattern supposed to line up, but you can visually tell it doesn't. Then we have toyed with using that as a visual feedback loop on the AI model, just like using engineer would look and say, This doesn't look right. This filets arise, ports don't line up. This interferes. It's detecting those visually, in addition to other ways, and then feeding that back into an edit where it'll start jumping based on the visual feedback of the cat then. So yeah, that on a natural evolution to significantly mature, detects the cat product, significantly reduce hallucinations, significantly reduce what are visually detectable errors in the geometric intent and that image feedback loop, we found we've really liked it. We've really liked it essentially, before delivering a generation, giving an image back to the model, and seeing if it's happy with its own output.
necessary. Necessary is the right I don't know if the answer, is it necessary? Are we going to do it? Yes, it seems necessary on two fronts, one which is a naming we're going to eventually have to rename it. It's going to be more than text. And that's a big, good problem. Today we have a kind of breaking that. Then we've toyed with some image to CAD work, which we have really liked, and some customers have really wanted, like some of the older like European engineering companies, like hundreds of years of data, carrying so much data in the archives, so much data that's stuck on a draft print that was never digitized. Then that kind of like drawing the CAD workflow, or reverse engineering, a part that they take a picture of workflow then extremely advantageous for them to do. So we've done image to CAD work, preliminary work. We probably won't kick it off into a full series, a it doesn't deserve a full team to work on. Then image to Cat side has been in demand, and we have to wait with that as well. Kind of what we call an agent feedback loop on my pay grade, something like that, and all specifics on what exactly the industry calls it. Then put things like, when you get AI generation, let's say it has the two features that are supposed to be connected but are not, then a whole pattern supposed to line up, but you can visually tell it doesn't. Then we have toyed with using that as a visual feedback loop on the AI model, just like using engineer would look and say, This doesn't look right. This filets arise, ports don't line up. This interferes. It's detecting those visually, in addition to other ways, and then feeding that back into an edit where it'll start jumping based on the visual feedback of the cat then. So yeah, that on a natural evolution to significantly mature, detects the cat product, significantly reduce hallucinations, significantly reduce what are visually detectable errors in the geometric intent and that image feedback loop, we found we've really liked it. We've really liked it essentially, before delivering a generation, giving an image back to the model, and seeing if it's happy with its own output.
necessary. Necessary is the right I don't know if the answer, is it necessary? Are we going to do it? Yes, it seems necessary on two fronts, one which is a naming we're going to eventually have to rename it. It's going to be more than text. And that's a big, good problem. Today we have a kind of breaking that. Then we've toyed with some image to CAD work, which we have really liked, and some customers have really wanted, like some of the older like European engineering companies, like hundreds of years of data, carrying so much data in the archives, so much data that's stuck on a draft print that was never digitized. Then that kind of like drawing the CAD workflow, or reverse engineering, a part that they take a picture of workflow then extremely advantageous for them to do. So we've done image to CAD work, preliminary work. We probably won't kick it off into a full series, a it doesn't deserve a full team to work on. Then image to Cat side has been in demand, and we have to wait with that as well. Kind of what we call an agent feedback loop on my pay grade, something like that, and all specifics on what exactly the industry calls it. Then put things like, when you get AI generation, let's say it has the two features that are supposed to be connected but are not, then a whole pattern supposed to line up, but you can visually tell it doesn't. Then we have toyed with using that as a visual feedback loop on the AI model, just like using engineer would look and say, This doesn't look right. This filets arise, ports don't line up. This interferes. It's detecting those visually, in addition to other ways, and then feeding that back into an edit where it'll start jumping based on the visual feedback of the cat then. So yeah, that on a natural evolution to significantly mature, detects the cat product, significantly reduce hallucinations, significantly reduce what are visually detectable errors in the geometric intent and that image feedback loop, we found we've really liked it. We've really liked it essentially, before delivering a generation, giving an image back to the model, and seeing if it's happy with its own output.
necessary. Necessary is the right I don't know if the answer, is it necessary? Are we going to do it? Yes, it seems necessary on two fronts, one which is a naming we're going to eventually have to rename it. It's going to be more than text. And that's a big, good problem. Today we have a kind of breaking that. Then we've toyed with some image to CAD work, which we have really liked, and some customers have really wanted, like some of the older like European engineering companies, like hundreds of years of data, carrying so much data in the archives, so much data that's stuck on a draft print that was never digitized. Then that kind of like drawing the CAD workflow, or reverse engineering, a part that they take a picture of workflow then extremely advantageous for them to do. So we've done image to CAD work, preliminary work. We probably won't kick it off into a full series, a it doesn't deserve a full team to work on. Then image to Cat side has been in demand, and we have to wait with that as well. Kind of what we call an agent feedback loop on my pay grade, something like that, and all specifics on what exactly the industry calls it. Then put things like, when you get AI generation, let's say it has the two features that are supposed to be connected but are not, then a whole pattern supposed to line up, but you can visually tell it doesn't. Then we have toyed with using that as a visual feedback loop on the AI model, just like using engineer would look and say, This doesn't look right. This filets arise, ports don't line up. This interferes. It's detecting those visually, in addition to other ways, and then feeding that back into an edit where it'll start jumping based on the visual feedback of the cat then. So yeah, that on a natural evolution to significantly mature, detects the cat product, significantly reduce hallucinations, significantly reduce what are visually detectable errors in the geometric intent and that image feedback loop, we found we've really liked it. We've really liked it essentially, before delivering a generation, giving an image back to the model, and seeing if it's happy with its own output.
S Speaker 321:27So understand that. Thanks. Thanks for sharing that as well. And we'd love to sort of now get a sense of the GTM. I know you have both enterprise and prosumer motion, and prosim motion seems to be doing really good. We'd love to sort of get your thoughts
So understand that. Thanks. Thanks for sharing that as well. And we'd love to sort of now get a sense of the GTM. I know you have both enterprise and prosumer motion, and prosim motion seems to be doing really good. We'd love to sort of get your thoughts
So understand that. Thanks. Thanks for sharing that as well. And we'd love to sort of now get a sense of the GTM. I know you have both enterprise and prosumer motion, and prosim motion seems to be doing really good. We'd love to sort of get your thoughts
So understand that. Thanks. Thanks for sharing that as well. And we'd love to sort of now get a sense of the GTM. I know you have both enterprise and prosumer motion, and prosim motion seems to be doing really good. We'd love to sort of get your thoughts
S Speaker 221:39on that. Yeah, where we've done the majority, which is that prosumer tier, strong growth, strong attention. Our focus right now is turning that into the enterprise funnel. Then, because the enterprise customers, they those contract sizes, we're doing that fine tuning and providing everything else around that on those are seven to eight figure annual contracts we're looking at with them, where, if we nail one of those, we're trying to serve 300,000 consumers worth of requests. Then that enterprise focus we generally deemed valuable. A lot of the consumer stuff, in due time will be like a strong, recurring new base, but it's not priority one for the company that we shifted kind of up in the pretty but especially probably since I've spoken base and last I think he's even seen this chart, then it's been a minute. So long story short, the on the enterprises we we closed our first pilot with Blue Origin a number of weeks ago. It was like last week of May. We're focused on that pilot right now. We're negotiating these Volkswagens to land strong automotive customers, where once the origin pilot's done, we're working on negotiating what that's gonna look like as a production contract. Then we'll push these in a pilot's automotive as a VP one. So we wanted to bifurcate those on engineering team bandwidth, so we've been holding off on those. And then a slew of other companies. It starts a little out of date even there's a bunch more to put in here then, but the focus right now is mature, that generative AI fine tuning platform, turn more of that into self serve, expand that into the right data sets. We've done SolidWorks, we've been priyo, we've done X. We haven't done get to yet get he is needed for, for Volkswagen specifically. So that's next up on the docket for a data pipeline. But long story short, the goal is with these that you know, if we convert or five of these production contracts, we're well beyond break even as a company. That's easier than the slog of consumer sales. And those kind of follows the Enterprise product material, consumer follows. That one focus right now is deliver on those pilots consumers will follow, and that these are materially larger contracts and potential than anything the consumer market can provide. I find two, including markets at scale, you know, 10 to 100 times bigger than just
on that. Yeah, where we've done the majority, which is that prosumer tier, strong growth, strong attention. Our focus right now is turning that into the enterprise funnel. Then, because the enterprise customers, they those contract sizes, we're doing that fine tuning and providing everything else around that on those are seven to eight figure annual contracts we're looking at with them, where, if we nail one of those, we're trying to serve 300,000 consumers worth of requests. Then that enterprise focus we generally deemed valuable. A lot of the consumer stuff, in due time will be like a strong, recurring new base, but it's not priority one for the company that we shifted kind of up in the pretty but especially probably since I've spoken base and last I think he's even seen this chart, then it's been a minute. So long story short, the on the enterprises we we closed our first pilot with Blue Origin a number of weeks ago. It was like last week of May. We're focused on that pilot right now. We're negotiating these Volkswagens to land strong automotive customers, where once the origin pilot's done, we're working on negotiating what that's gonna look like as a production contract. Then we'll push these in a pilot's automotive as a VP one. So we wanted to bifurcate those on engineering team bandwidth, so we've been holding off on those. And then a slew of other companies. It starts a little out of date even there's a bunch more to put in here then, but the focus right now is mature, that generative AI fine tuning platform, turn more of that into self serve, expand that into the right data sets. We've done SolidWorks, we've been priyo, we've done X. We haven't done get to yet get he is needed for, for Volkswagen specifically. So that's next up on the docket for a data pipeline. But long story short, the goal is with these that you know, if we convert or five of these production contracts, we're well beyond break even as a company. That's easier than the slog of consumer sales. And those kind of follows the Enterprise product material, consumer follows. That one focus right now is deliver on those pilots consumers will follow, and that these are materially larger contracts and potential than anything the consumer market can provide. I find two, including markets at scale, you know, 10 to 100 times bigger than just
on that. Yeah, where we've done the majority, which is that prosumer tier, strong growth, strong attention. Our focus right now is turning that into the enterprise funnel. Then, because the enterprise customers, they those contract sizes, we're doing that fine tuning and providing everything else around that on those are seven to eight figure annual contracts we're looking at with them, where, if we nail one of those, we're trying to serve 300,000 consumers worth of requests. Then that enterprise focus we generally deemed valuable. A lot of the consumer stuff, in due time will be like a strong, recurring new base, but it's not priority one for the company that we shifted kind of up in the pretty but especially probably since I've spoken base and last I think he's even seen this chart, then it's been a minute. So long story short, the on the enterprises we we closed our first pilot with Blue Origin a number of weeks ago. It was like last week of May. We're focused on that pilot right now. We're negotiating these Volkswagens to land strong automotive customers, where once the origin pilot's done, we're working on negotiating what that's gonna look like as a production contract. Then we'll push these in a pilot's automotive as a VP one. So we wanted to bifurcate those on engineering team bandwidth, so we've been holding off on those. And then a slew of other companies. It starts a little out of date even there's a bunch more to put in here then, but the focus right now is mature, that generative AI fine tuning platform, turn more of that into self serve, expand that into the right data sets. We've done SolidWorks, we've been priyo, we've done X. We haven't done get to yet get he is needed for, for Volkswagen specifically. So that's next up on the docket for a data pipeline. But long story short, the goal is with these that you know, if we convert or five of these production contracts, we're well beyond break even as a company. That's easier than the slog of consumer sales. And those kind of follows the Enterprise product material, consumer follows. That one focus right now is deliver on those pilots consumers will follow, and that these are materially larger contracts and potential than anything the consumer market can provide. I find two, including markets at scale, you know, 10 to 100 times bigger than just
on that. Yeah, where we've done the majority, which is that prosumer tier, strong growth, strong attention. Our focus right now is turning that into the enterprise funnel. Then, because the enterprise customers, they those contract sizes, we're doing that fine tuning and providing everything else around that on those are seven to eight figure annual contracts we're looking at with them, where, if we nail one of those, we're trying to serve 300,000 consumers worth of requests. Then that enterprise focus we generally deemed valuable. A lot of the consumer stuff, in due time will be like a strong, recurring new base, but it's not priority one for the company that we shifted kind of up in the pretty but especially probably since I've spoken base and last I think he's even seen this chart, then it's been a minute. So long story short, the on the enterprises we we closed our first pilot with Blue Origin a number of weeks ago. It was like last week of May. We're focused on that pilot right now. We're negotiating these Volkswagens to land strong automotive customers, where once the origin pilot's done, we're working on negotiating what that's gonna look like as a production contract. Then we'll push these in a pilot's automotive as a VP one. So we wanted to bifurcate those on engineering team bandwidth, so we've been holding off on those. And then a slew of other companies. It starts a little out of date even there's a bunch more to put in here then, but the focus right now is mature, that generative AI fine tuning platform, turn more of that into self serve, expand that into the right data sets. We've done SolidWorks, we've been priyo, we've done X. We haven't done get to yet get he is needed for, for Volkswagen specifically. So that's next up on the docket for a data pipeline. But long story short, the goal is with these that you know, if we convert or five of these production contracts, we're well beyond break even as a company. That's easier than the slog of consumer sales. And those kind of follows the Enterprise product material, consumer follows. That one focus right now is deliver on those pilots consumers will follow, and that these are materially larger contracts and potential than anything the consumer market can provide. I find two, including markets at scale, you know, 10 to 100 times bigger than just
S Speaker 323:18consumer CAD subscriptions. Okay, understand that. So, Jordan, the questions I have here are, how are you finding these enterprise customers? Is there a POC needed for a customer to adopt you? How does that POC look like? And do you go into fine tuning? Poster, POC, how long does that fine tuning process
consumer CAD subscriptions. Okay, understand that. So, Jordan, the questions I have here are, how are you finding these enterprise customers? Is there a POC needed for a customer to adopt you? How does that POC look like? And do you go into fine tuning? Poster, POC, how long does that fine tuning process
consumer CAD subscriptions. Okay, understand that. So, Jordan, the questions I have here are, how are you finding these enterprise customers? Is there a POC needed for a customer to adopt you? How does that POC look like? And do you go into fine tuning? Poster, POC, how long does that fine tuning process
consumer CAD subscriptions. Okay, understand that. So, Jordan, the questions I have here are, how are you finding these enterprise customers? Is there a POC needed for a customer to adopt you? How does that POC look like? And do you go into fine tuning? Poster, POC, how long does that fine tuning process
S Speaker 223:34take? No great question. I'll use a Blue Origin POC as an example. Then, but step one was then delivering their data to us. Then we went through that as phase one, over about a three week period with them, of getting their data, understanding the metadata, mapping that model, developing the trio to our language, our data format, pipeline, and maturing that. And then we figured phase two, and what we call ready to train. Then we had a sufficient large amount of their data converted then that we felt good entering the training period. We're doing that training right now and and then phase three is, I'm simply testing that model within the CAD environment and within other environments. Then, are they getting useful insights from that, or the things that models missing on then? But it's a pretty rapid sequence there. Our goal is that every time we do these fine tunings, it's a more hands off, automated process. The example we use is scale AI generative AI platform then, where the goal is to get that to a point they can sign up. They can link to their s3 bucket where their data is. They can choose a base model. They can choose the benchmarks they put in their credit card, it starts charging and training. Then we'll probably be at that for some data set. Some are harder to deal with others, but some data sets by end of the year where that's a fully hands off process, no more concierge, no more white glove. That school on pipeline is every time it's easier. The Blue POC is intended to be about a two to three month voc there, but very aggressively getting into, maybe to summarize my answer for your question, very aggressively getting into that fine tuning, that fine tuning delivers, and they can adopt that in a flexible number of ways. Then they can test out and blue is going to be in parallel. They can test out ways to integrate it. But the number one thing is, does that provide valuable enterprise value to their broad and what we basically, if it does, integrated power makes sense
take? No great question. I'll use a Blue Origin POC as an example. Then, but step one was then delivering their data to us. Then we went through that as phase one, over about a three week period with them, of getting their data, understanding the metadata, mapping that model, developing the trio to our language, our data format, pipeline, and maturing that. And then we figured phase two, and what we call ready to train. Then we had a sufficient large amount of their data converted then that we felt good entering the training period. We're doing that training right now and and then phase three is, I'm simply testing that model within the CAD environment and within other environments. Then, are they getting useful insights from that, or the things that models missing on then? But it's a pretty rapid sequence there. Our goal is that every time we do these fine tunings, it's a more hands off, automated process. The example we use is scale AI generative AI platform then, where the goal is to get that to a point they can sign up. They can link to their s3 bucket where their data is. They can choose a base model. They can choose the benchmarks they put in their credit card, it starts charging and training. Then we'll probably be at that for some data set. Some are harder to deal with others, but some data sets by end of the year where that's a fully hands off process, no more concierge, no more white glove. That school on pipeline is every time it's easier. The Blue POC is intended to be about a two to three month voc there, but very aggressively getting into, maybe to summarize my answer for your question, very aggressively getting into that fine tuning, that fine tuning delivers, and they can adopt that in a flexible number of ways. Then they can test out and blue is going to be in parallel. They can test out ways to integrate it. But the number one thing is, does that provide valuable enterprise value to their broad and what we basically, if it does, integrated power makes sense
take? No great question. I'll use a Blue Origin POC as an example. Then, but step one was then delivering their data to us. Then we went through that as phase one, over about a three week period with them, of getting their data, understanding the metadata, mapping that model, developing the trio to our language, our data format, pipeline, and maturing that. And then we figured phase two, and what we call ready to train. Then we had a sufficient large amount of their data converted then that we felt good entering the training period. We're doing that training right now and and then phase three is, I'm simply testing that model within the CAD environment and within other environments. Then, are they getting useful insights from that, or the things that models missing on then? But it's a pretty rapid sequence there. Our goal is that every time we do these fine tunings, it's a more hands off, automated process. The example we use is scale AI generative AI platform then, where the goal is to get that to a point they can sign up. They can link to their s3 bucket where their data is. They can choose a base model. They can choose the benchmarks they put in their credit card, it starts charging and training. Then we'll probably be at that for some data set. Some are harder to deal with others, but some data sets by end of the year where that's a fully hands off process, no more concierge, no more white glove. That school on pipeline is every time it's easier. The Blue POC is intended to be about a two to three month voc there, but very aggressively getting into, maybe to summarize my answer for your question, very aggressively getting into that fine tuning, that fine tuning delivers, and they can adopt that in a flexible number of ways. Then they can test out and blue is going to be in parallel. They can test out ways to integrate it. But the number one thing is, does that provide valuable enterprise value to their broad and what we basically, if it does, integrated power makes sense
take? No great question. I'll use a Blue Origin POC as an example. Then, but step one was then delivering their data to us. Then we went through that as phase one, over about a three week period with them, of getting their data, understanding the metadata, mapping that model, developing the trio to our language, our data format, pipeline, and maturing that. And then we figured phase two, and what we call ready to train. Then we had a sufficient large amount of their data converted then that we felt good entering the training period. We're doing that training right now and and then phase three is, I'm simply testing that model within the CAD environment and within other environments. Then, are they getting useful insights from that, or the things that models missing on then? But it's a pretty rapid sequence there. Our goal is that every time we do these fine tunings, it's a more hands off, automated process. The example we use is scale AI generative AI platform then, where the goal is to get that to a point they can sign up. They can link to their s3 bucket where their data is. They can choose a base model. They can choose the benchmarks they put in their credit card, it starts charging and training. Then we'll probably be at that for some data set. Some are harder to deal with others, but some data sets by end of the year where that's a fully hands off process, no more concierge, no more white glove. That school on pipeline is every time it's easier. The Blue POC is intended to be about a two to three month voc there, but very aggressively getting into, maybe to summarize my answer for your question, very aggressively getting into that fine tuning, that fine tuning delivers, and they can adopt that in a flexible number of ways. Then they can test out and blue is going to be in parallel. They can test out ways to integrate it. But the number one thing is, does that provide valuable enterprise value to their broad and what we basically, if it does, integrated power makes sense
25:02for them. Understand that Dawn, so
for them. Understand that Dawn, so
for them. Understand that Dawn, so
for them. Understand that Dawn, so
S Speaker 325:03say, two to three months today, when you move into a completely self fine tuning platform, how much is it able to use? An expectation
say, two to three months today, when you move into a completely self fine tuning platform, how much is it able to use? An expectation
say, two to three months today, when you move into a completely self fine tuning platform, how much is it able to use? An expectation
say, two to three months today, when you move into a completely self fine tuning platform, how much is it able to use? An expectation
S Speaker 225:11is, if your pipelines are fully automated and mature, then if you enter the fine tuning the moment you connect that three bucket, or whatever bucket you want, then, so you're talking, you know, as far as far as a preliminary model, like, generally, our small sample size, we like to train on, like blues, full data sets, 2 million files. We're working with a subset of that data for the first version. Let them test that out, just so we, you know, walk before we run on the more expensive side of the training then. But those first, like, couple 100 files you can put in, you can have a result or two on top of our base model, but you can test out and start to see on that kind of emergent behavior of it, knowing your parts more than the base models, but you start handing that over. So long story short, with that, the expectation is you can see value within a couple days, if not short number of weeks, if you need, like a larger data set, if they're kind of walking us in the fine tuning. And we're feeling good, the blue data set, we've been very happy with. And as a POC, they've been very aggressive. They get it on where the tech is going. They're huge fans of the road map on data exception, so as we finish up blue here and pass them off to interface three, we're getting ready for that phase three handover. That's when we're going to pick up these next two. We're negotiating them right now. F Tech's actually jumped forward there, quoted in the scoping phase. They're looking at a POC as well. They're big on aluminum extrusion company. Then it's a pretty similar, pretty common job that wouldn't be too difficult of a training, just based on the they have a lot of parts, but fairly simple kind of subset of geometry so they modularize, right? So, yeah, that's by end of the year I expect, you know, blue will be in production. A subset of these other ones will be in production, and we will be working through what's kind of that long tail of customers that are processing more time, or they need to see more proof points then. But every single one barrier entry gets on set up time get scale. Ai generative. AI platform is different. Ai platform is a perfect example. You use their dashboards as a buckets internally for what we want ours to look like, is that
is, if your pipelines are fully automated and mature, then if you enter the fine tuning the moment you connect that three bucket, or whatever bucket you want, then, so you're talking, you know, as far as far as a preliminary model, like, generally, our small sample size, we like to train on, like blues, full data sets, 2 million files. We're working with a subset of that data for the first version. Let them test that out, just so we, you know, walk before we run on the more expensive side of the training then. But those first, like, couple 100 files you can put in, you can have a result or two on top of our base model, but you can test out and start to see on that kind of emergent behavior of it, knowing your parts more than the base models, but you start handing that over. So long story short, with that, the expectation is you can see value within a couple days, if not short number of weeks, if you need, like a larger data set, if they're kind of walking us in the fine tuning. And we're feeling good, the blue data set, we've been very happy with. And as a POC, they've been very aggressive. They get it on where the tech is going. They're huge fans of the road map on data exception, so as we finish up blue here and pass them off to interface three, we're getting ready for that phase three handover. That's when we're going to pick up these next two. We're negotiating them right now. F Tech's actually jumped forward there, quoted in the scoping phase. They're looking at a POC as well. They're big on aluminum extrusion company. Then it's a pretty similar, pretty common job that wouldn't be too difficult of a training, just based on the they have a lot of parts, but fairly simple kind of subset of geometry so they modularize, right? So, yeah, that's by end of the year I expect, you know, blue will be in production. A subset of these other ones will be in production, and we will be working through what's kind of that long tail of customers that are processing more time, or they need to see more proof points then. But every single one barrier entry gets on set up time get scale. Ai generative. AI platform is different. Ai platform is a perfect example. You use their dashboards as a buckets internally for what we want ours to look like, is that
is, if your pipelines are fully automated and mature, then if you enter the fine tuning the moment you connect that three bucket, or whatever bucket you want, then, so you're talking, you know, as far as far as a preliminary model, like, generally, our small sample size, we like to train on, like blues, full data sets, 2 million files. We're working with a subset of that data for the first version. Let them test that out, just so we, you know, walk before we run on the more expensive side of the training then. But those first, like, couple 100 files you can put in, you can have a result or two on top of our base model, but you can test out and start to see on that kind of emergent behavior of it, knowing your parts more than the base models, but you start handing that over. So long story short, with that, the expectation is you can see value within a couple days, if not short number of weeks, if you need, like a larger data set, if they're kind of walking us in the fine tuning. And we're feeling good, the blue data set, we've been very happy with. And as a POC, they've been very aggressive. They get it on where the tech is going. They're huge fans of the road map on data exception, so as we finish up blue here and pass them off to interface three, we're getting ready for that phase three handover. That's when we're going to pick up these next two. We're negotiating them right now. F Tech's actually jumped forward there, quoted in the scoping phase. They're looking at a POC as well. They're big on aluminum extrusion company. Then it's a pretty similar, pretty common job that wouldn't be too difficult of a training, just based on the they have a lot of parts, but fairly simple kind of subset of geometry so they modularize, right? So, yeah, that's by end of the year I expect, you know, blue will be in production. A subset of these other ones will be in production, and we will be working through what's kind of that long tail of customers that are processing more time, or they need to see more proof points then. But every single one barrier entry gets on set up time get scale. Ai generative. AI platform is different. Ai platform is a perfect example. You use their dashboards as a buckets internally for what we want ours to look like, is that
is, if your pipelines are fully automated and mature, then if you enter the fine tuning the moment you connect that three bucket, or whatever bucket you want, then, so you're talking, you know, as far as far as a preliminary model, like, generally, our small sample size, we like to train on, like blues, full data sets, 2 million files. We're working with a subset of that data for the first version. Let them test that out, just so we, you know, walk before we run on the more expensive side of the training then. But those first, like, couple 100 files you can put in, you can have a result or two on top of our base model, but you can test out and start to see on that kind of emergent behavior of it, knowing your parts more than the base models, but you start handing that over. So long story short, with that, the expectation is you can see value within a couple days, if not short number of weeks, if you need, like a larger data set, if they're kind of walking us in the fine tuning. And we're feeling good, the blue data set, we've been very happy with. And as a POC, they've been very aggressive. They get it on where the tech is going. They're huge fans of the road map on data exception, so as we finish up blue here and pass them off to interface three, we're getting ready for that phase three handover. That's when we're going to pick up these next two. We're negotiating them right now. F Tech's actually jumped forward there, quoted in the scoping phase. They're looking at a POC as well. They're big on aluminum extrusion company. Then it's a pretty similar, pretty common job that wouldn't be too difficult of a training, just based on the they have a lot of parts, but fairly simple kind of subset of geometry so they modularize, right? So, yeah, that's by end of the year I expect, you know, blue will be in production. A subset of these other ones will be in production, and we will be working through what's kind of that long tail of customers that are processing more time, or they need to see more proof points then. But every single one barrier entry gets on set up time get scale. Ai generative. AI platform is different. Ai platform is a perfect example. You use their dashboards as a buckets internally for what we want ours to look like, is that
S Speaker 226:55good money. We're gonna do the same, the same with our investors at the here it's, and it's a unique parallel where we're the only ones that can do that kind of interface, that kind of platform, with CAD and give that flexibility and introduce that back and wait where that can be used by any enterprise user, or if you want that in the CAD environment, you have it straight
good money. We're gonna do the same, the same with our investors at the here it's, and it's a unique parallel where we're the only ones that can do that kind of interface, that kind of platform, with CAD and give that flexibility and introduce that back and wait where that can be used by any enterprise user, or if you want that in the CAD environment, you have it straight
good money. We're gonna do the same, the same with our investors at the here it's, and it's a unique parallel where we're the only ones that can do that kind of interface, that kind of platform, with CAD and give that flexibility and introduce that back and wait where that can be used by any enterprise user, or if you want that in the CAD environment, you have it straight
good money. We're gonna do the same, the same with our investors at the here it's, and it's a unique parallel where we're the only ones that can do that kind of interface, that kind of platform, with CAD and give that flexibility and introduce that back and wait where that can be used by any enterprise user, or if you want that in the CAD environment, you have it straight
S Speaker 327:13back in the CAD environment. Just to get a sense of numbers. Jordan, what could the ACB for a Blue Origin land could be? And how much do you think they can expand?
back in the CAD environment. Just to get a sense of numbers. Jordan, what could the ACB for a Blue Origin land could be? And how much do you think they can expand?
back in the CAD environment. Just to get a sense of numbers. Jordan, what could the ACB for a Blue Origin land could be? And how much do you think they can expand?
back in the CAD environment. Just to get a sense of numbers. Jordan, what could the ACB for a Blue Origin land could be? And how much do you think they can expand?
S Speaker 227:21That's a great question. Our goal was this year, having them at least at seven figure ACV. And the way we price it is, like, you know, a bit of a discovery phase for us is, you know, they have 13,000 engineers. What is the value of them being able to have every single one of those 13,000 people interact with their engineering data and query it? Is that a five figure problem? No, that six figure problem? No, it was at seven maybe. Is it eight? Maybe nine? You have to be able to eight is where we think we're going to land there. Then day one of production is going to be seven figures by one to 2 million is where that's looking like then. And then, it really depends on size of the data set, how much metadata they're stacking on top of that, where they're sending over every specification, every program management document, every drawing like they're just stacking stuff on. It's worth you can get this in there that drives up the cost for us. That's why, I mean, like that scale AI perspective, scale, a average pre paying them, choosing how much to train, on top of then and something. But we're never like in the red on training cost for a customer is that they're all pre paying the credits and to make sure that they, if they want to train and train, they want a bigger model, bigger tuning, stronger benchmarks, bigger like a new base model from us, because we will have new versions of base models come out. They choose what they want. They pay. But, yeah, that would be seven figure. ACV, I would argue we're in production contract seven figure. ACV, reasonable path. As we expand our data sets, we expand into tool pathing, we expand the manufacturing, then the value of what we're offering goes up, the scope of the data, the scope of the training goes up, all in parallel. That would become eight figure. Hard to say we ever hit nine, but I do think if we hit, you know, the full roadmap of these downstream areas, engineering analysis, others, and we can be a good dent, because like, like, it depends on the year, but like, I probably three to $4 billion a year run rate, then are we, like, how much of a dent can we make in that on engineering, labor and efficiency savings? Um, there's probably an argument we could hit nine figures, but that's like a four to five year round thing, like six to seven to eight figures in the scope of what we offer today, fair
That's a great question. Our goal was this year, having them at least at seven figure ACV. And the way we price it is, like, you know, a bit of a discovery phase for us is, you know, they have 13,000 engineers. What is the value of them being able to have every single one of those 13,000 people interact with their engineering data and query it? Is that a five figure problem? No, that six figure problem? No, it was at seven maybe. Is it eight? Maybe nine? You have to be able to eight is where we think we're going to land there. Then day one of production is going to be seven figures by one to 2 million is where that's looking like then. And then, it really depends on size of the data set, how much metadata they're stacking on top of that, where they're sending over every specification, every program management document, every drawing like they're just stacking stuff on. It's worth you can get this in there that drives up the cost for us. That's why, I mean, like that scale AI perspective, scale, a average pre paying them, choosing how much to train, on top of then and something. But we're never like in the red on training cost for a customer is that they're all pre paying the credits and to make sure that they, if they want to train and train, they want a bigger model, bigger tuning, stronger benchmarks, bigger like a new base model from us, because we will have new versions of base models come out. They choose what they want. They pay. But, yeah, that would be seven figure. ACV, I would argue we're in production contract seven figure. ACV, reasonable path. As we expand our data sets, we expand into tool pathing, we expand the manufacturing, then the value of what we're offering goes up, the scope of the data, the scope of the training goes up, all in parallel. That would become eight figure. Hard to say we ever hit nine, but I do think if we hit, you know, the full roadmap of these downstream areas, engineering analysis, others, and we can be a good dent, because like, like, it depends on the year, but like, I probably three to $4 billion a year run rate, then are we, like, how much of a dent can we make in that on engineering, labor and efficiency savings? Um, there's probably an argument we could hit nine figures, but that's like a four to five year round thing, like six to seven to eight figures in the scope of what we offer today, fair
That's a great question. Our goal was this year, having them at least at seven figure ACV. And the way we price it is, like, you know, a bit of a discovery phase for us is, you know, they have 13,000 engineers. What is the value of them being able to have every single one of those 13,000 people interact with their engineering data and query it? Is that a five figure problem? No, that six figure problem? No, it was at seven maybe. Is it eight? Maybe nine? You have to be able to eight is where we think we're going to land there. Then day one of production is going to be seven figures by one to 2 million is where that's looking like then. And then, it really depends on size of the data set, how much metadata they're stacking on top of that, where they're sending over every specification, every program management document, every drawing like they're just stacking stuff on. It's worth you can get this in there that drives up the cost for us. That's why, I mean, like that scale AI perspective, scale, a average pre paying them, choosing how much to train, on top of then and something. But we're never like in the red on training cost for a customer is that they're all pre paying the credits and to make sure that they, if they want to train and train, they want a bigger model, bigger tuning, stronger benchmarks, bigger like a new base model from us, because we will have new versions of base models come out. They choose what they want. They pay. But, yeah, that would be seven figure. ACV, I would argue we're in production contract seven figure. ACV, reasonable path. As we expand our data sets, we expand into tool pathing, we expand the manufacturing, then the value of what we're offering goes up, the scope of the data, the scope of the training goes up, all in parallel. That would become eight figure. Hard to say we ever hit nine, but I do think if we hit, you know, the full roadmap of these downstream areas, engineering analysis, others, and we can be a good dent, because like, like, it depends on the year, but like, I probably three to $4 billion a year run rate, then are we, like, how much of a dent can we make in that on engineering, labor and efficiency savings? Um, there's probably an argument we could hit nine figures, but that's like a four to five year round thing, like six to seven to eight figures in the scope of what we offer today, fair
That's a great question. Our goal was this year, having them at least at seven figure ACV. And the way we price it is, like, you know, a bit of a discovery phase for us is, you know, they have 13,000 engineers. What is the value of them being able to have every single one of those 13,000 people interact with their engineering data and query it? Is that a five figure problem? No, that six figure problem? No, it was at seven maybe. Is it eight? Maybe nine? You have to be able to eight is where we think we're going to land there. Then day one of production is going to be seven figures by one to 2 million is where that's looking like then. And then, it really depends on size of the data set, how much metadata they're stacking on top of that, where they're sending over every specification, every program management document, every drawing like they're just stacking stuff on. It's worth you can get this in there that drives up the cost for us. That's why, I mean, like that scale AI perspective, scale, a average pre paying them, choosing how much to train, on top of then and something. But we're never like in the red on training cost for a customer is that they're all pre paying the credits and to make sure that they, if they want to train and train, they want a bigger model, bigger tuning, stronger benchmarks, bigger like a new base model from us, because we will have new versions of base models come out. They choose what they want. They pay. But, yeah, that would be seven figure. ACV, I would argue we're in production contract seven figure. ACV, reasonable path. As we expand our data sets, we expand into tool pathing, we expand the manufacturing, then the value of what we're offering goes up, the scope of the data, the scope of the training goes up, all in parallel. That would become eight figure. Hard to say we ever hit nine, but I do think if we hit, you know, the full roadmap of these downstream areas, engineering analysis, others, and we can be a good dent, because like, like, it depends on the year, but like, I probably three to $4 billion a year run rate, then are we, like, how much of a dent can we make in that on engineering, labor and efficiency savings? Um, there's probably an argument we could hit nine figures, but that's like a four to five year round thing, like six to seven to eight figures in the scope of what we offer today, fair
S Speaker 329:00enough, and Jordan. So I'm assuming all the passion so far in terms of revenue is from presumable on,
enough, and Jordan. So I'm assuming all the passion so far in terms of revenue is from presumable on,
enough, and Jordan. So I'm assuming all the passion so far in terms of revenue is from presumable on,
enough, and Jordan. So I'm assuming all the passion so far in terms of revenue is from presumable on,
S Speaker 229:05the enterprises and the actual ACV from the enterprises. So that's not we use as the enterprise ACV, where Blue was 100k for their pilot, but then each of these is expected to be, that's where standard offering is kind of 100k pilot. We'll drop down a little bit for some groups like, I think Volkswagen want to close my 75 take it then sort of thing. But yeah, that's our goal right now is. And why we're doing some of the kind of short term plan right is we're pretty strong. Blue deliverance converts to production. If we show we can do tier one, aerospace, tier one, automotive, tier one, industrials companies, then we're a great spot for actually going into the sooner today, but until then, we wanted to show aggressive growth on these. I mentioned all the automotive specific features they need support on. We want to grow the ML team. We want to grow the engine team in order to make sure we can work in space, automotive, industrials, you know, other companies all at once and all right now, I don't want to be in a spot where we risk any of the pilots on quality, like having the team be drawn to things that's like the catch 22 on our side that led to, you know, let's, let's open up some states. Here is grow the team. Capture this enterprise pipeline successfully. If we do so, we're set for life, right?
the enterprises and the actual ACV from the enterprises. So that's not we use as the enterprise ACV, where Blue was 100k for their pilot, but then each of these is expected to be, that's where standard offering is kind of 100k pilot. We'll drop down a little bit for some groups like, I think Volkswagen want to close my 75 take it then sort of thing. But yeah, that's our goal right now is. And why we're doing some of the kind of short term plan right is we're pretty strong. Blue deliverance converts to production. If we show we can do tier one, aerospace, tier one, automotive, tier one, industrials companies, then we're a great spot for actually going into the sooner today, but until then, we wanted to show aggressive growth on these. I mentioned all the automotive specific features they need support on. We want to grow the ML team. We want to grow the engine team in order to make sure we can work in space, automotive, industrials, you know, other companies all at once and all right now, I don't want to be in a spot where we risk any of the pilots on quality, like having the team be drawn to things that's like the catch 22 on our side that led to, you know, let's, let's open up some states. Here is grow the team. Capture this enterprise pipeline successfully. If we do so, we're set for life, right?
the enterprises and the actual ACV from the enterprises. So that's not we use as the enterprise ACV, where Blue was 100k for their pilot, but then each of these is expected to be, that's where standard offering is kind of 100k pilot. We'll drop down a little bit for some groups like, I think Volkswagen want to close my 75 take it then sort of thing. But yeah, that's our goal right now is. And why we're doing some of the kind of short term plan right is we're pretty strong. Blue deliverance converts to production. If we show we can do tier one, aerospace, tier one, automotive, tier one, industrials companies, then we're a great spot for actually going into the sooner today, but until then, we wanted to show aggressive growth on these. I mentioned all the automotive specific features they need support on. We want to grow the ML team. We want to grow the engine team in order to make sure we can work in space, automotive, industrials, you know, other companies all at once and all right now, I don't want to be in a spot where we risk any of the pilots on quality, like having the team be drawn to things that's like the catch 22 on our side that led to, you know, let's, let's open up some states. Here is grow the team. Capture this enterprise pipeline successfully. If we do so, we're set for life, right?
the enterprises and the actual ACV from the enterprises. So that's not we use as the enterprise ACV, where Blue was 100k for their pilot, but then each of these is expected to be, that's where standard offering is kind of 100k pilot. We'll drop down a little bit for some groups like, I think Volkswagen want to close my 75 take it then sort of thing. But yeah, that's our goal right now is. And why we're doing some of the kind of short term plan right is we're pretty strong. Blue deliverance converts to production. If we show we can do tier one, aerospace, tier one, automotive, tier one, industrials companies, then we're a great spot for actually going into the sooner today, but until then, we wanted to show aggressive growth on these. I mentioned all the automotive specific features they need support on. We want to grow the ML team. We want to grow the engine team in order to make sure we can work in space, automotive, industrials, you know, other companies all at once and all right now, I don't want to be in a spot where we risk any of the pilots on quality, like having the team be drawn to things that's like the catch 22 on our side that led to, you know, let's, let's open up some states. Here is grow the team. Capture this enterprise pipeline successfully. If we do so, we're set for life, right?
S Speaker 330:03And quickly on the ground. How much have you raised so far? And what's the current race? What's the valuation you're targeting? And what about the series A when we plan to sort of have that? Yeah,
And quickly on the ground. How much have you raised so far? And what's the current race? What's the valuation you're targeting? And what about the series A when we plan to sort of have that? Yeah,
And quickly on the ground. How much have you raised so far? And what's the current race? What's the valuation you're targeting? And what about the series A when we plan to sort of have that? Yeah,
And quickly on the ground. How much have you raised so far? And what's the current race? What's the valuation you're targeting? And what about the series A when we plan to sort of have that? Yeah,
S Speaker 230:13so we have, and also needed, a full investor list is in here. Here's the highlights page. So the Carl bass trivia steering School is in here too. Then and then there's the full list as well. But we've raised historically, about 17. About 17 million over the last, you know, three, three and a half years. Then we did a set of safes. Last year, we raised about 12 million on safe. Last year at 60 million cap, the board decided this, or the last board meeting in June, we kick off a set of safes at 100 and we circulated approvals for those. This week, we have a million committed from groups we were warm with, and then starting to talk on the rest. So intent is to talk on the rest. So intent is to bring in about five that lets us grow the ML and graphics teams. And then we'll go off the a kind of like nominally scoped in the deck here, which was the end of q3 beginning of q4 then we'll kick that off. But 25 million a just to get that, this is the old Id actually update. These are going more off, like the recurring seats in TCP, on the enterprises on a change the threshold there. This is slightly dated. Then 25 million. Let's significantly mature the size of the team. Kick off the 4 million downstream areas that we just have the pilots in. They're the pilot teams in right now, and then print from there. But that'll get the q3 realistically. Now that we have these days happening, not q1 we're feeling pretty good on timing that we don't need to rush into that until we have that enterprise pipeline. That's why I get all my check marks of showing not industry specific. We're industry specific. We're industry agnostic. Onto wiki support that we can convert those pilots to production. You don't see anyone coming in on the safe gets the reward for coming in
so we have, and also needed, a full investor list is in here. Here's the highlights page. So the Carl bass trivia steering School is in here too. Then and then there's the full list as well. But we've raised historically, about 17. About 17 million over the last, you know, three, three and a half years. Then we did a set of safes. Last year, we raised about 12 million on safe. Last year at 60 million cap, the board decided this, or the last board meeting in June, we kick off a set of safes at 100 and we circulated approvals for those. This week, we have a million committed from groups we were warm with, and then starting to talk on the rest. So intent is to talk on the rest. So intent is to bring in about five that lets us grow the ML and graphics teams. And then we'll go off the a kind of like nominally scoped in the deck here, which was the end of q3 beginning of q4 then we'll kick that off. But 25 million a just to get that, this is the old Id actually update. These are going more off, like the recurring seats in TCP, on the enterprises on a change the threshold there. This is slightly dated. Then 25 million. Let's significantly mature the size of the team. Kick off the 4 million downstream areas that we just have the pilots in. They're the pilot teams in right now, and then print from there. But that'll get the q3 realistically. Now that we have these days happening, not q1 we're feeling pretty good on timing that we don't need to rush into that until we have that enterprise pipeline. That's why I get all my check marks of showing not industry specific. We're industry specific. We're industry agnostic. Onto wiki support that we can convert those pilots to production. You don't see anyone coming in on the safe gets the reward for coming in
so we have, and also needed, a full investor list is in here. Here's the highlights page. So the Carl bass trivia steering School is in here too. Then and then there's the full list as well. But we've raised historically, about 17. About 17 million over the last, you know, three, three and a half years. Then we did a set of safes. Last year, we raised about 12 million on safe. Last year at 60 million cap, the board decided this, or the last board meeting in June, we kick off a set of safes at 100 and we circulated approvals for those. This week, we have a million committed from groups we were warm with, and then starting to talk on the rest. So intent is to talk on the rest. So intent is to bring in about five that lets us grow the ML and graphics teams. And then we'll go off the a kind of like nominally scoped in the deck here, which was the end of q3 beginning of q4 then we'll kick that off. But 25 million a just to get that, this is the old Id actually update. These are going more off, like the recurring seats in TCP, on the enterprises on a change the threshold there. This is slightly dated. Then 25 million. Let's significantly mature the size of the team. Kick off the 4 million downstream areas that we just have the pilots in. They're the pilot teams in right now, and then print from there. But that'll get the q3 realistically. Now that we have these days happening, not q1 we're feeling pretty good on timing that we don't need to rush into that until we have that enterprise pipeline. That's why I get all my check marks of showing not industry specific. We're industry specific. We're industry agnostic. Onto wiki support that we can convert those pilots to production. You don't see anyone coming in on the safe gets the reward for coming in
so we have, and also needed, a full investor list is in here. Here's the highlights page. So the Carl bass trivia steering School is in here too. Then and then there's the full list as well. But we've raised historically, about 17. About 17 million over the last, you know, three, three and a half years. Then we did a set of safes. Last year, we raised about 12 million on safe. Last year at 60 million cap, the board decided this, or the last board meeting in June, we kick off a set of safes at 100 and we circulated approvals for those. This week, we have a million committed from groups we were warm with, and then starting to talk on the rest. So intent is to talk on the rest. So intent is to bring in about five that lets us grow the ML and graphics teams. And then we'll go off the a kind of like nominally scoped in the deck here, which was the end of q3 beginning of q4 then we'll kick that off. But 25 million a just to get that, this is the old Id actually update. These are going more off, like the recurring seats in TCP, on the enterprises on a change the threshold there. This is slightly dated. Then 25 million. Let's significantly mature the size of the team. Kick off the 4 million downstream areas that we just have the pilots in. They're the pilot teams in right now, and then print from there. But that'll get the q3 realistically. Now that we have these days happening, not q1 we're feeling pretty good on timing that we don't need to rush into that until we have that enterprise pipeline. That's why I get all my check marks of showing not industry specific. We're industry specific. We're industry agnostic. Onto wiki support that we can convert those pilots to production. You don't see anyone coming in on the safe gets the reward for coming in
S Speaker 331:28before those milestones are fully manifested, right? And any timeline on your end to close the currency
before those milestones are fully manifested, right? And any timeline on your end to close the currency
before those milestones are fully manifested, right? And any timeline on your end to close the currency
before those milestones are fully manifested, right? And any timeline on your end to close the currency
S Speaker 231:32from our goal is the next time, like 3060, days, like we have time in order to unlock the hires needed for folks wagging, for stellantis, for others, was to test the market and see if there's interest then. So unlocking that roadmap, unlocking that downstream customer pipeline, and then bringing in a capital impairment that I feel good, that those like the 100 billion prices like a nice in between where based on where people expected, like, it's a fairly low friction investment process we're looking at. It's not like too high of a price with that 3060, days to wrap it up, but we're already starting to unlock those hires based on what's been strong. COVID area interests from assessing the market on 100 million savings
from our goal is the next time, like 3060, days, like we have time in order to unlock the hires needed for folks wagging, for stellantis, for others, was to test the market and see if there's interest then. So unlocking that roadmap, unlocking that downstream customer pipeline, and then bringing in a capital impairment that I feel good, that those like the 100 billion prices like a nice in between where based on where people expected, like, it's a fairly low friction investment process we're looking at. It's not like too high of a price with that 3060, days to wrap it up, but we're already starting to unlock those hires based on what's been strong. COVID area interests from assessing the market on 100 million savings
from our goal is the next time, like 3060, days, like we have time in order to unlock the hires needed for folks wagging, for stellantis, for others, was to test the market and see if there's interest then. So unlocking that roadmap, unlocking that downstream customer pipeline, and then bringing in a capital impairment that I feel good, that those like the 100 billion prices like a nice in between where based on where people expected, like, it's a fairly low friction investment process we're looking at. It's not like too high of a price with that 3060, days to wrap it up, but we're already starting to unlock those hires based on what's been strong. COVID area interests from assessing the market on 100 million savings
from our goal is the next time, like 3060, days, like we have time in order to unlock the hires needed for folks wagging, for stellantis, for others, was to test the market and see if there's interest then. So unlocking that roadmap, unlocking that downstream customer pipeline, and then bringing in a capital impairment that I feel good, that those like the 100 billion prices like a nice in between where based on where people expected, like, it's a fairly low friction investment process we're looking at. It's not like too high of a price with that 3060, days to wrap it up, but we're already starting to unlock those hires based on what's been strong. COVID area interests from assessing the market on 100 million savings
S Speaker 232:24Okay, no, I did it. Would be happy to work with you guys, great, great company you guys have and do what you opened up with. I think the opportunity to work with you guys as a potential customer as well, you know, on that fine tuning, because I've seen a ton of inroads and other AI companies do the long
Okay, no, I did it. Would be happy to work with you guys, great, great company you guys have and do what you opened up with. I think the opportunity to work with you guys as a potential customer as well, you know, on that fine tuning, because I've seen a ton of inroads and other AI companies do the long
Okay, no, I did it. Would be happy to work with you guys, great, great company you guys have and do what you opened up with. I think the opportunity to work with you guys as a potential customer as well, you know, on that fine tuning, because I've seen a ton of inroads and other AI companies do the long
Okay, no, I did it. Would be happy to work with you guys, great, great company you guys have and do what you opened up with. I think the opportunity to work with you guys as a potential customer as well, you know, on that fine tuning, because I've seen a ton of inroads and other AI companies do the long
S Speaker 332:37run, work together, yeah, if you have a sales tech that you use for enterprise scoping, and if you can send that across as well, I as well, I would be like, we have an internal business development team so they can sort of scope if there is interest in from a partnership perspective as well. So we can start those
run, work together, yeah, if you have a sales tech that you use for enterprise scoping, and if you can send that across as well, I as well, I would be like, we have an internal business development team so they can sort of scope if there is interest in from a partnership perspective as well. So we can start those
run, work together, yeah, if you have a sales tech that you use for enterprise scoping, and if you can send that across as well, I as well, I would be like, we have an internal business development team so they can sort of scope if there is interest in from a partnership perspective as well. So we can start those
run, work together, yeah, if you have a sales tech that you use for enterprise scoping, and if you can send that across as well, I as well, I would be like, we have an internal business development team so they can sort of scope if there is interest in from a partnership perspective as well. So we can start those
S Speaker 232:51decisions in parallel, like four or five weeks. That works great for us on our timelines. And then I'll move in quickly before our sales director gives a sales deck as well. But you may want to have like a, like a good engineering contact, like a equivalent to him to talk to you directly on it, just so he likes the same speed the demos put a ton of, you know, demos worth, you know, million words worth saying with these on showing the product. So he, similarly, would probably want to hop on a call. We'll take
decisions in parallel, like four or five weeks. That works great for us on our timelines. And then I'll move in quickly before our sales director gives a sales deck as well. But you may want to have like a, like a good engineering contact, like a equivalent to him to talk to you directly on it, just so he likes the same speed the demos put a ton of, you know, demos worth, you know, million words worth saying with these on showing the product. So he, similarly, would probably want to hop on a call. We'll take
decisions in parallel, like four or five weeks. That works great for us on our timelines. And then I'll move in quickly before our sales director gives a sales deck as well. But you may want to have like a, like a good engineering contact, like a equivalent to him to talk to you directly on it, just so he likes the same speed the demos put a ton of, you know, demos worth, you know, million words worth saying with these on showing the product. So he, similarly, would probably want to hop on a call. We'll take
decisions in parallel, like four or five weeks. That works great for us on our timelines. And then I'll move in quickly before our sales director gives a sales deck as well. But you may want to have like a, like a good engineering contact, like a equivalent to him to talk to you directly on it, just so he likes the same speed the demos put a ton of, you know, demos worth, you know, million words worth saying with these on showing the product. So he, similarly, would probably want to hop on a call. We'll take
S Speaker 333:16that instead of time. Sounds great. Thanks a lot for your time. Absolute pleasure talking
that instead of time. Sounds great. Thanks a lot for your time. Absolute pleasure talking
that instead of time. Sounds great. Thanks a lot for your time. Absolute pleasure talking
that instead of time. Sounds great. Thanks a lot for your time. Absolute pleasure talking
33:20to you. Thanks, Nico as well. Thank you. Zero.
to you. Thanks, Nico as well. Thank you. Zero.
to you. Thanks, Nico as well. Thank you. Zero.
to you. Thanks, Nico as well. Thank you. Zero.