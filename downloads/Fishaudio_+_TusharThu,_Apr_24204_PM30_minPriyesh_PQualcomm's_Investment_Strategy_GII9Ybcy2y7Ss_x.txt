Meeting: Fishaudio + Tushar
Thu, Apr 24
2:04 PM
30 min
Priyesh P
Qualcomm's Investment Strategy and Overview 
URL: https://otter.ai/u/GII9Ybcy2y7Ss_x8OAmUAyRX3c0
Downloaded: 2025-12-22T11:37:31.712202
Method: text_extraction
============================================================

0:02anthropic and scale
S Speaker 10:06in the infrastructure space, and then several others, and then in the application space. We've done several more as well. We had done a seed investment in a company that did
in the infrastructure space, and then several others, and then in the application space. We've done several more as well. We had done a seed investment in a company that did
in the infrastructure space, and then several others, and then in the application space. We've done several more as well. We had done a seed investment in a company that did
in the infrastructure space, and then several others, and then in the application space. We've done several more as well. We had done a seed investment in a company that did
0:24text to speech, well said labs,
text to speech, well said labs,
text to speech, well said labs,
text to speech, well said labs,
S Speaker 10:28but it's mostly them in their business was primarily just focused on text to speech and not like serving that as an API, but that was a seed investment from a few years ago, and then we followed this base of audio and speech very carefully as well. It's something that across, you know, ships over a billion chips across mobile PCs, IoT, automotive, XR and a bunch of other things. And we So, as you can imagine, audio and speech
but it's mostly them in their business was primarily just focused on text to speech and not like serving that as an API, but that was a seed investment from a few years ago, and then we followed this base of audio and speech very carefully as well. It's something that across, you know, ships over a billion chips across mobile PCs, IoT, automotive, XR and a bunch of other things. And we So, as you can imagine, audio and speech
but it's mostly them in their business was primarily just focused on text to speech and not like serving that as an API, but that was a seed investment from a few years ago, and then we followed this base of audio and speech very carefully as well. It's something that across, you know, ships over a billion chips across mobile PCs, IoT, automotive, XR and a bunch of other things. And we So, as you can imagine, audio and speech
but it's mostly them in their business was primarily just focused on text to speech and not like serving that as an API, but that was a seed investment from a few years ago, and then we followed this base of audio and speech very carefully as well. It's something that across, you know, ships over a billion chips across mobile PCs, IoT, automotive, XR and a bunch of other things. And we So, as you can imagine, audio and speech
1:05across these platforms.
across these platforms.
across these platforms.
across these platforms.
S Speaker 22:13so I'm sure yeah. The founder of fish oil, or now we call it open audio and personality I begin. So
so I'm sure yeah. The founder of fish oil, or now we call it open audio and personality I begin. So
so I'm sure yeah. The founder of fish oil, or now we call it open audio and personality I begin. So
so I'm sure yeah. The founder of fish oil, or now we call it open audio and personality I begin. So
S Speaker 12:21the name initially was fish audio, yeah, okay. When did you start the company?
the name initially was fish audio, yeah, okay. When did you start the company?
the name initially was fish audio, yeah, okay. When did you start the company?
the name initially was fish audio, yeah, okay. When did you start the company?
S Speaker 22:27Oh, we started the company on July last year. Okay, okay, so you see, okay, got it, yeah, not too long, yeah. So I began working open source around six or, I mean, around eight years ago, since the beginning of my high school, and primarily on career mission at the moment and building my first product. Earn 20 300k US dollar per year, and then I go to us to study the University of Maryland. Around three years ago, I began working on voice, especially in open source, in voice conversion, voice exercise. And around two years ago, my ex girlfriend cheated, and we ended a six year relationship. And I don't know my thing, so I don't trust relationships anymore. We did AI. And unfortunately, AI company doesn't come with a good or expressive voice. So then we begin working on that part. We begin building ultra realistic and controllable AI voice. And on July last year, we released free speech. One point last year, we released the fish speech, the weapon for the best open source model. And then on July last year, I left Nvidia to full time building the company fish audio, and now we call it research lab open audio, and we have grown from 400k revenue to 4 million in around two months. Yeah, okay,
Oh, we started the company on July last year. Okay, okay, so you see, okay, got it, yeah, not too long, yeah. So I began working open source around six or, I mean, around eight years ago, since the beginning of my high school, and primarily on career mission at the moment and building my first product. Earn 20 300k US dollar per year, and then I go to us to study the University of Maryland. Around three years ago, I began working on voice, especially in open source, in voice conversion, voice exercise. And around two years ago, my ex girlfriend cheated, and we ended a six year relationship. And I don't know my thing, so I don't trust relationships anymore. We did AI. And unfortunately, AI company doesn't come with a good or expressive voice. So then we begin working on that part. We begin building ultra realistic and controllable AI voice. And on July last year, we released free speech. One point last year, we released the fish speech, the weapon for the best open source model. And then on July last year, I left Nvidia to full time building the company fish audio, and now we call it research lab open audio, and we have grown from 400k revenue to 4 million in around two months. Yeah, okay,
Oh, we started the company on July last year. Okay, okay, so you see, okay, got it, yeah, not too long, yeah. So I began working open source around six or, I mean, around eight years ago, since the beginning of my high school, and primarily on career mission at the moment and building my first product. Earn 20 300k US dollar per year, and then I go to us to study the University of Maryland. Around three years ago, I began working on voice, especially in open source, in voice conversion, voice exercise. And around two years ago, my ex girlfriend cheated, and we ended a six year relationship. And I don't know my thing, so I don't trust relationships anymore. We did AI. And unfortunately, AI company doesn't come with a good or expressive voice. So then we begin working on that part. We begin building ultra realistic and controllable AI voice. And on July last year, we released free speech. One point last year, we released the fish speech, the weapon for the best open source model. And then on July last year, I left Nvidia to full time building the company fish audio, and now we call it research lab open audio, and we have grown from 400k revenue to 4 million in around two months. Yeah, okay,
Oh, we started the company on July last year. Okay, okay, so you see, okay, got it, yeah, not too long, yeah. So I began working open source around six or, I mean, around eight years ago, since the beginning of my high school, and primarily on career mission at the moment and building my first product. Earn 20 300k US dollar per year, and then I go to us to study the University of Maryland. Around three years ago, I began working on voice, especially in open source, in voice conversion, voice exercise. And around two years ago, my ex girlfriend cheated, and we ended a six year relationship. And I don't know my thing, so I don't trust relationships anymore. We did AI. And unfortunately, AI company doesn't come with a good or expressive voice. So then we begin working on that part. We begin building ultra realistic and controllable AI voice. And on July last year, we released free speech. One point last year, we released the fish speech, the weapon for the best open source model. And then on July last year, I left Nvidia to full time building the company fish audio, and now we call it research lab open audio, and we have grown from 400k revenue to 4 million in around two months. Yeah, okay,
S Speaker 14:04congratulations. That's pretty good. And then so most of you maybe tell me more about the product, and then I'm guessing like most of your customers are developers.
congratulations. That's pretty good. And then so most of you maybe tell me more about the product, and then I'm guessing like most of your customers are developers.
congratulations. That's pretty good. And then so most of you maybe tell me more about the product, and then I'm guessing like most of your customers are developers.
congratulations. That's pretty good. And then so most of you maybe tell me more about the product, and then I'm guessing like most of your customers are developers.
S Speaker 24:44yeah. So this is what, when we did a user survey to see what's our what was, what's our customers on fishing audio, and most of them are concentrators. They use that to create professional contents. Yeah, interesting.
yeah. So this is what, when we did a user survey to see what's our what was, what's our customers on fishing audio, and most of them are concentrators. They use that to create professional contents. Yeah, interesting.
yeah. So this is what, when we did a user survey to see what's our what was, what's our customers on fishing audio, and most of them are concentrators. They use that to create professional contents. Yeah, interesting.
yeah. So this is what, when we did a user survey to see what's our what was, what's our customers on fishing audio, and most of them are concentrators. They use that to create professional contents. Yeah, interesting.
S Speaker 15:01Got it. Got it, got it? Okay, so, and then, so, so, how does this plug into the workflows? Which is like this, there's tools like, you know, there's tools like, what's the like? There's tools like, captions that people are using. There's tools like, you know, Hagen, and all these other tools that people are using to create content, which is so how does this fit in to their workflow today? So
Got it. Got it, got it? Okay, so, and then, so, so, how does this plug into the workflows? Which is like this, there's tools like, you know, there's tools like, what's the like? There's tools like, captions that people are using. There's tools like, you know, Hagen, and all these other tools that people are using to create content, which is so how does this fit in to their workflow today? So
Got it. Got it, got it? Okay, so, and then, so, so, how does this plug into the workflows? Which is like this, there's tools like, you know, there's tools like, what's the like? There's tools like, captions that people are using. There's tools like, you know, Hagen, and all these other tools that people are using to create content, which is so how does this fit in to their workflow today? So
Got it. Got it, got it? Okay, so, and then, so, so, how does this plug into the workflows? Which is like this, there's tools like, you know, there's tools like, what's the like? There's tools like, captions that people are using. There's tools like, you know, Hagen, and all these other tools that people are using to create content, which is so how does this fit in to their workflow today? So
S Speaker 25:33we built both monolayer foundation layer and application layer. Feature audit is part of our application layer. As you see, we provide them a security which allows them to play with the voice online.
we built both monolayer foundation layer and application layer. Feature audit is part of our application layer. As you see, we provide them a security which allows them to play with the voice online.
we built both monolayer foundation layer and application layer. Feature audit is part of our application layer. As you see, we provide them a security which allows them to play with the voice online.
we built both monolayer foundation layer and application layer. Feature audit is part of our application layer. As you see, we provide them a security which allows them to play with the voice online.
5:46I'm your host, Jessica Parker, today we have
I'm your host, Jessica Parker, today we have
I'm your host, Jessica Parker, today we have
I'm your host, Jessica Parker, today we have
S Speaker 36:35I'm your host, Jessica Parker, today we have two president,
I'm your host, Jessica Parker, today we have two president,
I'm your host, Jessica Parker, today we have two president,
I'm your host, Jessica Parker, today we have two president,
S Speaker 26:39Donald Trump added into your video, yeah,
Donald Trump added into your video, yeah,
Donald Trump added into your video, yeah,
Donald Trump added into your video, yeah,
S Speaker 16:44got it. And then what happened? Like, so people use this mostly in like, you know, they like, they generate content, and then they generate this audio, and then the speed generation, typically, they copy and paste from somewhere they probably generated from, like a chat GPT or something. And then they copy and paste the speech, the text. And then they just, you choose a voice on your platform, and then they convert it to that voice.
got it. And then what happened? Like, so people use this mostly in like, you know, they like, they generate content, and then they generate this audio, and then the speed generation, typically, they copy and paste from somewhere they probably generated from, like a chat GPT or something. And then they copy and paste the speech, the text. And then they just, you choose a voice on your platform, and then they convert it to that voice.
got it. And then what happened? Like, so people use this mostly in like, you know, they like, they generate content, and then they generate this audio, and then the speed generation, typically, they copy and paste from somewhere they probably generated from, like a chat GPT or something. And then they copy and paste the speech, the text. And then they just, you choose a voice on your platform, and then they convert it to that voice.
got it. And then what happened? Like, so people use this mostly in like, you know, they like, they generate content, and then they generate this audio, and then the speed generation, typically, they copy and paste from somewhere they probably generated from, like a chat GPT or something. And then they copy and paste the speech, the text. And then they just, you choose a voice on your platform, and then they convert it to that voice.
S Speaker 27:14Generally they some people prefer to use the text they write by themselves, and some people use AI generate text, and in our platform, they can either pick up voice, existing voice, or create their own voice. It only takes like 30 seconds to create to clone them. For example, I can give a trial for cloning myself. Nothing compares the joy of hearing my child love it bubbles are from deep inside them, pure and honest. In those moments, all my worries fade away, replaced by happiness that fills every part. It's a sound of perfect love. So you have like a 17 second audio clip, and generally takes another, like, 10 seconds to make it a model, so you can then be able to use it in API, or just use to generate in real time. Yeah, and I think we have to.
Generally they some people prefer to use the text they write by themselves, and some people use AI generate text, and in our platform, they can either pick up voice, existing voice, or create their own voice. It only takes like 30 seconds to create to clone them. For example, I can give a trial for cloning myself. Nothing compares the joy of hearing my child love it bubbles are from deep inside them, pure and honest. In those moments, all my worries fade away, replaced by happiness that fills every part. It's a sound of perfect love. So you have like a 17 second audio clip, and generally takes another, like, 10 seconds to make it a model, so you can then be able to use it in API, or just use to generate in real time. Yeah, and I think we have to.
Generally they some people prefer to use the text they write by themselves, and some people use AI generate text, and in our platform, they can either pick up voice, existing voice, or create their own voice. It only takes like 30 seconds to create to clone them. For example, I can give a trial for cloning myself. Nothing compares the joy of hearing my child love it bubbles are from deep inside them, pure and honest. In those moments, all my worries fade away, replaced by happiness that fills every part. It's a sound of perfect love. So you have like a 17 second audio clip, and generally takes another, like, 10 seconds to make it a model, so you can then be able to use it in API, or just use to generate in real time. Yeah, and I think we have to.
Generally they some people prefer to use the text they write by themselves, and some people use AI generate text, and in our platform, they can either pick up voice, existing voice, or create their own voice. It only takes like 30 seconds to create to clone them. For example, I can give a trial for cloning myself. Nothing compares the joy of hearing my child love it bubbles are from deep inside them, pure and honest. In those moments, all my worries fade away, replaced by happiness that fills every part. It's a sound of perfect love. So you have like a 17 second audio clip, and generally takes another, like, 10 seconds to make it a model, so you can then be able to use it in API, or just use to generate in real time. Yeah, and I think we have to.
S Speaker 18:18And so should you What's that different? Like, why do people use your blood? Watching
And so should you What's that different? Like, why do people use your blood? Watching
And so should you What's that different? Like, why do people use your blood? Watching
And so should you What's that different? Like, why do people use your blood? Watching
S Speaker 28:22my child sleep peacefully at night, yeah, it fills me with such tender wonder. Their gentle breathing, the soft curve of their cheek, the way their fingers curl slightly. It's like witnessing pure innocence. This does it not only during our but also given
my child sleep peacefully at night, yeah, it fills me with such tender wonder. Their gentle breathing, the soft curve of their cheek, the way their fingers curl slightly. It's like witnessing pure innocence. This does it not only during our but also given
my child sleep peacefully at night, yeah, it fills me with such tender wonder. Their gentle breathing, the soft curve of their cheek, the way their fingers curl slightly. It's like witnessing pure innocence. This does it not only during our but also given
my child sleep peacefully at night, yeah, it fills me with such tender wonder. Their gentle breathing, the soft curve of their cheek, the way their fingers curl slightly. It's like witnessing pure innocence. This does it not only during our but also given
S Speaker 18:44and then. So why do people use your platform over 11 labs or MERS or cartesia or like, there's, there's, there's a lot of platforms these days that do voice cloning and speech generation. So why do users use open audio versus those platforms? Compared
and then. So why do people use your platform over 11 labs or MERS or cartesia or like, there's, there's, there's a lot of platforms these days that do voice cloning and speech generation. So why do users use open audio versus those platforms? Compared
and then. So why do people use your platform over 11 labs or MERS or cartesia or like, there's, there's, there's a lot of platforms these days that do voice cloning and speech generation. So why do users use open audio versus those platforms? Compared
and then. So why do people use your platform over 11 labs or MERS or cartesia or like, there's, there's, there's a lot of platforms these days that do voice cloning and speech generation. So why do users use open audio versus those platforms? Compared
S Speaker 29:05to most competitors, we are more prosumer focused. Well, you know, there are Cartesian but it carrier doesn't care a lot about on the prosumer side, and nevertheless care, but they ship their focus to the B to B cells right now. So their model hasn't been updated for a while. The best model is still the model is two three years ago. So our model right now can provide a better can put a better result in terms of controllability and the next so if you so. We also have the RN external version of model we will release soon, which is the control model. You'll be able to control the tiny emotion using just text, and the model will follow that. For example, this is terrified voice, something
to most competitors, we are more prosumer focused. Well, you know, there are Cartesian but it carrier doesn't care a lot about on the prosumer side, and nevertheless care, but they ship their focus to the B to B cells right now. So their model hasn't been updated for a while. The best model is still the model is two three years ago. So our model right now can provide a better can put a better result in terms of controllability and the next so if you so. We also have the RN external version of model we will release soon, which is the control model. You'll be able to control the tiny emotion using just text, and the model will follow that. For example, this is terrified voice, something
to most competitors, we are more prosumer focused. Well, you know, there are Cartesian but it carrier doesn't care a lot about on the prosumer side, and nevertheless care, but they ship their focus to the B to B cells right now. So their model hasn't been updated for a while. The best model is still the model is two three years ago. So our model right now can provide a better can put a better result in terms of controllability and the next so if you so. We also have the RN external version of model we will release soon, which is the control model. You'll be able to control the tiny emotion using just text, and the model will follow that. For example, this is terrified voice, something
to most competitors, we are more prosumer focused. Well, you know, there are Cartesian but it carrier doesn't care a lot about on the prosumer side, and nevertheless care, but they ship their focus to the B to B cells right now. So their model hasn't been updated for a while. The best model is still the model is two three years ago. So our model right now can provide a better can put a better result in terms of controllability and the next so if you so. We also have the RN external version of model we will release soon, which is the control model. You'll be able to control the tiny emotion using just text, and the model will follow that. For example, this is terrified voice, something
S Speaker 49:59in the basement. I I can hear it.
in the basement. I I can hear it.
in the basement. I I can hear it.
in the basement. I I can hear it.
S Speaker 110:15Okay, so essentially, you're saying that the quality of your model is better,
Okay, so essentially, you're saying that the quality of your model is better,
Okay, so essentially, you're saying that the quality of your model is better,
Okay, so essentially, you're saying that the quality of your model is better,
S Speaker 210:20yeah. So even give a try. Try to close your with comparing you between using 11 s and using feature audio. Most people will say, Oh, it's much better. Oh,
yeah. So even give a try. Try to close your with comparing you between using 11 s and using feature audio. Most people will say, Oh, it's much better. Oh,
yeah. So even give a try. Try to close your with comparing you between using 11 s and using feature audio. Most people will say, Oh, it's much better. Oh,
yeah. So even give a try. Try to close your with comparing you between using 11 s and using feature audio. Most people will say, Oh, it's much better. Oh,
10:36And even carte even
S Speaker 210:37Cartesian. So say you have this kind of,
Cartesian. So say you have this kind of,
Cartesian. So say you have this kind of,
Cartesian. So say you have this kind of,
10:44maybe just some random voice, maybe just
maybe just some random voice, maybe just
maybe just some random voice, maybe just
maybe just some random voice, maybe just
10:46who like, in your opinion, like you
who like, in your opinion, like you
who like, in your opinion, like you
who like, in your opinion, like you
10:49have the best voice model today. Yeah.
have the best voice model today. Yeah.
have the best voice model today. Yeah.
have the best voice model today. Yeah.
S Speaker 110:54So and what like, what's like? How do you measure the like? How do you benchmark quality?
So and what like, what's like? How do you measure the like? How do you benchmark quality?
So and what like, what's like? How do you measure the like? How do you benchmark quality?
So and what like, what's like? How do you measure the like? How do you benchmark quality?
S Speaker 211:02So we have most testing. We will call ourselves the weapons the most on tier one and 11 labs, Cartesian they're also on tier one. So when we, ever, both of us are, can provide almost the same level of quality. We provide more controls, like a brief breathe love right now, and also what we are going to do in the next step is what makes a difference between us and 11 and all the competitors, which is the control part. Every time you generate, right now, it can give you a random voice. It can be, not only be terrifying, it can be a joyful voice, eventful.
So we have most testing. We will call ourselves the weapons the most on tier one and 11 labs, Cartesian they're also on tier one. So when we, ever, both of us are, can provide almost the same level of quality. We provide more controls, like a brief breathe love right now, and also what we are going to do in the next step is what makes a difference between us and 11 and all the competitors, which is the control part. Every time you generate, right now, it can give you a random voice. It can be, not only be terrifying, it can be a joyful voice, eventful.
So we have most testing. We will call ourselves the weapons the most on tier one and 11 labs, Cartesian they're also on tier one. So when we, ever, both of us are, can provide almost the same level of quality. We provide more controls, like a brief breathe love right now, and also what we are going to do in the next step is what makes a difference between us and 11 and all the competitors, which is the control part. Every time you generate, right now, it can give you a random voice. It can be, not only be terrifying, it can be a joyful voice, eventful.
So we have most testing. We will call ourselves the weapons the most on tier one and 11 labs, Cartesian they're also on tier one. So when we, ever, both of us are, can provide almost the same level of quality. We provide more controls, like a brief breathe love right now, and also what we are going to do in the next step is what makes a difference between us and 11 and all the competitors, which is the control part. Every time you generate, right now, it can give you a random voice. It can be, not only be terrifying, it can be a joyful voice, eventful.
S Speaker 311:50We're gonna Disney World. I've been saving for three years. And finally, finally, we can go the look on your face. Yeah, this is
We're gonna Disney World. I've been saving for three years. And finally, finally, we can go the look on your face. Yeah, this is
We're gonna Disney World. I've been saving for three years. And finally, finally, we can go the look on your face. Yeah, this is
We're gonna Disney World. I've been saving for three years. And finally, finally, we can go the look on your face. Yeah, this is
S Speaker 211:59a chatgpt journey text. And as you see, the model will follow the emotion in the text and also the text prompt.
a chatgpt journey text. And as you see, the model will follow the emotion in the text and also the text prompt.
a chatgpt journey text. And as you see, the model will follow the emotion in the text and also the text prompt.
a chatgpt journey text. And as you see, the model will follow the emotion in the text and also the text prompt.
S Speaker 112:09Yeah, got it so you got essentially more emotions, the ability to
Yeah, got it so you got essentially more emotions, the ability to
Yeah, got it so you got essentially more emotions, the ability to
Yeah, got it so you got essentially more emotions, the ability to
12:19control, like when somebody control
control, like when somebody control
control, like when somebody control
control, like when somebody control
S Speaker 112:23and somebody breathes and taking care of all of those and, yeah,
and somebody breathes and taking care of all of those and, yeah,
and somebody breathes and taking care of all of those and, yeah,
and somebody breathes and taking care of all of those and, yeah,
S Speaker 212:29just basically close the gap between, you know, AI toy and production tool. So this will become the next mid journey. Basically people, not only professional consumers, but everyone in the world, will be able to use our platform to create controllable audio content. I think that it will make a huge difference. Yeah,
just basically close the gap between, you know, AI toy and production tool. So this will become the next mid journey. Basically people, not only professional consumers, but everyone in the world, will be able to use our platform to create controllable audio content. I think that it will make a huge difference. Yeah,
just basically close the gap between, you know, AI toy and production tool. So this will become the next mid journey. Basically people, not only professional consumers, but everyone in the world, will be able to use our platform to create controllable audio content. I think that it will make a huge difference. Yeah,
just basically close the gap between, you know, AI toy and production tool. So this will become the next mid journey. Basically people, not only professional consumers, but everyone in the world, will be able to use our platform to create controllable audio content. I think that it will make a huge difference. Yeah,
S Speaker 112:51okay, and what's the like? So you want to do? You want to focus on prosumer for now?
okay, and what's the like? So you want to do? You want to focus on prosumer for now?
okay, and what's the like? So you want to do? You want to focus on prosumer for now?
okay, and what's the like? So you want to do? You want to focus on prosumer for now?
S Speaker 213:03Focus on prosumer for now. So basically, we are gathering their feedback. Data is their feedback and their downloads, their downloads. This can all kind of signal to tune, to do our job and tune our model. Yeah. Okay, yeah. So sense.
Focus on prosumer for now. So basically, we are gathering their feedback. Data is their feedback and their downloads, their downloads. This can all kind of signal to tune, to do our job and tune our model. Yeah. Okay, yeah. So sense.
Focus on prosumer for now. So basically, we are gathering their feedback. Data is their feedback and their downloads, their downloads. This can all kind of signal to tune, to do our job and tune our model. Yeah. Okay, yeah. So sense.
Focus on prosumer for now. So basically, we are gathering their feedback. Data is their feedback and their downloads, their downloads. This can all kind of signal to tune, to do our job and tune our model. Yeah. Okay, yeah. So sense.
S Speaker 113:25And so you start shipping. When did you start shipping?
And so you start shipping. When did you start shipping?
And so you start shipping. When did you start shipping?
And so you start shipping. When did you start shipping?
S Speaker 213:29So we begin working on the company on July last year, and we begin focusing on consumer and consumer side, beginning on January this year. Oh,
So we begin working on the company on July last year, and we begin focusing on consumer and consumer side, beginning on January this year. Oh,
So we begin working on the company on July last year, and we begin focusing on consumer and consumer side, beginning on January this year. Oh,
So we begin working on the company on July last year, and we begin focusing on consumer and consumer side, beginning on January this year. Oh,
S Speaker 113:45so really, did you go from like 400k to 4 million the last since January? Yeah,
so really, did you go from like 400k to 4 million the last since January? Yeah,
so really, did you go from like 400k to 4 million the last since January? Yeah,
so really, did you go from like 400k to 4 million the last since January? Yeah,
13:54this is our weekly income
this is our weekly income
this is our weekly income
this is our weekly income
S Speaker 213:58between January and the mid March. Yeah,
between January and the mid March. Yeah,
between January and the mid March. Yeah,
between January and the mid March. Yeah,
S Speaker 114:01that's very interesting. And then, and so, this is across how many users.
that's very interesting. And then, and so, this is across how many users.
that's very interesting. And then, and so, this is across how many users.
that's very interesting. And then, and so, this is across how many users.
S Speaker 214:08So we are around 80k weekly active users right now. So this is, oh, this is the number of users, okay, 80,000 This is not now. This is the number of revenue. This is revenue per week,
So we are around 80k weekly active users right now. So this is, oh, this is the number of users, okay, 80,000 This is not now. This is the number of revenue. This is revenue per week,
So we are around 80k weekly active users right now. So this is, oh, this is the number of users, okay, 80,000 This is not now. This is the number of revenue. This is revenue per week,
So we are around 80k weekly active users right now. So this is, oh, this is the number of users, okay, 80,000 This is not now. This is the number of revenue. This is revenue per week,
S Speaker 114:18yeah, what is the revenue per week? And then, so, so your revenue per week is 76,000 across 80,000 80,000 you said weekly active users? Yeah. 80,000 we get users, yeah. And so I'll be like, typically, most of these, they come for, like, some project. I'm guessing that you're charging them on based on usage.
yeah, what is the revenue per week? And then, so, so your revenue per week is 76,000 across 80,000 80,000 you said weekly active users? Yeah. 80,000 we get users, yeah. And so I'll be like, typically, most of these, they come for, like, some project. I'm guessing that you're charging them on based on usage.
yeah, what is the revenue per week? And then, so, so your revenue per week is 76,000 across 80,000 80,000 you said weekly active users? Yeah. 80,000 we get users, yeah. And so I'll be like, typically, most of these, they come for, like, some project. I'm guessing that you're charging them on based on usage.
yeah, what is the revenue per week? And then, so, so your revenue per week is 76,000 across 80,000 80,000 you said weekly active users? Yeah. 80,000 we get users, yeah. And so I'll be like, typically, most of these, they come for, like, some project. I'm guessing that you're charging them on based on usage.
S Speaker 214:43So we charge them two way. One way is the which most people choose, the premium package at either $15 a month or $120 per year. And some other users, which are the developers from open source means from some company, but they use the API, which is $15 per million characters. Yeah. They have two different
So we charge them two way. One way is the which most people choose, the premium package at either $15 a month or $120 per year. And some other users, which are the developers from open source means from some company, but they use the API, which is $15 per million characters. Yeah. They have two different
So we charge them two way. One way is the which most people choose, the premium package at either $15 a month or $120 per year. And some other users, which are the developers from open source means from some company, but they use the API, which is $15 per million characters. Yeah. They have two different
So we charge them two way. One way is the which most people choose, the premium package at either $15 a month or $120 per year. And some other users, which are the developers from open source means from some company, but they use the API, which is $15 per million characters. Yeah. They have two different
S Speaker 115:06processes, yeah. And how much of how many of these are on that monthly plan versus yearly plan?
processes, yeah. And how much of how many of these are on that monthly plan versus yearly plan?
processes, yeah. And how much of how many of these are on that monthly plan versus yearly plan?
processes, yeah. And how much of how many of these are on that monthly plan versus yearly plan?
S Speaker 215:14So around 25 I mean, around 20% are yearly plan, yeah,
So around 25 I mean, around 20% are yearly plan, yeah,
So around 25 I mean, around 20% are yearly plan, yeah,
So around 25 I mean, around 20% are yearly plan, yeah,
S Speaker 115:20yearly plan, okay? And then the rest are a monthly plan, yeah, okay. And then like, how are you? I guess it's super early days, so, but the usage of most of these
yearly plan, okay? And then the rest are a monthly plan, yeah, okay. And then like, how are you? I guess it's super early days, so, but the usage of most of these
yearly plan, okay? And then the rest are a monthly plan, yeah, okay. And then like, how are you? I guess it's super early days, so, but the usage of most of these
yearly plan, okay? And then the rest are a monthly plan, yeah, okay. And then like, how are you? I guess it's super early days, so, but the usage of most of these
15:38how does that trending like?
how does that trending like?
how does that trending like?
how does that trending like?
S Speaker 115:41They typically like when somebody signs up, are they using that? Using a platform? How many times a week?
They typically like when somebody signs up, are they using that? Using a platform? How many times a week?
They typically like when somebody signs up, are they using that? Using a platform? How many times a week?
They typically like when somebody signs up, are they using that? Using a platform? How many times a week?
S Speaker 215:51So from what we see, they use the platform around average, if a user is all active on this day, they generate around 30 to 40 auto clips only a day, and is how our retention looks like. And on average, they spend 30 to 45 minutes a day on a platform. Okay?
So from what we see, they use the platform around average, if a user is all active on this day, they generate around 30 to 40 auto clips only a day, and is how our retention looks like. And on average, they spend 30 to 45 minutes a day on a platform. Okay?
So from what we see, they use the platform around average, if a user is all active on this day, they generate around 30 to 40 auto clips only a day, and is how our retention looks like. And on average, they spend 30 to 45 minutes a day on a platform. Okay?
So from what we see, they use the platform around average, if a user is all active on this day, they generate around 30 to 40 auto clips only a day, and is how our retention looks like. And on average, they spend 30 to 45 minutes a day on a platform. Okay?
S Speaker 116:16And what's the pricing difference between your platform and the others?
And what's the pricing difference between your platform and the others?
And what's the pricing difference between your platform and the others?
And what's the pricing difference between your platform and the others?
S Speaker 216:19So right now our pricing model, we are cheaper than that right now, and we are going to have additional plan after we release the new model, which currently we allow user to you to have unlimited use when they have the premium membership available, and later on, there will be a credit system there to limit their usage of the latest model, which is because the latest model is much larger. Yeah, okay,
So right now our pricing model, we are cheaper than that right now, and we are going to have additional plan after we release the new model, which currently we allow user to you to have unlimited use when they have the premium membership available, and later on, there will be a credit system there to limit their usage of the latest model, which is because the latest model is much larger. Yeah, okay,
So right now our pricing model, we are cheaper than that right now, and we are going to have additional plan after we release the new model, which currently we allow user to you to have unlimited use when they have the premium membership available, and later on, there will be a credit system there to limit their usage of the latest model, which is because the latest model is much larger. Yeah, okay,
So right now our pricing model, we are cheaper than that right now, and we are going to have additional plan after we release the new model, which currently we allow user to you to have unlimited use when they have the premium membership available, and later on, there will be a credit system there to limit their usage of the latest model, which is because the latest model is much larger. Yeah, okay,
S Speaker 116:50so and like, what's the difference between price referring your level is Cartesian more expensive,
so and like, what's the difference between price referring your level is Cartesian more expensive,
so and like, what's the difference between price referring your level is Cartesian more expensive,
so and like, what's the difference between price referring your level is Cartesian more expensive,
S Speaker 216:57very small expense. So when we are using API, collision is around two times higher than us, and 11 levels around three to four times higher price. Okay,
very small expense. So when we are using API, collision is around two times higher than us, and 11 levels around three to four times higher price. Okay,
very small expense. So when we are using API, collision is around two times higher than us, and 11 levels around three to four times higher price. Okay,
very small expense. So when we are using API, collision is around two times higher than us, and 11 levels around three to four times higher price. Okay,
S Speaker 117:14so can you, would you be able to talk a little bit about the technology, which is how, like, What, in your view, what is 11 labs using? And then we sort of know that, you know, car teacher is using state space models. What's the technology that you are using that allows you to be better than others?
so can you, would you be able to talk a little bit about the technology, which is how, like, What, in your view, what is 11 labs using? And then we sort of know that, you know, car teacher is using state space models. What's the technology that you are using that allows you to be better than others?
so can you, would you be able to talk a little bit about the technology, which is how, like, What, in your view, what is 11 labs using? And then we sort of know that, you know, car teacher is using state space models. What's the technology that you are using that allows you to be better than others?
so can you, would you be able to talk a little bit about the technology, which is how, like, What, in your view, what is 11 labs using? And then we sort of know that, you know, car teacher is using state space models. What's the technology that you are using that allows you to be better than others?
S Speaker 217:39Yeah, so COVID states model in unless there are two series, so their online v2 model is using something like a style TTS, which is known on the regressive model, and using embedding, audio embedding, which limits their representation in terms of like a clone special voices. And they have a new model they are working on, which is LLM based, not released yet. And on our side, our model is large range model based. So our model has is, we call it dual AI algorithm model, dual auto regressive model. We begin working on that on March of year, and it's a model that's two one slow transform and one fast transform sticking together after we begin widely using that and release the largest model We see, then more she and the sesame for the
Yeah, so COVID states model in unless there are two series, so their online v2 model is using something like a style TTS, which is known on the regressive model, and using embedding, audio embedding, which limits their representation in terms of like a clone special voices. And they have a new model they are working on, which is LLM based, not released yet. And on our side, our model is large range model based. So our model has is, we call it dual AI algorithm model, dual auto regressive model. We begin working on that on March of year, and it's a model that's two one slow transform and one fast transform sticking together after we begin widely using that and release the largest model We see, then more she and the sesame for the
Yeah, so COVID states model in unless there are two series, so their online v2 model is using something like a style TTS, which is known on the regressive model, and using embedding, audio embedding, which limits their representation in terms of like a clone special voices. And they have a new model they are working on, which is LLM based, not released yet. And on our side, our model is large range model based. So our model has is, we call it dual AI algorithm model, dual auto regressive model. We begin working on that on March of year, and it's a model that's two one slow transform and one fast transform sticking together after we begin widely using that and release the largest model We see, then more she and the sesame for the
Yeah, so COVID states model in unless there are two series, so their online v2 model is using something like a style TTS, which is known on the regressive model, and using embedding, audio embedding, which limits their representation in terms of like a clone special voices. And they have a new model they are working on, which is LLM based, not released yet. And on our side, our model is large range model based. So our model has is, we call it dual AI algorithm model, dual auto regressive model. We begin working on that on March of year, and it's a model that's two one slow transform and one fast transform sticking together after we begin widely using that and release the largest model We see, then more she and the sesame for the
S Speaker 118:43I have to read up more and more she which is, so what's the underlying architecture? Like? It's not state space, it's not Mamba. It's not it's a transformer. It is transformer. Okay, got it.
I have to read up more and more she which is, so what's the underlying architecture? Like? It's not state space, it's not Mamba. It's not it's a transformer. It is transformer. Okay, got it.
I have to read up more and more she which is, so what's the underlying architecture? Like? It's not state space, it's not Mamba. It's not it's a transformer. It is transformer. Okay, got it.
I have to read up more and more she which is, so what's the underlying architecture? Like? It's not state space, it's not Mamba. It's not it's a transformer. It is transformer. Okay, got it.
18:56But Mamba is some transformer elements
But Mamba is some transformer elements
But Mamba is some transformer elements
But Mamba is some transformer elements
S Speaker 218:59as a variant. They claim it has a, you know, better latency. But the funny thing is, generally the weaseling audio, which is the same as not crazy long. It's only like a K 16k conics. It doesn't make a difference when you are using mama, yeah. Go ahead.
as a variant. They claim it has a, you know, better latency. But the funny thing is, generally the weaseling audio, which is the same as not crazy long. It's only like a K 16k conics. It doesn't make a difference when you are using mama, yeah. Go ahead.
as a variant. They claim it has a, you know, better latency. But the funny thing is, generally the weaseling audio, which is the same as not crazy long. It's only like a K 16k conics. It doesn't make a difference when you are using mama, yeah. Go ahead.
as a variant. They claim it has a, you know, better latency. But the funny thing is, generally the weaseling audio, which is the same as not crazy long. It's only like a K 16k conics. It doesn't make a difference when you are using mama, yeah. Go ahead.
S Speaker 219:24I think the core part of our technology, the mode for us, is on data. So one side, we have the data from real online user. Another part is we have our own data cleaning pipeline. We build that from scratch. That's why we are able to to to have the model that is very, very controllable. I can show you some sample one second,
I think the core part of our technology, the mode for us, is on data. So one side, we have the data from real online user. Another part is we have our own data cleaning pipeline. We build that from scratch. That's why we are able to to to have the model that is very, very controllable. I can show you some sample one second,
I think the core part of our technology, the mode for us, is on data. So one side, we have the data from real online user. Another part is we have our own data cleaning pipeline. We build that from scratch. That's why we are able to to to have the model that is very, very controllable. I can show you some sample one second,
I think the core part of our technology, the mode for us, is on data. So one side, we have the data from real online user. Another part is we have our own data cleaning pipeline. We build that from scratch. That's why we are able to to to have the model that is very, very controllable. I can show you some sample one second,
20:12Let me find you. Oh.
S Speaker 220:24Yeah, so we have sample like that. It's not quite clear on this screen, but basically, we have asked our data annotators to annotate this kind of environment, emotion change and everything. And we have our model which is able to caption audio into stuff like that. And this part is very important. This one can use this text to control the emotion. Yeah, we work on that part for a while. Interesting.
Yeah, so we have sample like that. It's not quite clear on this screen, but basically, we have asked our data annotators to annotate this kind of environment, emotion change and everything. And we have our model which is able to caption audio into stuff like that. And this part is very important. This one can use this text to control the emotion. Yeah, we work on that part for a while. Interesting.
Yeah, so we have sample like that. It's not quite clear on this screen, but basically, we have asked our data annotators to annotate this kind of environment, emotion change and everything. And we have our model which is able to caption audio into stuff like that. And this part is very important. This one can use this text to control the emotion. Yeah, we work on that part for a while. Interesting.
Yeah, so we have sample like that. It's not quite clear on this screen, but basically, we have asked our data annotators to annotate this kind of environment, emotion change and everything. And we have our model which is able to caption audio into stuff like that. And this part is very important. This one can use this text to control the emotion. Yeah, we work on that part for a while. Interesting.
S Speaker 121:02and so over like, what's Gigi? What do you like? What's your roadmap for rest of the year? Which is, where do you see taking open audio? You want to continue to focus on audio only, and then, what do you want to continue to add? And then, or do you want to we're
and so over like, what's Gigi? What do you like? What's your roadmap for rest of the year? Which is, where do you see taking open audio? You want to continue to focus on audio only, and then, what do you want to continue to add? And then, or do you want to we're
and so over like, what's Gigi? What do you like? What's your roadmap for rest of the year? Which is, where do you see taking open audio? You want to continue to focus on audio only, and then, what do you want to continue to add? And then, or do you want to we're
and so over like, what's Gigi? What do you like? What's your roadmap for rest of the year? Which is, where do you see taking open audio? You want to continue to focus on audio only, and then, what do you want to continue to add? And then, or do you want to we're
21:25going to add text,
S Speaker 121:29text, which is essentially being able to generate text.
text, which is essentially being able to generate text.
text, which is essentially being able to generate text.
text, which is essentially being able to generate text.
S Speaker 221:33We generate, we have a cyber working on text and to collect text data. So the next step of audio, first thing will be release the control model and then increase the user base of you know, feature audio and generic revenue. Another part will be begin working on the AI companion project, which compound combines both our voice and our kids model and make them end to end and be able to deliver that product. Yeah. Okay,
We generate, we have a cyber working on text and to collect text data. So the next step of audio, first thing will be release the control model and then increase the user base of you know, feature audio and generic revenue. Another part will be begin working on the AI companion project, which compound combines both our voice and our kids model and make them end to end and be able to deliver that product. Yeah. Okay,
We generate, we have a cyber working on text and to collect text data. So the next step of audio, first thing will be release the control model and then increase the user base of you know, feature audio and generic revenue. Another part will be begin working on the AI companion project, which compound combines both our voice and our kids model and make them end to end and be able to deliver that product. Yeah. Okay,
We generate, we have a cyber working on text and to collect text data. So the next step of audio, first thing will be release the control model and then increase the user base of you know, feature audio and generic revenue. Another part will be begin working on the AI companion project, which compound combines both our voice and our kids model and make them end to end and be able to deliver that product. Yeah. Okay,
S Speaker 122:07but, like, but wasn't, wouldn't that? Like, that's why would you add tax, because it'd be very hard for you
but, like, but wasn't, wouldn't that? Like, that's why would you add tax, because it'd be very hard for you
but, like, but wasn't, wouldn't that? Like, that's why would you add tax, because it'd be very hard for you
but, like, but wasn't, wouldn't that? Like, that's why would you add tax, because it'd be very hard for you
S Speaker 222:19Claude. But you can imagine they are more human intelligence, right? But AI companion say your boyfriend, your girlfriend, doesn't need to be 140 IQ. They don't need to be able to solve crazy math problem or do legal hard for you, that's not what he or she should do so in terms of AI companion, we found there's we don't need such high intelligence, but it needs to make people feel connected. It needs to care about people's feelings, and clearly open AI and as the robust model didn't do so well on that, because they are more focused on the functionality and the agentic part.
Claude. But you can imagine they are more human intelligence, right? But AI companion say your boyfriend, your girlfriend, doesn't need to be 140 IQ. They don't need to be able to solve crazy math problem or do legal hard for you, that's not what he or she should do so in terms of AI companion, we found there's we don't need such high intelligence, but it needs to make people feel connected. It needs to care about people's feelings, and clearly open AI and as the robust model didn't do so well on that, because they are more focused on the functionality and the agentic part.
Claude. But you can imagine they are more human intelligence, right? But AI companion say your boyfriend, your girlfriend, doesn't need to be 140 IQ. They don't need to be able to solve crazy math problem or do legal hard for you, that's not what he or she should do so in terms of AI companion, we found there's we don't need such high intelligence, but it needs to make people feel connected. It needs to care about people's feelings, and clearly open AI and as the robust model didn't do so well on that, because they are more focused on the functionality and the agentic part.
Claude. But you can imagine they are more human intelligence, right? But AI companion say your boyfriend, your girlfriend, doesn't need to be 140 IQ. They don't need to be able to solve crazy math problem or do legal hard for you, that's not what he or she should do so in terms of AI companion, we found there's we don't need such high intelligence, but it needs to make people feel connected. It needs to care about people's feelings, and clearly open AI and as the robust model didn't do so well on that, because they are more focused on the functionality and the agentic part.
S Speaker 123:03Do you see that demo from what's that startup?
Do you see that demo from what's that startup?
Do you see that demo from what's that startup?
Do you see that demo from what's that startup?
23:11The Oculus founders
S Speaker 123:28recently where they did a demo of the conversational
recently where they did a demo of the conversational
recently where they did a demo of the conversational
recently where they did a demo of the conversational
23:41AI sesame, sesame.
S Speaker 123:47Did you see the demo from sesame? Ai, yes. So like, is that what you want to do? It will be
Did you see the demo from sesame? Ai, yes. So like, is that what you want to do? It will be
Did you see the demo from sesame? Ai, yes. So like, is that what you want to do? It will be
Did you see the demo from sesame? Ai, yes. So like, is that what you want to do? It will be
S Speaker 223:55part of us, what we're going to do. We chat about this paper, but unfortunately, so they are not, they didn't finish the part, the most important part. So using this end to end model,
part of us, what we're going to do. We chat about this paper, but unfortunately, so they are not, they didn't finish the part, the most important part. So using this end to end model,
part of us, what we're going to do. We chat about this paper, but unfortunately, so they are not, they didn't finish the part, the most important part. So using this end to end model,
part of us, what we're going to do. We chat about this paper, but unfortunately, so they are not, they didn't finish the part, the most important part. So using this end to end model,
24:09I don't know. So usually
I don't know. So usually
I don't know. So usually
I don't know. So usually
S Speaker 224:11it shows, like, Priyesh. Everyone feels like it's NQF model. But finally, it's a PTS model, because if you click
it shows, like, Priyesh. Everyone feels like it's NQF model. But finally, it's a PTS model, because if you click
it shows, like, Priyesh. Everyone feels like it's NQF model. But finally, it's a PTS model, because if you click
it shows, like, Priyesh. Everyone feels like it's NQF model. But finally, it's a PTS model, because if you click
24:18on the demo, it seems they got, like, a lot of good feedback on
on the demo, it seems they got, like, a lot of good feedback on
on the demo, it seems they got, like, a lot of good feedback on
on the demo, it seems they got, like, a lot of good feedback on
S Speaker 124:50are building the agent. Okay, how many people do you have? So we have eight
are building the agent. Okay, how many people do you have? So we have eight
are building the agent. Okay, how many people do you have? So we have eight
are building the agent. Okay, how many people do you have? So we have eight
S Speaker 224:54people in our engineering team, including me, okay? And everyone's from open source. Average people get my 5k stars. Yeah, and two of them canceled their Tiktok offered to join, and one of them already working, he left, and almost everyone, including our team, was working in some large companies. And we told them all and say, Hey, to create a company, I the
people in our engineering team, including me, okay? And everyone's from open source. Average people get my 5k stars. Yeah, and two of them canceled their Tiktok offered to join, and one of them already working, he left, and almost everyone, including our team, was working in some large companies. And we told them all and say, Hey, to create a company, I the
people in our engineering team, including me, okay? And everyone's from open source. Average people get my 5k stars. Yeah, and two of them canceled their Tiktok offered to join, and one of them already working, he left, and almost everyone, including our team, was working in some large companies. And we told them all and say, Hey, to create a company, I the
people in our engineering team, including me, okay? And everyone's from open source. Average people get my 5k stars. Yeah, and two of them canceled their Tiktok offered to join, and one of them already working, he left, and almost everyone, including our team, was working in some large companies. And we told them all and say, Hey, to create a company, I the
S Speaker 125:26okay, also in San Carlos. I was
okay, also in San Carlos. I was
okay, also in San Carlos. I was
okay, also in San Carlos. I was
S Speaker 225:29three months ago. I really was in a car, you know, there's so close to Cupertino,
three months ago. I really was in a car, you know, there's so close to Cupertino,
three months ago. I really was in a car, you know, there's so close to Cupertino,
three months ago. I really was in a car, you know, there's so close to Cupertino,
25:37somebody who's there. Hey, so
somebody who's there. Hey, so
somebody who's there. Hey, so
somebody who's there. Hey, so
S Speaker 125:44round wise, you just raised us. But what was it? Was it a seed round, like $2 million which is So who did you raise money from?
round wise, you just raised us. But what was it? Was it a seed round, like $2 million which is So who did you raise money from?
round wise, you just raised us. But what was it? Was it a seed round, like $2 million which is So who did you raise money from?
round wise, you just raised us. But what was it? Was it a seed round, like $2 million which is So who did you raise money from?
25:55He's a famous individual investor.
He's a famous individual investor.
He's a famous individual investor.
He's a famous individual investor.
25:59It's mostly Angel check
It's mostly Angel check
It's mostly Angel check
It's mostly Angel check
26:03that you pick total comments. Have you raised?
that you pick total comments. Have you raised?
that you pick total comments. Have you raised?
that you pick total comments. Have you raised?
S Speaker 226:07today, we totally we raised four by 5 million in
today, we totally we raised four by 5 million in
today, we totally we raised four by 5 million in
today, we totally we raised four by 5 million in
S Speaker 126:12total. Yeah, total, including this $2 million excluding, including what's the valuation was the terms that you're
total. Yeah, total, including this $2 million excluding, including what's the valuation was the terms that you're
total. Yeah, total, including this $2 million excluding, including what's the valuation was the terms that you're
total. Yeah, total, including this $2 million excluding, including what's the valuation was the terms that you're
26:22closing this at least. And
closing this at least. And
closing this at least. And
closing this at least. And
26:27okay, got it? Okay.
S Speaker 126:32We typically don't do like a note after this, after the round, we can discuss, if you're open to adding more at this valuation, then we would, we can discuss now, or we would have to consider in the next round,
We typically don't do like a note after this, after the round, we can discuss, if you're open to adding more at this valuation, then we would, we can discuss now, or we would have to consider in the next round,
We typically don't do like a note after this, after the round, we can discuss, if you're open to adding more at this valuation, then we would, we can discuss now, or we would have to consider in the next round,
We typically don't do like a note after this, after the round, we can discuss, if you're open to adding more at this valuation, then we would, we can discuss now, or we would have to consider in the next round,
26:47we would typically,
S Speaker 126:51I mean, this is very interesting, for sure. And then if you're if a size of your model can actually fit on the edge, then we have a lot of interesting opportunities to take you to across mobile and PCs, so a lot of the creators that we work with, so we we put their models on the AI PCs, and then we take them to a lot of creators that are trying to use them. So that's the that would be our angle to work with. You
I mean, this is very interesting, for sure. And then if you're if a size of your model can actually fit on the edge, then we have a lot of interesting opportunities to take you to across mobile and PCs, so a lot of the creators that we work with, so we we put their models on the AI PCs, and then we take them to a lot of creators that are trying to use them. So that's the that would be our angle to work with. You
I mean, this is very interesting, for sure. And then if you're if a size of your model can actually fit on the edge, then we have a lot of interesting opportunities to take you to across mobile and PCs, so a lot of the creators that we work with, so we we put their models on the AI PCs, and then we take them to a lot of creators that are trying to use them. So that's the that would be our angle to work with. You
I mean, this is very interesting, for sure. And then if you're if a size of your model can actually fit on the edge, then we have a lot of interesting opportunities to take you to across mobile and PCs, so a lot of the creators that we work with, so we we put their models on the AI PCs, and then we take them to a lot of creators that are trying to use them. So that's the that would be our angle to work with. You
S Speaker 227:16have smaller models that is able to rob a PC or even phone. Actually
have smaller models that is able to rob a PC or even phone. Actually
have smaller models that is able to rob a PC or even phone. Actually
have smaller models that is able to rob a PC or even phone. Actually
S Speaker 127:21you're being more model, my guess is would be able to run as well. So
you're being more model, my guess is would be able to run as well. So
you're being more model, my guess is would be able to run as well. So
you're being more model, my guess is would be able to run as well. So
27:25we have three models, one 40,000,001
we have three models, one 40,000,001
we have three models, one 40,000,001
we have three models, one 40,000,001
27:28point 5,000,000,001 7 billion. So I believe
point 5,000,000,001 7 billion. So I believe
point 5,000,000,001 7 billion. So I believe
point 5,000,000,001 7 billion. So I believe
27:31we can fit the 40 million model in all mobile devices.
we can fit the 40 million model in all mobile devices.
we can fit the 40 million model in all mobile devices.
we can fit the 40 million model in all mobile devices.
27:38No, you can actually do what was the largest
No, you can actually do what was the largest
No, you can actually do what was the largest
No, you can actually do what was the largest
S Speaker 227:40one, it's a 7 billion, because audio is requires at least 20 tokens per second. So if it can run 24 seconds, it can work. Yeah,
one, it's a 7 billion, because audio is requires at least 20 tokens per second. So if it can run 24 seconds, it can work. Yeah,
one, it's a 7 billion, because audio is requires at least 20 tokens per second. So if it can run 24 seconds, it can work. Yeah,
one, it's a 7 billion, because audio is requires at least 20 tokens per second. So if it can run 24 seconds, it can work. Yeah,
S Speaker 127:50let me get I think a PC, for sure, can work at 20 tokens per second, on on with a 7 billion. I don't know mobile just yet, whether it's this year, but let me get back so you but, but you will have a model that you run them out. So that's interesting for sure. Would you be open to adding more to this round? Or no? Yeah,
let me get I think a PC, for sure, can work at 20 tokens per second, on on with a 7 billion. I don't know mobile just yet, whether it's this year, but let me get back so you but, but you will have a model that you run them out. So that's interesting for sure. Would you be open to adding more to this round? Or no? Yeah,
let me get I think a PC, for sure, can work at 20 tokens per second, on on with a 7 billion. I don't know mobile just yet, whether it's this year, but let me get back so you but, but you will have a model that you run them out. So that's interesting for sure. Would you be open to adding more to this round? Or no? Yeah,
let me get I think a PC, for sure, can work at 20 tokens per second, on on with a 7 billion. I don't know mobile just yet, whether it's this year, but let me get back so you but, but you will have a model that you run them out. So that's interesting for sure. Would you be open to adding more to this round? Or no? Yeah,
28:06I think we have more. Yeah.
I think we have more. Yeah.
I think we have more. Yeah.
I think we have more. Yeah.
S Speaker 128:10okay, so thanks for sharing this. I think we have a tech right, Priyesh from
okay, so thanks for sharing this. I think we have a tech right, Priyesh from
okay, so thanks for sharing this. I think we have a tech right, Priyesh from
okay, so thanks for sharing this. I think we have a tech right, Priyesh from
S Speaker 228:31and location, show you the website. Sorry, everything is just real time online data, very
and location, show you the website. Sorry, everything is just real time online data, very
and location, show you the website. Sorry, everything is just real time online data, very
and location, show you the website. Sorry, everything is just real time online data, very
S Speaker 228:42you. Yeah, sounds good, yeah. All right, thank you.
you. Yeah, sounds good, yeah. All right, thank you.
you. Yeah, sounds good, yeah. All right, thank you.
you. Yeah, sounds good, yeah. All right, thank you.
S Speaker 228:58Let me see I can send you some screenshot in the Zoom now, so you can keep that on your record. I mean,
Let me see I can send you some screenshot in the Zoom now, so you can keep that on your record. I mean,
Let me see I can send you some screenshot in the Zoom now, so you can keep that on your record. I mean,
Let me see I can send you some screenshot in the Zoom now, so you can keep that on your record. I mean,
S Speaker 129:11yeah, you can send it
yeah, you can send it
yeah, you can send it
yeah, you can send it
29:33I send you three images.
I send you three images.
I send you three images.
I send you three images.
S Speaker 129:42Yeah, thanks. So we'll get back to discuss and get back. And congratulations,
Yeah, thanks. So we'll get back to discuss and get back. And congratulations,
Yeah, thanks. So we'll get back to discuss and get back. And congratulations,
Yeah, thanks. So we'll get back to discuss and get back. And congratulations,
29:47good success so far. Yeah,
good success so far. Yeah,
good success so far. Yeah,
good success so far. Yeah,
29:49thank you. See you guys.
thank you. See you guys.
thank you. See you guys.
thank you. See you guys.