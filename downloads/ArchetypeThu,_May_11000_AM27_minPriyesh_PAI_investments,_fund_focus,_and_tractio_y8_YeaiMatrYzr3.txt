Meeting: Archetype
Thu, May 1
10:00 AM
27 min
Priyesh P
AI investments, fund focus, and traction.
1:00
Using 
URL: https://otter.ai/u/y8_YeaiMatrYzr3cuvFz-Zfd2qI
Downloaded: 2025-12-22T11:31:57.071248
Method: text_extraction
============================================================

S Speaker 11:00Hey, Hey, Brandon, can you hear me? Well, yes, nice to meet you. Absolutely. Brandon, pleasure meeting you. How are you doing today? All right,
Hey, Hey, Brandon, can you hear me? Well, yes, nice to meet you. Absolutely. Brandon, pleasure meeting you. How are you doing today? All right,
Hey, Hey, Brandon, can you hear me? Well, yes, nice to meet you. Absolutely. Brandon, pleasure meeting you. How are you doing today? All right,
Hey, Hey, Brandon, can you hear me? Well, yes, nice to meet you. Absolutely. Brandon, pleasure meeting you. How are you doing today? All right,
S Speaker 21:10so if I recall you reached out via the signup form, and I recall you were super enthusiastic and excited. So I'd love to hear more.
so if I recall you reached out via the signup form, and I recall you were super enthusiastic and excited. So I'd love to hear more.
so if I recall you reached out via the signup form, and I recall you were super enthusiastic and excited. So I'd love to hear more.
so if I recall you reached out via the signup form, and I recall you were super enthusiastic and excited. So I'd love to hear more.
S Speaker 22:00love to hear more about your the funds, current posture, and are you based in Silicon Valley, here, down in San Diego, or somewhere else? I'm in the Silicon Valley.
love to hear more about your the funds, current posture, and are you based in Silicon Valley, here, down in San Diego, or somewhere else? I'm in the Silicon Valley.
love to hear more about your the funds, current posture, and are you based in Silicon Valley, here, down in San Diego, or somewhere else? I'm in the Silicon Valley.
love to hear more about your the funds, current posture, and are you based in Silicon Valley, here, down in San Diego, or somewhere else? I'm in the Silicon Valley.
S Speaker 12:10Yeah. Cool. Perfect. Perfect. Brandon. So Brandon, absolutely. I think we are the corporate venture arm of Qualcomm, typically aimed to deploy about 150 $280 million a year in us, geography overall, we are a global fund. So we have offices in India, Israel, China, Latin America, London and Brazil. So few, quite a Global Fund. In that matter. Have been around for 25 plus years, made deployed more than $2 billion in capital, and we invest out of the balance sheet of Qualcomm, so can be a long term partner. For that matter, we don't have the required, I would say, mandates to return the fund as such, but at the same time, we make our decisions very independently. Have to follow the same, I would say, financial discipline as any other venture fund would. And then investment areas, I would say AI has been a big focus area for us. We have made good investments in the foundation, Model layer and the infrastructure layer, with anthropic hugging, face scale, AI, weights and biases. So, so we've, we've done good number of investments in that space, physical AI is a focus area for us this year. I hope I can, I will be able to drive a few investments in that area, as well as a lot of vertical AI applications, AI agents, that's where we are very actively looking at check sizes are two to $15 million we are typically a Series A investor, sometimes in AI we have started opportunistically doing more seed because The market demands it. But other than that, preferably series A would like to see a little bit traction things like that, and then have invested from series A to almost pre IPO rounds as well cool anything
Yeah. Cool. Perfect. Perfect. Brandon. So Brandon, absolutely. I think we are the corporate venture arm of Qualcomm, typically aimed to deploy about 150 $280 million a year in us, geography overall, we are a global fund. So we have offices in India, Israel, China, Latin America, London and Brazil. So few, quite a Global Fund. In that matter. Have been around for 25 plus years, made deployed more than $2 billion in capital, and we invest out of the balance sheet of Qualcomm, so can be a long term partner. For that matter, we don't have the required, I would say, mandates to return the fund as such, but at the same time, we make our decisions very independently. Have to follow the same, I would say, financial discipline as any other venture fund would. And then investment areas, I would say AI has been a big focus area for us. We have made good investments in the foundation, Model layer and the infrastructure layer, with anthropic hugging, face scale, AI, weights and biases. So, so we've, we've done good number of investments in that space, physical AI is a focus area for us this year. I hope I can, I will be able to drive a few investments in that area, as well as a lot of vertical AI applications, AI agents, that's where we are very actively looking at check sizes are two to $15 million we are typically a Series A investor, sometimes in AI we have started opportunistically doing more seed because The market demands it. But other than that, preferably series A would like to see a little bit traction things like that, and then have invested from series A to almost pre IPO rounds as well cool anything
Yeah. Cool. Perfect. Perfect. Brandon. So Brandon, absolutely. I think we are the corporate venture arm of Qualcomm, typically aimed to deploy about 150 $280 million a year in us, geography overall, we are a global fund. So we have offices in India, Israel, China, Latin America, London and Brazil. So few, quite a Global Fund. In that matter. Have been around for 25 plus years, made deployed more than $2 billion in capital, and we invest out of the balance sheet of Qualcomm, so can be a long term partner. For that matter, we don't have the required, I would say, mandates to return the fund as such, but at the same time, we make our decisions very independently. Have to follow the same, I would say, financial discipline as any other venture fund would. And then investment areas, I would say AI has been a big focus area for us. We have made good investments in the foundation, Model layer and the infrastructure layer, with anthropic hugging, face scale, AI, weights and biases. So, so we've, we've done good number of investments in that space, physical AI is a focus area for us this year. I hope I can, I will be able to drive a few investments in that area, as well as a lot of vertical AI applications, AI agents, that's where we are very actively looking at check sizes are two to $15 million we are typically a Series A investor, sometimes in AI we have started opportunistically doing more seed because The market demands it. But other than that, preferably series A would like to see a little bit traction things like that, and then have invested from series A to almost pre IPO rounds as well cool anything
Yeah. Cool. Perfect. Perfect. Brandon. So Brandon, absolutely. I think we are the corporate venture arm of Qualcomm, typically aimed to deploy about 150 $280 million a year in us, geography overall, we are a global fund. So we have offices in India, Israel, China, Latin America, London and Brazil. So few, quite a Global Fund. In that matter. Have been around for 25 plus years, made deployed more than $2 billion in capital, and we invest out of the balance sheet of Qualcomm, so can be a long term partner. For that matter, we don't have the required, I would say, mandates to return the fund as such, but at the same time, we make our decisions very independently. Have to follow the same, I would say, financial discipline as any other venture fund would. And then investment areas, I would say AI has been a big focus area for us. We have made good investments in the foundation, Model layer and the infrastructure layer, with anthropic hugging, face scale, AI, weights and biases. So, so we've, we've done good number of investments in that space, physical AI is a focus area for us this year. I hope I can, I will be able to drive a few investments in that area, as well as a lot of vertical AI applications, AI agents, that's where we are very actively looking at check sizes are two to $15 million we are typically a Series A investor, sometimes in AI we have started opportunistically doing more seed because The market demands it. But other than that, preferably series A would like to see a little bit traction things like that, and then have invested from series A to almost pre IPO rounds as well cool anything
3:57specific that I can answer Brandon
specific that I can answer Brandon
specific that I can answer Brandon
specific that I can answer Brandon
S Speaker 24:00no that line's approval with the story last time. So you guys are pretty consistent,
no that line's approval with the story last time. So you guys are pretty consistent,
no that line's approval with the story last time. So you guys are pretty consistent,
no that line's approval with the story last time. So you guys are pretty consistent,
S Speaker 14:06right? I would just say that we've expanded a little bit on our feed thesis since the last time we would have spoken to you. But other than that, the story is consistent. Yes.
right? I would just say that we've expanded a little bit on our feed thesis since the last time we would have spoken to you. But other than that, the story is consistent. Yes.
right? I would just say that we've expanded a little bit on our feed thesis since the last time we would have spoken to you. But other than that, the story is consistent. Yes.
right? I would just say that we've expanded a little bit on our feed thesis since the last time we would have spoken to you. But other than that, the story is consistent. Yes.
S Speaker 24:17Well, great. So I guess maybe to start kind of a quick version of the pitch for the series, A that we are currently raising. Cool, since you're a strategic investor and you have a background in the space, I'll go faster so we can have more of a discussion.
Well, great. So I guess maybe to start kind of a quick version of the pitch for the series, A that we are currently raising. Cool, since you're a strategic investor and you have a background in the space, I'll go faster so we can have more of a discussion.
Well, great. So I guess maybe to start kind of a quick version of the pitch for the series, A that we are currently raising. Cool, since you're a strategic investor and you have a background in the space, I'll go faster so we can have more of a discussion.
Well, great. So I guess maybe to start kind of a quick version of the pitch for the series, A that we are currently raising. Cool, since you're a strategic investor and you have a background in the space, I'll go faster so we can have more of a discussion.
4:35But cool, so you got to just what we're doing.
But cool, so you got to just what we're doing.
But cool, so you got to just what we're doing.
But cool, so you got to just what we're doing.
S Speaker 24:39We were among the very first physical AI companies. We have the coder handle, he's probably seen our seed round, Ben rock, Amazon, autofi, not public. But Jeff Bezos also made a personal investment over the summer. And you probably both into our team. You know, many years working there at Google on AI for sensing, we've now grown to 31 people. Recently brought on a VP of sales, as we get more repeatable with our commercialization and kind of our grounding in our approach is going back to Google that we were experts in pioneering ways to apply deep learning to sensor data. In doing so, we take a signals first approach for exotic things like radar, for example, having the AI learn directly from the signal how the world behaves. And so now that we're in this transformer model era, this foundation model era, likewise, this kind of signals, first learning from observation approach, as opposed to learning from human labels. Approach is how we are building Newton. And we think, what else we see it in the markets today. This is quite a differentiated way to build a kind of world model. Please,
We were among the very first physical AI companies. We have the coder handle, he's probably seen our seed round, Ben rock, Amazon, autofi, not public. But Jeff Bezos also made a personal investment over the summer. And you probably both into our team. You know, many years working there at Google on AI for sensing, we've now grown to 31 people. Recently brought on a VP of sales, as we get more repeatable with our commercialization and kind of our grounding in our approach is going back to Google that we were experts in pioneering ways to apply deep learning to sensor data. In doing so, we take a signals first approach for exotic things like radar, for example, having the AI learn directly from the signal how the world behaves. And so now that we're in this transformer model era, this foundation model era, likewise, this kind of signals, first learning from observation approach, as opposed to learning from human labels. Approach is how we are building Newton. And we think, what else we see it in the markets today. This is quite a differentiated way to build a kind of world model. Please,
We were among the very first physical AI companies. We have the coder handle, he's probably seen our seed round, Ben rock, Amazon, autofi, not public. But Jeff Bezos also made a personal investment over the summer. And you probably both into our team. You know, many years working there at Google on AI for sensing, we've now grown to 31 people. Recently brought on a VP of sales, as we get more repeatable with our commercialization and kind of our grounding in our approach is going back to Google that we were experts in pioneering ways to apply deep learning to sensor data. In doing so, we take a signals first approach for exotic things like radar, for example, having the AI learn directly from the signal how the world behaves. And so now that we're in this transformer model era, this foundation model era, likewise, this kind of signals, first learning from observation approach, as opposed to learning from human labels. Approach is how we are building Newton. And we think, what else we see it in the markets today. This is quite a differentiated way to build a kind of world model. Please,
We were among the very first physical AI companies. We have the coder handle, he's probably seen our seed round, Ben rock, Amazon, autofi, not public. But Jeff Bezos also made a personal investment over the summer. And you probably both into our team. You know, many years working there at Google on AI for sensing, we've now grown to 31 people. Recently brought on a VP of sales, as we get more repeatable with our commercialization and kind of our grounding in our approach is going back to Google that we were experts in pioneering ways to apply deep learning to sensor data. In doing so, we take a signals first approach for exotic things like radar, for example, having the AI learn directly from the signal how the world behaves. And so now that we're in this transformer model era, this foundation model era, likewise, this kind of signals, first learning from observation approach, as opposed to learning from human labels. Approach is how we are building Newton. And we think, what else we see it in the markets today. This is quite a differentiated way to build a kind of world model. Please,
S Speaker 15:51go ahead, very quick. Question there Brandon, so you mentioned not using human labels, so you're not doing supervised learning. How is this working?
go ahead, very quick. Question there Brandon, so you mentioned not using human labels, so you're not doing supervised learning. How is this working?
go ahead, very quick. Question there Brandon, so you mentioned not using human labels, so you're not doing supervised learning. How is this working?
go ahead, very quick. Question there Brandon, so you mentioned not using human labels, so you're not doing supervised learning. How is this working?
S Speaker 18:57and Brandon. You call it foundation model. Have you seen emerging properties out of it? Have you been able to apply it to, say, different industries where you haven't had the training data for things like that?
and Brandon. You call it foundation model. Have you seen emerging properties out of it? Have you been able to apply it to, say, different industries where you haven't had the training data for things like that?
and Brandon. You call it foundation model. Have you seen emerging properties out of it? Have you been able to apply it to, say, different industries where you haven't had the training data for things like that?
and Brandon. You call it foundation model. Have you seen emerging properties out of it? Have you been able to apply it to, say, different industries where you haven't had the training data for things like that?
S Speaker 29:09We absolutely have. So the this is the logo wall currently, and everyone with a dark blue dots actually breaking news. 60 sign last night. A really large 850k deal. So let me flip our statements here. Very proud of that. That's the fifth blue along the top. Okay, bingo. Look at that. Nice. So, yeah, these are all big organizations with these problems. They are in very different verticals, and we can talk more about that, but the patterns that we see about in general, the most common types of sensor data are cameras and low dimensional time series, not yet Lidars, radar is still pretty new, and the most common use cases are wanting to monitor something about human behavior, or something about machine behavior. Human behavior could be safety, could be intent, prediction for some vehicle or a consumer device, machine behavior is often predictive maintenance, anomaly detection, forecasting, so on and so forth. Now to your question about is the model able to generalize? So in the physics domain, you probably saw these videos where, in both these cases, this mechanical system and this thermo thermodynamic system, Newton is zero shotting, this real time forecasting of what the motion is going to be, what the temp is going to be. This has since held up this kind of zero shot physics predictions, which can be used for anomaly detection. This held up, not only in the research paper you probably read, but also now with customers, with NTT for gearbox anomalies, with CMI for turbine anomalies, with AMI for with Applied Materials, excuse me for some inter manufacturing anomalies, and we're now applying it with Schlumberger for prediction of their horizontal drilling rig states. So this appears to be generalizing very well to sensors and very complex physical systems it hasn't seen before. It
We absolutely have. So the this is the logo wall currently, and everyone with a dark blue dots actually breaking news. 60 sign last night. A really large 850k deal. So let me flip our statements here. Very proud of that. That's the fifth blue along the top. Okay, bingo. Look at that. Nice. So, yeah, these are all big organizations with these problems. They are in very different verticals, and we can talk more about that, but the patterns that we see about in general, the most common types of sensor data are cameras and low dimensional time series, not yet Lidars, radar is still pretty new, and the most common use cases are wanting to monitor something about human behavior, or something about machine behavior. Human behavior could be safety, could be intent, prediction for some vehicle or a consumer device, machine behavior is often predictive maintenance, anomaly detection, forecasting, so on and so forth. Now to your question about is the model able to generalize? So in the physics domain, you probably saw these videos where, in both these cases, this mechanical system and this thermo thermodynamic system, Newton is zero shotting, this real time forecasting of what the motion is going to be, what the temp is going to be. This has since held up this kind of zero shot physics predictions, which can be used for anomaly detection. This held up, not only in the research paper you probably read, but also now with customers, with NTT for gearbox anomalies, with CMI for turbine anomalies, with AMI for with Applied Materials, excuse me for some inter manufacturing anomalies, and we're now applying it with Schlumberger for prediction of their horizontal drilling rig states. So this appears to be generalizing very well to sensors and very complex physical systems it hasn't seen before. It
We absolutely have. So the this is the logo wall currently, and everyone with a dark blue dots actually breaking news. 60 sign last night. A really large 850k deal. So let me flip our statements here. Very proud of that. That's the fifth blue along the top. Okay, bingo. Look at that. Nice. So, yeah, these are all big organizations with these problems. They are in very different verticals, and we can talk more about that, but the patterns that we see about in general, the most common types of sensor data are cameras and low dimensional time series, not yet Lidars, radar is still pretty new, and the most common use cases are wanting to monitor something about human behavior, or something about machine behavior. Human behavior could be safety, could be intent, prediction for some vehicle or a consumer device, machine behavior is often predictive maintenance, anomaly detection, forecasting, so on and so forth. Now to your question about is the model able to generalize? So in the physics domain, you probably saw these videos where, in both these cases, this mechanical system and this thermo thermodynamic system, Newton is zero shotting, this real time forecasting of what the motion is going to be, what the temp is going to be. This has since held up this kind of zero shot physics predictions, which can be used for anomaly detection. This held up, not only in the research paper you probably read, but also now with customers, with NTT for gearbox anomalies, with CMI for turbine anomalies, with AMI for with Applied Materials, excuse me for some inter manufacturing anomalies, and we're now applying it with Schlumberger for prediction of their horizontal drilling rig states. So this appears to be generalizing very well to sensors and very complex physical systems it hasn't seen before. It
We absolutely have. So the this is the logo wall currently, and everyone with a dark blue dots actually breaking news. 60 sign last night. A really large 850k deal. So let me flip our statements here. Very proud of that. That's the fifth blue along the top. Okay, bingo. Look at that. Nice. So, yeah, these are all big organizations with these problems. They are in very different verticals, and we can talk more about that, but the patterns that we see about in general, the most common types of sensor data are cameras and low dimensional time series, not yet Lidars, radar is still pretty new, and the most common use cases are wanting to monitor something about human behavior, or something about machine behavior. Human behavior could be safety, could be intent, prediction for some vehicle or a consumer device, machine behavior is often predictive maintenance, anomaly detection, forecasting, so on and so forth. Now to your question about is the model able to generalize? So in the physics domain, you probably saw these videos where, in both these cases, this mechanical system and this thermo thermodynamic system, Newton is zero shotting, this real time forecasting of what the motion is going to be, what the temp is going to be. This has since held up this kind of zero shot physics predictions, which can be used for anomaly detection. This held up, not only in the research paper you probably read, but also now with customers, with NTT for gearbox anomalies, with CMI for turbine anomalies, with AMI for with Applied Materials, excuse me for some inter manufacturing anomalies, and we're now applying it with Schlumberger for prediction of their horizontal drilling rig states. So this appears to be generalizing very well to sensors and very complex physical systems it hasn't seen before. It
S Speaker 111:18seems to be generalizing much better than some of the other LLM based companies that I have come across which are building for robots so you use do seem to have something there for that market as well. Very important, 100%
seems to be generalizing much better than some of the other LLM based companies that I have come across which are building for robots so you use do seem to have something there for that market as well. Very important, 100%
seems to be generalizing much better than some of the other LLM based companies that I have come across which are building for robots so you use do seem to have something there for that market as well. Very important, 100%
seems to be generalizing much better than some of the other LLM based companies that I have come across which are building for robots so you use do seem to have something there for that market as well. Very important, 100%
S Speaker 211:30and we think the difference is that we are grounding the model only on data from the physical world. We are training a model off of web videos and trying to get to do real life stuff. Here's an example, more on the semantic side, where in our work with the Jima construction, great case study I'll send you just yesterday. Really cool, cool video. But the focus there was on measuring construction productivity. And this was a neat example. Where in their, you know, fine tuning run in their use. We never talked about snow, but when it snowed, Newton could put the concept of snow together with the construction work and interpret that well, the snow could be why there was a productivity hit. So this kind of conceptual generalization is one that we're excited about, too, and the flow of the model internally. This is a big test diagram, but a bit more technical of an explanation is that we have this physics sub component that's doing what you saw with that, like bouncing spring, for example. So it signals in and then some signal out of forecast, a reconstruction, what have you that then goes into this semantic component, and there it's interpreting what that signal means. And so the user's prompt higher dimensional signals like video, that all gets merged at that semantic level. And that's then how you get an output like a text description and alert a visualization, so on and so forth.
and we think the difference is that we are grounding the model only on data from the physical world. We are training a model off of web videos and trying to get to do real life stuff. Here's an example, more on the semantic side, where in our work with the Jima construction, great case study I'll send you just yesterday. Really cool, cool video. But the focus there was on measuring construction productivity. And this was a neat example. Where in their, you know, fine tuning run in their use. We never talked about snow, but when it snowed, Newton could put the concept of snow together with the construction work and interpret that well, the snow could be why there was a productivity hit. So this kind of conceptual generalization is one that we're excited about, too, and the flow of the model internally. This is a big test diagram, but a bit more technical of an explanation is that we have this physics sub component that's doing what you saw with that, like bouncing spring, for example. So it signals in and then some signal out of forecast, a reconstruction, what have you that then goes into this semantic component, and there it's interpreting what that signal means. And so the user's prompt higher dimensional signals like video, that all gets merged at that semantic level. And that's then how you get an output like a text description and alert a visualization, so on and so forth.
and we think the difference is that we are grounding the model only on data from the physical world. We are training a model off of web videos and trying to get to do real life stuff. Here's an example, more on the semantic side, where in our work with the Jima construction, great case study I'll send you just yesterday. Really cool, cool video. But the focus there was on measuring construction productivity. And this was a neat example. Where in their, you know, fine tuning run in their use. We never talked about snow, but when it snowed, Newton could put the concept of snow together with the construction work and interpret that well, the snow could be why there was a productivity hit. So this kind of conceptual generalization is one that we're excited about, too, and the flow of the model internally. This is a big test diagram, but a bit more technical of an explanation is that we have this physics sub component that's doing what you saw with that, like bouncing spring, for example. So it signals in and then some signal out of forecast, a reconstruction, what have you that then goes into this semantic component, and there it's interpreting what that signal means. And so the user's prompt higher dimensional signals like video, that all gets merged at that semantic level. And that's then how you get an output like a text description and alert a visualization, so on and so forth.
and we think the difference is that we are grounding the model only on data from the physical world. We are training a model off of web videos and trying to get to do real life stuff. Here's an example, more on the semantic side, where in our work with the Jima construction, great case study I'll send you just yesterday. Really cool, cool video. But the focus there was on measuring construction productivity. And this was a neat example. Where in their, you know, fine tuning run in their use. We never talked about snow, but when it snowed, Newton could put the concept of snow together with the construction work and interpret that well, the snow could be why there was a productivity hit. So this kind of conceptual generalization is one that we're excited about, too, and the flow of the model internally. This is a big test diagram, but a bit more technical of an explanation is that we have this physics sub component that's doing what you saw with that, like bouncing spring, for example. So it signals in and then some signal out of forecast, a reconstruction, what have you that then goes into this semantic component, and there it's interpreting what that signal means. And so the user's prompt higher dimensional signals like video, that all gets merged at that semantic level. And that's then how you get an output like a text description and alert a visualization, so on and so forth.
S Speaker 113:02Very interesting. And Brandon, the previous example showed me that was through a CCTV camera feed. Were you taking any other sensor input for that as well?
Very interesting. And Brandon, the previous example showed me that was through a CCTV camera feed. Were you taking any other sensor input for that as well?
Very interesting. And Brandon, the previous example showed me that was through a CCTV camera feed. Were you taking any other sensor input for that as well?
Very interesting. And Brandon, the previous example showed me that was through a CCTV camera feed. Were you taking any other sensor input for that as well?
S Speaker 213:12So for that one, we had 27 camera feeds, and we had the weather and the tides, because this was a, this was a maritime construction project, and how they took the model and visualized them in an application. Is this interface where they can search, you know, any activities across camera views, across dates. They can get these kind of these, these can style views that meet their their formats and procedures for how they want to measure work. This was all done by hand before, and then for how that time was spent, we overlay that weather and tide data with the work activity, and they can, furthermore, they can click into any specific moment and review what was happening then.
So for that one, we had 27 camera feeds, and we had the weather and the tides, because this was a, this was a maritime construction project, and how they took the model and visualized them in an application. Is this interface where they can search, you know, any activities across camera views, across dates. They can get these kind of these, these can style views that meet their their formats and procedures for how they want to measure work. This was all done by hand before, and then for how that time was spent, we overlay that weather and tide data with the work activity, and they can, furthermore, they can click into any specific moment and review what was happening then.
So for that one, we had 27 camera feeds, and we had the weather and the tides, because this was a, this was a maritime construction project, and how they took the model and visualized them in an application. Is this interface where they can search, you know, any activities across camera views, across dates. They can get these kind of these, these can style views that meet their their formats and procedures for how they want to measure work. This was all done by hand before, and then for how that time was spent, we overlay that weather and tide data with the work activity, and they can, furthermore, they can click into any specific moment and review what was happening then.
So for that one, we had 27 camera feeds, and we had the weather and the tides, because this was a, this was a maritime construction project, and how they took the model and visualized them in an application. Is this interface where they can search, you know, any activities across camera views, across dates. They can get these kind of these, these can style views that meet their their formats and procedures for how they want to measure work. This was all done by hand before, and then for how that time was spent, we overlay that weather and tide data with the work activity, and they can, furthermore, they can click into any specific moment and review what was happening then.
S Speaker 113:55So in this case, Brandon, I'm just trying to sort of paralyze with a few of the problems I've seen with other companies, few in our portfolio company as well. So in this case, it's fair to say that because you had weather data input as well, and you have built a multi modal model here, the model was able to understand that this probably could be snow, and with Align it with a computer vision feed, and then eventually come to the conclusion it was snow, and made insights based
So in this case, Brandon, I'm just trying to sort of paralyze with a few of the problems I've seen with other companies, few in our portfolio company as well. So in this case, it's fair to say that because you had weather data input as well, and you have built a multi modal model here, the model was able to understand that this probably could be snow, and with Align it with a computer vision feed, and then eventually come to the conclusion it was snow, and made insights based
So in this case, Brandon, I'm just trying to sort of paralyze with a few of the problems I've seen with other companies, few in our portfolio company as well. So in this case, it's fair to say that because you had weather data input as well, and you have built a multi modal model here, the model was able to understand that this probably could be snow, and with Align it with a computer vision feed, and then eventually come to the conclusion it was snow, and made insights based
So in this case, Brandon, I'm just trying to sort of paralyze with a few of the problems I've seen with other companies, few in our portfolio company as well. So in this case, it's fair to say that because you had weather data input as well, and you have built a multi modal model here, the model was able to understand that this probably could be snow, and with Align it with a computer vision feed, and then eventually come to the conclusion it was snow, and made insights based
S Speaker 214:27on that. That's fair to say. And the significant thing of all that chain is understanding what that snow means for the customer's task,
on that. That's fair to say. And the significant thing of all that chain is understanding what that snow means for the customer's task,
on that. That's fair to say. And the significant thing of all that chain is understanding what that snow means for the customer's task,
on that. That's fair to say. And the significant thing of all that chain is understanding what that snow means for the customer's task,
14:37right, right? Yeah,
S Speaker 214:41a simple example that's this kind of like information fusion is our work with Dell on safety for the city of Bellevue. And so here we have the visual feed with the traffic signal feed, and the traffic signal gives context to the thing that we see this because camera can't see all the traffic lights. They are very tiny. If a person's crossing the street, are they jaywalking? Are they they not? This context is super important. So this is not sharp right now, but that white box that was the walk sign that he got so he crosses, that's one near miss. That's a second near miss. And we can understand that now by putting these different signals together. So the multi modality is very key, but how you solve actual, real life problems? This is a broader application our partners have built to visualize all the different outputs, AI overlay on the city, so on, so forth, and zoomed in, example of a sub component is like. This is an example of how we look for when there is someone who is crossing the street, light is going to use this to extend the walk time. So give you 10 more seconds, for example, to cross safely. But here again, this camera view doesn't see the traffic signals, and so we can use that context feed with the camera feed. And now Newton can make sense of what the scene shows
a simple example that's this kind of like information fusion is our work with Dell on safety for the city of Bellevue. And so here we have the visual feed with the traffic signal feed, and the traffic signal gives context to the thing that we see this because camera can't see all the traffic lights. They are very tiny. If a person's crossing the street, are they jaywalking? Are they they not? This context is super important. So this is not sharp right now, but that white box that was the walk sign that he got so he crosses, that's one near miss. That's a second near miss. And we can understand that now by putting these different signals together. So the multi modality is very key, but how you solve actual, real life problems? This is a broader application our partners have built to visualize all the different outputs, AI overlay on the city, so on, so forth, and zoomed in, example of a sub component is like. This is an example of how we look for when there is someone who is crossing the street, light is going to use this to extend the walk time. So give you 10 more seconds, for example, to cross safely. But here again, this camera view doesn't see the traffic signals, and so we can use that context feed with the camera feed. And now Newton can make sense of what the scene shows
a simple example that's this kind of like information fusion is our work with Dell on safety for the city of Bellevue. And so here we have the visual feed with the traffic signal feed, and the traffic signal gives context to the thing that we see this because camera can't see all the traffic lights. They are very tiny. If a person's crossing the street, are they jaywalking? Are they they not? This context is super important. So this is not sharp right now, but that white box that was the walk sign that he got so he crosses, that's one near miss. That's a second near miss. And we can understand that now by putting these different signals together. So the multi modality is very key, but how you solve actual, real life problems? This is a broader application our partners have built to visualize all the different outputs, AI overlay on the city, so on, so forth, and zoomed in, example of a sub component is like. This is an example of how we look for when there is someone who is crossing the street, light is going to use this to extend the walk time. So give you 10 more seconds, for example, to cross safely. But here again, this camera view doesn't see the traffic signals, and so we can use that context feed with the camera feed. And now Newton can make sense of what the scene shows
a simple example that's this kind of like information fusion is our work with Dell on safety for the city of Bellevue. And so here we have the visual feed with the traffic signal feed, and the traffic signal gives context to the thing that we see this because camera can't see all the traffic lights. They are very tiny. If a person's crossing the street, are they jaywalking? Are they they not? This context is super important. So this is not sharp right now, but that white box that was the walk sign that he got so he crosses, that's one near miss. That's a second near miss. And we can understand that now by putting these different signals together. So the multi modality is very key, but how you solve actual, real life problems? This is a broader application our partners have built to visualize all the different outputs, AI overlay on the city, so on, so forth, and zoomed in, example of a sub component is like. This is an example of how we look for when there is someone who is crossing the street, light is going to use this to extend the walk time. So give you 10 more seconds, for example, to cross safely. But here again, this camera view doesn't see the traffic signals, and so we can use that context feed with the camera feed. And now Newton can make sense of what the scene shows
S Speaker 116:00and Brandon, so I'm just curious here, what does it take? Because the pilots that you have done, I could see that it's very horizontal right now. So what does it take for you to fine tune each of these systems for a very specific use case in one industry? Is it scalable and does it require a lot of time on your end?
and Brandon, so I'm just curious here, what does it take? Because the pilots that you have done, I could see that it's very horizontal right now. So what does it take for you to fine tune each of these systems for a very specific use case in one industry? Is it scalable and does it require a lot of time on your end?
and Brandon, so I'm just curious here, what does it take? Because the pilots that you have done, I could see that it's very horizontal right now. So what does it take for you to fine tune each of these systems for a very specific use case in one industry? Is it scalable and does it require a lot of time on your end?
and Brandon, so I'm just curious here, what does it take? Because the pilots that you have done, I could see that it's very horizontal right now. So what does it take for you to fine tune each of these systems for a very specific use case in one industry? Is it scalable and does it require a lot of time on your end?
S Speaker 216:22Yeah. So first up, our product is this platform around the model. And this platform abstracts and adjusts a few APIs, everything a customer needs to build their own use case. And so you see here, this platform takes care of, how do I stream real time sensor data? How do I orchestrate my GPUs to be cost efficient? How do I deploy to an on prem endpoint, the server rack at a factory, so on and so forth and so our base model is always getting better, and what the customer is supposed to do is that they are going to use our tools to build a lens and we have a GUI version of this. We have an API version of this, but pretty much our analogy to an agent in this, in this JSON structure here on the left, and that can be lenses in cascade to run a workflow like this diagram on the the right, which is how we're doing anomaly detection for wind turbines and so for a customer, begin to end flow like this, where they get onboarded, they pick or define their lenses, they hook in their sample data that you fine tune if needed to hit your your benchmarks, and then you can deploy. So all this is getting faster as we have matured the base model and these tools as a reference, we're in this journey from this current, very kind of AI services approach to a self serve approach. So that construction project that took us nine months of work together our more recent projects with NTT and with at&t, those have been for two months for Comcast, two months. So it's getting faster and faster. What we're going to right now, and being kept with a handful of companies, is now giving them access to this where they can use the Python client in GitHub fully themselves to test things. They can usually prototype things. The last thing we haven't handed over yet is fine tuning tools. But like the applications that you saw, like the city of Bell one that was built from the customer,
Yeah. So first up, our product is this platform around the model. And this platform abstracts and adjusts a few APIs, everything a customer needs to build their own use case. And so you see here, this platform takes care of, how do I stream real time sensor data? How do I orchestrate my GPUs to be cost efficient? How do I deploy to an on prem endpoint, the server rack at a factory, so on and so forth and so our base model is always getting better, and what the customer is supposed to do is that they are going to use our tools to build a lens and we have a GUI version of this. We have an API version of this, but pretty much our analogy to an agent in this, in this JSON structure here on the left, and that can be lenses in cascade to run a workflow like this diagram on the the right, which is how we're doing anomaly detection for wind turbines and so for a customer, begin to end flow like this, where they get onboarded, they pick or define their lenses, they hook in their sample data that you fine tune if needed to hit your your benchmarks, and then you can deploy. So all this is getting faster as we have matured the base model and these tools as a reference, we're in this journey from this current, very kind of AI services approach to a self serve approach. So that construction project that took us nine months of work together our more recent projects with NTT and with at&t, those have been for two months for Comcast, two months. So it's getting faster and faster. What we're going to right now, and being kept with a handful of companies, is now giving them access to this where they can use the Python client in GitHub fully themselves to test things. They can usually prototype things. The last thing we haven't handed over yet is fine tuning tools. But like the applications that you saw, like the city of Bell one that was built from the customer,
Yeah. So first up, our product is this platform around the model. And this platform abstracts and adjusts a few APIs, everything a customer needs to build their own use case. And so you see here, this platform takes care of, how do I stream real time sensor data? How do I orchestrate my GPUs to be cost efficient? How do I deploy to an on prem endpoint, the server rack at a factory, so on and so forth and so our base model is always getting better, and what the customer is supposed to do is that they are going to use our tools to build a lens and we have a GUI version of this. We have an API version of this, but pretty much our analogy to an agent in this, in this JSON structure here on the left, and that can be lenses in cascade to run a workflow like this diagram on the the right, which is how we're doing anomaly detection for wind turbines and so for a customer, begin to end flow like this, where they get onboarded, they pick or define their lenses, they hook in their sample data that you fine tune if needed to hit your your benchmarks, and then you can deploy. So all this is getting faster as we have matured the base model and these tools as a reference, we're in this journey from this current, very kind of AI services approach to a self serve approach. So that construction project that took us nine months of work together our more recent projects with NTT and with at&t, those have been for two months for Comcast, two months. So it's getting faster and faster. What we're going to right now, and being kept with a handful of companies, is now giving them access to this where they can use the Python client in GitHub fully themselves to test things. They can usually prototype things. The last thing we haven't handed over yet is fine tuning tools. But like the applications that you saw, like the city of Bell one that was built from the customer,
Yeah. So first up, our product is this platform around the model. And this platform abstracts and adjusts a few APIs, everything a customer needs to build their own use case. And so you see here, this platform takes care of, how do I stream real time sensor data? How do I orchestrate my GPUs to be cost efficient? How do I deploy to an on prem endpoint, the server rack at a factory, so on and so forth and so our base model is always getting better, and what the customer is supposed to do is that they are going to use our tools to build a lens and we have a GUI version of this. We have an API version of this, but pretty much our analogy to an agent in this, in this JSON structure here on the left, and that can be lenses in cascade to run a workflow like this diagram on the the right, which is how we're doing anomaly detection for wind turbines and so for a customer, begin to end flow like this, where they get onboarded, they pick or define their lenses, they hook in their sample data that you fine tune if needed to hit your your benchmarks, and then you can deploy. So all this is getting faster as we have matured the base model and these tools as a reference, we're in this journey from this current, very kind of AI services approach to a self serve approach. So that construction project that took us nine months of work together our more recent projects with NTT and with at&t, those have been for two months for Comcast, two months. So it's getting faster and faster. What we're going to right now, and being kept with a handful of companies, is now giving them access to this where they can use the Python client in GitHub fully themselves to test things. They can usually prototype things. The last thing we haven't handed over yet is fine tuning tools. But like the applications that you saw, like the city of Bell one that was built from the customer,
18:37not from us, very
S Speaker 118:39interesting. Brandon. It seems like, if you have answers for everything I'm thinking about. So was from from the last seed to the current series, a what had, what was the progress that the team has made, so that I can combine it with the previous discussions we had? Oh, absolutely.
interesting. Brandon. It seems like, if you have answers for everything I'm thinking about. So was from from the last seed to the current series, a what had, what was the progress that the team has made, so that I can combine it with the previous discussions we had? Oh, absolutely.
interesting. Brandon. It seems like, if you have answers for everything I'm thinking about. So was from from the last seed to the current series, a what had, what was the progress that the team has made, so that I can combine it with the previous discussions we had? Oh, absolutely.
interesting. Brandon. It seems like, if you have answers for everything I'm thinking about. So was from from the last seed to the current series, a what had, what was the progress that the team has made, so that I can combine it with the previous discussions we had? Oh, absolutely.
S Speaker 218:59I mean, I think at the last meeting, we had the idea for the model, and we were like talking to Infineon about them, maybe being a partner. We had no customers. We, I think, of our five co founders, not everyone had left to Google yet. So it was, was, super, super early, because the big achievements I would call out, and then I would say, what we were raising this money to accomplish next, is that one we have landed these, these super massive logos with deal sizes now with Mercedes as big as 850k
I mean, I think at the last meeting, we had the idea for the model, and we were like talking to Infineon about them, maybe being a partner. We had no customers. We, I think, of our five co founders, not everyone had left to Google yet. So it was, was, super, super early, because the big achievements I would call out, and then I would say, what we were raising this money to accomplish next, is that one we have landed these, these super massive logos with deal sizes now with Mercedes as big as 850k
I mean, I think at the last meeting, we had the idea for the model, and we were like talking to Infineon about them, maybe being a partner. We had no customers. We, I think, of our five co founders, not everyone had left to Google yet. So it was, was, super, super early, because the big achievements I would call out, and then I would say, what we were raising this money to accomplish next, is that one we have landed these, these super massive logos with deal sizes now with Mercedes as big as 850k
I mean, I think at the last meeting, we had the idea for the model, and we were like talking to Infineon about them, maybe being a partner. We had no customers. We, I think, of our five co founders, not everyone had left to Google yet. So it was, was, super, super early, because the big achievements I would call out, and then I would say, what we were raising this money to accomplish next, is that one we have landed these, these super massive logos with deal sizes now with Mercedes as big as 850k
19:41The rest have all been in the six figures. Typically,
The rest have all been in the six figures. Typically,
The rest have all been in the six figures. Typically,
The rest have all been in the six figures. Typically,
S Speaker 219:45we one and then then two. In doing so this is now no longer near books. We got to a million in not AR, to be fair, but pilot revenue, folks willingness to pay in 2024 we've now crossed our second million with Mercedes as of May of 2025 and so that curve is getting steeper. We've been able to serve this range of verticalized customers because our model has the common underlying components to serve their use cases, which, from a data and task point of view, look pretty similar, even if how we might sell to a vertical is a bit different. And then three at the level of the model, through these pilots, we've proven that the tech works, and it's continuing to work as we scale it up. So the motivation for this, this series, A is that, you know, quite honestly, we have more inbound than we can handle. We are leaving money on the table. If any of these folks with green dots signs a deal over PPP summer, we don't have the staff to fulfill an enterprise grade, great grade, a great, great, great, great product. So we think we have customer validation, we have tech validation, and we want to raise this money to build the enterprise grade version of this and do things in a repeatable, scalable fashion with that enterprise grade product
we one and then then two. In doing so this is now no longer near books. We got to a million in not AR, to be fair, but pilot revenue, folks willingness to pay in 2024 we've now crossed our second million with Mercedes as of May of 2025 and so that curve is getting steeper. We've been able to serve this range of verticalized customers because our model has the common underlying components to serve their use cases, which, from a data and task point of view, look pretty similar, even if how we might sell to a vertical is a bit different. And then three at the level of the model, through these pilots, we've proven that the tech works, and it's continuing to work as we scale it up. So the motivation for this, this series, A is that, you know, quite honestly, we have more inbound than we can handle. We are leaving money on the table. If any of these folks with green dots signs a deal over PPP summer, we don't have the staff to fulfill an enterprise grade, great grade, a great, great, great, great product. So we think we have customer validation, we have tech validation, and we want to raise this money to build the enterprise grade version of this and do things in a repeatable, scalable fashion with that enterprise grade product
we one and then then two. In doing so this is now no longer near books. We got to a million in not AR, to be fair, but pilot revenue, folks willingness to pay in 2024 we've now crossed our second million with Mercedes as of May of 2025 and so that curve is getting steeper. We've been able to serve this range of verticalized customers because our model has the common underlying components to serve their use cases, which, from a data and task point of view, look pretty similar, even if how we might sell to a vertical is a bit different. And then three at the level of the model, through these pilots, we've proven that the tech works, and it's continuing to work as we scale it up. So the motivation for this, this series, A is that, you know, quite honestly, we have more inbound than we can handle. We are leaving money on the table. If any of these folks with green dots signs a deal over PPP summer, we don't have the staff to fulfill an enterprise grade, great grade, a great, great, great, great product. So we think we have customer validation, we have tech validation, and we want to raise this money to build the enterprise grade version of this and do things in a repeatable, scalable fashion with that enterprise grade product
we one and then then two. In doing so this is now no longer near books. We got to a million in not AR, to be fair, but pilot revenue, folks willingness to pay in 2024 we've now crossed our second million with Mercedes as of May of 2025 and so that curve is getting steeper. We've been able to serve this range of verticalized customers because our model has the common underlying components to serve their use cases, which, from a data and task point of view, look pretty similar, even if how we might sell to a vertical is a bit different. And then three at the level of the model, through these pilots, we've proven that the tech works, and it's continuing to work as we scale it up. So the motivation for this, this series, A is that, you know, quite honestly, we have more inbound than we can handle. We are leaving money on the table. If any of these folks with green dots signs a deal over PPP summer, we don't have the staff to fulfill an enterprise grade, great grade, a great, great, great, great product. So we think we have customer validation, we have tech validation, and we want to raise this money to build the enterprise grade version of this and do things in a repeatable, scalable fashion with that enterprise grade product
S Speaker 121:19that makes that makes a lot of sense. Brandon, so GTM wise, given that you're very horizontal, I would assume you just hired, you mentioned you just hired a BD lead. How are you thinking about sales in the future? You mentioned a lot of inbound, but apart from them, apart from that, how is the go to market motion would look like? Yeah.
that makes that makes a lot of sense. Brandon, so GTM wise, given that you're very horizontal, I would assume you just hired, you mentioned you just hired a BD lead. How are you thinking about sales in the future? You mentioned a lot of inbound, but apart from them, apart from that, how is the go to market motion would look like? Yeah.
that makes that makes a lot of sense. Brandon, so GTM wise, given that you're very horizontal, I would assume you just hired, you mentioned you just hired a BD lead. How are you thinking about sales in the future? You mentioned a lot of inbound, but apart from them, apart from that, how is the go to market motion would look like? Yeah.
that makes that makes a lot of sense. Brandon, so GTM wise, given that you're very horizontal, I would assume you just hired, you mentioned you just hired a BD lead. How are you thinking about sales in the future? You mentioned a lot of inbound, but apart from them, apart from that, how is the go to market motion would look like? Yeah.
S Speaker 221:41So the main thing we're trying to get to is, what's the velocity? How fast can we get someone from you know, today we do these, the these, these POCs, they're very hands on. We want to be doing that. That isn't what the business is. What we want to be doing is, here's this product, and you can try it yourself at your pace, here's this, here's here's access to it. You have one month in that month do your tests. If you come to conviction, let's do a commercial deal. So we want to get that trial, that test period down to just one month. We also, too, want to go to outbound marketing and sales. So that's how we want to evolve. And there's a version of this too. And NTT, for example, is an example of this, of selling through si to less sophisticated customers, such that NTT, what they've done is built a shop floor assistant based on our lens for anomaly detection, and now that's an application service they can resell across all their manufacturing customers. So that kind of channel partnership, we think is interesting too, though it's all still a bit early.
So the main thing we're trying to get to is, what's the velocity? How fast can we get someone from you know, today we do these, the these, these POCs, they're very hands on. We want to be doing that. That isn't what the business is. What we want to be doing is, here's this product, and you can try it yourself at your pace, here's this, here's here's access to it. You have one month in that month do your tests. If you come to conviction, let's do a commercial deal. So we want to get that trial, that test period down to just one month. We also, too, want to go to outbound marketing and sales. So that's how we want to evolve. And there's a version of this too. And NTT, for example, is an example of this, of selling through si to less sophisticated customers, such that NTT, what they've done is built a shop floor assistant based on our lens for anomaly detection, and now that's an application service they can resell across all their manufacturing customers. So that kind of channel partnership, we think is interesting too, though it's all still a bit early.
So the main thing we're trying to get to is, what's the velocity? How fast can we get someone from you know, today we do these, the these, these POCs, they're very hands on. We want to be doing that. That isn't what the business is. What we want to be doing is, here's this product, and you can try it yourself at your pace, here's this, here's here's access to it. You have one month in that month do your tests. If you come to conviction, let's do a commercial deal. So we want to get that trial, that test period down to just one month. We also, too, want to go to outbound marketing and sales. So that's how we want to evolve. And there's a version of this too. And NTT, for example, is an example of this, of selling through si to less sophisticated customers, such that NTT, what they've done is built a shop floor assistant based on our lens for anomaly detection, and now that's an application service they can resell across all their manufacturing customers. So that kind of channel partnership, we think is interesting too, though it's all still a bit early.
So the main thing we're trying to get to is, what's the velocity? How fast can we get someone from you know, today we do these, the these, these POCs, they're very hands on. We want to be doing that. That isn't what the business is. What we want to be doing is, here's this product, and you can try it yourself at your pace, here's this, here's here's access to it. You have one month in that month do your tests. If you come to conviction, let's do a commercial deal. So we want to get that trial, that test period down to just one month. We also, too, want to go to outbound marketing and sales. So that's how we want to evolve. And there's a version of this too. And NTT, for example, is an example of this, of selling through si to less sophisticated customers, such that NTT, what they've done is built a shop floor assistant based on our lens for anomaly detection, and now that's an application service they can resell across all their manufacturing customers. So that kind of channel partnership, we think is interesting too, though it's all still a bit early.
S Speaker 122:58understood. Brandon, very interesting. You mentioned a series a raise. How big a raise Are you raising? What kind of valuation you're looking for?
understood. Brandon, very interesting. You mentioned a series a raise. How big a raise Are you raising? What kind of valuation you're looking for?
understood. Brandon, very interesting. You mentioned a series a raise. How big a raise Are you raising? What kind of valuation you're looking for?
understood. Brandon, very interesting. You mentioned a series a raise. How big a raise Are you raising? What kind of valuation you're looking for?
S Speaker 223:07Yes. So we're looking to raise at least 35 million, and our target valuation, thus is 200 mil plus. Understood.
Yes. So we're looking to raise at least 35 million, and our target valuation, thus is 200 mil plus. Understood.
Yes. So we're looking to raise at least 35 million, and our target valuation, thus is 200 mil plus. Understood.
Yes. So we're looking to raise at least 35 million, and our target valuation, thus is 200 mil plus. Understood.
S Speaker 123:15We are check sizes. I would say the sweet spot for us is between five to seven sometimes up to 10. So I think it fits right in. There are a lot of follow up questions that I'm very excited about. Brandon would do a good ton of research on my end before I come back to you on that. Any thoughts on the composition of the round? How are you thinking about it? Do you have a lead in place? How are you thinking about onboarding strategic things like that?
We are check sizes. I would say the sweet spot for us is between five to seven sometimes up to 10. So I think it fits right in. There are a lot of follow up questions that I'm very excited about. Brandon would do a good ton of research on my end before I come back to you on that. Any thoughts on the composition of the round? How are you thinking about it? Do you have a lead in place? How are you thinking about onboarding strategic things like that?
We are check sizes. I would say the sweet spot for us is between five to seven sometimes up to 10. So I think it fits right in. There are a lot of follow up questions that I'm very excited about. Brandon would do a good ton of research on my end before I come back to you on that. Any thoughts on the composition of the round? How are you thinking about it? Do you have a lead in place? How are you thinking about onboarding strategic things like that?
We are check sizes. I would say the sweet spot for us is between five to seven sometimes up to 10. So I think it fits right in. There are a lot of follow up questions that I'm very excited about. Brandon would do a good ton of research on my end before I come back to you on that. Any thoughts on the composition of the round? How are you thinking about it? Do you have a lead in place? How are you thinking about onboarding strategic things like that?
S Speaker 223:45Yeah, so we just kicked off the Process Two weeks ago, so you caught us at a perfect time, but We thus have it settled on a lead yet, and it's probably going to be another month, maybe. So you have plenty of time, if you'd like, I can follow up with this deck, some materials, as well as if you feel ready, access to the data room. Just know that, yeah, we're prioritized getting the the lead in place first. So it's slower to have the next meeting or answer questions, but as soon as we have clarity, you know you are among the top next priority in terms of the round composition. It worked well for us at the seed to have benroc as the lead financial investor and surround them with Amazon and Hitachi as two strategics. And so we likewise imagine bringing strategics to the table for the series A folks like yourself who represent not just potentially an end customer, but a channel, and so far as we can sell edge versions of Newton with your silicon, I think that is pretty exciting. So if you want to talk more, I'd be
Yeah, so we just kicked off the Process Two weeks ago, so you caught us at a perfect time, but We thus have it settled on a lead yet, and it's probably going to be another month, maybe. So you have plenty of time, if you'd like, I can follow up with this deck, some materials, as well as if you feel ready, access to the data room. Just know that, yeah, we're prioritized getting the the lead in place first. So it's slower to have the next meeting or answer questions, but as soon as we have clarity, you know you are among the top next priority in terms of the round composition. It worked well for us at the seed to have benroc as the lead financial investor and surround them with Amazon and Hitachi as two strategics. And so we likewise imagine bringing strategics to the table for the series A folks like yourself who represent not just potentially an end customer, but a channel, and so far as we can sell edge versions of Newton with your silicon, I think that is pretty exciting. So if you want to talk more, I'd be
Yeah, so we just kicked off the Process Two weeks ago, so you caught us at a perfect time, but We thus have it settled on a lead yet, and it's probably going to be another month, maybe. So you have plenty of time, if you'd like, I can follow up with this deck, some materials, as well as if you feel ready, access to the data room. Just know that, yeah, we're prioritized getting the the lead in place first. So it's slower to have the next meeting or answer questions, but as soon as we have clarity, you know you are among the top next priority in terms of the round composition. It worked well for us at the seed to have benroc as the lead financial investor and surround them with Amazon and Hitachi as two strategics. And so we likewise imagine bringing strategics to the table for the series A folks like yourself who represent not just potentially an end customer, but a channel, and so far as we can sell edge versions of Newton with your silicon, I think that is pretty exciting. So if you want to talk more, I'd be
Yeah, so we just kicked off the Process Two weeks ago, so you caught us at a perfect time, but We thus have it settled on a lead yet, and it's probably going to be another month, maybe. So you have plenty of time, if you'd like, I can follow up with this deck, some materials, as well as if you feel ready, access to the data room. Just know that, yeah, we're prioritized getting the the lead in place first. So it's slower to have the next meeting or answer questions, but as soon as we have clarity, you know you are among the top next priority in terms of the round composition. It worked well for us at the seed to have benroc as the lead financial investor and surround them with Amazon and Hitachi as two strategics. And so we likewise imagine bringing strategics to the table for the series A folks like yourself who represent not just potentially an end customer, but a channel, and so far as we can sell edge versions of Newton with your silicon, I think that is pretty exciting. So if you want to talk more, I'd be
S Speaker 124:49glad to talk absolutely Brandon. I think, I think that's a big value proposition that we can bring. We work with a lot of, I would say, the logos that you have on your deck. We work with a lot of automobile OEMs, mobile and PC OEMs happy to act as a channel partner. I will hold on to that thought. I've been only a year and a more, a little bit more with the team, but I'd like to loop in a few more members of my team who have been with Qualcomm for decades, so they can speak way more better on what strategic value we can bring. Would appreciate an access to the deck, and when the data room is ready, happy to look at that as well. I would come back. I would like to set up a follow up call, looping in Tushar. Tushar has Tushar is the managing director at Qualcomm, and just he runs the Americas investment focus. And I believe Tushar was also a part of the sea discussion. That sounds familiar? Yeah, yeah. So he has the background that'll be great. And then meanwhile, sometime early, so we have an off site next week. So I'm not sure if, if you would be available doing another follow up call on Monday. If not, maybe we'll have to wait for a week, what does the timeline look better for you?
glad to talk absolutely Brandon. I think, I think that's a big value proposition that we can bring. We work with a lot of, I would say, the logos that you have on your deck. We work with a lot of automobile OEMs, mobile and PC OEMs happy to act as a channel partner. I will hold on to that thought. I've been only a year and a more, a little bit more with the team, but I'd like to loop in a few more members of my team who have been with Qualcomm for decades, so they can speak way more better on what strategic value we can bring. Would appreciate an access to the deck, and when the data room is ready, happy to look at that as well. I would come back. I would like to set up a follow up call, looping in Tushar. Tushar has Tushar is the managing director at Qualcomm, and just he runs the Americas investment focus. And I believe Tushar was also a part of the sea discussion. That sounds familiar? Yeah, yeah. So he has the background that'll be great. And then meanwhile, sometime early, so we have an off site next week. So I'm not sure if, if you would be available doing another follow up call on Monday. If not, maybe we'll have to wait for a week, what does the timeline look better for you?
glad to talk absolutely Brandon. I think, I think that's a big value proposition that we can bring. We work with a lot of, I would say, the logos that you have on your deck. We work with a lot of automobile OEMs, mobile and PC OEMs happy to act as a channel partner. I will hold on to that thought. I've been only a year and a more, a little bit more with the team, but I'd like to loop in a few more members of my team who have been with Qualcomm for decades, so they can speak way more better on what strategic value we can bring. Would appreciate an access to the deck, and when the data room is ready, happy to look at that as well. I would come back. I would like to set up a follow up call, looping in Tushar. Tushar has Tushar is the managing director at Qualcomm, and just he runs the Americas investment focus. And I believe Tushar was also a part of the sea discussion. That sounds familiar? Yeah, yeah. So he has the background that'll be great. And then meanwhile, sometime early, so we have an off site next week. So I'm not sure if, if you would be available doing another follow up call on Monday. If not, maybe we'll have to wait for a week, what does the timeline look better for you?
glad to talk absolutely Brandon. I think, I think that's a big value proposition that we can bring. We work with a lot of, I would say, the logos that you have on your deck. We work with a lot of automobile OEMs, mobile and PC OEMs happy to act as a channel partner. I will hold on to that thought. I've been only a year and a more, a little bit more with the team, but I'd like to loop in a few more members of my team who have been with Qualcomm for decades, so they can speak way more better on what strategic value we can bring. Would appreciate an access to the deck, and when the data room is ready, happy to look at that as well. I would come back. I would like to set up a follow up call, looping in Tushar. Tushar has Tushar is the managing director at Qualcomm, and just he runs the Americas investment focus. And I believe Tushar was also a part of the sea discussion. That sounds familiar? Yeah, yeah. So he has the background that'll be great. And then meanwhile, sometime early, so we have an off site next week. So I'm not sure if, if you would be available doing another follow up call on Monday. If not, maybe we'll have to wait for a week, what does the timeline look better for you?
26:04Let me put you with Anna for scheduling
Let me put you with Anna for scheduling
Let me put you with Anna for scheduling
Let me put you with Anna for scheduling
S Speaker 226:08myself. Next week's pretty packed with lead investor meetings, and then I'm going to Comcast. The next week, we are going to meet with the C suite and hopefully make a big step forward on the commercial side. And then the week after that, I am at Dell tech world. Though I'll be a lot more successful while in Vegas to have additional meetings. Plus my co founder as well. He's happens to be traveling today, but you could also meet him without me too. You definitely should meet him too, but yeah, so in any case, let me write you back today. I'll send you this deck. I'll send you some links. I will plus in Hannah and let's schedule the
myself. Next week's pretty packed with lead investor meetings, and then I'm going to Comcast. The next week, we are going to meet with the C suite and hopefully make a big step forward on the commercial side. And then the week after that, I am at Dell tech world. Though I'll be a lot more successful while in Vegas to have additional meetings. Plus my co founder as well. He's happens to be traveling today, but you could also meet him without me too. You definitely should meet him too, but yeah, so in any case, let me write you back today. I'll send you this deck. I'll send you some links. I will plus in Hannah and let's schedule the
myself. Next week's pretty packed with lead investor meetings, and then I'm going to Comcast. The next week, we are going to meet with the C suite and hopefully make a big step forward on the commercial side. And then the week after that, I am at Dell tech world. Though I'll be a lot more successful while in Vegas to have additional meetings. Plus my co founder as well. He's happens to be traveling today, but you could also meet him without me too. You definitely should meet him too, but yeah, so in any case, let me write you back today. I'll send you this deck. I'll send you some links. I will plus in Hannah and let's schedule the
myself. Next week's pretty packed with lead investor meetings, and then I'm going to Comcast. The next week, we are going to meet with the C suite and hopefully make a big step forward on the commercial side. And then the week after that, I am at Dell tech world. Though I'll be a lot more successful while in Vegas to have additional meetings. Plus my co founder as well. He's happens to be traveling today, but you could also meet him without me too. You definitely should meet him too, but yeah, so in any case, let me write you back today. I'll send you this deck. I'll send you some links. I will plus in Hannah and let's schedule the
S Speaker 126:44next best time. Brandon, thanks a lot for your time. This is very exciting. I'm doing this thesis, so I do see a lot of market inefficiencies. It's great to see a lot of things that you're talking it was a great cause.
next best time. Brandon, thanks a lot for your time. This is very exciting. I'm doing this thesis, so I do see a lot of market inefficiencies. It's great to see a lot of things that you're talking it was a great cause.
next best time. Brandon, thanks a lot for your time. This is very exciting. I'm doing this thesis, so I do see a lot of market inefficiencies. It's great to see a lot of things that you're talking it was a great cause.
next best time. Brandon, thanks a lot for your time. This is very exciting. I'm doing this thesis, so I do see a lot of market inefficiencies. It's great to see a lot of things that you're talking it was a great cause.
S Speaker 226:56Thank you. That's to us. It's so obvious, and maybe a little bit frustrating, how obvious it is to us that like llms, transformers, transformers are not just for text. Everything you can do, rebuild models, things with agents, all that should be possible as well for this whole world of sensor data that is so much bigger than the web.
Thank you. That's to us. It's so obvious, and maybe a little bit frustrating, how obvious it is to us that like llms, transformers, transformers are not just for text. Everything you can do, rebuild models, things with agents, all that should be possible as well for this whole world of sensor data that is so much bigger than the web.
Thank you. That's to us. It's so obvious, and maybe a little bit frustrating, how obvious it is to us that like llms, transformers, transformers are not just for text. Everything you can do, rebuild models, things with agents, all that should be possible as well for this whole world of sensor data that is so much bigger than the web.
Thank you. That's to us. It's so obvious, and maybe a little bit frustrating, how obvious it is to us that like llms, transformers, transformers are not just for text. Everything you can do, rebuild models, things with agents, all that should be possible as well for this whole world of sensor data that is so much bigger than the web.
S Speaker 127:17I know, I know, and it's exciting that you you started on this vision a few years back when things weren't that obvious. So thanks a lot for your time again, and we'll follow up soon. Thank you. Bye.
I know, I know, and it's exciting that you you started on this vision a few years back when things weren't that obvious. So thanks a lot for your time again, and we'll follow up soon. Thank you. Bye.
I know, I know, and it's exciting that you you started on this vision a few years back when things weren't that obvious. So thanks a lot for your time again, and we'll follow up soon. Thank you. Bye.
I know, I know, and it's exciting that you you started on this vision a few years back when things weren't that obvious. So thanks a lot for your time again, and we'll follow up soon. Thank you. Bye.