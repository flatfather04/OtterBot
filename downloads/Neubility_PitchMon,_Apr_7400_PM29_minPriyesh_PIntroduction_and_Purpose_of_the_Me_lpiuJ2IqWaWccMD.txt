Meeting: Neubility Pitch
Mon, Apr 7
4:00 PM
29 min
Priyesh P
Introduction and Purpose of the Meeting
0:39
Inv
URL: https://otter.ai/u/lpiuJ2IqWaWccMDAAS94tIaESAA
Downloaded: 2025-12-22T12:21:44.728072
Method: text_extraction
============================================================

0:39Hi, Priyesh, yes, yes.
Hi, Priyesh, yes, yes.
Hi, Priyesh, yes, yes.
Hi, Priyesh, yes, yes.
S Speaker 10:51A lot. No problem. A lot. Yeah, of course, is Andrew plan to join as well. They will join. So
A lot. No problem. A lot. Yeah, of course, is Andrew plan to join as well. They will join. So
A lot. No problem. A lot. Yeah, of course, is Andrew plan to join as well. They will join. So
A lot. No problem. A lot. Yeah, of course, is Andrew plan to join as well. They will join. So
S Speaker 21:07if it's okay with you, we can get going. Definitely can come
if it's okay with you, we can get going. Definitely can come
if it's okay with you, we can get going. Definitely can come
if it's okay with you, we can get going. Definitely can come
1:11while talking for sure,
while talking for sure,
while talking for sure,
while talking for sure,
S Speaker 11:12for sure. So particularly, I'm doing the thesis on physical AI, and we're looking at companies in this space, trying to see if there are a few investment prospects in that area. And that's why I wanted to have a follow up call with you. I think we discussed this, but I can give you a brief about how we operate at a fund, and then would understand, love to understand what Nebula is kind of trying to do. Today, I went to the website. I've done a little bit of my research on my own and but I'd like to understand what's the product roadmap going forward. How are they thinking about things? So just to pick it off, a brief background about myself, I'm an investor with Qualcom ventures here. Been with the team for about a year now. Prior to that, I was with mental ventures for a brief period of time, and mortgage ventures for some time, and then, originally from India, worked with a lot of early stage startups back then, and then made a pivot move to the US made a pivot into venture. So being in venture for about two and a half years now, very excited about the physical AI space, trying to see investments in that area. And then we also feel a lot of our chips down the line with AI sort of trying to re bring robotics back to life. We feel Qualcomm would have a big play, that a lot of our chips would go on robots, a lot of autonomous driving systems. And that's why it's also a strategically fit area for us to invest in. From a fund perspective, we are the corporate venture arm of Qualcomm in different regions, so I'm in the US team, but we also have a team in China, where in Israel, Europe, Latin America, in Brazil and in India as well. And then our check sizes are anywhere from $2 million to $15 million we invest out of the balance sheet of Qualcomm. So we don't have a fund cycle, but we don't sort of have all that mandates to return the funds, so we sort of try to become the long term partner for the companies. And then, apart from Ai, we invest in a lot of technology. So we work with a lot of automobile companies invest. So we invest a lot in automobile tech stack. We work with a lot of IoT companies. So IoT, computer vision, those are big focus areas for us. Apart from that, we have also done investments in AR VR and then the more recent AI foundation models, infrastructure, tooling, layer, things like that. So that's the brief background. Happy to answer any other questions you
for sure. So particularly, I'm doing the thesis on physical AI, and we're looking at companies in this space, trying to see if there are a few investment prospects in that area. And that's why I wanted to have a follow up call with you. I think we discussed this, but I can give you a brief about how we operate at a fund, and then would understand, love to understand what Nebula is kind of trying to do. Today, I went to the website. I've done a little bit of my research on my own and but I'd like to understand what's the product roadmap going forward. How are they thinking about things? So just to pick it off, a brief background about myself, I'm an investor with Qualcom ventures here. Been with the team for about a year now. Prior to that, I was with mental ventures for a brief period of time, and mortgage ventures for some time, and then, originally from India, worked with a lot of early stage startups back then, and then made a pivot move to the US made a pivot into venture. So being in venture for about two and a half years now, very excited about the physical AI space, trying to see investments in that area. And then we also feel a lot of our chips down the line with AI sort of trying to re bring robotics back to life. We feel Qualcomm would have a big play, that a lot of our chips would go on robots, a lot of autonomous driving systems. And that's why it's also a strategically fit area for us to invest in. From a fund perspective, we are the corporate venture arm of Qualcomm in different regions, so I'm in the US team, but we also have a team in China, where in Israel, Europe, Latin America, in Brazil and in India as well. And then our check sizes are anywhere from $2 million to $15 million we invest out of the balance sheet of Qualcomm. So we don't have a fund cycle, but we don't sort of have all that mandates to return the funds, so we sort of try to become the long term partner for the companies. And then, apart from Ai, we invest in a lot of technology. So we work with a lot of automobile companies invest. So we invest a lot in automobile tech stack. We work with a lot of IoT companies. So IoT, computer vision, those are big focus areas for us. Apart from that, we have also done investments in AR VR and then the more recent AI foundation models, infrastructure, tooling, layer, things like that. So that's the brief background. Happy to answer any other questions you
for sure. So particularly, I'm doing the thesis on physical AI, and we're looking at companies in this space, trying to see if there are a few investment prospects in that area. And that's why I wanted to have a follow up call with you. I think we discussed this, but I can give you a brief about how we operate at a fund, and then would understand, love to understand what Nebula is kind of trying to do. Today, I went to the website. I've done a little bit of my research on my own and but I'd like to understand what's the product roadmap going forward. How are they thinking about things? So just to pick it off, a brief background about myself, I'm an investor with Qualcom ventures here. Been with the team for about a year now. Prior to that, I was with mental ventures for a brief period of time, and mortgage ventures for some time, and then, originally from India, worked with a lot of early stage startups back then, and then made a pivot move to the US made a pivot into venture. So being in venture for about two and a half years now, very excited about the physical AI space, trying to see investments in that area. And then we also feel a lot of our chips down the line with AI sort of trying to re bring robotics back to life. We feel Qualcomm would have a big play, that a lot of our chips would go on robots, a lot of autonomous driving systems. And that's why it's also a strategically fit area for us to invest in. From a fund perspective, we are the corporate venture arm of Qualcomm in different regions, so I'm in the US team, but we also have a team in China, where in Israel, Europe, Latin America, in Brazil and in India as well. And then our check sizes are anywhere from $2 million to $15 million we invest out of the balance sheet of Qualcomm. So we don't have a fund cycle, but we don't sort of have all that mandates to return the funds, so we sort of try to become the long term partner for the companies. And then, apart from Ai, we invest in a lot of technology. So we work with a lot of automobile companies invest. So we invest a lot in automobile tech stack. We work with a lot of IoT companies. So IoT, computer vision, those are big focus areas for us. Apart from that, we have also done investments in AR VR and then the more recent AI foundation models, infrastructure, tooling, layer, things like that. So that's the brief background. Happy to answer any other questions you
for sure. So particularly, I'm doing the thesis on physical AI, and we're looking at companies in this space, trying to see if there are a few investment prospects in that area. And that's why I wanted to have a follow up call with you. I think we discussed this, but I can give you a brief about how we operate at a fund, and then would understand, love to understand what Nebula is kind of trying to do. Today, I went to the website. I've done a little bit of my research on my own and but I'd like to understand what's the product roadmap going forward. How are they thinking about things? So just to pick it off, a brief background about myself, I'm an investor with Qualcom ventures here. Been with the team for about a year now. Prior to that, I was with mental ventures for a brief period of time, and mortgage ventures for some time, and then, originally from India, worked with a lot of early stage startups back then, and then made a pivot move to the US made a pivot into venture. So being in venture for about two and a half years now, very excited about the physical AI space, trying to see investments in that area. And then we also feel a lot of our chips down the line with AI sort of trying to re bring robotics back to life. We feel Qualcomm would have a big play, that a lot of our chips would go on robots, a lot of autonomous driving systems. And that's why it's also a strategically fit area for us to invest in. From a fund perspective, we are the corporate venture arm of Qualcomm in different regions, so I'm in the US team, but we also have a team in China, where in Israel, Europe, Latin America, in Brazil and in India as well. And then our check sizes are anywhere from $2 million to $15 million we invest out of the balance sheet of Qualcomm. So we don't have a fund cycle, but we don't sort of have all that mandates to return the funds, so we sort of try to become the long term partner for the companies. And then, apart from Ai, we invest in a lot of technology. So we work with a lot of automobile companies invest. So we invest a lot in automobile tech stack. We work with a lot of IoT companies. So IoT, computer vision, those are big focus areas for us. Apart from that, we have also done investments in AR VR and then the more recent AI foundation models, infrastructure, tooling, layer, things like that. So that's the brief background. Happy to answer any other questions you
S Speaker 23:05may have for me. Yeah, sure. I want to ask if you got any investments in Korea, and
may have for me. Yeah, sure. I want to ask if you got any investments in Korea, and
may have for me. Yeah, sure. I want to ask if you got any investments in Korea, and
may have for me. Yeah, sure. I want to ask if you got any investments in Korea, and
3:11what the process that it looks like if you decide to
what the process that it looks like if you decide to
what the process that it looks like if you decide to
what the process that it looks like if you decide to
S Speaker 13:13invest. So I remember, it was before I joined, but probably a few years back, we had a team in Korea as well. Now most of our Korean investments go through the Chinese team or the Indian team. So down the line, I will have to connect you through one of those things, but trying to see if there's an opportunity here, and then maybe I can connect you someone else in the more
invest. So I remember, it was before I joined, but probably a few years back, we had a team in Korea as well. Now most of our Korean investments go through the Chinese team or the Indian team. So down the line, I will have to connect you through one of those things, but trying to see if there's an opportunity here, and then maybe I can connect you someone else in the more
invest. So I remember, it was before I joined, but probably a few years back, we had a team in Korea as well. Now most of our Korean investments go through the Chinese team or the Indian team. So down the line, I will have to connect you through one of those things, but trying to see if there's an opportunity here, and then maybe I can connect you someone else in the more
invest. So I remember, it was before I joined, but probably a few years back, we had a team in Korea as well. Now most of our Korean investments go through the Chinese team or the Indian team. So down the line, I will have to connect you through one of those things, but trying to see if there's an opportunity here, and then maybe I can connect you someone else in the more
3:31regional teams there. Got it. And is the investment process
regional teams there. Got it. And is the investment process
regional teams there. Got it. And is the investment process
regional teams there. Got it. And is the investment process
S Speaker 13:33pretty quick. So for us, it usually takes three to four weeks. What a process looks like is an investment manager like me would create some convictions around the company, have a discussion. We will have fun management calls. So we will invite the team to sort of speak to the entire Google team, and then we have a couple of internal discussions. So the investment decisions are made by the fund, not by Qualcomm, and we do sort of see if there is any strategic fit, but that's and typically the process, entire process takes about three to four weeks for us. Got it
pretty quick. So for us, it usually takes three to four weeks. What a process looks like is an investment manager like me would create some convictions around the company, have a discussion. We will have fun management calls. So we will invite the team to sort of speak to the entire Google team, and then we have a couple of internal discussions. So the investment decisions are made by the fund, not by Qualcomm, and we do sort of see if there is any strategic fit, but that's and typically the process, entire process takes about three to four weeks for us. Got it
pretty quick. So for us, it usually takes three to four weeks. What a process looks like is an investment manager like me would create some convictions around the company, have a discussion. We will have fun management calls. So we will invite the team to sort of speak to the entire Google team, and then we have a couple of internal discussions. So the investment decisions are made by the fund, not by Qualcomm, and we do sort of see if there is any strategic fit, but that's and typically the process, entire process takes about three to four weeks for us. Got it
pretty quick. So for us, it usually takes three to four weeks. What a process looks like is an investment manager like me would create some convictions around the company, have a discussion. We will have fun management calls. So we will invite the team to sort of speak to the entire Google team, and then we have a couple of internal discussions. So the investment decisions are made by the fund, not by Qualcomm, and we do sort of see if there is any strategic fit, but that's and typically the process, entire process takes about three to four weeks for us. Got it
S Speaker 24:04Yes, and then do you have you also invested in, like service robotics
Yes, and then do you have you also invested in, like service robotics
Yes, and then do you have you also invested in, like service robotics
Yes, and then do you have you also invested in, like service robotics
S Speaker 14:08companies? So we, early on, we had an investment in a warehouse robotic company, but not as many robotic companies post that, right?
companies? So we, early on, we had an investment in a warehouse robotic company, but not as many robotic companies post that, right?
companies? So we, early on, we had an investment in a warehouse robotic company, but not as many robotic companies post that, right?
companies? So we, early on, we had an investment in a warehouse robotic company, but not as many robotic companies post that, right?
4:19Yeah, sure. Thanks a lot.
Yeah, sure. Thanks a lot.
Yeah, sure. Thanks a lot.
Yeah, sure. Thanks a lot.
S Speaker 24:22So yes, would you, would you like me to give you a presentation, or should I just give you, like, a brief explanation on where things stand with us and what our
So yes, would you, would you like me to give you a presentation, or should I just give you, like, a brief explanation on where things stand with us and what our
So yes, would you, would you like me to give you a presentation, or should I just give you, like, a brief explanation on where things stand with us and what our
So yes, would you, would you like me to give you a presentation, or should I just give you, like, a brief explanation on where things stand with us and what our
S Speaker 14:29vision is? I think whatever you prefer, that would be great. I think
vision is? I think whatever you prefer, that would be great. I think
vision is? I think whatever you prefer, that would be great. I think
vision is? I think whatever you prefer, that would be great. I think
6:25the second piece is, is,
the second piece is, is,
the second piece is, is,
the second piece is, is,
S Speaker 26:28is the humanoid market, and for that, we are developing what we call an ammr, which is an autonomous mobile manipulation robot and and this robot is something that can basically pick up, move things and place things down. So this allows us to further refine the the operation that we're doing for deliveries, because now it allows us to leave things behind instead of having to waste wait for somebody to connect things up. And also we can enter new spaces, like warehouses, distribution centers, manufacturing facilities, with this type of robot. And we know that there are a lot of prototypes out there. If you go to modex or promad, even at GTC, you've already seen these robots picking up in place and things, but we know that a lot of them are still at the early demo stage. So when we talk with Korean compartments here who have a need for this type of automation device, the problem is that they can't find a solution that's already made, that's commercially available at a price point that they're uncomfortable with, and they also need high degree reliability they can easily find in the market today. So with this network that we have, a lot of our investors are green conglomerates, we're able to get these business opportunities, and we think they start acquiring this data pretty rapidly, because we already have a digital prototype that we build, that we're training with Nvidia Isaac, and we're gonna build a prototype with this prototype this year and start deploying them in these environment related centers that we had in South Korea. So so, yeah, I mean, and the reason why we can do this better than other companies is because we already have the backbone of AI, let's say, from our autonomous delivery robots, and we also have service experience so we've been able to tailor our UI in way that enhances the customer experience, whether for robot sleep management or ordering, for the whole ecosystem that's required to for a customer to seamlessly use robot robotics as a service. So yeah, so we have those two work streams, and then starts one thing. In addition to on these, I don't deliver robots. We don't just do deliveries. We also do Thomas controlling. So we can add High Definition AI camera on top of our side lock delivery robot then becomes a control robot that can take video recordings of a certain environment, like private properties. We can also add, like gas leakage potential sensors, fly detention sensors, and deploy these in factories, like large indoor factories that have a need for this type of automated device.
is the humanoid market, and for that, we are developing what we call an ammr, which is an autonomous mobile manipulation robot and and this robot is something that can basically pick up, move things and place things down. So this allows us to further refine the the operation that we're doing for deliveries, because now it allows us to leave things behind instead of having to waste wait for somebody to connect things up. And also we can enter new spaces, like warehouses, distribution centers, manufacturing facilities, with this type of robot. And we know that there are a lot of prototypes out there. If you go to modex or promad, even at GTC, you've already seen these robots picking up in place and things, but we know that a lot of them are still at the early demo stage. So when we talk with Korean compartments here who have a need for this type of automation device, the problem is that they can't find a solution that's already made, that's commercially available at a price point that they're uncomfortable with, and they also need high degree reliability they can easily find in the market today. So with this network that we have, a lot of our investors are green conglomerates, we're able to get these business opportunities, and we think they start acquiring this data pretty rapidly, because we already have a digital prototype that we build, that we're training with Nvidia Isaac, and we're gonna build a prototype with this prototype this year and start deploying them in these environment related centers that we had in South Korea. So so, yeah, I mean, and the reason why we can do this better than other companies is because we already have the backbone of AI, let's say, from our autonomous delivery robots, and we also have service experience so we've been able to tailor our UI in way that enhances the customer experience, whether for robot sleep management or ordering, for the whole ecosystem that's required to for a customer to seamlessly use robot robotics as a service. So yeah, so we have those two work streams, and then starts one thing. In addition to on these, I don't deliver robots. We don't just do deliveries. We also do Thomas controlling. So we can add High Definition AI camera on top of our side lock delivery robot then becomes a control robot that can take video recordings of a certain environment, like private properties. We can also add, like gas leakage potential sensors, fly detention sensors, and deploy these in factories, like large indoor factories that have a need for this type of automated device.
is the humanoid market, and for that, we are developing what we call an ammr, which is an autonomous mobile manipulation robot and and this robot is something that can basically pick up, move things and place things down. So this allows us to further refine the the operation that we're doing for deliveries, because now it allows us to leave things behind instead of having to waste wait for somebody to connect things up. And also we can enter new spaces, like warehouses, distribution centers, manufacturing facilities, with this type of robot. And we know that there are a lot of prototypes out there. If you go to modex or promad, even at GTC, you've already seen these robots picking up in place and things, but we know that a lot of them are still at the early demo stage. So when we talk with Korean compartments here who have a need for this type of automation device, the problem is that they can't find a solution that's already made, that's commercially available at a price point that they're uncomfortable with, and they also need high degree reliability they can easily find in the market today. So with this network that we have, a lot of our investors are green conglomerates, we're able to get these business opportunities, and we think they start acquiring this data pretty rapidly, because we already have a digital prototype that we build, that we're training with Nvidia Isaac, and we're gonna build a prototype with this prototype this year and start deploying them in these environment related centers that we had in South Korea. So so, yeah, I mean, and the reason why we can do this better than other companies is because we already have the backbone of AI, let's say, from our autonomous delivery robots, and we also have service experience so we've been able to tailor our UI in way that enhances the customer experience, whether for robot sleep management or ordering, for the whole ecosystem that's required to for a customer to seamlessly use robot robotics as a service. So yeah, so we have those two work streams, and then starts one thing. In addition to on these, I don't deliver robots. We don't just do deliveries. We also do Thomas controlling. So we can add High Definition AI camera on top of our side lock delivery robot then becomes a control robot that can take video recordings of a certain environment, like private properties. We can also add, like gas leakage potential sensors, fly detention sensors, and deploy these in factories, like large indoor factories that have a need for this type of automated device.
is the humanoid market, and for that, we are developing what we call an ammr, which is an autonomous mobile manipulation robot and and this robot is something that can basically pick up, move things and place things down. So this allows us to further refine the the operation that we're doing for deliveries, because now it allows us to leave things behind instead of having to waste wait for somebody to connect things up. And also we can enter new spaces, like warehouses, distribution centers, manufacturing facilities, with this type of robot. And we know that there are a lot of prototypes out there. If you go to modex or promad, even at GTC, you've already seen these robots picking up in place and things, but we know that a lot of them are still at the early demo stage. So when we talk with Korean compartments here who have a need for this type of automation device, the problem is that they can't find a solution that's already made, that's commercially available at a price point that they're uncomfortable with, and they also need high degree reliability they can easily find in the market today. So with this network that we have, a lot of our investors are green conglomerates, we're able to get these business opportunities, and we think they start acquiring this data pretty rapidly, because we already have a digital prototype that we build, that we're training with Nvidia Isaac, and we're gonna build a prototype with this prototype this year and start deploying them in these environment related centers that we had in South Korea. So so, yeah, I mean, and the reason why we can do this better than other companies is because we already have the backbone of AI, let's say, from our autonomous delivery robots, and we also have service experience so we've been able to tailor our UI in way that enhances the customer experience, whether for robot sleep management or ordering, for the whole ecosystem that's required to for a customer to seamlessly use robot robotics as a service. So yeah, so we have those two work streams, and then starts one thing. In addition to on these, I don't deliver robots. We don't just do deliveries. We also do Thomas controlling. So we can add High Definition AI camera on top of our side lock delivery robot then becomes a control robot that can take video recordings of a certain environment, like private properties. We can also add, like gas leakage potential sensors, fly detention sensors, and deploy these in factories, like large indoor factories that have a need for this type of automated device.
S Speaker 18:35stopped here, and then I'll leave it to you to ask any questions or things. Is it fair to say today that your advantage is, let's say, in navigating across dense environments, and that's something that you've been focusing on. You You've started with, let's say urban navigation problems. And then do you plan to sort of extend our capabilities in industrial warehouse, kind manufacturing kind of
stopped here, and then I'll leave it to you to ask any questions or things. Is it fair to say today that your advantage is, let's say, in navigating across dense environments, and that's something that you've been focusing on. You You've started with, let's say urban navigation problems. And then do you plan to sort of extend our capabilities in industrial warehouse, kind manufacturing kind of
stopped here, and then I'll leave it to you to ask any questions or things. Is it fair to say today that your advantage is, let's say, in navigating across dense environments, and that's something that you've been focusing on. You You've started with, let's say urban navigation problems. And then do you plan to sort of extend our capabilities in industrial warehouse, kind manufacturing kind of
stopped here, and then I'll leave it to you to ask any questions or things. Is it fair to say today that your advantage is, let's say, in navigating across dense environments, and that's something that you've been focusing on. You You've started with, let's say urban navigation problems. And then do you plan to sort of extend our capabilities in industrial warehouse, kind manufacturing kind of
S Speaker 28:56environment as well. Right? Right, exactly. So we use cameras instead of lidars for our core sensor stack. So, so that is the advantage that we're constantly building. Because, you know, the more data you have in a lot of diverse environments, the better algorithms to come. So we started out with urban dense environments, and we also are doing indoor slash outdoor delivery. So our robots right now can actually take something from a restaurant in a nervous Street and go to the apartment complex, take the elevator, go up and drop and wait in front of the door of an apartment that's on the 10th floor of a building. So it can do indoor and outdoor deliveries. And we think that this end to end, the fact that robot can actually go to doorstep is a very important factor in increasing the
environment as well. Right? Right, exactly. So we use cameras instead of lidars for our core sensor stack. So, so that is the advantage that we're constantly building. Because, you know, the more data you have in a lot of diverse environments, the better algorithms to come. So we started out with urban dense environments, and we also are doing indoor slash outdoor delivery. So our robots right now can actually take something from a restaurant in a nervous Street and go to the apartment complex, take the elevator, go up and drop and wait in front of the door of an apartment that's on the 10th floor of a building. So it can do indoor and outdoor deliveries. And we think that this end to end, the fact that robot can actually go to doorstep is a very important factor in increasing the
environment as well. Right? Right, exactly. So we use cameras instead of lidars for our core sensor stack. So, so that is the advantage that we're constantly building. Because, you know, the more data you have in a lot of diverse environments, the better algorithms to come. So we started out with urban dense environments, and we also are doing indoor slash outdoor delivery. So our robots right now can actually take something from a restaurant in a nervous Street and go to the apartment complex, take the elevator, go up and drop and wait in front of the door of an apartment that's on the 10th floor of a building. So it can do indoor and outdoor deliveries. And we think that this end to end, the fact that robot can actually go to doorstep is a very important factor in increasing the
environment as well. Right? Right, exactly. So we use cameras instead of lidars for our core sensor stack. So, so that is the advantage that we're constantly building. Because, you know, the more data you have in a lot of diverse environments, the better algorithms to come. So we started out with urban dense environments, and we also are doing indoor slash outdoor delivery. So our robots right now can actually take something from a restaurant in a nervous Street and go to the apartment complex, take the elevator, go up and drop and wait in front of the door of an apartment that's on the 10th floor of a building. So it can do indoor and outdoor deliveries. And we think that this end to end, the fact that robot can actually go to doorstep is a very important factor in increasing the
9:33demand for this type of service,
demand for this type of service,
demand for this type of service,
demand for this type of service,
S Speaker 19:36yeah. And how does the robot sort of navigate the elevator and all the other does it have actual arms to sort of navigate the buttons and things
yeah. And how does the robot sort of navigate the elevator and all the other does it have actual arms to sort of navigate the buttons and things
yeah. And how does the robot sort of navigate the elevator and all the other does it have actual arms to sort of navigate the buttons and things
yeah. And how does the robot sort of navigate the elevator and all the other does it have actual arms to sort of navigate the buttons and things
S Speaker 29:45like that? Yeah. So there will be two main methods. So one will be to use the IoT device on the robot, have it communicate with the IoT device in elevators, so that it doesn't have to push anything, but can just get and do that. The other option is, is to have the the arms that we will attach the robot for the ammr, and have the arms just press a button and and do whatever the human typically does. And we think that both are important, because while having the IoT connection is going to
like that? Yeah. So there will be two main methods. So one will be to use the IoT device on the robot, have it communicate with the IoT device in elevators, so that it doesn't have to push anything, but can just get and do that. The other option is, is to have the the arms that we will attach the robot for the ammr, and have the arms just press a button and and do whatever the human typically does. And we think that both are important, because while having the IoT connection is going to
like that? Yeah. So there will be two main methods. So one will be to use the IoT device on the robot, have it communicate with the IoT device in elevators, so that it doesn't have to push anything, but can just get and do that. The other option is, is to have the the arms that we will attach the robot for the ammr, and have the arms just press a button and and do whatever the human typically does. And we think that both are important, because while having the IoT connection is going to
like that? Yeah. So there will be two main methods. So one will be to use the IoT device on the robot, have it communicate with the IoT device in elevators, so that it doesn't have to push anything, but can just get and do that. The other option is, is to have the the arms that we will attach the robot for the ammr, and have the arms just press a button and and do whatever the human typically does. And we think that both are important, because while having the IoT connection is going to
10:23be more seamless,
S Speaker 210:26the only issue is that if there are, like a lot of different elevator companies that we that we need to integrate with. It might act as a bit of a hurdle in terms of scope of the speed of go to market, but if we have arms, it means like, we don't really need to even talk with the other companies to start and the robots inside right away. So we want to take both approaches. And right now, we've already integrated with three of the major companies in South Korea. So there's a bit of preparatory work that's required. As long as that's done, we think that this is enough that could work. Well, we want this to work in even any, any new environment where you don't even have a contract with that, with the other company. So yeah, that's the vision. And also for the companies have already partnered with. Do you have to, do the companies do? Do they need to go back and retrofit all of the elevators back? Or is it just one contract, and they already have that IoT sensor and built in all of those elevators already? Yeah, normally, like the elevators that have been installed and in the past, like 15 years, they all have it sensors already. And then once the elevator goes beyond 15 years, the cost of maintaining the elevators actually becomes higher than replacing with anyone based on the elevator company's policies. So we think that it's just a matter of time
the only issue is that if there are, like a lot of different elevator companies that we that we need to integrate with. It might act as a bit of a hurdle in terms of scope of the speed of go to market, but if we have arms, it means like, we don't really need to even talk with the other companies to start and the robots inside right away. So we want to take both approaches. And right now, we've already integrated with three of the major companies in South Korea. So there's a bit of preparatory work that's required. As long as that's done, we think that this is enough that could work. Well, we want this to work in even any, any new environment where you don't even have a contract with that, with the other company. So yeah, that's the vision. And also for the companies have already partnered with. Do you have to, do the companies do? Do they need to go back and retrofit all of the elevators back? Or is it just one contract, and they already have that IoT sensor and built in all of those elevators already? Yeah, normally, like the elevators that have been installed and in the past, like 15 years, they all have it sensors already. And then once the elevator goes beyond 15 years, the cost of maintaining the elevators actually becomes higher than replacing with anyone based on the elevator company's policies. So we think that it's just a matter of time
the only issue is that if there are, like a lot of different elevator companies that we that we need to integrate with. It might act as a bit of a hurdle in terms of scope of the speed of go to market, but if we have arms, it means like, we don't really need to even talk with the other companies to start and the robots inside right away. So we want to take both approaches. And right now, we've already integrated with three of the major companies in South Korea. So there's a bit of preparatory work that's required. As long as that's done, we think that this is enough that could work. Well, we want this to work in even any, any new environment where you don't even have a contract with that, with the other company. So yeah, that's the vision. And also for the companies have already partnered with. Do you have to, do the companies do? Do they need to go back and retrofit all of the elevators back? Or is it just one contract, and they already have that IoT sensor and built in all of those elevators already? Yeah, normally, like the elevators that have been installed and in the past, like 15 years, they all have it sensors already. And then once the elevator goes beyond 15 years, the cost of maintaining the elevators actually becomes higher than replacing with anyone based on the elevator company's policies. So we think that it's just a matter of time
the only issue is that if there are, like a lot of different elevator companies that we that we need to integrate with. It might act as a bit of a hurdle in terms of scope of the speed of go to market, but if we have arms, it means like, we don't really need to even talk with the other companies to start and the robots inside right away. So we want to take both approaches. And right now, we've already integrated with three of the major companies in South Korea. So there's a bit of preparatory work that's required. As long as that's done, we think that this is enough that could work. Well, we want this to work in even any, any new environment where you don't even have a contract with that, with the other company. So yeah, that's the vision. And also for the companies have already partnered with. Do you have to, do the companies do? Do they need to go back and retrofit all of the elevators back? Or is it just one contract, and they already have that IoT sensor and built in all of those elevators already? Yeah, normally, like the elevators that have been installed and in the past, like 15 years, they all have it sensors already. And then once the elevator goes beyond 15 years, the cost of maintaining the elevators actually becomes higher than replacing with anyone based on the elevator company's policies. So we think that it's just a matter of time
S Speaker 111:29while elevators have the it license and coming to the humanoid robot now. So the humanoid robot? Is it actually humanoid form factor that you are planning to build, or will it just be more on the parent delivery robot structure?
while elevators have the it license and coming to the humanoid robot now. So the humanoid robot? Is it actually humanoid form factor that you are planning to build, or will it just be more on the parent delivery robot structure?
while elevators have the it license and coming to the humanoid robot now. So the humanoid robot? Is it actually humanoid form factor that you are planning to build, or will it just be more on the parent delivery robot structure?
while elevators have the it license and coming to the humanoid robot now. So the humanoid robot? Is it actually humanoid form factor that you are planning to build, or will it just be more on the parent delivery robot structure?
S Speaker 211:44Yeah, so we want to build something that is not as expensive as as a humanoid or complicated in the early stages, at least. So we want to use our wheel base that we have refined over the years from our sidewalk delivery robot business attached like a spine to it and some arms so that it's it's much more low cost, but still can perform 80% of the functionalities that humanoids are
Yeah, so we want to build something that is not as expensive as as a humanoid or complicated in the early stages, at least. So we want to use our wheel base that we have refined over the years from our sidewalk delivery robot business attached like a spine to it and some arms so that it's it's much more low cost, but still can perform 80% of the functionalities that humanoids are
Yeah, so we want to build something that is not as expensive as as a humanoid or complicated in the early stages, at least. So we want to use our wheel base that we have refined over the years from our sidewalk delivery robot business attached like a spine to it and some arms so that it's it's much more low cost, but still can perform 80% of the functionalities that humanoids are
Yeah, so we want to build something that is not as expensive as as a humanoid or complicated in the early stages, at least. So we want to use our wheel base that we have refined over the years from our sidewalk delivery robot business attached like a spine to it and some arms so that it's it's much more low cost, but still can perform 80% of the functionalities that humanoids are
S Speaker 112:12expected to perform, right? Yeah. And you mentioned a couple of use cases that are fitting with this. One of it is delivery, but also sort of leaving the food there. And then you mentioned a few industrial manufacturing use cases. Do you have anything specific in mind? Are there specific markets and use cases you're going after?
expected to perform, right? Yeah. And you mentioned a couple of use cases that are fitting with this. One of it is delivery, but also sort of leaving the food there. And then you mentioned a few industrial manufacturing use cases. Do you have anything specific in mind? Are there specific markets and use cases you're going after?
expected to perform, right? Yeah. And you mentioned a couple of use cases that are fitting with this. One of it is delivery, but also sort of leaving the food there. And then you mentioned a few industrial manufacturing use cases. Do you have anything specific in mind? Are there specific markets and use cases you're going after?
expected to perform, right? Yeah. And you mentioned a couple of use cases that are fitting with this. One of it is delivery, but also sort of leaving the food there. And then you mentioned a few industrial manufacturing use cases. Do you have anything specific in mind? Are there specific markets and use cases you're going after?
S Speaker 212:36in terms of the delivery space, I guess it's more about doing things like parcel deliveries, so expanding to that area. And we have discussed with with logistics companies in South Korea that are already doing parcel deliveries, mail deliveries, and they have the need for this type of device, so they're willing to adopt like a commercial prototype once it's out. And then, in terms of the manufacturing that you mentioned, I think we'll probably start with warehouses, distribution centers, before going into manufacturing facilities, which require a bit more to mess in terms of the operations that a robot has to do. But warehouse houses, distribution centers. They just need the robot to pick up things and place them on trays, you know, those types of basic operations that don't require as much dexterity. So that's where we want to get started. And then we've, we've visited a facility of a Korean conglomerate that has a huge e commerce business, and right now they use certain robots, so people work with the robots, but it'll be better for them to automate the whole process, and that's a big need that we see in this
in terms of the delivery space, I guess it's more about doing things like parcel deliveries, so expanding to that area. And we have discussed with with logistics companies in South Korea that are already doing parcel deliveries, mail deliveries, and they have the need for this type of device, so they're willing to adopt like a commercial prototype once it's out. And then, in terms of the manufacturing that you mentioned, I think we'll probably start with warehouses, distribution centers, before going into manufacturing facilities, which require a bit more to mess in terms of the operations that a robot has to do. But warehouse houses, distribution centers. They just need the robot to pick up things and place them on trays, you know, those types of basic operations that don't require as much dexterity. So that's where we want to get started. And then we've, we've visited a facility of a Korean conglomerate that has a huge e commerce business, and right now they use certain robots, so people work with the robots, but it'll be better for them to automate the whole process, and that's a big need that we see in this
in terms of the delivery space, I guess it's more about doing things like parcel deliveries, so expanding to that area. And we have discussed with with logistics companies in South Korea that are already doing parcel deliveries, mail deliveries, and they have the need for this type of device, so they're willing to adopt like a commercial prototype once it's out. And then, in terms of the manufacturing that you mentioned, I think we'll probably start with warehouses, distribution centers, before going into manufacturing facilities, which require a bit more to mess in terms of the operations that a robot has to do. But warehouse houses, distribution centers. They just need the robot to pick up things and place them on trays, you know, those types of basic operations that don't require as much dexterity. So that's where we want to get started. And then we've, we've visited a facility of a Korean conglomerate that has a huge e commerce business, and right now they use certain robots, so people work with the robots, but it'll be better for them to automate the whole process, and that's a big need that we see in this
in terms of the delivery space, I guess it's more about doing things like parcel deliveries, so expanding to that area. And we have discussed with with logistics companies in South Korea that are already doing parcel deliveries, mail deliveries, and they have the need for this type of device, so they're willing to adopt like a commercial prototype once it's out. And then, in terms of the manufacturing that you mentioned, I think we'll probably start with warehouses, distribution centers, before going into manufacturing facilities, which require a bit more to mess in terms of the operations that a robot has to do. But warehouse houses, distribution centers. They just need the robot to pick up things and place them on trays, you know, those types of basic operations that don't require as much dexterity. So that's where we want to get started. And then we've, we've visited a facility of a Korean conglomerate that has a huge e commerce business, and right now they use certain robots, so people work with the robots, but it'll be better for them to automate the whole process, and that's a big need that we see in this
S Speaker 113:45market. And what's the timeline you're thinking about launching some of these new form factors?
market. And what's the timeline you're thinking about launching some of these new form factors?
market. And what's the timeline you're thinking about launching some of these new form factors?
market. And what's the timeline you're thinking about launching some of these new form factors?
S Speaker 213:52Yes. So we want to come up with a physical prototype this year and start collecting data, and then we would launch our first commercial service next year in 2026
Yes. So we want to come up with a physical prototype this year and start collecting data, and then we would launch our first commercial service next year in 2026
Yes. So we want to come up with a physical prototype this year and start collecting data, and then we would launch our first commercial service next year in 2026
Yes. So we want to come up with a physical prototype this year and start collecting data, and then we would launch our first commercial service next year in 2026
S Speaker 114:03understood. And how are you thinking about the models that would go behind some of these new form factors? Though, I think I remember when we discussed you mentioned you've collected a ton of data from your delivery business side of things, and you're planning to use that to create algorithms. Can you explain that a little bit more
understood. And how are you thinking about the models that would go behind some of these new form factors? Though, I think I remember when we discussed you mentioned you've collected a ton of data from your delivery business side of things, and you're planning to use that to create algorithms. Can you explain that a little bit more
understood. And how are you thinking about the models that would go behind some of these new form factors? Though, I think I remember when we discussed you mentioned you've collected a ton of data from your delivery business side of things, and you're planning to use that to create algorithms. Can you explain that a little bit more
understood. And how are you thinking about the models that would go behind some of these new form factors? Though, I think I remember when we discussed you mentioned you've collected a ton of data from your delivery business side of things, and you're planning to use that to create algorithms. Can you explain that a little bit more
S Speaker 214:26for sidewalk delivery, we have, let's say, three different layers. So there's the part of perception, where the robot tries to understand is facing which areas it can actually drive on. We have what we call localization, which is about the robot understanding its starting point and destination and figuring out the optimal route. And then we have planning and control, which is about taking in all that information, having the robot actually move according to to what it needs to do. So, you know, we think move this to manipulation, we would need the same skills of perception and localization, planning and control, but just in a more with a more complex form of hardware perception, because it needs to understand what objects it's seeing, localization, because it has to understand the distance between the object and the manipulator for it to actually go and grab the object. Well. And then there's the whole planning control around this motion. The difference would probably be that if we use manipulators, we have to understand the date the dynamics between the manipulator and the object that it's grabbing, yeah, and for that we would, we would need to have to have simulated environments, to have real world data and and that's going to be like a different data set from what we've been collecting so far, right? But the other parts are going to be what we can build on.
for sidewalk delivery, we have, let's say, three different layers. So there's the part of perception, where the robot tries to understand is facing which areas it can actually drive on. We have what we call localization, which is about the robot understanding its starting point and destination and figuring out the optimal route. And then we have planning and control, which is about taking in all that information, having the robot actually move according to to what it needs to do. So, you know, we think move this to manipulation, we would need the same skills of perception and localization, planning and control, but just in a more with a more complex form of hardware perception, because it needs to understand what objects it's seeing, localization, because it has to understand the distance between the object and the manipulator for it to actually go and grab the object. Well. And then there's the whole planning control around this motion. The difference would probably be that if we use manipulators, we have to understand the date the dynamics between the manipulator and the object that it's grabbing, yeah, and for that we would, we would need to have to have simulated environments, to have real world data and and that's going to be like a different data set from what we've been collecting so far, right? But the other parts are going to be what we can build on.
for sidewalk delivery, we have, let's say, three different layers. So there's the part of perception, where the robot tries to understand is facing which areas it can actually drive on. We have what we call localization, which is about the robot understanding its starting point and destination and figuring out the optimal route. And then we have planning and control, which is about taking in all that information, having the robot actually move according to to what it needs to do. So, you know, we think move this to manipulation, we would need the same skills of perception and localization, planning and control, but just in a more with a more complex form of hardware perception, because it needs to understand what objects it's seeing, localization, because it has to understand the distance between the object and the manipulator for it to actually go and grab the object. Well. And then there's the whole planning control around this motion. The difference would probably be that if we use manipulators, we have to understand the date the dynamics between the manipulator and the object that it's grabbing, yeah, and for that we would, we would need to have to have simulated environments, to have real world data and and that's going to be like a different data set from what we've been collecting so far, right? But the other parts are going to be what we can build on.
for sidewalk delivery, we have, let's say, three different layers. So there's the part of perception, where the robot tries to understand is facing which areas it can actually drive on. We have what we call localization, which is about the robot understanding its starting point and destination and figuring out the optimal route. And then we have planning and control, which is about taking in all that information, having the robot actually move according to to what it needs to do. So, you know, we think move this to manipulation, we would need the same skills of perception and localization, planning and control, but just in a more with a more complex form of hardware perception, because it needs to understand what objects it's seeing, localization, because it has to understand the distance between the object and the manipulator for it to actually go and grab the object. Well. And then there's the whole planning control around this motion. The difference would probably be that if we use manipulators, we have to understand the date the dynamics between the manipulator and the object that it's grabbing, yeah, and for that we would, we would need to have to have simulated environments, to have real world data and and that's going to be like a different data set from what we've been collecting so far, right? But the other parts are going to be what we can build on.
15:54And then we would,
S Speaker 215:57we would also be able to use the service component, like the robot fleet management system that we have in place and the and the different software that we have created to to build that seamless customer experience when they when they use our robot service,
we would also be able to use the service component, like the robot fleet management system that we have in place and the and the different software that we have created to to build that seamless customer experience when they when they use our robot service,
we would also be able to use the service component, like the robot fleet management system that we have in place and the and the different software that we have created to to build that seamless customer experience when they when they use our robot service,
we would also be able to use the service component, like the robot fleet management system that we have in place and the and the different software that we have created to to build that seamless customer experience when they when they use our robot service,
16:14got it? Got it? Yeah, that makes a lot of sense.
got it? Got it? Yeah, that makes a lot of sense.
got it? Got it? Yeah, that makes a lot of sense.
got it? Got it? Yeah, that makes a lot of sense.
S Speaker 116:18Do? I also came across new abilities, sense. How is that part of the business doing? I think that is the perception and localization module that you've put together in a package, yeah. How do you see that future and also back, coming back on the perception model. What's the architecture behind it?
Do? I also came across new abilities, sense. How is that part of the business doing? I think that is the perception and localization module that you've put together in a package, yeah. How do you see that future and also back, coming back on the perception model. What's the architecture behind it?
Do? I also came across new abilities, sense. How is that part of the business doing? I think that is the perception and localization module that you've put together in a package, yeah. How do you see that future and also back, coming back on the perception model. What's the architecture behind it?
Do? I also came across new abilities, sense. How is that part of the business doing? I think that is the perception and localization module that you've put together in a package, yeah. How do you see that future and also back, coming back on the perception model. What's the architecture behind it?
S Speaker 216:43for you really sense that's going to be like our licensing module, and it basically means that with the vast amount of data that we collected, we were able to train our own algorithms, and now we want to have other companies be able to benefit from that. So we are discussing with a company called unit tree in China, they want to have like a brain for their robot, because right now they're just focusing on the hardware and the embedded software. So so they need, they need the autonomous driving software on their robot for those robots to be able to do autonomous patrolling of like large industrial facilities and so on. And we've already also been discussing with Samsung Electronics on licensing our software for their AGVs that they use in their production facilities. So Samsung has the technology for autonomous driving in indoor environments, but but they don't have one for outdoor environments, and they believe that will take them at least two years to to match what we've already done in this space. So they want to actually adopt our software in their AGVs for indoor slash outdoor, autonomous driving and deliveries of prototypes of whatever needs to be delivered in those production environments. So those are the early discussions we're having. We also have discussion on going with with rainbow robotics, which is an investee of Samsung Electronics. They also make humanoid robots, like four legged robots and so on. And Samsung wants to, wants us to work together with them, because they invested in both of our companies. So they are also trying to build a robot with arms, and they need a software because they're just hardware centric. So those are the key discussions we're having on that the ability perception, what it's based on. So we use a combination of map less autonomy and visual slam. So map less autonomy means that, if we can get GPS signals, the robot is able to just go from point A to point B with that because, because of the self driving algorithm as a robot moves along that that global path, what we call it a global path. It makes its own local path, because it has to avoid obstacles and and just drive on the routes where it makes sense. So, so that is done in areas where GPS signals are good. So we don't need any prior mapping. We, just as a human does. We enter on Google Maps, the starting point, destination point, we use that that that road that the path that the Google Maps API, or neighbor Maps API shows, and have the robot follow that route. But when the GPS signal is weak or when it bounces off of tall buildings, we cannot rely on that anymore, because the accuracy still isn't good enough. So for that, we we use what we call visual slam, which is about taking in the images that come in through our cameras and creating the map of the environment and using that for the robot to position itself. And that can be used in both indoor environments and also in complex urban urban environments. So in our expertise is in combining the two at a low cost, using low computing power to provide a service at a low price point.
for you really sense that's going to be like our licensing module, and it basically means that with the vast amount of data that we collected, we were able to train our own algorithms, and now we want to have other companies be able to benefit from that. So we are discussing with a company called unit tree in China, they want to have like a brain for their robot, because right now they're just focusing on the hardware and the embedded software. So so they need, they need the autonomous driving software on their robot for those robots to be able to do autonomous patrolling of like large industrial facilities and so on. And we've already also been discussing with Samsung Electronics on licensing our software for their AGVs that they use in their production facilities. So Samsung has the technology for autonomous driving in indoor environments, but but they don't have one for outdoor environments, and they believe that will take them at least two years to to match what we've already done in this space. So they want to actually adopt our software in their AGVs for indoor slash outdoor, autonomous driving and deliveries of prototypes of whatever needs to be delivered in those production environments. So those are the early discussions we're having. We also have discussion on going with with rainbow robotics, which is an investee of Samsung Electronics. They also make humanoid robots, like four legged robots and so on. And Samsung wants to, wants us to work together with them, because they invested in both of our companies. So they are also trying to build a robot with arms, and they need a software because they're just hardware centric. So those are the key discussions we're having on that the ability perception, what it's based on. So we use a combination of map less autonomy and visual slam. So map less autonomy means that, if we can get GPS signals, the robot is able to just go from point A to point B with that because, because of the self driving algorithm as a robot moves along that that global path, what we call it a global path. It makes its own local path, because it has to avoid obstacles and and just drive on the routes where it makes sense. So, so that is done in areas where GPS signals are good. So we don't need any prior mapping. We, just as a human does. We enter on Google Maps, the starting point, destination point, we use that that that road that the path that the Google Maps API, or neighbor Maps API shows, and have the robot follow that route. But when the GPS signal is weak or when it bounces off of tall buildings, we cannot rely on that anymore, because the accuracy still isn't good enough. So for that, we we use what we call visual slam, which is about taking in the images that come in through our cameras and creating the map of the environment and using that for the robot to position itself. And that can be used in both indoor environments and also in complex urban urban environments. So in our expertise is in combining the two at a low cost, using low computing power to provide a service at a low price point.
for you really sense that's going to be like our licensing module, and it basically means that with the vast amount of data that we collected, we were able to train our own algorithms, and now we want to have other companies be able to benefit from that. So we are discussing with a company called unit tree in China, they want to have like a brain for their robot, because right now they're just focusing on the hardware and the embedded software. So so they need, they need the autonomous driving software on their robot for those robots to be able to do autonomous patrolling of like large industrial facilities and so on. And we've already also been discussing with Samsung Electronics on licensing our software for their AGVs that they use in their production facilities. So Samsung has the technology for autonomous driving in indoor environments, but but they don't have one for outdoor environments, and they believe that will take them at least two years to to match what we've already done in this space. So they want to actually adopt our software in their AGVs for indoor slash outdoor, autonomous driving and deliveries of prototypes of whatever needs to be delivered in those production environments. So those are the early discussions we're having. We also have discussion on going with with rainbow robotics, which is an investee of Samsung Electronics. They also make humanoid robots, like four legged robots and so on. And Samsung wants to, wants us to work together with them, because they invested in both of our companies. So they are also trying to build a robot with arms, and they need a software because they're just hardware centric. So those are the key discussions we're having on that the ability perception, what it's based on. So we use a combination of map less autonomy and visual slam. So map less autonomy means that, if we can get GPS signals, the robot is able to just go from point A to point B with that because, because of the self driving algorithm as a robot moves along that that global path, what we call it a global path. It makes its own local path, because it has to avoid obstacles and and just drive on the routes where it makes sense. So, so that is done in areas where GPS signals are good. So we don't need any prior mapping. We, just as a human does. We enter on Google Maps, the starting point, destination point, we use that that that road that the path that the Google Maps API, or neighbor Maps API shows, and have the robot follow that route. But when the GPS signal is weak or when it bounces off of tall buildings, we cannot rely on that anymore, because the accuracy still isn't good enough. So for that, we we use what we call visual slam, which is about taking in the images that come in through our cameras and creating the map of the environment and using that for the robot to position itself. And that can be used in both indoor environments and also in complex urban urban environments. So in our expertise is in combining the two at a low cost, using low computing power to provide a service at a low price point.
for you really sense that's going to be like our licensing module, and it basically means that with the vast amount of data that we collected, we were able to train our own algorithms, and now we want to have other companies be able to benefit from that. So we are discussing with a company called unit tree in China, they want to have like a brain for their robot, because right now they're just focusing on the hardware and the embedded software. So so they need, they need the autonomous driving software on their robot for those robots to be able to do autonomous patrolling of like large industrial facilities and so on. And we've already also been discussing with Samsung Electronics on licensing our software for their AGVs that they use in their production facilities. So Samsung has the technology for autonomous driving in indoor environments, but but they don't have one for outdoor environments, and they believe that will take them at least two years to to match what we've already done in this space. So they want to actually adopt our software in their AGVs for indoor slash outdoor, autonomous driving and deliveries of prototypes of whatever needs to be delivered in those production environments. So those are the early discussions we're having. We also have discussion on going with with rainbow robotics, which is an investee of Samsung Electronics. They also make humanoid robots, like four legged robots and so on. And Samsung wants to, wants us to work together with them, because they invested in both of our companies. So they are also trying to build a robot with arms, and they need a software because they're just hardware centric. So those are the key discussions we're having on that the ability perception, what it's based on. So we use a combination of map less autonomy and visual slam. So map less autonomy means that, if we can get GPS signals, the robot is able to just go from point A to point B with that because, because of the self driving algorithm as a robot moves along that that global path, what we call it a global path. It makes its own local path, because it has to avoid obstacles and and just drive on the routes where it makes sense. So, so that is done in areas where GPS signals are good. So we don't need any prior mapping. We, just as a human does. We enter on Google Maps, the starting point, destination point, we use that that that road that the path that the Google Maps API, or neighbor Maps API shows, and have the robot follow that route. But when the GPS signal is weak or when it bounces off of tall buildings, we cannot rely on that anymore, because the accuracy still isn't good enough. So for that, we we use what we call visual slam, which is about taking in the images that come in through our cameras and creating the map of the environment and using that for the robot to position itself. And that can be used in both indoor environments and also in complex urban urban environments. So in our expertise is in combining the two at a low cost, using low computing power to provide a service at a low price point.
S Speaker 120:17That's very interesting, though. So we, as Qualcomm, we are connected to possibly all the humanoid robot companies. Just last week, we did a round of discussions with 1x dexterity robots, a lot of these companies and the perception model is something that is very exciting. A lot of these companies are building their brains for the robots internally, but it makes a lot of sense to sort of outsource some of this. And then I'm sure you would have come across the likes of skilled AI physical intelligence trying to create their own robotic models. How do you see newbility sense compared to some of those foundation model companies?
That's very interesting, though. So we, as Qualcomm, we are connected to possibly all the humanoid robot companies. Just last week, we did a round of discussions with 1x dexterity robots, a lot of these companies and the perception model is something that is very exciting. A lot of these companies are building their brains for the robots internally, but it makes a lot of sense to sort of outsource some of this. And then I'm sure you would have come across the likes of skilled AI physical intelligence trying to create their own robotic models. How do you see newbility sense compared to some of those foundation model companies?
That's very interesting, though. So we, as Qualcomm, we are connected to possibly all the humanoid robot companies. Just last week, we did a round of discussions with 1x dexterity robots, a lot of these companies and the perception model is something that is very exciting. A lot of these companies are building their brains for the robots internally, but it makes a lot of sense to sort of outsource some of this. And then I'm sure you would have come across the likes of skilled AI physical intelligence trying to create their own robotic models. How do you see newbility sense compared to some of those foundation model companies?
That's very interesting, though. So we, as Qualcomm, we are connected to possibly all the humanoid robot companies. Just last week, we did a round of discussions with 1x dexterity robots, a lot of these companies and the perception model is something that is very exciting. A lot of these companies are building their brains for the robots internally, but it makes a lot of sense to sort of outsource some of this. And then I'm sure you would have come across the likes of skilled AI physical intelligence trying to create their own robotic models. How do you see newbility sense compared to some of those foundation model companies?
S Speaker 221:02Yeah, like you mentioned, it's all, let's say, going towards the same vision. I think the best that we have is that we've already done commercial services in urban streets over four or five years. Of course, there were regulations in South Korea that prevented us actively deploying them until late 2024 late 2023 sorry but, but since all those regulations have been abolished, we've been we've been really actively deploying them in the streets. And we think it's important to have real world data, not just data from the simulated environments, because the level of fidelity still cannot match. So you know, this is why we really want to aggressively expand as quickly as possible to different environments and global markets, whether indoor or outdoor, because we think this is an advantage that we need to really cling on and build on.
Yeah, like you mentioned, it's all, let's say, going towards the same vision. I think the best that we have is that we've already done commercial services in urban streets over four or five years. Of course, there were regulations in South Korea that prevented us actively deploying them until late 2024 late 2023 sorry but, but since all those regulations have been abolished, we've been we've been really actively deploying them in the streets. And we think it's important to have real world data, not just data from the simulated environments, because the level of fidelity still cannot match. So you know, this is why we really want to aggressively expand as quickly as possible to different environments and global markets, whether indoor or outdoor, because we think this is an advantage that we need to really cling on and build on.
Yeah, like you mentioned, it's all, let's say, going towards the same vision. I think the best that we have is that we've already done commercial services in urban streets over four or five years. Of course, there were regulations in South Korea that prevented us actively deploying them until late 2024 late 2023 sorry but, but since all those regulations have been abolished, we've been we've been really actively deploying them in the streets. And we think it's important to have real world data, not just data from the simulated environments, because the level of fidelity still cannot match. So you know, this is why we really want to aggressively expand as quickly as possible to different environments and global markets, whether indoor or outdoor, because we think this is an advantage that we need to really cling on and build on.
Yeah, like you mentioned, it's all, let's say, going towards the same vision. I think the best that we have is that we've already done commercial services in urban streets over four or five years. Of course, there were regulations in South Korea that prevented us actively deploying them until late 2024 late 2023 sorry but, but since all those regulations have been abolished, we've been we've been really actively deploying them in the streets. And we think it's important to have real world data, not just data from the simulated environments, because the level of fidelity still cannot match. So you know, this is why we really want to aggressively expand as quickly as possible to different environments and global markets, whether indoor or outdoor, because we think this is an advantage that we need to really cling on and build on.
S Speaker 121:58That makes sense to and when you say you have collected a lot of urban, dense environment data, how do you collect data? How do you sort of structure it? What's, what's your, I would say secret sauce behind structuring the entire data and making sure it becomes a mode for you.
That makes sense to and when you say you have collected a lot of urban, dense environment data, how do you collect data? How do you sort of structure it? What's, what's your, I would say secret sauce behind structuring the entire data and making sure it becomes a mode for you.
That makes sense to and when you say you have collected a lot of urban, dense environment data, how do you collect data? How do you sort of structure it? What's, what's your, I would say secret sauce behind structuring the entire data and making sure it becomes a mode for you.
That makes sense to and when you say you have collected a lot of urban, dense environment data, how do you collect data? How do you sort of structure it? What's, what's your, I would say secret sauce behind structuring the entire data and making sure it becomes a mode for you.
S Speaker 222:19right now we, you know, in the early stages, we collected data, we labeled everything manually, and then took a lot of time and effort. We tried outsourcing that to data labeling companies, we realized that the quality wasn't up to what we wanted, so we did that. We started off with a high quality database. Now we use like auto labeling techniques. We use semi supervised learning. We're trying to get to unsupervised learning. So we want to, you know, try to make the the data collection process as high quality as possible, as automated as possible. So, so, yeah, so I think there still are a lot of companies out there that rely on supervised learning and and our difference is that, you know, over the years, we've been able to change that, that whole system to our semi supervised. Eventually it will be unsupervised. And we want to, we want to do this as soon as possible. So that's what I would like to comment on that question. And this can also provide, you know to the AMRs, once we, once we deploy these in commercial environment,
right now we, you know, in the early stages, we collected data, we labeled everything manually, and then took a lot of time and effort. We tried outsourcing that to data labeling companies, we realized that the quality wasn't up to what we wanted, so we did that. We started off with a high quality database. Now we use like auto labeling techniques. We use semi supervised learning. We're trying to get to unsupervised learning. So we want to, you know, try to make the the data collection process as high quality as possible, as automated as possible. So, so, yeah, so I think there still are a lot of companies out there that rely on supervised learning and and our difference is that, you know, over the years, we've been able to change that, that whole system to our semi supervised. Eventually it will be unsupervised. And we want to, we want to do this as soon as possible. So that's what I would like to comment on that question. And this can also provide, you know to the AMRs, once we, once we deploy these in commercial environment,
right now we, you know, in the early stages, we collected data, we labeled everything manually, and then took a lot of time and effort. We tried outsourcing that to data labeling companies, we realized that the quality wasn't up to what we wanted, so we did that. We started off with a high quality database. Now we use like auto labeling techniques. We use semi supervised learning. We're trying to get to unsupervised learning. So we want to, you know, try to make the the data collection process as high quality as possible, as automated as possible. So, so, yeah, so I think there still are a lot of companies out there that rely on supervised learning and and our difference is that, you know, over the years, we've been able to change that, that whole system to our semi supervised. Eventually it will be unsupervised. And we want to, we want to do this as soon as possible. So that's what I would like to comment on that question. And this can also provide, you know to the AMRs, once we, once we deploy these in commercial environment,
right now we, you know, in the early stages, we collected data, we labeled everything manually, and then took a lot of time and effort. We tried outsourcing that to data labeling companies, we realized that the quality wasn't up to what we wanted, so we did that. We started off with a high quality database. Now we use like auto labeling techniques. We use semi supervised learning. We're trying to get to unsupervised learning. So we want to, you know, try to make the the data collection process as high quality as possible, as automated as possible. So, so, yeah, so I think there still are a lot of companies out there that rely on supervised learning and and our difference is that, you know, over the years, we've been able to change that, that whole system to our semi supervised. Eventually it will be unsupervised. And we want to, we want to do this as soon as possible. So that's what I would like to comment on that question. And this can also provide, you know to the AMRs, once we, once we deploy these in commercial environment,
S Speaker 123:38right? That makes sense. And how, how is the company doing today, in terms of traction? What's your plan to sort of, where do you plan to reach by the end of 2025 and then is, do you plan to be fundraising anytime soon?
right? That makes sense. And how, how is the company doing today, in terms of traction? What's your plan to sort of, where do you plan to reach by the end of 2025 and then is, do you plan to be fundraising anytime soon?
right? That makes sense. And how, how is the company doing today, in terms of traction? What's your plan to sort of, where do you plan to reach by the end of 2025 and then is, do you plan to be fundraising anytime soon?
right? That makes sense. And how, how is the company doing today, in terms of traction? What's your plan to sort of, where do you plan to reach by the end of 2025 and then is, do you plan to be fundraising anytime soon?
S Speaker 223:57Yes, so, I mean, we are actually, we're doing our series B round,
Yes, so, I mean, we are actually, we're doing our series B round,
Yes, so, I mean, we are actually, we're doing our series B round,
Yes, so, I mean, we are actually, we're doing our series B round,
24:02and we have raised about
and we have raised about
and we have raised about
and we have raised about
S Speaker 224:06$5 million so far, but, but we want to raise at least twice as much for this round. Yeah, we're also actively seeking investors from overseas markets. For the first time, so all of our investors so far has been, have been from South Korea, but since GTC, we've had some interest from other investors, and we're also talking with them for their possible potential investments in us in terms of traction. Yeah. I mean, we want to reach about $6 million in revenue this year, which is going to be about five to 6x increase in revenue compared to last year. And we believe that this is something we can attain based on the contracts we have so far this year, we want to actively start deploying our robots in USA and Japan this year. So we already have commercial services in Saudi Arabia. We're part of the neon project. We're the only autonomous driving robot company that is in neon currently. So we want to expand the Saudi Arabian business, obviously, and also this in the Middle East, like Dubai and Qatar in those countries, but, but we also are starting to see some movement in the USA, because we have two large distributors there.
$5 million so far, but, but we want to raise at least twice as much for this round. Yeah, we're also actively seeking investors from overseas markets. For the first time, so all of our investors so far has been, have been from South Korea, but since GTC, we've had some interest from other investors, and we're also talking with them for their possible potential investments in us in terms of traction. Yeah. I mean, we want to reach about $6 million in revenue this year, which is going to be about five to 6x increase in revenue compared to last year. And we believe that this is something we can attain based on the contracts we have so far this year, we want to actively start deploying our robots in USA and Japan this year. So we already have commercial services in Saudi Arabia. We're part of the neon project. We're the only autonomous driving robot company that is in neon currently. So we want to expand the Saudi Arabian business, obviously, and also this in the Middle East, like Dubai and Qatar in those countries, but, but we also are starting to see some movement in the USA, because we have two large distributors there.
$5 million so far, but, but we want to raise at least twice as much for this round. Yeah, we're also actively seeking investors from overseas markets. For the first time, so all of our investors so far has been, have been from South Korea, but since GTC, we've had some interest from other investors, and we're also talking with them for their possible potential investments in us in terms of traction. Yeah. I mean, we want to reach about $6 million in revenue this year, which is going to be about five to 6x increase in revenue compared to last year. And we believe that this is something we can attain based on the contracts we have so far this year, we want to actively start deploying our robots in USA and Japan this year. So we already have commercial services in Saudi Arabia. We're part of the neon project. We're the only autonomous driving robot company that is in neon currently. So we want to expand the Saudi Arabian business, obviously, and also this in the Middle East, like Dubai and Qatar in those countries, but, but we also are starting to see some movement in the USA, because we have two large distributors there.
$5 million so far, but, but we want to raise at least twice as much for this round. Yeah, we're also actively seeking investors from overseas markets. For the first time, so all of our investors so far has been, have been from South Korea, but since GTC, we've had some interest from other investors, and we're also talking with them for their possible potential investments in us in terms of traction. Yeah. I mean, we want to reach about $6 million in revenue this year, which is going to be about five to 6x increase in revenue compared to last year. And we believe that this is something we can attain based on the contracts we have so far this year, we want to actively start deploying our robots in USA and Japan this year. So we already have commercial services in Saudi Arabia. We're part of the neon project. We're the only autonomous driving robot company that is in neon currently. So we want to expand the Saudi Arabian business, obviously, and also this in the Middle East, like Dubai and Qatar in those countries, but, but we also are starting to see some movement in the USA, because we have two large distributors there.
25:23They are actively seeking out
They are actively seeking out
They are actively seeking out
They are actively seeking out
S Speaker 225:27customers for us. So we have a company called Nexus AMR that has a partnership with blue star, which is a large B to B distributor, and they have a large sales force. So we're getting leads Through Blue Star, basically. And then we are working with a company called robot Lab, which is the largest robot distributor in the US. They have asked us for doing demos and golf courses and college campuses and so on, and we have just started doing those. So we believe that these can lead to concrete opportunities in the US market. And we want to enter the US market also as quickly as possible, because we know that that is where most of the robots are deployed today, and we think that's important for us.
customers for us. So we have a company called Nexus AMR that has a partnership with blue star, which is a large B to B distributor, and they have a large sales force. So we're getting leads Through Blue Star, basically. And then we are working with a company called robot Lab, which is the largest robot distributor in the US. They have asked us for doing demos and golf courses and college campuses and so on, and we have just started doing those. So we believe that these can lead to concrete opportunities in the US market. And we want to enter the US market also as quickly as possible, because we know that that is where most of the robots are deployed today, and we think that's important for us.
customers for us. So we have a company called Nexus AMR that has a partnership with blue star, which is a large B to B distributor, and they have a large sales force. So we're getting leads Through Blue Star, basically. And then we are working with a company called robot Lab, which is the largest robot distributor in the US. They have asked us for doing demos and golf courses and college campuses and so on, and we have just started doing those. So we believe that these can lead to concrete opportunities in the US market. And we want to enter the US market also as quickly as possible, because we know that that is where most of the robots are deployed today, and we think that's important for us.
customers for us. So we have a company called Nexus AMR that has a partnership with blue star, which is a large B to B distributor, and they have a large sales force. So we're getting leads Through Blue Star, basically. And then we are working with a company called robot Lab, which is the largest robot distributor in the US. They have asked us for doing demos and golf courses and college campuses and so on, and we have just started doing those. So we believe that these can lead to concrete opportunities in the US market. And we want to enter the US market also as quickly as possible, because we know that that is where most of the robots are deployed today, and we think that's important for us.
S Speaker 126:10That makes sense, though, and for the current round, you mentioned you probably are planning to raise somewhere around 10 million. What was the last round valuation, and do you think this round would be priced, or are you planning to do a safe convertible, anything like that?
That makes sense, though, and for the current round, you mentioned you probably are planning to raise somewhere around 10 million. What was the last round valuation, and do you think this round would be priced, or are you planning to do a safe convertible, anything like that?
That makes sense, though, and for the current round, you mentioned you probably are planning to raise somewhere around 10 million. What was the last round valuation, and do you think this round would be priced, or are you planning to do a safe convertible, anything like that?
That makes sense, though, and for the current round, you mentioned you probably are planning to raise somewhere around 10 million. What was the last round valuation, and do you think this round would be priced, or are you planning to do a safe convertible, anything like that?
26:27Yeah, yeah. So the valuation
Yeah, yeah. So the valuation
Yeah, yeah. So the valuation
Yeah, yeah. So the valuation
26:30for the last round was I'm
for the last round was I'm
for the last round was I'm
for the last round was I'm
26:35just trying to convert in in dollars,
just trying to convert in in dollars,
just trying to convert in in dollars,
just trying to convert in in dollars,
S Speaker 226:42about 70 million, $70 million yeah, this round is, is not that much more expensive. It's about 75 or $80 million because of the fact that South Korean market currently isn't at its strongest. And so a lot of the different companies have all lowered their valuations. We've, we've slightly increased it, and it's, yeah, the conditions are basically RCPS. That's like the basic
about 70 million, $70 million yeah, this round is, is not that much more expensive. It's about 75 or $80 million because of the fact that South Korean market currently isn't at its strongest. And so a lot of the different companies have all lowered their valuations. We've, we've slightly increased it, and it's, yeah, the conditions are basically RCPS. That's like the basic
about 70 million, $70 million yeah, this round is, is not that much more expensive. It's about 75 or $80 million because of the fact that South Korean market currently isn't at its strongest. And so a lot of the different companies have all lowered their valuations. We've, we've slightly increased it, and it's, yeah, the conditions are basically RCPS. That's like the basic
about 70 million, $70 million yeah, this round is, is not that much more expensive. It's about 75 or $80 million because of the fact that South Korean market currently isn't at its strongest. And so a lot of the different companies have all lowered their valuations. We've, we've slightly increased it, and it's, yeah, the conditions are basically RCPS. That's like the basic
27:13condition, got it, got it too.
condition, got it, got it too.
condition, got it, got it too.
condition, got it, got it too.
S Speaker 127:17That's very interesting. I would love to follow up here too. So the plan is still to be the the founding team, and the team would still be in Korea, but you still plan to expand it on the international markets. You wouldn't be moving the base anytime soon, right?
That's very interesting. I would love to follow up here too. So the plan is still to be the the founding team, and the team would still be in Korea, but you still plan to expand it on the international markets. You wouldn't be moving the base anytime soon, right?
That's very interesting. I would love to follow up here too. So the plan is still to be the the founding team, and the team would still be in Korea, but you still plan to expand it on the international markets. You wouldn't be moving the base anytime soon, right?
That's very interesting. I would love to follow up here too. So the plan is still to be the the founding team, and the team would still be in Korea, but you still plan to expand it on the international markets. You wouldn't be moving the base anytime soon, right?
S Speaker 227:33Right? I mean, yeah, well, that's because most of our operations are still in South Korea, so we have a lot of work that is ongoing here. We want to probably establish like a sales force, at least in the US and Japan, before we started hiring like software developers from those markets, but, but we think that we have good quality engineers in Korea who can hire at a lower cost than like the US. So that's where the base is going to be for for
Right? I mean, yeah, well, that's because most of our operations are still in South Korea, so we have a lot of work that is ongoing here. We want to probably establish like a sales force, at least in the US and Japan, before we started hiring like software developers from those markets, but, but we think that we have good quality engineers in Korea who can hire at a lower cost than like the US. So that's where the base is going to be for for
Right? I mean, yeah, well, that's because most of our operations are still in South Korea, so we have a lot of work that is ongoing here. We want to probably establish like a sales force, at least in the US and Japan, before we started hiring like software developers from those markets, but, but we think that we have good quality engineers in Korea who can hire at a lower cost than like the US. So that's where the base is going to be for for
Right? I mean, yeah, well, that's because most of our operations are still in South Korea, so we have a lot of work that is ongoing here. We want to probably establish like a sales force, at least in the US and Japan, before we started hiring like software developers from those markets, but, but we think that we have good quality engineers in Korea who can hire at a lower cost than like the US. So that's where the base is going to be for for
S Speaker 228:41to that fund as well. Oh, yeah, that'd be great. Thank you so much.
to that fund as well. Oh, yeah, that'd be great. Thank you so much.
to that fund as well. Oh, yeah, that'd be great. Thank you so much.
to that fund as well. Oh, yeah, that'd be great. Thank you so much.
S Speaker 128:45They are very strategic, so they do do a good, great job at that, for sure.
They are very strategic, so they do do a good, great job at that, for sure.
They are very strategic, so they do do a good, great job at that, for sure.
They are very strategic, so they do do a good, great job at that, for sure.
28:51Yeah, no. Really appreciate
Yeah, no. Really appreciate
Yeah, no. Really appreciate
Yeah, no. Really appreciate
S Speaker 128:53it, and thanks a lot for your time today. It was very interesting, a lot of insights. It's a space that I particularly am very excited about. So would definitely come back with some more questions, and would love your of course, feel free, please don't hesitate, absolutely. Thank you, though. Thanks a lot for your time
it, and thanks a lot for your time today. It was very interesting, a lot of insights. It's a space that I particularly am very excited about. So would definitely come back with some more questions, and would love your of course, feel free, please don't hesitate, absolutely. Thank you, though. Thanks a lot for your time
it, and thanks a lot for your time today. It was very interesting, a lot of insights. It's a space that I particularly am very excited about. So would definitely come back with some more questions, and would love your of course, feel free, please don't hesitate, absolutely. Thank you, though. Thanks a lot for your time
it, and thanks a lot for your time today. It was very interesting, a lot of insights. It's a space that I particularly am very excited about. So would definitely come back with some more questions, and would love your of course, feel free, please don't hesitate, absolutely. Thank you, though. Thanks a lot for your time
S Speaker 229:10today. Best luck. Thank you. Have a good one. You too. See you. Bye. Cheers. Thanks, bye bye.
today. Best luck. Thank you. Have a good one. You too. See you. Bye. Cheers. Thanks, bye bye.
today. Best luck. Thank you. Have a good one. You too. See you. Bye. Cheers. Thanks, bye bye.
today. Best luck. Thank you. Have a good one. You too. See you. Bye. Cheers. Thanks, bye bye.