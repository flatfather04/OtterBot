Meeting: Note
Tue, Dec 10, 2024
8:34 AM
49 min
Priyesh P
Introduction and Background of Participants
0:01
Cha
URL: https://otter.ai/u/JFB6iFEg9hCkcX06wM3fXhqDPuI
Downloaded: 2025-12-22T13:33:58.357452
Method: text_extraction
============================================================

Speaker 1
Nice to see you all. Appreciate you bustling to get time for this round. I'll introduce myself as part of the presentation, but look, why don't you go ahead and introduce
Nice to see you all. Appreciate you bustling to get time for this round. I'll introduce myself as part of the presentation, but look, why don't you go ahead and introduce
Nice to see you all. Appreciate you bustling to get time for this round. I'll introduce myself as part of the presentation, but look, why don't you go ahead and introduce
Nice to see you all. Appreciate you bustling to get time for this round. I'll introduce myself as part of the presentation, but look, why don't you go ahead and introduce
yourself. Hi everybody. I'm Loic Juilliard,
yourself. Hi everybody. I'm Loic Juilliard,
yourself. Hi everybody. I'm Loic Juilliard,
yourself. Hi everybody. I'm Loic Juilliard,
Speaker 2
I'm a CTO Pacific. You've been with the company for almost two years now. The third year, financial technology, the entire stack for the company. I started marker my career not very far. If you're in San Juan, not very far from your Qualcomm office there. I started in Surat la as well for a company at the team at the time named sur net. It was part of at&t labs. We were particular data center staff across from that little gardens over there. So, so I started an ATT LA to stay there for for five to six years, and moved on to speed collector for for me, you call it light micro, which Interesting enough, I think so, some of the work with Tara. I worked with him as well at light micro, MCC and RPC, and then ARM processors, and did a sort of solutions with that. Then, when I was at T I worked for a gentleman by the name of Steve Fisher, became the CEO of Salesforce. He wanted me to join Salesforce, which I did. I stayed there for seven years and done. My company grew really very fast, and some of that service delivery. And when I left, I was the head of healthcare for the health and Salesforce. The Salesforce to go to Unity Technologies. I was responsible for all the online services games. For those of you who play games, or kids that play games, probably played Bucha and go, which was implemented on unity. Unity has 1.3 billion devices in the world running their game. So we were receiving events and providing services for all these devices, that includes the as business, that includes a multiplayer and all the event and profiling of players through event management. So I stayed there for over two years. Then I went to Sama, which was a different thing. It was nonprofit that turned for profit. We were doing computer vision and specifically annotation for very large corporations, Google, Tesla, Waymo, we're all customers of sama. There was a mission behind this. It was to educate folks inside of Africa in AI adaptation, we're giving him the skill sets. We were first reviewers and eventually found their own company there. And last but not least, I moved up Salah and joined safely you working with George here. I was personally my family, and I saw some resonated with me. I kind of
I'm a CTO Pacific. You've been with the company for almost two years now. The third year, financial technology, the entire stack for the company. I started marker my career not very far. If you're in San Juan, not very far from your Qualcomm office there. I started in Surat la as well for a company at the team at the time named sur net. It was part of at&t labs. We were particular data center staff across from that little gardens over there. So, so I started an ATT LA to stay there for for five to six years, and moved on to speed collector for for me, you call it light micro, which Interesting enough, I think so, some of the work with Tara. I worked with him as well at light micro, MCC and RPC, and then ARM processors, and did a sort of solutions with that. Then, when I was at T I worked for a gentleman by the name of Steve Fisher, became the CEO of Salesforce. He wanted me to join Salesforce, which I did. I stayed there for seven years and done. My company grew really very fast, and some of that service delivery. And when I left, I was the head of healthcare for the health and Salesforce. The Salesforce to go to Unity Technologies. I was responsible for all the online services games. For those of you who play games, or kids that play games, probably played Bucha and go, which was implemented on unity. Unity has 1.3 billion devices in the world running their game. So we were receiving events and providing services for all these devices, that includes the as business, that includes a multiplayer and all the event and profiling of players through event management. So I stayed there for over two years. Then I went to Sama, which was a different thing. It was nonprofit that turned for profit. We were doing computer vision and specifically annotation for very large corporations, Google, Tesla, Waymo, we're all customers of sama. There was a mission behind this. It was to educate folks inside of Africa in AI adaptation, we're giving him the skill sets. We were first reviewers and eventually found their own company there. And last but not least, I moved up Salah and joined safely you working with George here. I was personally my family, and I saw some resonated with me. I kind of
I'm a CTO Pacific. You've been with the company for almost two years now. The third year, financial technology, the entire stack for the company. I started marker my career not very far. If you're in San Juan, not very far from your Qualcomm office there. I started in Surat la as well for a company at the team at the time named sur net. It was part of at&t labs. We were particular data center staff across from that little gardens over there. So, so I started an ATT LA to stay there for for five to six years, and moved on to speed collector for for me, you call it light micro, which Interesting enough, I think so, some of the work with Tara. I worked with him as well at light micro, MCC and RPC, and then ARM processors, and did a sort of solutions with that. Then, when I was at T I worked for a gentleman by the name of Steve Fisher, became the CEO of Salesforce. He wanted me to join Salesforce, which I did. I stayed there for seven years and done. My company grew really very fast, and some of that service delivery. And when I left, I was the head of healthcare for the health and Salesforce. The Salesforce to go to Unity Technologies. I was responsible for all the online services games. For those of you who play games, or kids that play games, probably played Bucha and go, which was implemented on unity. Unity has 1.3 billion devices in the world running their game. So we were receiving events and providing services for all these devices, that includes the as business, that includes a multiplayer and all the event and profiling of players through event management. So I stayed there for over two years. Then I went to Sama, which was a different thing. It was nonprofit that turned for profit. We were doing computer vision and specifically annotation for very large corporations, Google, Tesla, Waymo, we're all customers of sama. There was a mission behind this. It was to educate folks inside of Africa in AI adaptation, we're giving him the skill sets. We were first reviewers and eventually found their own company there. And last but not least, I moved up Salah and joined safely you working with George here. I was personally my family, and I saw some resonated with me. I kind of
I'm a CTO Pacific. You've been with the company for almost two years now. The third year, financial technology, the entire stack for the company. I started marker my career not very far. If you're in San Juan, not very far from your Qualcomm office there. I started in Surat la as well for a company at the team at the time named sur net. It was part of at&t labs. We were particular data center staff across from that little gardens over there. So, so I started an ATT LA to stay there for for five to six years, and moved on to speed collector for for me, you call it light micro, which Interesting enough, I think so, some of the work with Tara. I worked with him as well at light micro, MCC and RPC, and then ARM processors, and did a sort of solutions with that. Then, when I was at T I worked for a gentleman by the name of Steve Fisher, became the CEO of Salesforce. He wanted me to join Salesforce, which I did. I stayed there for seven years and done. My company grew really very fast, and some of that service delivery. And when I left, I was the head of healthcare for the health and Salesforce. The Salesforce to go to Unity Technologies. I was responsible for all the online services games. For those of you who play games, or kids that play games, probably played Bucha and go, which was implemented on unity. Unity has 1.3 billion devices in the world running their game. So we were receiving events and providing services for all these devices, that includes the as business, that includes a multiplayer and all the event and profiling of players through event management. So I stayed there for over two years. Then I went to Sama, which was a different thing. It was nonprofit that turned for profit. We were doing computer vision and specifically annotation for very large corporations, Google, Tesla, Waymo, we're all customers of sama. There was a mission behind this. It was to educate folks inside of Africa in AI adaptation, we're giving him the skill sets. We were first reviewers and eventually found their own company there. And last but not least, I moved up Salah and joined safely you working with George here. I was personally my family, and I saw some resonated with me. I kind of
optimistic where we are technology. Do
optimistic where we are technology. Do
optimistic where we are technology. Do
optimistic where we are technology. Do
Speaker 3
you have a hard stop at 830? Move? Really started
you have a hard stop at 830? Move? Really started
you have a hard stop at 830? Move? Really started
you have a hard stop at 830? Move? Really started
Speaker 1
safety charge. Quick question,
safety charge. Quick question,
safety charge. Quick question,
safety charge. Quick question,
Speaker 4
time the video is when you get to fall right? Is it a video that you save, or is it two minutes? I mean, how long is the video running? Buffer of 10 minutes. And
time the video is when you get to fall right? Is it a video that you save, or is it two minutes? I mean, how long is the video running? Buffer of 10 minutes. And
time the video is when you get to fall right? Is it a video that you save, or is it two minutes? I mean, how long is the video running? Buffer of 10 minutes. And
time the video is when you get to fall right? Is it a video that you save, or is it two minutes? I mean, how long is the video running? Buffer of 10 minutes. And
Speaker 1
then basically what will happen is they'll get, as soon as an on ground event is affected, they're gonna get the 10 minutes of prior video, and then they're also gonna get all the time somebody around and 10 minutes post. So how we're total usually, how did you get to sell the factories? So many
then basically what will happen is they'll get, as soon as an on ground event is affected, they're gonna get the 10 minutes of prior video, and then they're also gonna get all the time somebody around and 10 minutes post. So how we're total usually, how did you get to sell the factories? So many
then basically what will happen is they'll get, as soon as an on ground event is affected, they're gonna get the 10 minutes of prior video, and then they're also gonna get all the time somebody around and 10 minutes post. So how we're total usually, how did you get to sell the factories? So many
then basically what will happen is they'll get, as soon as an on ground event is affected, they're gonna get the 10 minutes of prior video, and then they're also gonna get all the time somebody around and 10 minutes post. So how we're total usually, how did you get to sell the factories? So many
things, mostly, this is a long process of
things, mostly, this is a long process of
things, mostly, this is a long process of
things, mostly, this is a long process of
Speaker 1
a long period where we've obviously collected a ton of data at this point, so we believe we have a wider support healthcare data set. We're approaching 100 terabytes of video data. But we also develop a process where we use the human and loop to basically tune our algorithms to really, really high sensitivity, and then we screen muscle armed out through the human loop our customers. We got a science fiction level product that's on us to get our accuracy to a point where our cogs makes sense. And so a long journey with this company was really just iterating and hammering and doing more and more things to train models of more data, one time, overfit to each individual community before the support of general model things like that.
a long period where we've obviously collected a ton of data at this point, so we believe we have a wider support healthcare data set. We're approaching 100 terabytes of video data. But we also develop a process where we use the human and loop to basically tune our algorithms to really, really high sensitivity, and then we screen muscle armed out through the human loop our customers. We got a science fiction level product that's on us to get our accuracy to a point where our cogs makes sense. And so a long journey with this company was really just iterating and hammering and doing more and more things to train models of more data, one time, overfit to each individual community before the support of general model things like that.
a long period where we've obviously collected a ton of data at this point, so we believe we have a wider support healthcare data set. We're approaching 100 terabytes of video data. But we also develop a process where we use the human and loop to basically tune our algorithms to really, really high sensitivity, and then we screen muscle armed out through the human loop our customers. We got a science fiction level product that's on us to get our accuracy to a point where our cogs makes sense. And so a long journey with this company was really just iterating and hammering and doing more and more things to train models of more data, one time, overfit to each individual community before the support of general model things like that.
a long period where we've obviously collected a ton of data at this point, so we believe we have a wider support healthcare data set. We're approaching 100 terabytes of video data. But we also develop a process where we use the human and loop to basically tune our algorithms to really, really high sensitivity, and then we screen muscle armed out through the human loop our customers. We got a science fiction level product that's on us to get our accuracy to a point where our cogs makes sense. And so a long journey with this company was really just iterating and hammering and doing more and more things to train models of more data, one time, overfit to each individual community before the support of general model things like that.
Speaker 4
So now we're at 80% margin, including the loop for the false alarms. To read out the false alarms. George,
So now we're at 80% margin, including the loop for the false alarms. To read out the false alarms. George,
So now we're at 80% margin, including the loop for the false alarms. To read out the false alarms. George,
So now we're at 80% margin, including the loop for the false alarms. To read out the false alarms. George,
Speaker 5
for this clear video review? Is it done by the nurse or done by the AI? Yeah, so today
for this clear video review? Is it done by the nurse or done by the AI? Yeah, so today
for this clear video review? Is it done by the nurse or done by the AI? Yeah, so today
for this clear video review? Is it done by the nurse or done by the AI? Yeah, so today
Speaker 1
it's done by the nurse. We are collecting all of the data that is being inputted to our system. Is label training data. And one of the things that we will build is the first ever AI occupational therapist. So you can imagine what will happen is, but after that program today is a clinician will look at the video and say, Aha, here's the things that we should change. We can see, you know, basically what happens without us is this person is just found, you know, see, if I have the moment where, so the staff member comes in and stands right here, and she's just found here by the doorway. And so what they have to try to address it. So what they'll do is say, like, Well, we found her in socks. Maybe, let's try non slip socks. But they don't really know. And so now for the first time, they can actually know and they could address it. And all of that data to our system. So you can imagine a world where we're automatically generating, incorporating all that into our system and saying, This is exactly what you should change. And then we can hit a truly global scale and support folks in developing countries things like that
it's done by the nurse. We are collecting all of the data that is being inputted to our system. Is label training data. And one of the things that we will build is the first ever AI occupational therapist. So you can imagine what will happen is, but after that program today is a clinician will look at the video and say, Aha, here's the things that we should change. We can see, you know, basically what happens without us is this person is just found, you know, see, if I have the moment where, so the staff member comes in and stands right here, and she's just found here by the doorway. And so what they have to try to address it. So what they'll do is say, like, Well, we found her in socks. Maybe, let's try non slip socks. But they don't really know. And so now for the first time, they can actually know and they could address it. And all of that data to our system. So you can imagine a world where we're automatically generating, incorporating all that into our system and saying, This is exactly what you should change. And then we can hit a truly global scale and support folks in developing countries things like that
it's done by the nurse. We are collecting all of the data that is being inputted to our system. Is label training data. And one of the things that we will build is the first ever AI occupational therapist. So you can imagine what will happen is, but after that program today is a clinician will look at the video and say, Aha, here's the things that we should change. We can see, you know, basically what happens without us is this person is just found, you know, see, if I have the moment where, so the staff member comes in and stands right here, and she's just found here by the doorway. And so what they have to try to address it. So what they'll do is say, like, Well, we found her in socks. Maybe, let's try non slip socks. But they don't really know. And so now for the first time, they can actually know and they could address it. And all of that data to our system. So you can imagine a world where we're automatically generating, incorporating all that into our system and saying, This is exactly what you should change. And then we can hit a truly global scale and support folks in developing countries things like that
it's done by the nurse. We are collecting all of the data that is being inputted to our system. Is label training data. And one of the things that we will build is the first ever AI occupational therapist. So you can imagine what will happen is, but after that program today is a clinician will look at the video and say, Aha, here's the things that we should change. We can see, you know, basically what happens without us is this person is just found, you know, see, if I have the moment where, so the staff member comes in and stands right here, and she's just found here by the doorway. And so what they have to try to address it. So what they'll do is say, like, Well, we found her in socks. Maybe, let's try non slip socks. But they don't really know. And so now for the first time, they can actually know and they could address it. And all of that data to our system. So you can imagine a world where we're automatically generating, incorporating all that into our system and saying, This is exactly what you should change. And then we can hit a truly global scale and support folks in developing countries things like that
with the first ever AI. So is this clear
with the first ever AI. So is this clear
with the first ever AI. So is this clear
with the first ever AI. So is this clear
Speaker 5
video review also part of the post? Of all like protocol? Because I kind of learned that from another startup that's after the fall, there's a protocol that's the nurse no need to immediately check the senior people in order to avoid any potential legal issue. So is this already a part of the workflow right now? It
video review also part of the post? Of all like protocol? Because I kind of learned that from another startup that's after the fall, there's a protocol that's the nurse no need to immediately check the senior people in order to avoid any potential legal issue. So is this already a part of the workflow right now? It
video review also part of the post? Of all like protocol? Because I kind of learned that from another startup that's after the fall, there's a protocol that's the nurse no need to immediately check the senior people in order to avoid any potential legal issue. So is this already a part of the workflow right now? It
video review also part of the post? Of all like protocol? Because I kind of learned that from another startup that's after the fall, there's a protocol that's the nurse no need to immediately check the senior people in order to avoid any potential legal issue. So is this already a part of the workflow right now? It
Speaker 1
is. Yeah. So what they're supposed to do is, after every fall they're supposed to identify something, but basically today they're throwing drugs in the dark. So they would say things like, let's try changing our socks. And what you can see here is actually the stocks are going to the ground. So the intervention in this case was, it's about 830 in the morning, and she's getting out to go to the restaurant on her own, and so they instead, basically will court first, and they rounded on her before they support everybody else. They go to the bathroom proactively. But we see all sorts of things where it's like, oh, this person's getting dizzy when they're getting from a bunch of medications. And make sure we can have a right trade off for them, because maybe that medication is actually putting them at more risk. That's where. Or we'll see things that are like not medical panel. One that really stuck with me is this lady had two baby dolls. She, like, legitimately believes these in her infants, and she's caring for them, you know, session, she's in a twin size bed, like this one, and she couldn't, like, all three of them, couldn't fit in the bed comfortably, and so she was basically sliding out of bed. There wasn't enough space. And so the intervention wasn't anything medical. Was to get her a crib next to the bed so she could see that her babies were safe. It's all about how we understand somebody's on that need. All this innovation for childcare that just hasn't happened for owner care. There's like a million AI smart gaming cameras, but if you think about a similar set of needs on the other side of life, we have like, the same kinds of needs where we really like to go with support folks. And then with this data set, we can basically go earlier and earlier product roadmap is we support with the folks most in need. And then we collect this data set, we just add and just add more and more value, or just support a broader runner. George
is. Yeah. So what they're supposed to do is, after every fall they're supposed to identify something, but basically today they're throwing drugs in the dark. So they would say things like, let's try changing our socks. And what you can see here is actually the stocks are going to the ground. So the intervention in this case was, it's about 830 in the morning, and she's getting out to go to the restaurant on her own, and so they instead, basically will court first, and they rounded on her before they support everybody else. They go to the bathroom proactively. But we see all sorts of things where it's like, oh, this person's getting dizzy when they're getting from a bunch of medications. And make sure we can have a right trade off for them, because maybe that medication is actually putting them at more risk. That's where. Or we'll see things that are like not medical panel. One that really stuck with me is this lady had two baby dolls. She, like, legitimately believes these in her infants, and she's caring for them, you know, session, she's in a twin size bed, like this one, and she couldn't, like, all three of them, couldn't fit in the bed comfortably, and so she was basically sliding out of bed. There wasn't enough space. And so the intervention wasn't anything medical. Was to get her a crib next to the bed so she could see that her babies were safe. It's all about how we understand somebody's on that need. All this innovation for childcare that just hasn't happened for owner care. There's like a million AI smart gaming cameras, but if you think about a similar set of needs on the other side of life, we have like, the same kinds of needs where we really like to go with support folks. And then with this data set, we can basically go earlier and earlier product roadmap is we support with the folks most in need. And then we collect this data set, we just add and just add more and more value, or just support a broader runner. George
is. Yeah. So what they're supposed to do is, after every fall they're supposed to identify something, but basically today they're throwing drugs in the dark. So they would say things like, let's try changing our socks. And what you can see here is actually the stocks are going to the ground. So the intervention in this case was, it's about 830 in the morning, and she's getting out to go to the restaurant on her own, and so they instead, basically will court first, and they rounded on her before they support everybody else. They go to the bathroom proactively. But we see all sorts of things where it's like, oh, this person's getting dizzy when they're getting from a bunch of medications. And make sure we can have a right trade off for them, because maybe that medication is actually putting them at more risk. That's where. Or we'll see things that are like not medical panel. One that really stuck with me is this lady had two baby dolls. She, like, legitimately believes these in her infants, and she's caring for them, you know, session, she's in a twin size bed, like this one, and she couldn't, like, all three of them, couldn't fit in the bed comfortably, and so she was basically sliding out of bed. There wasn't enough space. And so the intervention wasn't anything medical. Was to get her a crib next to the bed so she could see that her babies were safe. It's all about how we understand somebody's on that need. All this innovation for childcare that just hasn't happened for owner care. There's like a million AI smart gaming cameras, but if you think about a similar set of needs on the other side of life, we have like, the same kinds of needs where we really like to go with support folks. And then with this data set, we can basically go earlier and earlier product roadmap is we support with the folks most in need. And then we collect this data set, we just add and just add more and more value, or just support a broader runner. George
is. Yeah. So what they're supposed to do is, after every fall they're supposed to identify something, but basically today they're throwing drugs in the dark. So they would say things like, let's try changing our socks. And what you can see here is actually the stocks are going to the ground. So the intervention in this case was, it's about 830 in the morning, and she's getting out to go to the restaurant on her own, and so they instead, basically will court first, and they rounded on her before they support everybody else. They go to the bathroom proactively. But we see all sorts of things where it's like, oh, this person's getting dizzy when they're getting from a bunch of medications. And make sure we can have a right trade off for them, because maybe that medication is actually putting them at more risk. That's where. Or we'll see things that are like not medical panel. One that really stuck with me is this lady had two baby dolls. She, like, legitimately believes these in her infants, and she's caring for them, you know, session, she's in a twin size bed, like this one, and she couldn't, like, all three of them, couldn't fit in the bed comfortably, and so she was basically sliding out of bed. There wasn't enough space. And so the intervention wasn't anything medical. Was to get her a crib next to the bed so she could see that her babies were safe. It's all about how we understand somebody's on that need. All this innovation for childcare that just hasn't happened for owner care. There's like a million AI smart gaming cameras, but if you think about a similar set of needs on the other side of life, we have like, the same kinds of needs where we really like to go with support folks. And then with this data set, we can basically go earlier and earlier product roadmap is we support with the folks most in need. And then we collect this data set, we just add and just add more and more value, or just support a broader runner. George
Clark, do you go up on getting such a large data set
Clark, do you go up on getting such a large data set
Clark, do you go up on getting such a large data set
Clark, do you go up on getting such a large data set
Speaker 1
slowly and thankfully, you have to be really committed to start this company, because it took us a year to get our first 22 falls, and then it was just like by getting more and less more traction, bootstrap more data and grow the data set further and further and get to a point where now the flywheel is just spending more just spending more by delivering customer value, we're getting more and more data and able to release more and more products. How
slowly and thankfully, you have to be really committed to start this company, because it took us a year to get our first 22 falls, and then it was just like by getting more and less more traction, bootstrap more data and grow the data set further and further and get to a point where now the flywheel is just spending more just spending more by delivering customer value, we're getting more and more data and able to release more and more products. How
slowly and thankfully, you have to be really committed to start this company, because it took us a year to get our first 22 falls, and then it was just like by getting more and less more traction, bootstrap more data and grow the data set further and further and get to a point where now the flywheel is just spending more just spending more by delivering customer value, we're getting more and more data and able to release more and more products. How
slowly and thankfully, you have to be really committed to start this company, because it took us a year to get our first 22 falls, and then it was just like by getting more and less more traction, bootstrap more data and grow the data set further and further and get to a point where now the flywheel is just spending more just spending more by delivering customer value, we're getting more and more data and able to release more and more products. How
many unique endpoints? How many unique endpoints? Is that we've
many unique endpoints? How many unique endpoints? Is that we've
many unique endpoints? How many unique endpoints? Is that we've
many unique endpoints? How many unique endpoints? Is that we've
Speaker 1
supported about 20,000 residents today. We have about 10,000 cameras, and it's
supported about 20,000 residents today. We have about 10,000 cameras, and it's
supported about 20,000 residents today. We have about 10,000 cameras, and it's
supported about 20,000 residents today. We have about 10,000 cameras, and it's
going to explore more period of time, approximately. My
going to explore more period of time, approximately. My
going to explore more period of time, approximately. My
going to explore more period of time, approximately. My
Speaker 1
Speaker 6
product in 2019 and so you've been working with various organizations where you have segmented specific types of environments where you're not that you'll be able to capture the data that you're looking for, and you do that through your relationships and partnerships with various medical industries, I guess, has not focused there are customers, right? We're delivering
product in 2019 and so you've been working with various organizations where you have segmented specific types of environments where you're not that you'll be able to capture the data that you're looking for, and you do that through your relationships and partnerships with various medical industries, I guess, has not focused there are customers, right? We're delivering
product in 2019 and so you've been working with various organizations where you have segmented specific types of environments where you're not that you'll be able to capture the data that you're looking for, and you do that through your relationships and partnerships with various medical industries, I guess, has not focused there are customers, right? We're delivering
product in 2019 and so you've been working with various organizations where you have segmented specific types of environments where you're not that you'll be able to capture the data that you're looking for, and you do that through your relationships and partnerships with various medical industries, I guess, has not focused there are customers, right? We're delivering
Speaker 1
the product and getting paid to deliver the product and service for them, and then by delivering the product and getting paid by customers, we can access the data set. Thank you. This
the product and getting paid to deliver the product and service for them, and then by delivering the product and getting paid by customers, we can access the data set. Thank you. This
the product and getting paid to deliver the product and service for them, and then by delivering the product and getting paid by customers, we can access the data set. Thank you. This
the product and getting paid to deliver the product and service for them, and then by delivering the product and getting paid by customers, we can access the data set. Thank you. This
Speaker 7
is mostly deployed in nursing, health care facilities, right? George, I mean, you mentioned how many communities, like 500 community each community has roughly how many there's about 100 beds where the data collected five years
is mostly deployed in nursing, health care facilities, right? George, I mean, you mentioned how many communities, like 500 community each community has roughly how many there's about 100 beds where the data collected five years
is mostly deployed in nursing, health care facilities, right? George, I mean, you mentioned how many communities, like 500 community each community has roughly how many there's about 100 beds where the data collected five years
is mostly deployed in nursing, health care facilities, right? George, I mean, you mentioned how many communities, like 500 community each community has roughly how many there's about 100 beds where the data collected five years
Speaker 6
or so, usually one camera or location, so you don't have to deal with stitching of video feeds, and you essentially have a final location in the room that provides you with the complete footprint of the room itself. That's right.
or so, usually one camera or location, so you don't have to deal with stitching of video feeds, and you essentially have a final location in the room that provides you with the complete footprint of the room itself. That's right.
or so, usually one camera or location, so you don't have to deal with stitching of video feeds, and you essentially have a final location in the room that provides you with the complete footprint of the room itself. That's right.
or so, usually one camera or location, so you don't have to deal with stitching of video feeds, and you essentially have a final location in the room that provides you with the complete footprint of the room itself. That's right.
Speaker 3
Thank you. Now, I think maybe a good point to actually also talk about the transition that you made to snap dragon chips and why and how that happened. Yeah, definitely. So in perspective of the data
Thank you. Now, I think maybe a good point to actually also talk about the transition that you made to snap dragon chips and why and how that happened. Yeah, definitely. So in perspective of the data
Thank you. Now, I think maybe a good point to actually also talk about the transition that you made to snap dragon chips and why and how that happened. Yeah, definitely. So in perspective of the data
Thank you. Now, I think maybe a good point to actually also talk about the transition that you made to snap dragon chips and why and how that happened. Yeah, definitely. So in perspective of the data
Speaker 2
set, if we stitch the videos together, we have 16 years of videos
set, if we stitch the videos together, we have 16 years of videos
set, if we stitch the videos together, we have 16 years of videos
set, if we stitch the videos together, we have 16 years of videos
Speaker 1
So loics, I can always come back and talk more about customer interaction,
So loics, I can always come back and talk more about customer interaction,
So loics, I can always come back and talk more about customer interaction,
So loics, I can always come back and talk more about customer interaction,
Speaker 2
sure, so I'll talk about the technology there. So Titan is our platform. This is the overarching platform that manages our services from the premises all the way to cloud in the location, back to the facilities. And here, for the purpose of this presentation, we split in three layers. One layer is a sense services as well. We use the quantum technology and web cloud services to route and log and report. There's a tremendous amount of reporting services available. And the last part of the AI is, these are the models that we train that run on premises equipment to deliver the service that we have. So, yeah. So this is, this is our guardian Pro. This is our camera. We did not I'm gonna brag about this one more time, because we deliver this camera in eight months. This is from the time we actually the ideation all the way to the first system, first camera delivered with code running incredibly fast. We were at GA in about 18 months total, today, we have 1000 studies deployed. So it's gone extremely well. It's camera that has been built for the environment is running in, yes, visible to human servants. And it's really energy. We call it an AI processing build. These are the best optical capabilities, because this is giving us incredible amount of processing power that we can run many, many models. Can run many, many models. It's also really diverse in terms of connectivity, super squi, power Ethernet, and also LT, 5g modem on
sure, so I'll talk about the technology there. So Titan is our platform. This is the overarching platform that manages our services from the premises all the way to cloud in the location, back to the facilities. And here, for the purpose of this presentation, we split in three layers. One layer is a sense services as well. We use the quantum technology and web cloud services to route and log and report. There's a tremendous amount of reporting services available. And the last part of the AI is, these are the models that we train that run on premises equipment to deliver the service that we have. So, yeah. So this is, this is our guardian Pro. This is our camera. We did not I'm gonna brag about this one more time, because we deliver this camera in eight months. This is from the time we actually the ideation all the way to the first system, first camera delivered with code running incredibly fast. We were at GA in about 18 months total, today, we have 1000 studies deployed. So it's gone extremely well. It's camera that has been built for the environment is running in, yes, visible to human servants. And it's really energy. We call it an AI processing build. These are the best optical capabilities, because this is giving us incredible amount of processing power that we can run many, many models. Can run many, many models. It's also really diverse in terms of connectivity, super squi, power Ethernet, and also LT, 5g modem on
sure, so I'll talk about the technology there. So Titan is our platform. This is the overarching platform that manages our services from the premises all the way to cloud in the location, back to the facilities. And here, for the purpose of this presentation, we split in three layers. One layer is a sense services as well. We use the quantum technology and web cloud services to route and log and report. There's a tremendous amount of reporting services available. And the last part of the AI is, these are the models that we train that run on premises equipment to deliver the service that we have. So, yeah. So this is, this is our guardian Pro. This is our camera. We did not I'm gonna brag about this one more time, because we deliver this camera in eight months. This is from the time we actually the ideation all the way to the first system, first camera delivered with code running incredibly fast. We were at GA in about 18 months total, today, we have 1000 studies deployed. So it's gone extremely well. It's camera that has been built for the environment is running in, yes, visible to human servants. And it's really energy. We call it an AI processing build. These are the best optical capabilities, because this is giving us incredible amount of processing power that we can run many, many models. Can run many, many models. It's also really diverse in terms of connectivity, super squi, power Ethernet, and also LT, 5g modem on
sure, so I'll talk about the technology there. So Titan is our platform. This is the overarching platform that manages our services from the premises all the way to cloud in the location, back to the facilities. And here, for the purpose of this presentation, we split in three layers. One layer is a sense services as well. We use the quantum technology and web cloud services to route and log and report. There's a tremendous amount of reporting services available. And the last part of the AI is, these are the models that we train that run on premises equipment to deliver the service that we have. So, yeah. So this is, this is our guardian Pro. This is our camera. We did not I'm gonna brag about this one more time, because we deliver this camera in eight months. This is from the time we actually the ideation all the way to the first system, first camera delivered with code running incredibly fast. We were at GA in about 18 months total, today, we have 1000 studies deployed. So it's gone extremely well. It's camera that has been built for the environment is running in, yes, visible to human servants. And it's really energy. We call it an AI processing build. These are the best optical capabilities, because this is giving us incredible amount of processing power that we can run many, many models. Can run many, many models. It's also really diverse in terms of connectivity, super squi, power Ethernet, and also LT, 5g modem on
there. So we have many
there. So we have many
there. So we have many
there. So we have many
ways of multiple models, maybe
ways of multiple models, maybe
ways of multiple models, maybe
ways of multiple models, maybe
Speaker 6
something that triggers an event, and then vision first, yeah, it's mostly
something that triggers an event, and then vision first, yeah, it's mostly
something that triggers an event, and then vision first, yeah, it's mostly
something that triggers an event, and then vision first, yeah, it's mostly
escalator. At this point, we are monitoring the
escalator. At this point, we are monitoring the
escalator. At this point, we are monitoring the
escalator. At this point, we are monitoring the
Speaker 2
video feed, and we trigger it based on an AI detection and a series of event reading, the event workflow execution that follows after that, the event happening is in the cloud. The camera is really all about detection. It's a sensor. It's just process of video content from together. Video content.
video feed, and we trigger it based on an AI detection and a series of event reading, the event workflow execution that follows after that, the event happening is in the cloud. The camera is really all about detection. It's a sensor. It's just process of video content from together. Video content.
video feed, and we trigger it based on an AI detection and a series of event reading, the event workflow execution that follows after that, the event happening is in the cloud. The camera is really all about detection. It's a sensor. It's just process of video content from together. Video content.
video feed, and we trigger it based on an AI detection and a series of event reading, the event workflow execution that follows after that, the event happening is in the cloud. The camera is really all about detection. It's a sensor. It's just process of video content from together. Video content.
Speaker 6
So there is some kind of motion detection, and I guess you have some
So there is some kind of motion detection, and I guess you have some
So there is some kind of motion detection, and I guess you have some
So there is some kind of motion detection, and I guess you have some
assessment of the frame or not.
assessment of the frame or not.
assessment of the frame or not.
assessment of the frame or not.
Speaker 2
Yeah, we have some filtering in. There is really an AI model learning that takes care of all this sort of motion all the time, logic stuff based on the detection, these decisions on whether to do with that comment,
Yeah, we have some filtering in. There is really an AI model learning that takes care of all this sort of motion all the time, logic stuff based on the detection, these decisions on whether to do with that comment,
Yeah, we have some filtering in. There is really an AI model learning that takes care of all this sort of motion all the time, logic stuff based on the detection, these decisions on whether to do with that comment,
Yeah, we have some filtering in. There is really an AI model learning that takes care of all this sort of motion all the time, logic stuff based on the detection, these decisions on whether to do with that comment,
and then the buffer.
Speaker 2
Yeah, so the camera has enough, has readily intelligent. It keeps a buffers before and after. So it has basically a trailing, trailing say to videos when, when you send one minute video for detection by the detection, by the detection of everybody smart and confirm that the fall, we are fetching the video out to the camera. So the pre buffer and the post buffer is fetched at a camera. And basically we have a window. We know video and everything is persisted on a
Yeah, so the camera has enough, has readily intelligent. It keeps a buffers before and after. So it has basically a trailing, trailing say to videos when, when you send one minute video for detection by the detection, by the detection of everybody smart and confirm that the fall, we are fetching the video out to the camera. So the pre buffer and the post buffer is fetched at a camera. And basically we have a window. We know video and everything is persisted on a
Yeah, so the camera has enough, has readily intelligent. It keeps a buffers before and after. So it has basically a trailing, trailing say to videos when, when you send one minute video for detection by the detection, by the detection of everybody smart and confirm that the fall, we are fetching the video out to the camera. So the pre buffer and the post buffer is fetched at a camera. And basically we have a window. We know video and everything is persisted on a
Yeah, so the camera has enough, has readily intelligent. It keeps a buffers before and after. So it has basically a trailing, trailing say to videos when, when you send one minute video for detection by the detection, by the detection of everybody smart and confirm that the fall, we are fetching the video out to the camera. So the pre buffer and the post buffer is fetched at a camera. And basically we have a window. We know video and everything is persisted on a
Speaker 7
camera about three hours, four hours. Key event they're looking for is the fall. So if they detect some falling event, that's the one that triggers the video record.
camera about three hours, four hours. Key event they're looking for is the fall. So if they detect some falling event, that's the one that triggers the video record.
camera about three hours, four hours. Key event they're looking for is the fall. So if they detect some falling event, that's the one that triggers the video record.
camera about three hours, four hours. Key event they're looking for is the fall. So if they detect some falling event, that's the one that triggers the video record.
Speaker 2
We have a level event is sent out, it's it's confirmed as a fall, and a request is made back to the camera for a pre buffers of attendance before, and all the rest of videos. And that gets uploaded where the customer reads the
We have a level event is sent out, it's it's confirmed as a fall, and a request is made back to the camera for a pre buffers of attendance before, and all the rest of videos. And that gets uploaded where the customer reads the
We have a level event is sent out, it's it's confirmed as a fall, and a request is made back to the camera for a pre buffers of attendance before, and all the rest of videos. And that gets uploaded where the customer reads the
We have a level event is sent out, it's it's confirmed as a fall, and a request is made back to the camera for a pre buffers of attendance before, and all the rest of videos. And that gets uploaded where the customer reads the
content process.
Speaker 2
Yeah. So we, I think George mentioned that we have human loops. We have a team of the monitors the events coming in to see one minute video, the minute that trigger the detection, and once they confirm that is the fall, this is where the sequencing happens, in terms of downloading the video sensors stitching back together so we form one continuous video. Customer. Can see this is what's used to assess the fall as well from our staff. So for this, 10,000 cameras, how many humans do you have?
Yeah. So we, I think George mentioned that we have human loops. We have a team of the monitors the events coming in to see one minute video, the minute that trigger the detection, and once they confirm that is the fall, this is where the sequencing happens, in terms of downloading the video sensors stitching back together so we form one continuous video. Customer. Can see this is what's used to assess the fall as well from our staff. So for this, 10,000 cameras, how many humans do you have?
Yeah. So we, I think George mentioned that we have human loops. We have a team of the monitors the events coming in to see one minute video, the minute that trigger the detection, and once they confirm that is the fall, this is where the sequencing happens, in terms of downloading the video sensors stitching back together so we form one continuous video. Customer. Can see this is what's used to assess the fall as well from our staff. So for this, 10,000 cameras, how many humans do you have?
Yeah. So we, I think George mentioned that we have human loops. We have a team of the monitors the events coming in to see one minute video, the minute that trigger the detection, and once they confirm that is the fall, this is where the sequencing happens, in terms of downloading the video sensors stitching back together so we form one continuous video. Customer. Can see this is what's used to assess the fall as well from our staff. So for this, 10,000 cameras, how many humans do you have?
And right now we're around 16 human
And right now we're around 16 human
And right now we're around 16 human
And right now we're around 16 human
Speaker 2
latest number, yeah. So it's also
latest number, yeah. So it's also
latest number, yeah. So it's also
latest number, yeah. So it's also
a lot of security, physical
a lot of security, physical
a lot of security, physical
a lot of security, physical
security on that
Speaker 2
example, no cell phone allowance. No cell phone allow incidental secure, physical, physical security.
example, no cell phone allowance. No cell phone allow incidental secure, physical, physical security.
example, no cell phone allowance. No cell phone allow incidental secure, physical, physical security.
example, no cell phone allowance. No cell phone allow incidental secure, physical, physical security.
Speaker 8
Like one quick question on this, if you get camera feed from any camera, which is not necessarily safely, I'm trying to understand if this software stack will still be applicable, you can still default detection. You can still
Like one quick question on this, if you get camera feed from any camera, which is not necessarily safely, I'm trying to understand if this software stack will still be applicable, you can still default detection. You can still
Like one quick question on this, if you get camera feed from any camera, which is not necessarily safely, I'm trying to understand if this software stack will still be applicable, you can still default detection. You can still
Like one quick question on this, if you get camera feed from any camera, which is not necessarily safely, I'm trying to understand if this software stack will still be applicable, you can still default detection. You can still
Speaker 2
call out events in the workflows. That's correct. So we actually do have not all our sources. We had prior cameras that we use. Prius model we had was a two stage models, camera streaming into a server that located in the premises, and the detection would be the server could have up to 30 cameras seeing on one server. I think that we can do it now in AI there's a lot of sensitivity on your sensor, the model is naturally better detecting things for sensors that you know that is being trained on and using also different cameras definitely require more training, so it's not as easy as just adding a video stream. You would get
call out events in the workflows. That's correct. So we actually do have not all our sources. We had prior cameras that we use. Prius model we had was a two stage models, camera streaming into a server that located in the premises, and the detection would be the server could have up to 30 cameras seeing on one server. I think that we can do it now in AI there's a lot of sensitivity on your sensor, the model is naturally better detecting things for sensors that you know that is being trained on and using also different cameras definitely require more training, so it's not as easy as just adding a video stream. You would get
call out events in the workflows. That's correct. So we actually do have not all our sources. We had prior cameras that we use. Prius model we had was a two stage models, camera streaming into a server that located in the premises, and the detection would be the server could have up to 30 cameras seeing on one server. I think that we can do it now in AI there's a lot of sensitivity on your sensor, the model is naturally better detecting things for sensors that you know that is being trained on and using also different cameras definitely require more training, so it's not as easy as just adding a video stream. You would get
call out events in the workflows. That's correct. So we actually do have not all our sources. We had prior cameras that we use. Prius model we had was a two stage models, camera streaming into a server that located in the premises, and the detection would be the server could have up to 30 cameras seeing on one server. I think that we can do it now in AI there's a lot of sensitivity on your sensor, the model is naturally better detecting things for sensors that you know that is being trained on and using also different cameras definitely require more training, so it's not as easy as just adding a video stream. You would get
at least six different camera
at least six different camera
at least six different camera
at least six different camera
types we have going forward
types we have going forward
types we have going forward
types we have going forward
Speaker 7
think this is the camera you deploy now, right with other camera that's right, and
think this is the camera you deploy now, right with other camera that's right, and
think this is the camera you deploy now, right with other camera that's right, and
think this is the camera you deploy now, right with other camera that's right, and
chip that's in there, which, which? Which? 5165
chip that's in there, which, which? Which? 5165
chip that's in there, which, which? Which? 5165
chip that's in there, which, which? Which? 5165
Speaker 2
okay, well, this is a selection process we went, I'm sure some more how we got there. So these are the chips we considered at a time. We shortlisted umbrella and Qualcomm, pretty typical there. And we'll see we're running it fully containerized. I'll talk about this a little bit later. It's a fully it's really beautiful design. So that was really important for us, more cost effective, but has issues with containerized support. We were able to support that with Qualcomm at the time, we did not look at the 5165 so we looked at these two, because was a bigger issue, but we actually work this out. So next
okay, well, this is a selection process we went, I'm sure some more how we got there. So these are the chips we considered at a time. We shortlisted umbrella and Qualcomm, pretty typical there. And we'll see we're running it fully containerized. I'll talk about this a little bit later. It's a fully it's really beautiful design. So that was really important for us, more cost effective, but has issues with containerized support. We were able to support that with Qualcomm at the time, we did not look at the 5165 so we looked at these two, because was a bigger issue, but we actually work this out. So next
okay, well, this is a selection process we went, I'm sure some more how we got there. So these are the chips we considered at a time. We shortlisted umbrella and Qualcomm, pretty typical there. And we'll see we're running it fully containerized. I'll talk about this a little bit later. It's a fully it's really beautiful design. So that was really important for us, more cost effective, but has issues with containerized support. We were able to support that with Qualcomm at the time, we did not look at the 5165 so we looked at these two, because was a bigger issue, but we actually work this out. So next
okay, well, this is a selection process we went, I'm sure some more how we got there. So these are the chips we considered at a time. We shortlisted umbrella and Qualcomm, pretty typical there. And we'll see we're running it fully containerized. I'll talk about this a little bit later. It's a fully it's really beautiful design. So that was really important for us, more cost effective, but has issues with containerized support. We were able to support that with Qualcomm at the time, we did not look at the 5165 so we looked at these two, because was a bigger issue, but we actually work this out. So next
Speaker 6
slide there is more specific what specificities to be offered
slide there is more specific what specificities to be offered
slide there is more specific what specificities to be offered
slide there is more specific what specificities to be offered
physically, I think the be awesome.
physically, I think the be awesome.
physically, I think the be awesome.
physically, I think the be awesome.
Speaker 2
Yeah, we're running in there, 65 and we're using your QCs. 6391 there for Wi Fi,
Yeah, we're running in there, 65 and we're using your QCs. 6391 there for Wi Fi,
Yeah, we're running in there, 65 and we're using your QCs. 6391 there for Wi Fi,
Yeah, we're running in there, 65 and we're using your QCs. 6391 there for Wi Fi,
Speaker 3
what specifically for containerization to be provided versus umbrella. So the version
what specifically for containerization to be provided versus umbrella. So the version
what specifically for containerization to be provided versus umbrella. So the version
what specifically for containerization to be provided versus umbrella. So the version
Speaker 2
of the version of OS that umbrella is running does not support containerization at all, so we would have had to recompile the kernel with CD 25 which we tried, and I think eventually we could have made it work, but there was no support on the app for this. Thank you. So to the next slide. This is what containerized workload we use here. So really it's a it's set up as an immutable set, very much like a data center would be set up so much, so much power on this bus, running different containers, on Docker, on the system, on deployment, is container. Is what you're seeing on that red box there is our perception plane. We call that energy to different services. We're able to run experimental production model at the same time, so that when we push the model, we will turn inside and promote them based on the results that we get in production. So we're basically detecting that falls and stuff to detect at the same time or better. And then once, once we get these results, we switch over. We monitor, if you can imagine, select 60 devices. We monitor every points that we can on the device, temperature, every component is monitor the quality of the network and so forth, and so that gives us a lot of control to the level. It's worked out really well. It's fairly advanced. What we're running there to be incredibly reliable. So far, deployment, as well as container, has to be a container out to that system, just operating from the rest. How
of the version of OS that umbrella is running does not support containerization at all, so we would have had to recompile the kernel with CD 25 which we tried, and I think eventually we could have made it work, but there was no support on the app for this. Thank you. So to the next slide. This is what containerized workload we use here. So really it's a it's set up as an immutable set, very much like a data center would be set up so much, so much power on this bus, running different containers, on Docker, on the system, on deployment, is container. Is what you're seeing on that red box there is our perception plane. We call that energy to different services. We're able to run experimental production model at the same time, so that when we push the model, we will turn inside and promote them based on the results that we get in production. So we're basically detecting that falls and stuff to detect at the same time or better. And then once, once we get these results, we switch over. We monitor, if you can imagine, select 60 devices. We monitor every points that we can on the device, temperature, every component is monitor the quality of the network and so forth, and so that gives us a lot of control to the level. It's worked out really well. It's fairly advanced. What we're running there to be incredibly reliable. So far, deployment, as well as container, has to be a container out to that system, just operating from the rest. How
of the version of OS that umbrella is running does not support containerization at all, so we would have had to recompile the kernel with CD 25 which we tried, and I think eventually we could have made it work, but there was no support on the app for this. Thank you. So to the next slide. This is what containerized workload we use here. So really it's a it's set up as an immutable set, very much like a data center would be set up so much, so much power on this bus, running different containers, on Docker, on the system, on deployment, is container. Is what you're seeing on that red box there is our perception plane. We call that energy to different services. We're able to run experimental production model at the same time, so that when we push the model, we will turn inside and promote them based on the results that we get in production. So we're basically detecting that falls and stuff to detect at the same time or better. And then once, once we get these results, we switch over. We monitor, if you can imagine, select 60 devices. We monitor every points that we can on the device, temperature, every component is monitor the quality of the network and so forth, and so that gives us a lot of control to the level. It's worked out really well. It's fairly advanced. What we're running there to be incredibly reliable. So far, deployment, as well as container, has to be a container out to that system, just operating from the rest. How
of the version of OS that umbrella is running does not support containerization at all, so we would have had to recompile the kernel with CD 25 which we tried, and I think eventually we could have made it work, but there was no support on the app for this. Thank you. So to the next slide. This is what containerized workload we use here. So really it's a it's set up as an immutable set, very much like a data center would be set up so much, so much power on this bus, running different containers, on Docker, on the system, on deployment, is container. Is what you're seeing on that red box there is our perception plane. We call that energy to different services. We're able to run experimental production model at the same time, so that when we push the model, we will turn inside and promote them based on the results that we get in production. So we're basically detecting that falls and stuff to detect at the same time or better. And then once, once we get these results, we switch over. We monitor, if you can imagine, select 60 devices. We monitor every points that we can on the device, temperature, every component is monitor the quality of the network and so forth, and so that gives us a lot of control to the level. It's worked out really well. It's fairly advanced. What we're running there to be incredibly reliable. So far, deployment, as well as container, has to be a container out to that system, just operating from the rest. How
much storage did you have on the device, on the camera? So actually,
much storage did you have on the device, on the camera? So actually,
much storage did you have on the device, on the camera? So actually,
much storage did you have on the device, on the camera? So actually,
Speaker 2
if you go back to slides before we have a gig up RAM and MCC and AMC, and I'm trying to get microSD,
if you go back to slides before we have a gig up RAM and MCC and AMC, and I'm trying to get microSD,
if you go back to slides before we have a gig up RAM and MCC and AMC, and I'm trying to get microSD,
if you go back to slides before we have a gig up RAM and MCC and AMC, and I'm trying to get microSD,
Okay, looks like that's the sale of backup,
Okay, looks like that's the sale of backup,
Okay, looks like that's the sale of backup,
Okay, looks like that's the sale of backup,
right? That's correct,
right? That's correct,
right? That's correct,
right? That's correct,
Speaker 2
yeah. And then we have four banks of IR, individually controlled. And then we talked forward and bring almost 40 months of IR into the camera, we can eliminate things at 200
yeah. And then we have four banks of IR, individually controlled. And then we talked forward and bring almost 40 months of IR into the camera, we can eliminate things at 200
yeah. And then we have four banks of IR, individually controlled. And then we talked forward and bring almost 40 months of IR into the camera, we can eliminate things at 200
yeah. And then we have four banks of IR, individually controlled. And then we talked forward and bring almost 40 months of IR into the camera, we can eliminate things at 200
Speaker 1
we're designing this whole spectrum. So instead of having a little red.so instead of having a little red.it completely dark that
we're designing this whole spectrum. So instead of having a little red.so instead of having a little red.it completely dark that
we're designing this whole spectrum. So instead of having a little red.so instead of having a little red.it completely dark that
we're designing this whole spectrum. So instead of having a little red.so instead of having a little red.it completely dark that
Speaker 4
night. So it doesn't look like a scary red eye in terms of the OS itself. But it is energy Linux
night. So it doesn't look like a scary red eye in terms of the OS itself. But it is energy Linux
night. So it doesn't look like a scary red eye in terms of the OS itself. But it is energy Linux
night. So it doesn't look like a scary red eye in terms of the OS itself. But it is energy Linux
Speaker 2
that you're using, or is it camera based solution we're using Yocto. So that there's also, there's no calling on the device. Is all that cooling, so there's no fan whatsoever. There's a lot of effort on temperature management we have to do. So we're bringing in 40 ones on social small devices. It's quite a bit small surface,
that you're using, or is it camera based solution we're using Yocto. So that there's also, there's no calling on the device. Is all that cooling, so there's no fan whatsoever. There's a lot of effort on temperature management we have to do. So we're bringing in 40 ones on social small devices. It's quite a bit small surface,
that you're using, or is it camera based solution we're using Yocto. So that there's also, there's no calling on the device. Is all that cooling, so there's no fan whatsoever. There's a lot of effort on temperature management we have to do. So we're bringing in 40 ones on social small devices. It's quite a bit small surface,
that you're using, or is it camera based solution we're using Yocto. So that there's also, there's no calling on the device. Is all that cooling, so there's no fan whatsoever. There's a lot of effort on temperature management we have to do. So we're bringing in 40 ones on social small devices. It's quite a bit small surface,
Speaker 1
but yeah, in the core parameters that we really needed from this, as you saw, it, was the key to building this company, was getting access to this data set that nobody has had before. And now we're, at this moment, we're going to train all these other AI models. And so really key for this device is that we need to have the capacity to be able to deploy many, many more AI models, and also not becoming and changing cameras and things like that. So we wanted fan lists, so could be there for 510, years, but also have the capacity for us just deploying more and more software
but yeah, in the core parameters that we really needed from this, as you saw, it, was the key to building this company, was getting access to this data set that nobody has had before. And now we're, at this moment, we're going to train all these other AI models. And so really key for this device is that we need to have the capacity to be able to deploy many, many more AI models, and also not becoming and changing cameras and things like that. So we wanted fan lists, so could be there for 510, years, but also have the capacity for us just deploying more and more software
but yeah, in the core parameters that we really needed from this, as you saw, it, was the key to building this company, was getting access to this data set that nobody has had before. And now we're, at this moment, we're going to train all these other AI models. And so really key for this device is that we need to have the capacity to be able to deploy many, many more AI models, and also not becoming and changing cameras and things like that. So we wanted fan lists, so could be there for 510, years, but also have the capacity for us just deploying more and more software
but yeah, in the core parameters that we really needed from this, as you saw, it, was the key to building this company, was getting access to this data set that nobody has had before. And now we're, at this moment, we're going to train all these other AI models. And so really key for this device is that we need to have the capacity to be able to deploy many, many more AI models, and also not becoming and changing cameras and things like that. So we wanted fan lists, so could be there for 510, years, but also have the capacity for us just deploying more and more software
Speaker 2
on top of it. 21 has a software stack, if you want to go down, is what we're running. I was using yoyo, the distribution that we're getting, and then we have yellow five Al, yellow five Ling data. So we've been quantized and normalized using actually quantum skill set. So we start with the same p DLC model and convert, convert to our NMX depending on what we want to do. That's what we use. And any dwarf so fisheye land, so we can put it anywhere on the wall. It's really flexible. And then we virtual pan tail to reach capture awesome
on top of it. 21 has a software stack, if you want to go down, is what we're running. I was using yoyo, the distribution that we're getting, and then we have yellow five Al, yellow five Ling data. So we've been quantized and normalized using actually quantum skill set. So we start with the same p DLC model and convert, convert to our NMX depending on what we want to do. That's what we use. And any dwarf so fisheye land, so we can put it anywhere on the wall. It's really flexible. And then we virtual pan tail to reach capture awesome
on top of it. 21 has a software stack, if you want to go down, is what we're running. I was using yoyo, the distribution that we're getting, and then we have yellow five Al, yellow five Ling data. So we've been quantized and normalized using actually quantum skill set. So we start with the same p DLC model and convert, convert to our NMX depending on what we want to do. That's what we use. And any dwarf so fisheye land, so we can put it anywhere on the wall. It's really flexible. And then we virtual pan tail to reach capture awesome
on top of it. 21 has a software stack, if you want to go down, is what we're running. I was using yoyo, the distribution that we're getting, and then we have yellow five Al, yellow five Ling data. So we've been quantized and normalized using actually quantum skill set. So we start with the same p DLC model and convert, convert to our NMX depending on what we want to do. That's what we use. And any dwarf so fisheye land, so we can put it anywhere on the wall. It's really flexible. And then we virtual pan tail to reach capture awesome
experience with IoT Core? You can use IoT Core. It's
experience with IoT Core? You can use IoT Core. It's
experience with IoT Core? You can use IoT Core. It's
experience with IoT Core? You can use IoT Core. It's
Speaker 2
been pretty good. So we're running all the other modules at this point, as the integration has been okay. Grid Grass, On the other hand, is too limited, and then we're having issues with supports on the Choose module. So we just, we just get 100 grams, but the IoT Core has been good. Very reliable. Is okay. So let finicky had time, but
been pretty good. So we're running all the other modules at this point, as the integration has been okay. Grid Grass, On the other hand, is too limited, and then we're having issues with supports on the Choose module. So we just, we just get 100 grams, but the IoT Core has been good. Very reliable. Is okay. So let finicky had time, but
been pretty good. So we're running all the other modules at this point, as the integration has been okay. Grid Grass, On the other hand, is too limited, and then we're having issues with supports on the Choose module. So we just, we just get 100 grams, but the IoT Core has been good. Very reliable. Is okay. So let finicky had time, but
been pretty good. So we're running all the other modules at this point, as the integration has been okay. Grid Grass, On the other hand, is too limited, and then we're having issues with supports on the Choose module. So we just, we just get 100 grams, but the IoT Core has been good. Very reliable. Is okay. So let finicky had time, but
Speaker 8
no. Good to see your containerized architecture to the platform. One question I had around, you know, any perception module or any model that comes in the future that's maybe equally as good or even better, involves, can you adopt that model for your text tech platform? And are you thinking thinking of those lines, or how do you see that play out?
no. Good to see your containerized architecture to the platform. One question I had around, you know, any perception module or any model that comes in the future that's maybe equally as good or even better, involves, can you adopt that model for your text tech platform? And are you thinking thinking of those lines, or how do you see that play out?
no. Good to see your containerized architecture to the platform. One question I had around, you know, any perception module or any model that comes in the future that's maybe equally as good or even better, involves, can you adopt that model for your text tech platform? And are you thinking thinking of those lines, or how do you see that play out?
no. Good to see your containerized architecture to the platform. One question I had around, you know, any perception module or any model that comes in the future that's maybe equally as good or even better, involves, can you adopt that model for your text tech platform? And are you thinking thinking of those lines, or how do you see that play out?
Speaker 2
Yeah. So for the models we are starting to experiment with transformer, namely, RTD, turn it supported on led 2.0 Thank you very much. We just, we, we actually, we actually saw that. And we already write experiments on on our servers, and then we're going to try it on the cameras very soon. So that would give us the plus is better performance, much better detection accuracy. I think the negative part is the training time is almost four or 5x so it takes us 48 hours right now. He would expect a week to produce them all. They don't retrain that often, but that's going
Yeah. So for the models we are starting to experiment with transformer, namely, RTD, turn it supported on led 2.0 Thank you very much. We just, we, we actually, we actually saw that. And we already write experiments on on our servers, and then we're going to try it on the cameras very soon. So that would give us the plus is better performance, much better detection accuracy. I think the negative part is the training time is almost four or 5x so it takes us 48 hours right now. He would expect a week to produce them all. They don't retrain that often, but that's going
Yeah. So for the models we are starting to experiment with transformer, namely, RTD, turn it supported on led 2.0 Thank you very much. We just, we, we actually, we actually saw that. And we already write experiments on on our servers, and then we're going to try it on the cameras very soon. So that would give us the plus is better performance, much better detection accuracy. I think the negative part is the training time is almost four or 5x so it takes us 48 hours right now. He would expect a week to produce them all. They don't retrain that often, but that's going
Yeah. So for the models we are starting to experiment with transformer, namely, RTD, turn it supported on led 2.0 Thank you very much. We just, we, we actually, we actually saw that. And we already write experiments on on our servers, and then we're going to try it on the cameras very soon. So that would give us the plus is better performance, much better detection accuracy. I think the negative part is the training time is almost four or 5x so it takes us 48 hours right now. He would expect a week to produce them all. They don't retrain that often, but that's going
Speaker 8
to provide a lot. A lot of those. Cost will also come down, I guess, and there's a
to provide a lot. A lot of those. Cost will also come down, I guess, and there's a
to provide a lot. A lot of those. Cost will also come down, I guess, and there's a
to provide a lot. A lot of those. Cost will also come down, I guess, and there's a
Speaker 2
lot of optimization that are being worked on on the training side, so we might be able to fall I'll talk a little bit later about different models we can train there, where the use cases are actually so that's all going to be running on the camera. So we're working on
lot of optimization that are being worked on on the training side, so we might be able to fall I'll talk a little bit later about different models we can train there, where the use cases are actually so that's all going to be running on the camera. So we're working on
lot of optimization that are being worked on on the training side, so we might be able to fall I'll talk a little bit later about different models we can train there, where the use cases are actually so that's all going to be running on the camera. So we're working on
lot of optimization that are being worked on on the training side, so we might be able to fall I'll talk a little bit later about different models we can train there, where the use cases are actually so that's all going to be running on the camera. So we're working on
Speaker 7
that. Would you guys have any other questions, maybe on the tech, on why they choose Qualcomm, etc? We could
that. Would you guys have any other questions, maybe on the tech, on why they choose Qualcomm, etc? We could
that. Would you guys have any other questions, maybe on the tech, on why they choose Qualcomm, etc? We could
that. Would you guys have any other questions, maybe on the tech, on why they choose Qualcomm, etc? We could
Speaker 2
go on the next slide. So I thought you'll find that interesting. This is actually our inference cost. Because we're not doing any inference in a cloud. We're not we don't have to pay for power. We have to pay for GPUs. Everything is done because of age, and this is a cost saving from an Amazon expense, 77% for us. Unlike most startups, scaling AI is not an issue, really fleet, obviously. But in terms of cost, it's linear, right? Because every time we deploy a camera, we are getting the revenue from that camera, and we're increasing our pool of devices that can actually infer so as we get more contracts, we're increasing basically our pool free is becomes available at the same time our revenue grows. And that's incredibly powerful. We only use 50% of the camera capacity today. It's a very powerful process. You meet 50% of the available like in terms of insurance capacity,
go on the next slide. So I thought you'll find that interesting. This is actually our inference cost. Because we're not doing any inference in a cloud. We're not we don't have to pay for power. We have to pay for GPUs. Everything is done because of age, and this is a cost saving from an Amazon expense, 77% for us. Unlike most startups, scaling AI is not an issue, really fleet, obviously. But in terms of cost, it's linear, right? Because every time we deploy a camera, we are getting the revenue from that camera, and we're increasing our pool of devices that can actually infer so as we get more contracts, we're increasing basically our pool free is becomes available at the same time our revenue grows. And that's incredibly powerful. We only use 50% of the camera capacity today. It's a very powerful process. You meet 50% of the available like in terms of insurance capacity,
go on the next slide. So I thought you'll find that interesting. This is actually our inference cost. Because we're not doing any inference in a cloud. We're not we don't have to pay for power. We have to pay for GPUs. Everything is done because of age, and this is a cost saving from an Amazon expense, 77% for us. Unlike most startups, scaling AI is not an issue, really fleet, obviously. But in terms of cost, it's linear, right? Because every time we deploy a camera, we are getting the revenue from that camera, and we're increasing our pool of devices that can actually infer so as we get more contracts, we're increasing basically our pool free is becomes available at the same time our revenue grows. And that's incredibly powerful. We only use 50% of the camera capacity today. It's a very powerful process. You meet 50% of the available like in terms of insurance capacity,
go on the next slide. So I thought you'll find that interesting. This is actually our inference cost. Because we're not doing any inference in a cloud. We're not we don't have to pay for power. We have to pay for GPUs. Everything is done because of age, and this is a cost saving from an Amazon expense, 77% for us. Unlike most startups, scaling AI is not an issue, really fleet, obviously. But in terms of cost, it's linear, right? Because every time we deploy a camera, we are getting the revenue from that camera, and we're increasing our pool of devices that can actually infer so as we get more contracts, we're increasing basically our pool free is becomes available at the same time our revenue grows. And that's incredibly powerful. We only use 50% of the camera capacity today. It's a very powerful process. You meet 50% of the available like in terms of insurance capacity,
Speaker 4
container support being one reason spec for choosing any other reasons.
container support being one reason spec for choosing any other reasons.
container support being one reason spec for choosing any other reasons.
container support being one reason spec for choosing any other reasons.
Speaker 2
and then we featured in
and then we featured in
and then we featured in
and then we featured in
so we could look at
Speaker 2
their solution on the Nano version, just a nano, the performance wasn't that great for the price point. It was a bit of a dissonance between their price point. They had better, had better solutions on their better, more powerful solution, solution. They were really costly as well. So it really didn't, didn't come out to be, to be the right solution. The capacity of the Nano was much more 65 and in the end, for the price point, we would not have had that coming out now, just on
their solution on the Nano version, just a nano, the performance wasn't that great for the price point. It was a bit of a dissonance between their price point. They had better, had better solutions on their better, more powerful solution, solution. They were really costly as well. So it really didn't, didn't come out to be, to be the right solution. The capacity of the Nano was much more 65 and in the end, for the price point, we would not have had that coming out now, just on
their solution on the Nano version, just a nano, the performance wasn't that great for the price point. It was a bit of a dissonance between their price point. They had better, had better solutions on their better, more powerful solution, solution. They were really costly as well. So it really didn't, didn't come out to be, to be the right solution. The capacity of the Nano was much more 65 and in the end, for the price point, we would not have had that coming out now, just on
their solution on the Nano version, just a nano, the performance wasn't that great for the price point. It was a bit of a dissonance between their price point. They had better, had better solutions on their better, more powerful solution, solution. They were really costly as well. So it really didn't, didn't come out to be, to be the right solution. The capacity of the Nano was much more 65 and in the end, for the price point, we would not have had that coming out now, just on
Speaker 1
that point, architect system didn't involve deployed run camera streams for that server, 24/7 and that had a video set. So you guys have, officially, we're no longer deploying individual views and now deploying reviews, and now, in terms
that point, architect system didn't involve deployed run camera streams for that server, 24/7 and that had a video set. So you guys have, officially, we're no longer deploying individual views and now deploying reviews, and now, in terms
that point, architect system didn't involve deployed run camera streams for that server, 24/7 and that had a video set. So you guys have, officially, we're no longer deploying individual views and now deploying reviews, and now, in terms
that point, architect system didn't involve deployed run camera streams for that server, 24/7 and that had a video set. So you guys have, officially, we're no longer deploying individual views and now deploying reviews, and now, in terms
Speaker 4
of the container support, what do we have on 56 isn't good enough, but we like something else.
of the container support, what do we have on 56 isn't good enough, but we like something else.
of the container support, what do we have on 56 isn't good enough, but we like something else.
of the container support, what do we have on 56 isn't good enough, but we like something else.
Speaker 2
It's things we've experienced. So the container is okay. I think the part I said that has been a little bit more difficult is that support of aileon Yoko, the Yoko version, is not the latest compiling area containers forming the containers often used. All the libraries are not compatible with the system that we're using. We try to stay on the latest containers out there, and that has been an issue
It's things we've experienced. So the container is okay. I think the part I said that has been a little bit more difficult is that support of aileon Yoko, the Yoko version, is not the latest compiling area containers forming the containers often used. All the libraries are not compatible with the system that we're using. We try to stay on the latest containers out there, and that has been an issue
It's things we've experienced. So the container is okay. I think the part I said that has been a little bit more difficult is that support of aileon Yoko, the Yoko version, is not the latest compiling area containers forming the containers often used. All the libraries are not compatible with the system that we're using. We try to stay on the latest containers out there, and that has been an issue
It's things we've experienced. So the container is okay. I think the part I said that has been a little bit more difficult is that support of aileon Yoko, the Yoko version, is not the latest compiling area containers forming the containers often used. All the libraries are not compatible with the system that we're using. We try to stay on the latest containers out there, and that has been an issue
Speaker 4
like maybe offline. If you describe the problem and send to shout an email, we appreciate it
like maybe offline. If you describe the problem and send to shout an email, we appreciate it
like maybe offline. If you describe the problem and send to shout an email, we appreciate it
like maybe offline. If you describe the problem and send to shout an email, we appreciate it
later. Of support
Speaker 2
on the floor was a surprise, because expired, basically, and when we got it, and now we have, there's a gap between now and the next version, so yeah, and then the AGC is a big change for us, because we do a lot of nitrogen. Having a single point for for AGC, the auto exposure is a problem, but that's, that's, yeah, that's something, thanks. Like, we had
on the floor was a surprise, because expired, basically, and when we got it, and now we have, there's a gap between now and the next version, so yeah, and then the AGC is a big change for us, because we do a lot of nitrogen. Having a single point for for AGC, the auto exposure is a problem, but that's, that's, yeah, that's something, thanks. Like, we had
on the floor was a surprise, because expired, basically, and when we got it, and now we have, there's a gap between now and the next version, so yeah, and then the AGC is a big change for us, because we do a lot of nitrogen. Having a single point for for AGC, the auto exposure is a problem, but that's, that's, yeah, that's something, thanks. Like, we had
on the floor was a surprise, because expired, basically, and when we got it, and now we have, there's a gap between now and the next version, so yeah, and then the AGC is a big change for us, because we do a lot of nitrogen. Having a single point for for AGC, the auto exposure is a problem, but that's, that's, yeah, that's something, thanks. Like, we had
a really good experience, and
a really good experience, and
a really good experience, and
a really good experience, and
Speaker 2
our customers have had a really good experience. The cameras went out, and we have yet to have a single camera with a hardware killer.
our customers have had a really good experience. The cameras went out, and we have yet to have a single camera with a hardware killer.
our customers have had a really good experience. The cameras went out, and we have yet to have a single camera with a hardware killer.
our customers have had a really good experience. The cameras went out, and we have yet to have a single camera with a hardware killer.
Speaker 1
George, how are you doing this using large language models or some of the ways?
George, how are you doing this using large language models or some of the ways?
George, how are you doing this using large language models or some of the ways?
George, how are you doing this using large language models or some of the ways?
Speaker 1
So knowing staff in the room is the exact same kinds of models we've been using, so computer vision can detect the staff member versus the resident. And then what we're building for is using LLM to extend is using LLM to exactly that. Okay, yeah, that will be running on
So knowing staff in the room is the exact same kinds of models we've been using, so computer vision can detect the staff member versus the resident. And then what we're building for is using LLM to extend is using LLM to exactly that. Okay, yeah, that will be running on
So knowing staff in the room is the exact same kinds of models we've been using, so computer vision can detect the staff member versus the resident. And then what we're building for is using LLM to extend is using LLM to exactly that. Okay, yeah, that will be running on
So knowing staff in the room is the exact same kinds of models we've been using, so computer vision can detect the staff member versus the resident. And then what we're building for is using LLM to extend is using LLM to exactly that. Okay, yeah, that will be running on
Speaker 2
the camera. We're going to be running on camera. I have a slide later on to discuss
the camera. We're going to be running on camera. I have a slide later on to discuss
the camera. We're going to be running on camera. I have a slide later on to discuss
the camera. We're going to be running on camera. I have a slide later on to discuss
Speaker 4
this. How many parameters? How many billion parameters? Yeah,
this. How many parameters? How many billion parameters? Yeah,
this. How many parameters? How many billion parameters? Yeah,
this. How many parameters? How many billion parameters? Yeah,
Speaker 2
so that's a good question. We would have to make it fit on the camera. Yeah, we haven't determined that yet. What we are running is we're doing nice experiments on detection itself and the translation into text that seems physical. We need to figure out how we want to Geo the inference that question we have right now we might have to TLD infer so we do initial inference in on the edge and forward content out for secondary inference.
so that's a good question. We would have to make it fit on the camera. Yeah, we haven't determined that yet. What we are running is we're doing nice experiments on detection itself and the translation into text that seems physical. We need to figure out how we want to Geo the inference that question we have right now we might have to TLD infer so we do initial inference in on the edge and forward content out for secondary inference.
so that's a good question. We would have to make it fit on the camera. Yeah, we haven't determined that yet. What we are running is we're doing nice experiments on detection itself and the translation into text that seems physical. We need to figure out how we want to Geo the inference that question we have right now we might have to TLD infer so we do initial inference in on the edge and forward content out for secondary inference.
so that's a good question. We would have to make it fit on the camera. Yeah, we haven't determined that yet. What we are running is we're doing nice experiments on detection itself and the translation into text that seems physical. We need to figure out how we want to Geo the inference that question we have right now we might have to TLD infer so we do initial inference in on the edge and forward content out for secondary inference.
Speaker 4
So once you learn more, if you want to discuss less, absolutely, there's definitely more
So once you learn more, if you want to discuss less, absolutely, there's definitely more
So once you learn more, if you want to discuss less, absolutely, there's definitely more
So once you learn more, if you want to discuss less, absolutely, there's definitely more
part of our future question regarding
part of our future question regarding
part of our future question regarding
part of our future question regarding
Speaker 5
use cases. So you know some of the four, actually, many of the four happened in the bathroom. How would you solve the issue for computer in the bathroom? Because it requires really high privacy. People might not want the bathroom.
use cases. So you know some of the four, actually, many of the four happened in the bathroom. How would you solve the issue for computer in the bathroom? Because it requires really high privacy. People might not want the bathroom.
use cases. So you know some of the four, actually, many of the four happened in the bathroom. How would you solve the issue for computer in the bathroom? Because it requires really high privacy. People might not want the bathroom.
use cases. So you know some of the four, actually, many of the four happened in the bathroom. How would you solve the issue for computer in the bathroom? Because it requires really high privacy. People might not want the bathroom.
Speaker 1
Speaker 8
use case. Okay? So that's just one, one question on the industry. It's not a very well managed industry, especially nursing homes and elderly care. My question is, you know, one of the challenges in these facilities is neglect and sometimes abused, right, by some of the workers that can these video feeds be used against the care giving members, right? And I'm trying to think, from a lot library perspective or compliance perspective, thing that's on your mind or on you know, these are the owners of these facilities. I'll be thinking about
use case. Okay? So that's just one, one question on the industry. It's not a very well managed industry, especially nursing homes and elderly care. My question is, you know, one of the challenges in these facilities is neglect and sometimes abused, right, by some of the workers that can these video feeds be used against the care giving members, right? And I'm trying to think, from a lot library perspective or compliance perspective, thing that's on your mind or on you know, these are the owners of these facilities. I'll be thinking about
use case. Okay? So that's just one, one question on the industry. It's not a very well managed industry, especially nursing homes and elderly care. My question is, you know, one of the challenges in these facilities is neglect and sometimes abused, right, by some of the workers that can these video feeds be used against the care giving members, right? And I'm trying to think, from a lot library perspective or compliance perspective, thing that's on your mind or on you know, these are the owners of these facilities. I'll be thinking about
use case. Okay? So that's just one, one question on the industry. It's not a very well managed industry, especially nursing homes and elderly care. My question is, you know, one of the challenges in these facilities is neglect and sometimes abused, right, by some of the workers that can these video feeds be used against the care giving members, right? And I'm trying to think, from a lot library perspective or compliance perspective, thing that's on your mind or on you know, these are the owners of these facilities. I'll be thinking about
that. Yeah, great question. So
that. Yeah, great question. So
that. Yeah, great question. So
that. Yeah, great question. So
Speaker 1
the, those are some of the big questions we got, again, early in company history. And one of the reasons why it was so important that we only have video of these specific moments and people can go look and respond to that video, because if we have video reporting all the time, it exposes that to a lot
the, those are some of the big questions we got, again, early in company history. And one of the reasons why it was so important that we only have video of these specific moments and people can go look and respond to that video, because if we have video reporting all the time, it exposes that to a lot
the, those are some of the big questions we got, again, early in company history. And one of the reasons why it was so important that we only have video of these specific moments and people can go look and respond to that video, because if we have video reporting all the time, it exposes that to a lot
the, those are some of the big questions we got, again, early in company history. And one of the reasons why it was so important that we only have video of these specific moments and people can go look and respond to that video, because if we have video reporting all the time, it exposes that to a lot
Speaker 8
of potential risk that's exactly select when the fall is detected. You only cut the
of potential risk that's exactly select when the fall is detected. You only cut the
of potential risk that's exactly select when the fall is detected. You only cut the
of potential risk that's exactly select when the fall is detected. You only cut the
Speaker 1
important nuance to understand is that about 75% of all litigations against nursing homes come from falls. Yeah. So we dramatically break down the number of falls and skipped over something, but we're just in our falls by about 50% and now we're at a point where, for instance, one of the contracts that came in was because that organization got a 19% production because of us, they basically can really reduce their risk using our system. And that's a lot of what now goes into like, we need to know how these risk events are happening so we can access them, but we don't want to get exposed
important nuance to understand is that about 75% of all litigations against nursing homes come from falls. Yeah. So we dramatically break down the number of falls and skipped over something, but we're just in our falls by about 50% and now we're at a point where, for instance, one of the contracts that came in was because that organization got a 19% production because of us, they basically can really reduce their risk using our system. And that's a lot of what now goes into like, we need to know how these risk events are happening so we can access them, but we don't want to get exposed
important nuance to understand is that about 75% of all litigations against nursing homes come from falls. Yeah. So we dramatically break down the number of falls and skipped over something, but we're just in our falls by about 50% and now we're at a point where, for instance, one of the contracts that came in was because that organization got a 19% production because of us, they basically can really reduce their risk using our system. And that's a lot of what now goes into like, we need to know how these risk events are happening so we can access them, but we don't want to get exposed
important nuance to understand is that about 75% of all litigations against nursing homes come from falls. Yeah. So we dramatically break down the number of falls and skipped over something, but we're just in our falls by about 50% and now we're at a point where, for instance, one of the contracts that came in was because that organization got a 19% production because of us, they basically can really reduce their risk using our system. And that's a lot of what now goes into like, we need to know how these risk events are happening so we can access them, but we don't want to get exposed
with all the other potential data. Thank
with all the other potential data. Thank
with all the other potential data. Thank
with all the other potential data. Thank
Speaker 9
you, George, just a couple of questions. Sorry for asking later said continuation actually, to answer questions. A lot of these nursing homes, they actually buy all kinds of technologies, for example, some of the nonprofit of all detections, etc. It's
you, George, just a couple of questions. Sorry for asking later said continuation actually, to answer questions. A lot of these nursing homes, they actually buy all kinds of technologies, for example, some of the nonprofit of all detections, etc. It's
you, George, just a couple of questions. Sorry for asking later said continuation actually, to answer questions. A lot of these nursing homes, they actually buy all kinds of technologies, for example, some of the nonprofit of all detections, etc. It's
you, George, just a couple of questions. Sorry for asking later said continuation actually, to answer questions. A lot of these nursing homes, they actually buy all kinds of technologies, for example, some of the nonprofit of all detections, etc. It's
Speaker 9
Speaker 1
there. Your middle question.
there. Your middle question.
there. Your middle question.
there. Your middle question.
Speaker 9
I was wondering if you actually looked into a shield of glass, if you actually have this type of plastic on top, on top of this answer, we'll definitely solve a little bit of the perception problem. There's always gonna be a percentage of people that, yeah, I
I was wondering if you actually looked into a shield of glass, if you actually have this type of plastic on top, on top of this answer, we'll definitely solve a little bit of the perception problem. There's always gonna be a percentage of people that, yeah, I
I was wondering if you actually looked into a shield of glass, if you actually have this type of plastic on top, on top of this answer, we'll definitely solve a little bit of the perception problem. There's always gonna be a percentage of people that, yeah, I
I was wondering if you actually looked into a shield of glass, if you actually have this type of plastic on top, on top of this answer, we'll definitely solve a little bit of the perception problem. There's always gonna be a percentage of people that, yeah, I
Speaker 1
think for our next generation sensor in particular, where we want to be able to run detection without keeping any video, I don't want to make it really clear to you so that that's what's happening. That kind of thing would be really interesting story design for that right now. Yeah, so
think for our next generation sensor in particular, where we want to be able to run detection without keeping any video, I don't want to make it really clear to you so that that's what's happening. That kind of thing would be really interesting story design for that right now. Yeah, so
think for our next generation sensor in particular, where we want to be able to run detection without keeping any video, I don't want to make it really clear to you so that that's what's happening. That kind of thing would be really interesting story design for that right now. Yeah, so
think for our next generation sensor in particular, where we want to be able to run detection without keeping any video, I don't want to make it really clear to you so that that's what's happening. That kind of thing would be really interesting story design for that right now. Yeah, so
Speaker 9
Speaker 3
I don't know any other questions from our team. So there was one question, George from our team as well. Did you ever run into CAMI vision? So once you order you want can be vision versus
I don't know any other questions from our team. So there was one question, George from our team as well. Did you ever run into CAMI vision? So once you order you want can be vision versus
I don't know any other questions from our team. So there was one question, George from our team as well. Did you ever run into CAMI vision? So once you order you want can be vision versus
I don't know any other questions from our team. So there was one question, George from our team as well. Did you ever run into CAMI vision? So once you order you want can be vision versus
we can kick your ass.
we can kick your ass.
we can kick your ass.
we can kick your ass.
Speaker 1
But I was quite trying to maybe two years ago, where they came in and basically just trying to copy what we're doing and offer a much lower cost. They're offering, like 25 bucks a month towards we start 25 bucks a month today, and it was a joy to see if our customers were interested, but the product just really didn't work very well in reliability. They tried to do in the human loop, which was really part of my process standpoint, as mentioned, as a vendor. And so folks that were interested, try to not have good experience. What you have to kind of understand is that this is a life safety system. And like, if you're telling a family you're going to be there at a really serious moment that you're not, it's a big deal, and now you're exposing the customers to get litigated against all that stuff because they pulled the family that they were able to know what will happen. It's not working with all that stuff. And so you really need a reliable life safety system. And Cami was coming from a more consumer standpoint than follow up,
But I was quite trying to maybe two years ago, where they came in and basically just trying to copy what we're doing and offer a much lower cost. They're offering, like 25 bucks a month towards we start 25 bucks a month today, and it was a joy to see if our customers were interested, but the product just really didn't work very well in reliability. They tried to do in the human loop, which was really part of my process standpoint, as mentioned, as a vendor. And so folks that were interested, try to not have good experience. What you have to kind of understand is that this is a life safety system. And like, if you're telling a family you're going to be there at a really serious moment that you're not, it's a big deal, and now you're exposing the customers to get litigated against all that stuff because they pulled the family that they were able to know what will happen. It's not working with all that stuff. And so you really need a reliable life safety system. And Cami was coming from a more consumer standpoint than follow up,
But I was quite trying to maybe two years ago, where they came in and basically just trying to copy what we're doing and offer a much lower cost. They're offering, like 25 bucks a month towards we start 25 bucks a month today, and it was a joy to see if our customers were interested, but the product just really didn't work very well in reliability. They tried to do in the human loop, which was really part of my process standpoint, as mentioned, as a vendor. And so folks that were interested, try to not have good experience. What you have to kind of understand is that this is a life safety system. And like, if you're telling a family you're going to be there at a really serious moment that you're not, it's a big deal, and now you're exposing the customers to get litigated against all that stuff because they pulled the family that they were able to know what will happen. It's not working with all that stuff. And so you really need a reliable life safety system. And Cami was coming from a more consumer standpoint than follow up,
But I was quite trying to maybe two years ago, where they came in and basically just trying to copy what we're doing and offer a much lower cost. They're offering, like 25 bucks a month towards we start 25 bucks a month today, and it was a joy to see if our customers were interested, but the product just really didn't work very well in reliability. They tried to do in the human loop, which was really part of my process standpoint, as mentioned, as a vendor. And so folks that were interested, try to not have good experience. What you have to kind of understand is that this is a life safety system. And like, if you're telling a family you're going to be there at a really serious moment that you're not, it's a big deal, and now you're exposing the customers to get litigated against all that stuff because they pulled the family that they were able to know what will happen. It's not working with all that stuff. And so you really need a reliable life safety system. And Cami was coming from a more consumer standpoint than follow up,
Speaker 8
compared to what we expect. Expecting in 2025 is magnitude is different, right? What's changed? Like it seems like, I mean, cities is at an inflection point and something's resonating with the market, or maybe the pipeline build from early this year is paying off. What are the two three reasons why, you know, we can go for 2025
compared to what we expect. Expecting in 2025 is magnitude is different, right? What's changed? Like it seems like, I mean, cities is at an inflection point and something's resonating with the market, or maybe the pipeline build from early this year is paying off. What are the two three reasons why, you know, we can go for 2025
compared to what we expect. Expecting in 2025 is magnitude is different, right? What's changed? Like it seems like, I mean, cities is at an inflection point and something's resonating with the market, or maybe the pipeline build from early this year is paying off. What are the two three reasons why, you know, we can go for 2025
compared to what we expect. Expecting in 2025 is magnitude is different, right? What's changed? Like it seems like, I mean, cities is at an inflection point and something's resonating with the market, or maybe the pipeline build from early this year is paying off. What are the two three reasons why, you know, we can go for 2025
Speaker 1
Yeah, so backed by, you know, we're going to beat our sales members for this year. So we have a lot of confidence in those numbers at this point. The, I think the big thing to understand about this industry is that the pandemic recovery has not been even across operators. So what happened? Basically, let me see if I have a slide on this. What happened was, in 2020, let me say the pandemic hit, and then different groups recovered at different pieces, and so you could really see that play out. And so we had, because so much of our growth is based on customer expansions, we had a bit of concentration risk with one big customer, Senior Living, who unfortunately has had a really hard time. So they've been contracting quite significantly, and they went from being 25% of our revenue to as they were contracting, they're down to something like 12% of our revenue. So what, what I showed before was that 94% of our base two everything, year over year, but we had these headwinds from folks that were really struggling, and so that created this headwind for us, that made our top line number look less, even though we were doubling year over year, or even six year over year from the customer base. So that was kind of the big thing to understand, that we've just hit pre pandemic occupancy on average last quarter, which is back at like 83 84% what this means is the folks that have been doing well are actually like well above this. But folks like from dill are now like, they're like 79% occupancy. If you go look at their stock price, you'll see they've really been hurting. And they actually are going to go they were 1300 communities when we started. Now they're 600 they're going to go down to like 450 communities total. So their business has contracted already by like 60% it's going to keep going, unfortunately, so that that's kind of the main headline thing to understand. The other growth has really been signing new logos. We're going to hit like 80 this year, and having those logos bring us to more locations. Our average customer base has like, 40 locations, and what we would see them do is start in a couple validated outcomes. And so then some of the big things are happening with Guardian Pro is we could really significantly drive these two levers as well. And so historically, we've been able to drive our revenue per bed just with our core products, but by having more and more confidence in it, basically getting more and more validity in the market. But now, as we're able to release things like clarity, we're able to upcharge more and more. And that was always one of the visions, and from that device, we can deliver more and more services. So we're not forecasting crazy amounts. We've added about $10 per year here. And in the future, we're adding like $5 a year. So we're conservative. We can follow our data and things like that, that will also drive revenue growth. And then, in terms of beds per community, we can now pass together more beds per community. Thing is really like this market now is really coming out of the pandemic in a big way. As documents
Yeah, so backed by, you know, we're going to beat our sales members for this year. So we have a lot of confidence in those numbers at this point. The, I think the big thing to understand about this industry is that the pandemic recovery has not been even across operators. So what happened? Basically, let me see if I have a slide on this. What happened was, in 2020, let me say the pandemic hit, and then different groups recovered at different pieces, and so you could really see that play out. And so we had, because so much of our growth is based on customer expansions, we had a bit of concentration risk with one big customer, Senior Living, who unfortunately has had a really hard time. So they've been contracting quite significantly, and they went from being 25% of our revenue to as they were contracting, they're down to something like 12% of our revenue. So what, what I showed before was that 94% of our base two everything, year over year, but we had these headwinds from folks that were really struggling, and so that created this headwind for us, that made our top line number look less, even though we were doubling year over year, or even six year over year from the customer base. So that was kind of the big thing to understand, that we've just hit pre pandemic occupancy on average last quarter, which is back at like 83 84% what this means is the folks that have been doing well are actually like well above this. But folks like from dill are now like, they're like 79% occupancy. If you go look at their stock price, you'll see they've really been hurting. And they actually are going to go they were 1300 communities when we started. Now they're 600 they're going to go down to like 450 communities total. So their business has contracted already by like 60% it's going to keep going, unfortunately, so that that's kind of the main headline thing to understand. The other growth has really been signing new logos. We're going to hit like 80 this year, and having those logos bring us to more locations. Our average customer base has like, 40 locations, and what we would see them do is start in a couple validated outcomes. And so then some of the big things are happening with Guardian Pro is we could really significantly drive these two levers as well. And so historically, we've been able to drive our revenue per bed just with our core products, but by having more and more confidence in it, basically getting more and more validity in the market. But now, as we're able to release things like clarity, we're able to upcharge more and more. And that was always one of the visions, and from that device, we can deliver more and more services. So we're not forecasting crazy amounts. We've added about $10 per year here. And in the future, we're adding like $5 a year. So we're conservative. We can follow our data and things like that, that will also drive revenue growth. And then, in terms of beds per community, we can now pass together more beds per community. Thing is really like this market now is really coming out of the pandemic in a big way. As documents
Yeah, so backed by, you know, we're going to beat our sales members for this year. So we have a lot of confidence in those numbers at this point. The, I think the big thing to understand about this industry is that the pandemic recovery has not been even across operators. So what happened? Basically, let me see if I have a slide on this. What happened was, in 2020, let me say the pandemic hit, and then different groups recovered at different pieces, and so you could really see that play out. And so we had, because so much of our growth is based on customer expansions, we had a bit of concentration risk with one big customer, Senior Living, who unfortunately has had a really hard time. So they've been contracting quite significantly, and they went from being 25% of our revenue to as they were contracting, they're down to something like 12% of our revenue. So what, what I showed before was that 94% of our base two everything, year over year, but we had these headwinds from folks that were really struggling, and so that created this headwind for us, that made our top line number look less, even though we were doubling year over year, or even six year over year from the customer base. So that was kind of the big thing to understand, that we've just hit pre pandemic occupancy on average last quarter, which is back at like 83 84% what this means is the folks that have been doing well are actually like well above this. But folks like from dill are now like, they're like 79% occupancy. If you go look at their stock price, you'll see they've really been hurting. And they actually are going to go they were 1300 communities when we started. Now they're 600 they're going to go down to like 450 communities total. So their business has contracted already by like 60% it's going to keep going, unfortunately, so that that's kind of the main headline thing to understand. The other growth has really been signing new logos. We're going to hit like 80 this year, and having those logos bring us to more locations. Our average customer base has like, 40 locations, and what we would see them do is start in a couple validated outcomes. And so then some of the big things are happening with Guardian Pro is we could really significantly drive these two levers as well. And so historically, we've been able to drive our revenue per bed just with our core products, but by having more and more confidence in it, basically getting more and more validity in the market. But now, as we're able to release things like clarity, we're able to upcharge more and more. And that was always one of the visions, and from that device, we can deliver more and more services. So we're not forecasting crazy amounts. We've added about $10 per year here. And in the future, we're adding like $5 a year. So we're conservative. We can follow our data and things like that, that will also drive revenue growth. And then, in terms of beds per community, we can now pass together more beds per community. Thing is really like this market now is really coming out of the pandemic in a big way. As documents
Yeah, so backed by, you know, we're going to beat our sales members for this year. So we have a lot of confidence in those numbers at this point. The, I think the big thing to understand about this industry is that the pandemic recovery has not been even across operators. So what happened? Basically, let me see if I have a slide on this. What happened was, in 2020, let me say the pandemic hit, and then different groups recovered at different pieces, and so you could really see that play out. And so we had, because so much of our growth is based on customer expansions, we had a bit of concentration risk with one big customer, Senior Living, who unfortunately has had a really hard time. So they've been contracting quite significantly, and they went from being 25% of our revenue to as they were contracting, they're down to something like 12% of our revenue. So what, what I showed before was that 94% of our base two everything, year over year, but we had these headwinds from folks that were really struggling, and so that created this headwind for us, that made our top line number look less, even though we were doubling year over year, or even six year over year from the customer base. So that was kind of the big thing to understand, that we've just hit pre pandemic occupancy on average last quarter, which is back at like 83 84% what this means is the folks that have been doing well are actually like well above this. But folks like from dill are now like, they're like 79% occupancy. If you go look at their stock price, you'll see they've really been hurting. And they actually are going to go they were 1300 communities when we started. Now they're 600 they're going to go down to like 450 communities total. So their business has contracted already by like 60% it's going to keep going, unfortunately, so that that's kind of the main headline thing to understand. The other growth has really been signing new logos. We're going to hit like 80 this year, and having those logos bring us to more locations. Our average customer base has like, 40 locations, and what we would see them do is start in a couple validated outcomes. And so then some of the big things are happening with Guardian Pro is we could really significantly drive these two levers as well. And so historically, we've been able to drive our revenue per bed just with our core products, but by having more and more confidence in it, basically getting more and more validity in the market. But now, as we're able to release things like clarity, we're able to upcharge more and more. And that was always one of the visions, and from that device, we can deliver more and more services. So we're not forecasting crazy amounts. We've added about $10 per year here. And in the future, we're adding like $5 a year. So we're conservative. We can follow our data and things like that, that will also drive revenue growth. And then, in terms of beds per community, we can now pass together more beds per community. Thing is really like this market now is really coming out of the pandemic in a big way. As documents
Speaker 8
increases, right get back to pre pandemic. I think there's more upside. Totally. What's
increases, right get back to pre pandemic. I think there's more upside. Totally. What's
increases, right get back to pre pandemic. I think there's more upside. Totally. What's
increases, right get back to pre pandemic. I think there's more upside. Totally. What's
Speaker 1
Speaker 8
our consumer and these are ones which have experience to fall in pretty low, correct? So these specific folks that opted
our consumer and these are ones which have experience to fall in pretty low, correct? So these specific folks that opted
our consumer and these are ones which have experience to fall in pretty low, correct? So these specific folks that opted
our consumer and these are ones which have experience to fall in pretty low, correct? So these specific folks that opted
Speaker 1
into our program compared to those that did not within the first 90 days of them moving in, which will be, you'll see about 90% opt in. Got it? I think if you want to understand percent
into our program compared to those that did not within the first 90 days of them moving in, which will be, you'll see about 90% opt in. Got it? I think if you want to understand percent
into our program compared to those that did not within the first 90 days of them moving in, which will be, you'll see about 90% opt in. Got it? I think if you want to understand percent
into our program compared to those that did not within the first 90 days of them moving in, which will be, you'll see about 90% opt in. Got it? I think if you want to understand percent
Speaker 8
every three weeks. Oh, that's an important every three weeks, you expect some event on average, on average. Thank you.
every three weeks. Oh, that's an important every three weeks, you expect some event on average, on average. Thank you.
every three weeks. Oh, that's an important every three weeks, you expect some event on average, on average. Thank you.
every three weeks. Oh, that's an important every three weeks, you expect some event on average, on average. Thank you.
Speaker 3
The Long Tail in this industry, there's a value problem. Industry.
The Long Tail in this industry, there's a value problem. Industry.
The Long Tail in this industry, there's a value problem. Industry.
The Long Tail in this industry, there's a value problem. Industry.
Speaker 1
Yeah. So we have customers across the spectrum. Our focus is really owning the enterprise. We also have single site operators. Value proposition Priyesh through regardless, we just expand customers in such a big way that we focus on owning lawyers, because our customers now represents, like, over 400 million in ARR, opportunity. And so the focus has been let those and grow them in a big way. But then what we can see here is that we can get to really high revenue numbers without having crazy market contribution. So the plan of record is, let's hit one 50 million, ar, 2027, and it keeps scaling from air really open this industry. But in that time, as we go past 100 million, Arr, we also will move into significant so being able to support folks in home, being able to expand globally. We've got our first health insurance that's right around the cost of it. There's a ton of everything we talked about Friday, but there's a ton of untapped revenue from the health insurance side. There's a lot of additional product features. Once at a time, the plan ever I heard is execute against this roadmap, hit 100 million plus Ar, and then we can kind of go from there toward supporting folks morning folks living in our home and things like that. So this is really important.
Yeah. So we have customers across the spectrum. Our focus is really owning the enterprise. We also have single site operators. Value proposition Priyesh through regardless, we just expand customers in such a big way that we focus on owning lawyers, because our customers now represents, like, over 400 million in ARR, opportunity. And so the focus has been let those and grow them in a big way. But then what we can see here is that we can get to really high revenue numbers without having crazy market contribution. So the plan of record is, let's hit one 50 million, ar, 2027, and it keeps scaling from air really open this industry. But in that time, as we go past 100 million, Arr, we also will move into significant so being able to support folks in home, being able to expand globally. We've got our first health insurance that's right around the cost of it. There's a ton of everything we talked about Friday, but there's a ton of untapped revenue from the health insurance side. There's a lot of additional product features. Once at a time, the plan ever I heard is execute against this roadmap, hit 100 million plus Ar, and then we can kind of go from there toward supporting folks morning folks living in our home and things like that. So this is really important.
Yeah. So we have customers across the spectrum. Our focus is really owning the enterprise. We also have single site operators. Value proposition Priyesh through regardless, we just expand customers in such a big way that we focus on owning lawyers, because our customers now represents, like, over 400 million in ARR, opportunity. And so the focus has been let those and grow them in a big way. But then what we can see here is that we can get to really high revenue numbers without having crazy market contribution. So the plan of record is, let's hit one 50 million, ar, 2027, and it keeps scaling from air really open this industry. But in that time, as we go past 100 million, Arr, we also will move into significant so being able to support folks in home, being able to expand globally. We've got our first health insurance that's right around the cost of it. There's a ton of everything we talked about Friday, but there's a ton of untapped revenue from the health insurance side. There's a lot of additional product features. Once at a time, the plan ever I heard is execute against this roadmap, hit 100 million plus Ar, and then we can kind of go from there toward supporting folks morning folks living in our home and things like that. So this is really important.
Yeah. So we have customers across the spectrum. Our focus is really owning the enterprise. We also have single site operators. Value proposition Priyesh through regardless, we just expand customers in such a big way that we focus on owning lawyers, because our customers now represents, like, over 400 million in ARR, opportunity. And so the focus has been let those and grow them in a big way. But then what we can see here is that we can get to really high revenue numbers without having crazy market contribution. So the plan of record is, let's hit one 50 million, ar, 2027, and it keeps scaling from air really open this industry. But in that time, as we go past 100 million, Arr, we also will move into significant so being able to support folks in home, being able to expand globally. We've got our first health insurance that's right around the cost of it. There's a ton of everything we talked about Friday, but there's a ton of untapped revenue from the health insurance side. There's a lot of additional product features. Once at a time, the plan ever I heard is execute against this roadmap, hit 100 million plus Ar, and then we can kind of go from there toward supporting folks morning folks living in our home and things like that. So this is really important.
Any other question from the
Any other question from the
Any other question from the
Any other question from the
Speaker 3
team, thanks George and lake for staying that long and also coming pretty well prepared if you can stay on for three four minutes,
team, thanks George and lake for staying that long and also coming pretty well prepared if you can stay on for three four minutes,
team, thanks George and lake for staying that long and also coming pretty well prepared if you can stay on for three four minutes,
team, thanks George and lake for staying that long and also coming pretty well prepared if you can stay on for three four minutes,
Thank you, everybody. Nice meeting you. Thanks for.
Thank you, everybody. Nice meeting you. Thanks for.
Thank you, everybody. Nice meeting you. Thanks for.
Thank you, everybody. Nice meeting you. Thanks for.
Speaker 1
Nice to see you all. Appreciate you bustling to get time for this round. I'll introduce myself as part of the presentation, but look, why don't you go ahead and introduce
yourself. Hi everybody. I'm Loic Juilliard,
Speaker 2
I'm a CTO Pacific. You've been with the company for almost two years now. The third year, financial technology, the entire stack for the company. I started marker my career not very far. If you're in San Juan, not very far from your Qualcomm office there. I started in Surat la as well for a company at the team at the time named sur net. It was part of at&t labs. We were particular data center staff across from that little gardens over there. So, so I started an ATT LA to stay there for for five to six years, and moved on to speed collector for for me, you call it light micro, which Interesting enough, I think so, some of the work with Tara. I worked with him as well at light micro, MCC and RPC, and then ARM processors, and did a sort of solutions with that. Then, when I was at T I worked for a gentleman by the name of Steve Fisher, became the CEO of Salesforce. He wanted me to join Salesforce, which I did. I stayed there for seven years and done. My company grew really very fast, and some of that service delivery. And when I left, I was the head of healthcare for the health and Salesforce. The Salesforce to go to Unity Technologies. I was responsible for all the online services games. For those of you who play games, or kids that play games, probably played Bucha and go, which was implemented on unity. Unity has 1.3 billion devices in the world running their game. So we were receiving events and providing services for all these devices, that includes the as business, that includes a multiplayer and all the event and profiling of players through event management. So I stayed there for over two years. Then I went to Sama, which was a different thing. It was nonprofit that turned for profit. We were doing computer vision and specifically annotation for very large corporations, Google, Tesla, Waymo, we're all customers of sama. There was a mission behind this. It was to educate folks inside of Africa in AI adaptation, we're giving him the skill sets. We were first reviewers and eventually found their own company there. And last but not least, I moved up Salah and joined safely you working with George here. I was personally my family, and I saw some resonated with me. I kind of
optimistic where we are technology. Do
Speaker 3
you have a hard stop at 830? Move? Really started
Speaker 1
safety charge. Quick question,
how much
Speaker 4
time the video is when you get to fall right? Is it a video that you save, or is it two minutes? I mean, how long is the video running? Buffer of 10 minutes. And
Speaker 1
then basically what will happen is they'll get, as soon as an on ground event is affected, they're gonna get the 10 minutes of prior video, and then they're also gonna get all the time somebody around and 10 minutes post. So how we're total usually, how did you get to sell the factories? So many
things, mostly, this is a long process of
Speaker 1
a long period where we've obviously collected a ton of data at this point, so we believe we have a wider support healthcare data set. We're approaching 100 terabytes of video data. But we also develop a process where we use the human and loop to basically tune our algorithms to really, really high sensitivity, and then we screen muscle armed out through the human loop our customers. We got a science fiction level product that's on us to get our accuracy to a point where our cogs makes sense. And so a long journey with this company was really just iterating and hammering and doing more and more things to train models of more data, one time, overfit to each individual community before the support of general model things like that.
Speaker 4
So now we're at 80% margin, including the loop for the false alarms. To read out the false alarms. George,
Speaker 5
for this clear video review? Is it done by the nurse or done by the AI? Yeah, so today
Speaker 1
it's done by the nurse. We are collecting all of the data that is being inputted to our system. Is label training data. And one of the things that we will build is the first ever AI occupational therapist. So you can imagine what will happen is, but after that program today is a clinician will look at the video and say, Aha, here's the things that we should change. We can see, you know, basically what happens without us is this person is just found, you know, see, if I have the moment where, so the staff member comes in and stands right here, and she's just found here by the doorway. And so what they have to try to address it. So what they'll do is say, like, Well, we found her in socks. Maybe, let's try non slip socks. But they don't really know. And so now for the first time, they can actually know and they could address it. And all of that data to our system. So you can imagine a world where we're automatically generating, incorporating all that into our system and saying, This is exactly what you should change. And then we can hit a truly global scale and support folks in developing countries things like that
with the first ever AI. So is this clear
Speaker 5
video review also part of the post? Of all like protocol? Because I kind of learned that from another startup that's after the fall, there's a protocol that's the nurse no need to immediately check the senior people in order to avoid any potential legal issue. So is this already a part of the workflow right now? It
Speaker 1
is. Yeah. So what they're supposed to do is, after every fall they're supposed to identify something, but basically today they're throwing drugs in the dark. So they would say things like, let's try changing our socks. And what you can see here is actually the stocks are going to the ground. So the intervention in this case was, it's about 830 in the morning, and she's getting out to go to the restaurant on her own, and so they instead, basically will court first, and they rounded on her before they support everybody else. They go to the bathroom proactively. But we see all sorts of things where it's like, oh, this person's getting dizzy when they're getting from a bunch of medications. And make sure we can have a right trade off for them, because maybe that medication is actually putting them at more risk. That's where. Or we'll see things that are like not medical panel. One that really stuck with me is this lady had two baby dolls. She, like, legitimately believes these in her infants, and she's caring for them, you know, session, she's in a twin size bed, like this one, and she couldn't, like, all three of them, couldn't fit in the bed comfortably, and so she was basically sliding out of bed. There wasn't enough space. And so the intervention wasn't anything medical. Was to get her a crib next to the bed so she could see that her babies were safe. It's all about how we understand somebody's on that need. All this innovation for childcare that just hasn't happened for owner care. There's like a million AI smart gaming cameras, but if you think about a similar set of needs on the other side of life, we have like, the same kinds of needs where we really like to go with support folks. And then with this data set, we can basically go earlier and earlier product roadmap is we support with the folks most in need. And then we collect this data set, we just add and just add more and more value, or just support a broader runner. George
Clark, do you go up on getting such a large data set
Speaker 1
slowly and thankfully, you have to be really committed to start this company, because it took us a year to get our first 22 falls, and then it was just like by getting more and less more traction, bootstrap more data and grow the data set further and further and get to a point where now the flywheel is just spending more just spending more by delivering customer value, we're getting more and more data and able to release more and more products. How
many unique endpoints? How many unique endpoints? Is that we've
Speaker 1
supported about 20,000 residents today. We have about 10,000 cameras, and it's
going to explore more period of time, approximately. My
Speaker 1
Speaker 6
product in 2019 and so you've been working with various organizations where you have segmented specific types of environments where you're not that you'll be able to capture the data that you're looking for, and you do that through your relationships and partnerships with various medical industries, I guess, has not focused there are customers, right? We're delivering
Speaker 1
the product and getting paid to deliver the product and service for them, and then by delivering the product and getting paid by customers, we can access the data set. Thank you. This
Speaker 7
is mostly deployed in nursing, health care facilities, right? George, I mean, you mentioned how many communities, like 500 community each community has roughly how many there's about 100 beds where the data collected five years
Speaker 6
or so, usually one camera or location, so you don't have to deal with stitching of video feeds, and you essentially have a final location in the room that provides you with the complete footprint of the room itself. That's right.
Speaker 3
Thank you. Now, I think maybe a good point to actually also talk about the transition that you made to snap dragon chips and why and how that happened. Yeah, definitely. So in perspective of the data
Speaker 2
set, if we stitch the videos together, we have 16 years of videos
we have today.
Speaker 1
So loics, I can always come back and talk more about customer interaction,
Speaker 2
sure, so I'll talk about the technology there. So Titan is our platform. This is the overarching platform that manages our services from the premises all the way to cloud in the location, back to the facilities. And here, for the purpose of this presentation, we split in three layers. One layer is a sense services as well. We use the quantum technology and web cloud services to route and log and report. There's a tremendous amount of reporting services available. And the last part of the AI is, these are the models that we train that run on premises equipment to deliver the service that we have. So, yeah. So this is, this is our guardian Pro. This is our camera. We did not I'm gonna brag about this one more time, because we deliver this camera in eight months. This is from the time we actually the ideation all the way to the first system, first camera delivered with code running incredibly fast. We were at GA in about 18 months total, today, we have 1000 studies deployed. So it's gone extremely well. It's camera that has been built for the environment is running in, yes, visible to human servants. And it's really energy. We call it an AI processing build. These are the best optical capabilities, because this is giving us incredible amount of processing power that we can run many, many models. Can run many, many models. It's also really diverse in terms of connectivity, super squi, power Ethernet, and also LT, 5g modem on
there. So we have many
ways of multiple models, maybe
Speaker 6
something that triggers an event, and then vision first, yeah, it's mostly
escalator. At this point, we are monitoring the
Speaker 2
video feed, and we trigger it based on an AI detection and a series of event reading, the event workflow execution that follows after that, the event happening is in the cloud. The camera is really all about detection. It's a sensor. It's just process of video content from together. Video content.
Speaker 6
So there is some kind of motion detection, and I guess you have some
assessment of the frame or not.
Speaker 2
Yeah, we have some filtering in. There is really an AI model learning that takes care of all this sort of motion all the time, logic stuff based on the detection, these decisions on whether to do with that comment,
and then the buffer.
Speaker 2
Yeah, so the camera has enough, has readily intelligent. It keeps a buffers before and after. So it has basically a trailing, trailing say to videos when, when you send one minute video for detection by the detection, by the detection of everybody smart and confirm that the fall, we are fetching the video out to the camera. So the pre buffer and the post buffer is fetched at a camera. And basically we have a window. We know video and everything is persisted on a
Speaker 7
camera about three hours, four hours. Key event they're looking for is the fall. So if they detect some falling event, that's the one that triggers the video record.
Speaker 2
We have a level event is sent out, it's it's confirmed as a fall, and a request is made back to the camera for a pre buffers of attendance before, and all the rest of videos. And that gets uploaded where the customer reads the
content process.
Speaker 2
Yeah. So we, I think George mentioned that we have human loops. We have a team of the monitors the events coming in to see one minute video, the minute that trigger the detection, and once they confirm that is the fall, this is where the sequencing happens, in terms of downloading the video sensors stitching back together so we form one continuous video. Customer. Can see this is what's used to assess the fall as well from our staff. So for this, 10,000 cameras, how many humans do you have?
And right now we're around 16 human
Speaker 2
latest number, yeah. So it's also
a lot of security, physical
security on that
side, for
Speaker 2
example, no cell phone allowance. No cell phone allow incidental secure, physical, physical security.
Speaker 8
Like one quick question on this, if you get camera feed from any camera, which is not necessarily safely, I'm trying to understand if this software stack will still be applicable, you can still default detection. You can still
Speaker 2
call out events in the workflows. That's correct. So we actually do have not all our sources. We had prior cameras that we use. Prius model we had was a two stage models, camera streaming into a server that located in the premises, and the detection would be the server could have up to 30 cameras seeing on one server. I think that we can do it now in AI there's a lot of sensitivity on your sensor, the model is naturally better detecting things for sensors that you know that is being trained on and using also different cameras definitely require more training, so it's not as easy as just adding a video stream. You would get
at least six different camera
types we have going forward
basis, I
Speaker 7
think this is the camera you deploy now, right with other camera that's right, and
what's the
chip that's in there, which, which? Which? 5165
Speaker 2
okay, well, this is a selection process we went, I'm sure some more how we got there. So these are the chips we considered at a time. We shortlisted umbrella and Qualcomm, pretty typical there. And we'll see we're running it fully containerized. I'll talk about this a little bit later. It's a fully it's really beautiful design. So that was really important for us, more cost effective, but has issues with containerized support. We were able to support that with Qualcomm at the time, we did not look at the 5165 so we looked at these two, because was a bigger issue, but we actually work this out. So next
Speaker 6
slide there is more specific what specificities to be offered
physically, I think the be awesome.
Speaker 2
Yeah, we're running in there, 65 and we're using your QCs. 6391 there for Wi Fi,
Speaker 3
what specifically for containerization to be provided versus umbrella. So the version
Speaker 2
of the version of OS that umbrella is running does not support containerization at all, so we would have had to recompile the kernel with CD 25 which we tried, and I think eventually we could have made it work, but there was no support on the app for this. Thank you. So to the next slide. This is what containerized workload we use here. So really it's a it's set up as an immutable set, very much like a data center would be set up so much, so much power on this bus, running different containers, on Docker, on the system, on deployment, is container. Is what you're seeing on that red box there is our perception plane. We call that energy to different services. We're able to run experimental production model at the same time, so that when we push the model, we will turn inside and promote them based on the results that we get in production. So we're basically detecting that falls and stuff to detect at the same time or better. And then once, once we get these results, we switch over. We monitor, if you can imagine, select 60 devices. We monitor every points that we can on the device, temperature, every component is monitor the quality of the network and so forth, and so that gives us a lot of control to the level. It's worked out really well. It's fairly advanced. What we're running there to be incredibly reliable. So far, deployment, as well as container, has to be a container out to that system, just operating from the rest. How
much storage did you have on the device, on the camera? So actually,
Speaker 2
if you go back to slides before we have a gig up RAM and MCC and AMC, and I'm trying to get microSD,
Okay, looks like that's the sale of backup,
right? That's correct,
Speaker 2
yeah. And then we have four banks of IR, individually controlled. And then we talked forward and bring almost 40 months of IR into the camera, we can eliminate things at 200
feet away. And
Speaker 1
we're designing this whole spectrum. So instead of having a little red.so instead of having a little red.it completely dark that
Speaker 4
night. So it doesn't look like a scary red eye in terms of the OS itself. But it is energy Linux
Speaker 2
that you're using, or is it camera based solution we're using Yocto. So that there's also, there's no calling on the device. Is all that cooling, so there's no fan whatsoever. There's a lot of effort on temperature management we have to do. So we're bringing in 40 ones on social small devices. It's quite a bit small surface,
Speaker 1
but yeah, in the core parameters that we really needed from this, as you saw, it, was the key to building this company, was getting access to this data set that nobody has had before. And now we're, at this moment, we're going to train all these other AI models. And so really key for this device is that we need to have the capacity to be able to deploy many, many more AI models, and also not becoming and changing cameras and things like that. So we wanted fan lists, so could be there for 510, years, but also have the capacity for us just deploying more and more software
Speaker 2
on top of it. 21 has a software stack, if you want to go down, is what we're running. I was using yoyo, the distribution that we're getting, and then we have yellow five Al, yellow five Ling data. So we've been quantized and normalized using actually quantum skill set. So we start with the same p DLC model and convert, convert to our NMX depending on what we want to do. That's what we use. And any dwarf so fisheye land, so we can put it anywhere on the wall. It's really flexible. And then we virtual pan tail to reach capture awesome
experience with IoT Core? You can use IoT Core. It's
Speaker 2
been pretty good. So we're running all the other modules at this point, as the integration has been okay. Grid Grass, On the other hand, is too limited, and then we're having issues with supports on the Choose module. So we just, we just get 100 grams, but the IoT Core has been good. Very reliable. Is okay. So let finicky had time, but
Speaker 8
no. Good to see your containerized architecture to the platform. One question I had around, you know, any perception module or any model that comes in the future that's maybe equally as good or even better, involves, can you adopt that model for your text tech platform? And are you thinking thinking of those lines, or how do you see that play out?
Speaker 2
Yeah. So for the models we are starting to experiment with transformer, namely, RTD, turn it supported on led 2.0 Thank you very much. We just, we, we actually, we actually saw that. And we already write experiments on on our servers, and then we're going to try it on the cameras very soon. So that would give us the plus is better performance, much better detection accuracy. I think the negative part is the training time is almost four or 5x so it takes us 48 hours right now. He would expect a week to produce them all. They don't retrain that often, but that's going
Speaker 8
to provide a lot. A lot of those. Cost will also come down, I guess, and there's a
Speaker 2
lot of optimization that are being worked on on the training side, so we might be able to fall I'll talk a little bit later about different models we can train there, where the use cases are actually so that's all going to be running on the camera. So we're working on
Speaker 7
that. Would you guys have any other questions, maybe on the tech, on why they choose Qualcomm, etc? We could
Speaker 2
go on the next slide. So I thought you'll find that interesting. This is actually our inference cost. Because we're not doing any inference in a cloud. We're not we don't have to pay for power. We have to pay for GPUs. Everything is done because of age, and this is a cost saving from an Amazon expense, 77% for us. Unlike most startups, scaling AI is not an issue, really fleet, obviously. But in terms of cost, it's linear, right? Because every time we deploy a camera, we are getting the revenue from that camera, and we're increasing our pool of devices that can actually infer so as we get more contracts, we're increasing basically our pool free is becomes available at the same time our revenue grows. And that's incredibly powerful. We only use 50% of the camera capacity today. It's a very powerful process. You meet 50% of the available like in terms of insurance capacity,
Speaker 4
container support being one reason spec for choosing any other reasons.
Speaker 2
and then we featured in
so we could look at
Speaker 2
their solution on the Nano version, just a nano, the performance wasn't that great for the price point. It was a bit of a dissonance between their price point. They had better, had better solutions on their better, more powerful solution, solution. They were really costly as well. So it really didn't, didn't come out to be, to be the right solution. The capacity of the Nano was much more 65 and in the end, for the price point, we would not have had that coming out now, just on
Speaker 1
that point, architect system didn't involve deployed run camera streams for that server, 24/7 and that had a video set. So you guys have, officially, we're no longer deploying individual views and now deploying reviews, and now, in terms
Speaker 4
of the container support, what do we have on 56 isn't good enough, but we like something else.
Speaker 2
It's things we've experienced. So the container is okay. I think the part I said that has been a little bit more difficult is that support of aileon Yoko, the Yoko version, is not the latest compiling area containers forming the containers often used. All the libraries are not compatible with the system that we're using. We try to stay on the latest containers out there, and that has been an issue
Speaker 4
like maybe offline. If you describe the problem and send to shout an email, we appreciate it
later. Of support
Speaker 2
on the floor was a surprise, because expired, basically, and when we got it, and now we have, there's a gap between now and the next version, so yeah, and then the AGC is a big change for us, because we do a lot of nitrogen. Having a single point for for AGC, the auto exposure is a problem, but that's, that's, yeah, that's something, thanks. Like, we had
a really good experience, and
Speaker 2
our customers have had a really good experience. The cameras went out, and we have yet to have a single camera with a hardware killer.
Speaker 1
George, how are you doing this using large language models or some of the ways?
Speaker 1
So knowing staff in the room is the exact same kinds of models we've been using, so computer vision can detect the staff member versus the resident. And then what we're building for is using LLM to extend is using LLM to exactly that. Okay, yeah, that will be running on
Speaker 2
the camera. We're going to be running on camera. I have a slide later on to discuss
Speaker 4
this. How many parameters? How many billion parameters? Yeah,
Speaker 2
so that's a good question. We would have to make it fit on the camera. Yeah, we haven't determined that yet. What we are running is we're doing nice experiments on detection itself and the translation into text that seems physical. We need to figure out how we want to Geo the inference that question we have right now we might have to TLD infer so we do initial inference in on the edge and forward content out for secondary inference.
Speaker 4
So once you learn more, if you want to discuss less, absolutely, there's definitely more
part of our future question regarding
Speaker 5
use cases. So you know some of the four, actually, many of the four happened in the bathroom. How would you solve the issue for computer in the bathroom? Because it requires really high privacy. People might not want the bathroom.
Speaker 1
Speaker 8
use case. Okay? So that's just one, one question on the industry. It's not a very well managed industry, especially nursing homes and elderly care. My question is, you know, one of the challenges in these facilities is neglect and sometimes abused, right, by some of the workers that can these video feeds be used against the care giving members, right? And I'm trying to think, from a lot library perspective or compliance perspective, thing that's on your mind or on you know, these are the owners of these facilities. I'll be thinking about
that. Yeah, great question. So
Speaker 1
the, those are some of the big questions we got, again, early in company history. And one of the reasons why it was so important that we only have video of these specific moments and people can go look and respond to that video, because if we have video reporting all the time, it exposes that to a lot
Speaker 8
of potential risk that's exactly select when the fall is detected. You only cut the
Speaker 1
important nuance to understand is that about 75% of all litigations against nursing homes come from falls. Yeah. So we dramatically break down the number of falls and skipped over something, but we're just in our falls by about 50% and now we're at a point where, for instance, one of the contracts that came in was because that organization got a 19% production because of us, they basically can really reduce their risk using our system. And that's a lot of what now goes into like, we need to know how these risk events are happening so we can access them, but we don't want to get exposed
with all the other potential data. Thank
Speaker 9
you, George, just a couple of questions. Sorry for asking later said continuation actually, to answer questions. A lot of these nursing homes, they actually buy all kinds of technologies, for example, some of the nonprofit of all detections, etc. It's
hard to hear
Speaker 9
Speaker 1
there. Your middle question.
Speaker 9
I was wondering if you actually looked into a shield of glass, if you actually have this type of plastic on top, on top of this answer, we'll definitely solve a little bit of the perception problem. There's always gonna be a percentage of people that, yeah, I
Speaker 1
think for our next generation sensor in particular, where we want to be able to run detection without keeping any video, I don't want to make it really clear to you so that that's what's happening. That kind of thing would be really interesting story design for that right now. Yeah, so
Speaker 9
Speaker 3
I don't know any other questions from our team. So there was one question, George from our team as well. Did you ever run into CAMI vision? So once you order you want can be vision versus
we can kick your ass.
Speaker 1
But I was quite trying to maybe two years ago, where they came in and basically just trying to copy what we're doing and offer a much lower cost. They're offering, like 25 bucks a month towards we start 25 bucks a month today, and it was a joy to see if our customers were interested, but the product just really didn't work very well in reliability. They tried to do in the human loop, which was really part of my process standpoint, as mentioned, as a vendor. And so folks that were interested, try to not have good experience. What you have to kind of understand is that this is a life safety system. And like, if you're telling a family you're going to be there at a really serious moment that you're not, it's a big deal, and now you're exposing the customers to get litigated against all that stuff because they pulled the family that they were able to know what will happen. It's not working with all that stuff. And so you really need a reliable life safety system. And Cami was coming from a more consumer standpoint than follow up,
Speaker 8
compared to what we expect. Expecting in 2025 is magnitude is different, right? What's changed? Like it seems like, I mean, cities is at an inflection point and something's resonating with the market, or maybe the pipeline build from early this year is paying off. What are the two three reasons why, you know, we can go for 2025
Speaker 1
Yeah, so backed by, you know, we're going to beat our sales members for this year. So we have a lot of confidence in those numbers at this point. The, I think the big thing to understand about this industry is that the pandemic recovery has not been even across operators. So what happened? Basically, let me see if I have a slide on this. What happened was, in 2020, let me say the pandemic hit, and then different groups recovered at different pieces, and so you could really see that play out. And so we had, because so much of our growth is based on customer expansions, we had a bit of concentration risk with one big customer, Senior Living, who unfortunately has had a really hard time. So they've been contracting quite significantly, and they went from being 25% of our revenue to as they were contracting, they're down to something like 12% of our revenue. So what, what I showed before was that 94% of our base two everything, year over year, but we had these headwinds from folks that were really struggling, and so that created this headwind for us, that made our top line number look less, even though we were doubling year over year, or even six year over year from the customer base. So that was kind of the big thing to understand, that we've just hit pre pandemic occupancy on average last quarter, which is back at like 83 84% what this means is the folks that have been doing well are actually like well above this. But folks like from dill are now like, they're like 79% occupancy. If you go look at their stock price, you'll see they've really been hurting. And they actually are going to go they were 1300 communities when we started. Now they're 600 they're going to go down to like 450 communities total. So their business has contracted already by like 60% it's going to keep going, unfortunately, so that that's kind of the main headline thing to understand. The other growth has really been signing new logos. We're going to hit like 80 this year, and having those logos bring us to more locations. Our average customer base has like, 40 locations, and what we would see them do is start in a couple validated outcomes. And so then some of the big things are happening with Guardian Pro is we could really significantly drive these two levers as well. And so historically, we've been able to drive our revenue per bed just with our core products, but by having more and more confidence in it, basically getting more and more validity in the market. But now, as we're able to release things like clarity, we're able to upcharge more and more. And that was always one of the visions, and from that device, we can deliver more and more services. So we're not forecasting crazy amounts. We've added about $10 per year here. And in the future, we're adding like $5 a year. So we're conservative. We can follow our data and things like that, that will also drive revenue growth. And then, in terms of beds per community, we can now pass together more beds per community. Thing is really like this market now is really coming out of the pandemic in a big way. As documents
Speaker 8
increases, right get back to pre pandemic. I think there's more upside. Totally. What's
Speaker 1
Speaker 8
our consumer and these are ones which have experience to fall in pretty low, correct? So these specific folks that opted
Speaker 1
into our program compared to those that did not within the first 90 days of them moving in, which will be, you'll see about 90% opt in. Got it? I think if you want to understand percent
Speaker 8
every three weeks. Oh, that's an important every three weeks, you expect some event on average, on average. Thank you.
Speaker 3
The Long Tail in this industry, there's a value problem. Industry.
Speaker 1
Yeah. So we have customers across the spectrum. Our focus is really owning the enterprise. We also have single site operators. Value proposition Priyesh through regardless, we just expand customers in such a big way that we focus on owning lawyers, because our customers now represents, like, over 400 million in ARR, opportunity. And so the focus has been let those and grow them in a big way. But then what we can see here is that we can get to really high revenue numbers without having crazy market contribution. So the plan of record is, let's hit one 50 million, ar, 2027, and it keeps scaling from air really open this industry. But in that time, as we go past 100 million, Arr, we also will move into significant so being able to support folks in home, being able to expand globally. We've got our first health insurance that's right around the cost of it. There's a ton of everything we talked about Friday, but there's a ton of untapped revenue from the health insurance side. There's a lot of additional product features. Once at a time, the plan ever I heard is execute against this roadmap, hit 100 million plus Ar, and then we can kind of go from there toward supporting folks morning folks living in our home and things like that. So this is really important.
Any other question from the
Speaker 3
team, thanks George and lake for staying that long and also coming pretty well prepared if you can stay on for three four minutes,
Thank you, everybody. Nice meeting you. Thanks for.
How accurate was this transcription?