Meeting: Traverse3D
Tue, Jun 18, 2024
1:02 PM
30 min
Priyesh P
AI and computer vision investments.
0:00
AI te
URL: https://otter.ai/u/8j3_lh0I9vNpBSDbCXlSPntjmtI
Downloaded: 2025-12-22T15:11:51.831612
Method: text_extraction
============================================================

S Speaker 10:00Yeah. So the evening pleasure connect. You know, I heard great things. So I'm really looking forward to meeting okay. So I'm a little bit about my background and Qualcomm ventures, as you can introduce yourself as well. And then we'd love to learn more about what you're building in your background as well. Even though I know a little bit
Yeah. So the evening pleasure connect. You know, I heard great things. So I'm really looking forward to meeting okay. So I'm a little bit about my background and Qualcomm ventures, as you can introduce yourself as well. And then we'd love to learn more about what you're building in your background as well. Even though I know a little bit
Yeah. So the evening pleasure connect. You know, I heard great things. So I'm really looking forward to meeting okay. So I'm a little bit about my background and Qualcomm ventures, as you can introduce yourself as well. And then we'd love to learn more about what you're building in your background as well. Even though I know a little bit
Yeah. So the evening pleasure connect. You know, I heard great things. So I'm really looking forward to meeting okay. So I'm a little bit about my background and Qualcomm ventures, as you can introduce yourself as well. And then we'd love to learn more about what you're building in your background as well. Even though I know a little bit
S Speaker 20:35absolutely same. Do you mind if I have to read AI notes? I just want to be very clear.
absolutely same. Do you mind if I have to read AI notes? I just want to be very clear.
absolutely same. Do you mind if I have to read AI notes? I just want to be very clear.
absolutely same. Do you mind if I have to read AI notes? I just want to be very clear.
S Speaker 10:42I think well, yeah, well, good. Yeah, I wish I was curious because you don't have like every meeting so there's there's different versions. Some people at otter some people. Firefly as some other one and then read is the first one. You may have heard of, really, really? So that's the first one. Yeah. So So my background is at Qualcomm background in engineering, camera, computer vision, background and then hence I was really excited about today.
I think well, yeah, well, good. Yeah, I wish I was curious because you don't have like every meeting so there's there's different versions. Some people at otter some people. Firefly as some other one and then read is the first one. You may have heard of, really, really? So that's the first one. Yeah. So So my background is at Qualcomm background in engineering, camera, computer vision, background and then hence I was really excited about today.
I think well, yeah, well, good. Yeah, I wish I was curious because you don't have like every meeting so there's there's different versions. Some people at otter some people. Firefly as some other one and then read is the first one. You may have heard of, really, really? So that's the first one. Yeah. So So my background is at Qualcomm background in engineering, camera, computer vision, background and then hence I was really excited about today.
I think well, yeah, well, good. Yeah, I wish I was curious because you don't have like every meeting so there's there's different versions. Some people at otter some people. Firefly as some other one and then read is the first one. You may have heard of, really, really? So that's the first one. Yeah. So So my background is at Qualcomm background in engineering, camera, computer vision, background and then hence I was really excited about today.
S Speaker 31:24You know, I've been working on image regeneration for a while, but those are those are techniques from years ago.
You know, I've been working on image regeneration for a while, but those are those are techniques from years ago.
You know, I've been working on image regeneration for a while, but those are those are techniques from years ago.
You know, I've been working on image regeneration for a while, but those are those are techniques from years ago.
S Speaker 11:36And since then, the word evolved to nurse and then now Garcia and splatting and so exciting for sure. So I'm curious to learn more.
And since then, the word evolved to nurse and then now Garcia and splatting and so exciting for sure. So I'm curious to learn more.
And since then, the word evolved to nurse and then now Garcia and splatting and so exciting for sure. So I'm curious to learn more.
And since then, the word evolved to nurse and then now Garcia and splatting and so exciting for sure. So I'm curious to learn more.
S Speaker 11:50product management bunch of different roles. I used to run our camera business as well. And then I joined Qualcomm ventures about seven years ago. So invest in you know, me and Francesco we've got a similar thesis and computer vision camera computer vision. And that's what you know that that subject just was talking about, where some and so invest in AI heavily computer vision, the type of areas. The firm has been around for me for years.
product management bunch of different roles. I used to run our camera business as well. And then I joined Qualcomm ventures about seven years ago. So invest in you know, me and Francesco we've got a similar thesis and computer vision camera computer vision. And that's what you know that that subject just was talking about, where some and so invest in AI heavily computer vision, the type of areas. The firm has been around for me for years.
product management bunch of different roles. I used to run our camera business as well. And then I joined Qualcomm ventures about seven years ago. So invest in you know, me and Francesco we've got a similar thesis and computer vision camera computer vision. And that's what you know that that subject just was talking about, where some and so invest in AI heavily computer vision, the type of areas. The firm has been around for me for years.
product management bunch of different roles. I used to run our camera business as well. And then I joined Qualcomm ventures about seven years ago. So invest in you know, me and Francesco we've got a similar thesis and computer vision camera computer vision. And that's what you know that that subject just was talking about, where some and so invest in AI heavily computer vision, the type of areas. The firm has been around for me for years.
S Speaker 12:30corporate venture firms. And so we invest in areas that are broadly speaking, pushing the boundaries of compute and so and so so, so that uses theme has remained the same. It's just that areas keep changing as the world keeps evolving to mobile, to mobile related technologies going into everything else, you know, ioki and automotive and xr devices,
corporate venture firms. And so we invest in areas that are broadly speaking, pushing the boundaries of compute and so and so so, so that uses theme has remained the same. It's just that areas keep changing as the world keeps evolving to mobile, to mobile related technologies going into everything else, you know, ioki and automotive and xr devices,
corporate venture firms. And so we invest in areas that are broadly speaking, pushing the boundaries of compute and so and so so, so that uses theme has remained the same. It's just that areas keep changing as the world keeps evolving to mobile, to mobile related technologies going into everything else, you know, ioki and automotive and xr devices,
corporate venture firms. And so we invest in areas that are broadly speaking, pushing the boundaries of compute and so and so so, so that uses theme has remained the same. It's just that areas keep changing as the world keeps evolving to mobile, to mobile related technologies going into everything else, you know, ioki and automotive and xr devices,
S Speaker 33:01having had men to cloud and to AI and
S Speaker 13:06so we have businesses, we have, you know, vertical businesses, business units, and each one of these multibillion dollar businesses and so, so investment mandate is across all of these areas, so which makes it fun, but also look at that stuff. So we tend to invest even to $10 million initial check size, but
so we have businesses, we have, you know, vertical businesses, business units, and each one of these multibillion dollar businesses and so, so investment mandate is across all of these areas, so which makes it fun, but also look at that stuff. So we tend to invest even to $10 million initial check size, but
so we have businesses, we have, you know, vertical businesses, business units, and each one of these multibillion dollar businesses and so, so investment mandate is across all of these areas, so which makes it fun, but also look at that stuff. So we tend to invest even to $10 million initial check size, but
so we have businesses, we have, you know, vertical businesses, business units, and each one of these multibillion dollar businesses and so, so investment mandate is across all of these areas, so which makes it fun, but also look at that stuff. So we tend to invest even to $10 million initial check size, but
3:34five is our sweet spot and series agnostic for the most part, but I would say
five is our sweet spot and series agnostic for the most part, but I would say
five is our sweet spot and series agnostic for the most part, but I would say
five is our sweet spot and series agnostic for the most part, but I would say
S Speaker 45:21I just keep it brief. We are excited. To hear from you, James. I'm a recent graduate MBA graduate from UCLA and prior to that I have worked with several early stage startups in product growth, fundraising, more recently been working with several venture funds, including Menlo Ventures Morpheus, and very recently joined this amazing team at Qualcomm.
I just keep it brief. We are excited. To hear from you, James. I'm a recent graduate MBA graduate from UCLA and prior to that I have worked with several early stage startups in product growth, fundraising, more recently been working with several venture funds, including Menlo Ventures Morpheus, and very recently joined this amazing team at Qualcomm.
I just keep it brief. We are excited. To hear from you, James. I'm a recent graduate MBA graduate from UCLA and prior to that I have worked with several early stage startups in product growth, fundraising, more recently been working with several venture funds, including Menlo Ventures Morpheus, and very recently joined this amazing team at Qualcomm.
I just keep it brief. We are excited. To hear from you, James. I'm a recent graduate MBA graduate from UCLA and prior to that I have worked with several early stage startups in product growth, fundraising, more recently been working with several venture funds, including Menlo Ventures Morpheus, and very recently joined this amazing team at Qualcomm.
S Speaker 25:42Pretty cool. That and pretty excited about this calling Well, big fans of Qualcomm for a while, actually for a variety of reasons. It's just a big fan of the tech Snapdragon and so the XR devices that you've put out when I was doing work in the lab we played with a few of those. And I think generally I don't get to speak with as many people who are knowledgeable about the space. The fact that you've come into this knowing what they're missing is tremendous. So they're very excited to tell you more about why we're building over building what we're building and why we're excited about it. A little bit of background on myself and I'll kind of flow into the the formal deck after that. But so I was from Nebraska, born and raised I got my degree in mechanical engineering and then robotics Meyer from Nebraska. My only engineering experience but true engineering experience was a fellowship at NASA when I was in school that was building common systems building drones. There was great I knew I wanted to kind of play in this deep tech vertical later on. But I was also in ROTC. And so I wanted to go and join the military afterwards. And I was an infantry officer for a number of years and I was a platoon commander, had an experience lots of leadership. And then I went into information operations which is far more technical. role. I was overseeing a lot of floor and a variety of different capabilities, which I will talk about at length, if you'd like me to but also opened my eyes to how technology was changing in the federal sector as well. And so I knew that I wanted to get out and I wanted to do something generally in that domain detect for federal government, or at least mission critical, which kind of widen the aperture to oil and gas, law enforcement, mining and other critical industries. And so came to Stanford to get my MBA as well. Love the MBA representation and also the engineer representation as well. But my I got my degree and Business Administration, and then also an additional degree in MS and symbolic systems, just kind of like cognitive science. And I was I was doing that I was working while we were doing the MBA. Yeah, yeah. So technically I am on a we have I graduated from the MBA program. I'm on a leave of absence from these blocks. It's a program I don't know if I'll actually go back and finish it. But let me take some of the deep learning and computer science courses that I really wanted to take you as you said numerous symbolic systems by symbolic systems, just symbolic systems
Pretty cool. That and pretty excited about this calling Well, big fans of Qualcomm for a while, actually for a variety of reasons. It's just a big fan of the tech Snapdragon and so the XR devices that you've put out when I was doing work in the lab we played with a few of those. And I think generally I don't get to speak with as many people who are knowledgeable about the space. The fact that you've come into this knowing what they're missing is tremendous. So they're very excited to tell you more about why we're building over building what we're building and why we're excited about it. A little bit of background on myself and I'll kind of flow into the the formal deck after that. But so I was from Nebraska, born and raised I got my degree in mechanical engineering and then robotics Meyer from Nebraska. My only engineering experience but true engineering experience was a fellowship at NASA when I was in school that was building common systems building drones. There was great I knew I wanted to kind of play in this deep tech vertical later on. But I was also in ROTC. And so I wanted to go and join the military afterwards. And I was an infantry officer for a number of years and I was a platoon commander, had an experience lots of leadership. And then I went into information operations which is far more technical. role. I was overseeing a lot of floor and a variety of different capabilities, which I will talk about at length, if you'd like me to but also opened my eyes to how technology was changing in the federal sector as well. And so I knew that I wanted to get out and I wanted to do something generally in that domain detect for federal government, or at least mission critical, which kind of widen the aperture to oil and gas, law enforcement, mining and other critical industries. And so came to Stanford to get my MBA as well. Love the MBA representation and also the engineer representation as well. But my I got my degree and Business Administration, and then also an additional degree in MS and symbolic systems, just kind of like cognitive science. And I was I was doing that I was working while we were doing the MBA. Yeah, yeah. So technically I am on a we have I graduated from the MBA program. I'm on a leave of absence from these blocks. It's a program I don't know if I'll actually go back and finish it. But let me take some of the deep learning and computer science courses that I really wanted to take you as you said numerous symbolic systems by symbolic systems, just symbolic systems
Pretty cool. That and pretty excited about this calling Well, big fans of Qualcomm for a while, actually for a variety of reasons. It's just a big fan of the tech Snapdragon and so the XR devices that you've put out when I was doing work in the lab we played with a few of those. And I think generally I don't get to speak with as many people who are knowledgeable about the space. The fact that you've come into this knowing what they're missing is tremendous. So they're very excited to tell you more about why we're building over building what we're building and why we're excited about it. A little bit of background on myself and I'll kind of flow into the the formal deck after that. But so I was from Nebraska, born and raised I got my degree in mechanical engineering and then robotics Meyer from Nebraska. My only engineering experience but true engineering experience was a fellowship at NASA when I was in school that was building common systems building drones. There was great I knew I wanted to kind of play in this deep tech vertical later on. But I was also in ROTC. And so I wanted to go and join the military afterwards. And I was an infantry officer for a number of years and I was a platoon commander, had an experience lots of leadership. And then I went into information operations which is far more technical. role. I was overseeing a lot of floor and a variety of different capabilities, which I will talk about at length, if you'd like me to but also opened my eyes to how technology was changing in the federal sector as well. And so I knew that I wanted to get out and I wanted to do something generally in that domain detect for federal government, or at least mission critical, which kind of widen the aperture to oil and gas, law enforcement, mining and other critical industries. And so came to Stanford to get my MBA as well. Love the MBA representation and also the engineer representation as well. But my I got my degree and Business Administration, and then also an additional degree in MS and symbolic systems, just kind of like cognitive science. And I was I was doing that I was working while we were doing the MBA. Yeah, yeah. So technically I am on a we have I graduated from the MBA program. I'm on a leave of absence from these blocks. It's a program I don't know if I'll actually go back and finish it. But let me take some of the deep learning and computer science courses that I really wanted to take you as you said numerous symbolic systems by symbolic systems, just symbolic systems
Pretty cool. That and pretty excited about this calling Well, big fans of Qualcomm for a while, actually for a variety of reasons. It's just a big fan of the tech Snapdragon and so the XR devices that you've put out when I was doing work in the lab we played with a few of those. And I think generally I don't get to speak with as many people who are knowledgeable about the space. The fact that you've come into this knowing what they're missing is tremendous. So they're very excited to tell you more about why we're building over building what we're building and why we're excited about it. A little bit of background on myself and I'll kind of flow into the the formal deck after that. But so I was from Nebraska, born and raised I got my degree in mechanical engineering and then robotics Meyer from Nebraska. My only engineering experience but true engineering experience was a fellowship at NASA when I was in school that was building common systems building drones. There was great I knew I wanted to kind of play in this deep tech vertical later on. But I was also in ROTC. And so I wanted to go and join the military afterwards. And I was an infantry officer for a number of years and I was a platoon commander, had an experience lots of leadership. And then I went into information operations which is far more technical. role. I was overseeing a lot of floor and a variety of different capabilities, which I will talk about at length, if you'd like me to but also opened my eyes to how technology was changing in the federal sector as well. And so I knew that I wanted to get out and I wanted to do something generally in that domain detect for federal government, or at least mission critical, which kind of widen the aperture to oil and gas, law enforcement, mining and other critical industries. And so came to Stanford to get my MBA as well. Love the MBA representation and also the engineer representation as well. But my I got my degree and Business Administration, and then also an additional degree in MS and symbolic systems, just kind of like cognitive science. And I was I was doing that I was working while we were doing the MBA. Yeah, yeah. So technically I am on a we have I graduated from the MBA program. I'm on a leave of absence from these blocks. It's a program I don't know if I'll actually go back and finish it. But let me take some of the deep learning and computer science courses that I really wanted to take you as you said numerous symbolic systems by symbolic systems, just symbolic systems
S Speaker 18:23not near as meeting Mike systems as in still. I'm guessing I mean by symbolic systems and we do a lot of like computational math. It is
not near as meeting Mike systems as in still. I'm guessing I mean by symbolic systems and we do a lot of like computational math. It is
not near as meeting Mike systems as in still. I'm guessing I mean by symbolic systems and we do a lot of like computational math. It is
not near as meeting Mike systems as in still. I'm guessing I mean by symbolic systems and we do a lot of like computational math. It is
S Speaker 111:13I'm sorry, we lost him for like a few seconds.
S Speaker 211:18Okay, just let me know if I if I dropped off again, but it takes forever to actually get any type of usable scan. It's very difficult and cumbersome. In order to capture those scans. You need eyes. It's sophisticated, expensive equipment. And then on top of that, once you have it, it's very difficult to actually create any type of additional analysis on top of it. Or applications on top of it as well. An area that we've seen a lot of enthusiasm for this is actually military training. So the virtual training and simulation marketing side of the military specifically is to the larger market as a foreigner billion dollar market and then inside of that it is around the $30 million mark. And they're using 10 year old tools in order to train a lot of individuals on how to operate a lot of heavy equipment, how to actually do conduct training on the landscapes, the terrains that you're going to be going into, or even using it to train autonomous systems using synthetic data. But it takes a very long time to create even one 3d asset a soul virtual environment is months and anytime that you want to do anything in that 3d space, it costs $150,000 minimum. We just got off a call with Stryver this morning actually they new immersive training and they that's what they charge DHL Verizon war for any type of virtual training for those fortune 500 customers didn't ask
Okay, just let me know if I if I dropped off again, but it takes forever to actually get any type of usable scan. It's very difficult and cumbersome. In order to capture those scans. You need eyes. It's sophisticated, expensive equipment. And then on top of that, once you have it, it's very difficult to actually create any type of additional analysis on top of it. Or applications on top of it as well. An area that we've seen a lot of enthusiasm for this is actually military training. So the virtual training and simulation marketing side of the military specifically is to the larger market as a foreigner billion dollar market and then inside of that it is around the $30 million mark. And they're using 10 year old tools in order to train a lot of individuals on how to operate a lot of heavy equipment, how to actually do conduct training on the landscapes, the terrains that you're going to be going into, or even using it to train autonomous systems using synthetic data. But it takes a very long time to create even one 3d asset a soul virtual environment is months and anytime that you want to do anything in that 3d space, it costs $150,000 minimum. We just got off a call with Stryver this morning actually they new immersive training and they that's what they charge DHL Verizon war for any type of virtual training for those fortune 500 customers didn't ask
Okay, just let me know if I if I dropped off again, but it takes forever to actually get any type of usable scan. It's very difficult and cumbersome. In order to capture those scans. You need eyes. It's sophisticated, expensive equipment. And then on top of that, once you have it, it's very difficult to actually create any type of additional analysis on top of it. Or applications on top of it as well. An area that we've seen a lot of enthusiasm for this is actually military training. So the virtual training and simulation marketing side of the military specifically is to the larger market as a foreigner billion dollar market and then inside of that it is around the $30 million mark. And they're using 10 year old tools in order to train a lot of individuals on how to operate a lot of heavy equipment, how to actually do conduct training on the landscapes, the terrains that you're going to be going into, or even using it to train autonomous systems using synthetic data. But it takes a very long time to create even one 3d asset a soul virtual environment is months and anytime that you want to do anything in that 3d space, it costs $150,000 minimum. We just got off a call with Stryver this morning actually they new immersive training and they that's what they charge DHL Verizon war for any type of virtual training for those fortune 500 customers didn't ask
Okay, just let me know if I if I dropped off again, but it takes forever to actually get any type of usable scan. It's very difficult and cumbersome. In order to capture those scans. You need eyes. It's sophisticated, expensive equipment. And then on top of that, once you have it, it's very difficult to actually create any type of additional analysis on top of it. Or applications on top of it as well. An area that we've seen a lot of enthusiasm for this is actually military training. So the virtual training and simulation marketing side of the military specifically is to the larger market as a foreigner billion dollar market and then inside of that it is around the $30 million mark. And they're using 10 year old tools in order to train a lot of individuals on how to operate a lot of heavy equipment, how to actually do conduct training on the landscapes, the terrains that you're going to be going into, or even using it to train autonomous systems using synthetic data. But it takes a very long time to create even one 3d asset a soul virtual environment is months and anytime that you want to do anything in that 3d space, it costs $150,000 minimum. We just got off a call with Stryver this morning actually they new immersive training and they that's what they charge DHL Verizon war for any type of virtual training for those fortune 500 customers didn't ask
S Speaker 112:52question so on the what are they using today in order to create these 3d assets?
question so on the what are they using today in order to create these 3d assets?
question so on the what are they using today in order to create these 3d assets?
question so on the what are they using today in order to create these 3d assets?
S Speaker 212:59Yeah, that's costing $150,000 and unreal, it's it's unity. Potentially sometimes phase
Yeah, that's costing $150,000 and unreal, it's it's unity. Potentially sometimes phase
Yeah, that's costing $150,000 and unreal, it's it's unity. Potentially sometimes phase
Yeah, that's costing $150,000 and unreal, it's it's unity. Potentially sometimes phase
S Speaker 113:09they've got to like a camera. You know, like, what's that? Matterport light camera?
they've got to like a camera. You know, like, what's that? Matterport light camera?
they've got to like a camera. You know, like, what's that? Matterport light camera?
they've got to like a camera. You know, like, what's that? Matterport light camera?
S Speaker 213:15Yeah. Is that what the setup is? For photogrammetry reconstruction? Absolutely. Typically, it's probably RGB D. So something that can just grab RGB video and also depth which I'm sure you're familiar with, and LiDAR, something that we like are enabled. And even then, once you have those tools, it usually comes out looking like they call it the melting ice cream cone effect. I'll give you I don't know if I'll be able to find the be exact picture that I want to find the terrible photogrammetry but I won't be able to find a few images that are just kind of like what the state of the art right now is in the military. side of the world. So maxar is like one of the largest providers of 3d imagery, 3d graphics to the government. And right now, they just got a $100 billion contract. It's one world drain and this is the this is what they're using. For the recreation of their environment. It's all looks terrible. And they do have a photogrammetry version of this. So actually, you know, I will show you the cesium example. So this is a real example the real unit has been using. This is cesium is like an online 3d geospatial tool. So like when I was on the one floor, we would be using tools similar to this done this exactly. For our planning purposes. And it just it just base it off of like Google imagery. photogrammetry but this is the level of fidelity that they're that they're getting for this, this planning operation and this has been in use from dem calm from the seventh Special Forces Group, so calm the US Army Reserve innovation command. And this has been trying to do planning, like mission planning based off of this type of PDs entry. So obviously just the quality is not there. It's very cumbersome to actually go and capture this. That's why they use google images or Google Maps, data, or they have a provider like Max are actually provided, but just extremely problematic to actually get good value out of out of these tools. Yeah, have you please cut me off if there's any other questions? And
Yeah. Is that what the setup is? For photogrammetry reconstruction? Absolutely. Typically, it's probably RGB D. So something that can just grab RGB video and also depth which I'm sure you're familiar with, and LiDAR, something that we like are enabled. And even then, once you have those tools, it usually comes out looking like they call it the melting ice cream cone effect. I'll give you I don't know if I'll be able to find the be exact picture that I want to find the terrible photogrammetry but I won't be able to find a few images that are just kind of like what the state of the art right now is in the military. side of the world. So maxar is like one of the largest providers of 3d imagery, 3d graphics to the government. And right now, they just got a $100 billion contract. It's one world drain and this is the this is what they're using. For the recreation of their environment. It's all looks terrible. And they do have a photogrammetry version of this. So actually, you know, I will show you the cesium example. So this is a real example the real unit has been using. This is cesium is like an online 3d geospatial tool. So like when I was on the one floor, we would be using tools similar to this done this exactly. For our planning purposes. And it just it just base it off of like Google imagery. photogrammetry but this is the level of fidelity that they're that they're getting for this, this planning operation and this has been in use from dem calm from the seventh Special Forces Group, so calm the US Army Reserve innovation command. And this has been trying to do planning, like mission planning based off of this type of PDs entry. So obviously just the quality is not there. It's very cumbersome to actually go and capture this. That's why they use google images or Google Maps, data, or they have a provider like Max are actually provided, but just extremely problematic to actually get good value out of out of these tools. Yeah, have you please cut me off if there's any other questions? And
Yeah. Is that what the setup is? For photogrammetry reconstruction? Absolutely. Typically, it's probably RGB D. So something that can just grab RGB video and also depth which I'm sure you're familiar with, and LiDAR, something that we like are enabled. And even then, once you have those tools, it usually comes out looking like they call it the melting ice cream cone effect. I'll give you I don't know if I'll be able to find the be exact picture that I want to find the terrible photogrammetry but I won't be able to find a few images that are just kind of like what the state of the art right now is in the military. side of the world. So maxar is like one of the largest providers of 3d imagery, 3d graphics to the government. And right now, they just got a $100 billion contract. It's one world drain and this is the this is what they're using. For the recreation of their environment. It's all looks terrible. And they do have a photogrammetry version of this. So actually, you know, I will show you the cesium example. So this is a real example the real unit has been using. This is cesium is like an online 3d geospatial tool. So like when I was on the one floor, we would be using tools similar to this done this exactly. For our planning purposes. And it just it just base it off of like Google imagery. photogrammetry but this is the level of fidelity that they're that they're getting for this, this planning operation and this has been in use from dem calm from the seventh Special Forces Group, so calm the US Army Reserve innovation command. And this has been trying to do planning, like mission planning based off of this type of PDs entry. So obviously just the quality is not there. It's very cumbersome to actually go and capture this. That's why they use google images or Google Maps, data, or they have a provider like Max are actually provided, but just extremely problematic to actually get good value out of out of these tools. Yeah, have you please cut me off if there's any other questions? And
Yeah. Is that what the setup is? For photogrammetry reconstruction? Absolutely. Typically, it's probably RGB D. So something that can just grab RGB video and also depth which I'm sure you're familiar with, and LiDAR, something that we like are enabled. And even then, once you have those tools, it usually comes out looking like they call it the melting ice cream cone effect. I'll give you I don't know if I'll be able to find the be exact picture that I want to find the terrible photogrammetry but I won't be able to find a few images that are just kind of like what the state of the art right now is in the military. side of the world. So maxar is like one of the largest providers of 3d imagery, 3d graphics to the government. And right now, they just got a $100 billion contract. It's one world drain and this is the this is what they're using. For the recreation of their environment. It's all looks terrible. And they do have a photogrammetry version of this. So actually, you know, I will show you the cesium example. So this is a real example the real unit has been using. This is cesium is like an online 3d geospatial tool. So like when I was on the one floor, we would be using tools similar to this done this exactly. For our planning purposes. And it just it just base it off of like Google imagery. photogrammetry but this is the level of fidelity that they're that they're getting for this, this planning operation and this has been in use from dem calm from the seventh Special Forces Group, so calm the US Army Reserve innovation command. And this has been trying to do planning, like mission planning based off of this type of PDs entry. So obviously just the quality is not there. It's very cumbersome to actually go and capture this. That's why they use google images or Google Maps, data, or they have a provider like Max are actually provided, but just extremely problematic to actually get good value out of out of these tools. Yeah, have you please cut me off if there's any other questions? And
S Speaker 115:40maxar uses this RGBD type of sunlight for to capture buildings like that it's putting the RGBD camera on a drone and and it's capturing images and then it's doing some reconstruction with the drone comes back.
maxar uses this RGBD type of sunlight for to capture buildings like that it's putting the RGBD camera on a drone and and it's capturing images and then it's doing some reconstruction with the drone comes back.
maxar uses this RGBD type of sunlight for to capture buildings like that it's putting the RGBD camera on a drone and and it's capturing images and then it's doing some reconstruction with the drone comes back.
maxar uses this RGBD type of sunlight for to capture buildings like that it's putting the RGBD camera on a drone and and it's capturing images and then it's doing some reconstruction with the drone comes back.
S Speaker 115:59I'm making is that is that the setup typically? Well, they're they're capturing this. Yep.
I'm making is that is that the setup typically? Well, they're they're capturing this. Yep.
I'm making is that is that the setup typically? Well, they're they're capturing this. Yep.
I'm making is that is that the setup typically? Well, they're they're capturing this. Yep.
S Speaker 216:04That's typically how they're capturing this. If they're, if they're capturing it at all. A lot of times they're trying to just say throwing it away and saving him.
That's typically how they're capturing this. If they're, if they're capturing it at all. A lot of times they're trying to just say throwing it away and saving him.
That's typically how they're capturing this. If they're, if they're capturing it at all. A lot of times they're trying to just say throwing it away and saving him.
That's typically how they're capturing this. If they're, if they're capturing it at all. A lot of times they're trying to just say throwing it away and saving him.
16:12Okay, okay. Well, and then but why are they even usable like
Okay, okay. Well, and then but why are they even usable like
Okay, okay. Well, and then but why are they even usable like
Okay, okay. Well, and then but why are they even usable like
S Speaker 216:21this is they be I will tell you what the alternative is. The alternative is what I've been using a you did this in the infantry I also do this on the workflow or the alternative is that you've got a topographical map, a protractor and a marker and everyone sits around the table and actually just utilizes that and it's getting incredibly fraught with air. I mean, you are and you get down to like the, you know, cooking on the map, but you know, where I have a two level of fidelity of like 100 meter so to speak, and you can be off by, you know, 10s of meters on anything for like, where your objective is where everything is at. It gets better when you start to do satellite imagery, or to do overhead, top down satellite imagery, you use a lot of information. And so I mean, I telling you, I'm looking over the shoulder, my geospatial intelligence analysts trying to decipher that the shadows out of those 10 tracks is on a trench and some of these like live combat zones. And so people they want this for things like battle damage assessment to understand that something, is the building actually been destroyed, or is it still standing? What the terrain actually looks like in a certain area. And as you get more of these tools, we're going to be leveraging 3d data, certainly all of the XR tooling that is going to be deployed requires that 3d data. There are countless examples and I can send this to you afterwards as well of programs that DARPA in the intelligence community has really gone after because they want to be able to, like from satellite imagery, reconstruct Osama bin Laden's compound and then be able to give that to the SEAL team, for instance, before they actually go out and do the race. They understand. Okay, I will have covered gear, I won't have covered gear etc. And then the area that we have gotten the most traction in that we're going after at our initial football is really the training aspect. So how can you actually can get somebody to understand what this environments going to look like? What this equipments going to look like these vehicles are going to look like when you don't have access to those physical vehicles, those physical environments. Can you capture from drone imagery can you capture it from handheld imagery, things like that? And so really excited to tell you more about this because we this is kind of where we are currently, and we think it's gonna get even crazier in the in the coming years and we think that we're going to be very well for where the direction that all of this is going and happy, excited to tell you more about it. Okay,
this is they be I will tell you what the alternative is. The alternative is what I've been using a you did this in the infantry I also do this on the workflow or the alternative is that you've got a topographical map, a protractor and a marker and everyone sits around the table and actually just utilizes that and it's getting incredibly fraught with air. I mean, you are and you get down to like the, you know, cooking on the map, but you know, where I have a two level of fidelity of like 100 meter so to speak, and you can be off by, you know, 10s of meters on anything for like, where your objective is where everything is at. It gets better when you start to do satellite imagery, or to do overhead, top down satellite imagery, you use a lot of information. And so I mean, I telling you, I'm looking over the shoulder, my geospatial intelligence analysts trying to decipher that the shadows out of those 10 tracks is on a trench and some of these like live combat zones. And so people they want this for things like battle damage assessment to understand that something, is the building actually been destroyed, or is it still standing? What the terrain actually looks like in a certain area. And as you get more of these tools, we're going to be leveraging 3d data, certainly all of the XR tooling that is going to be deployed requires that 3d data. There are countless examples and I can send this to you afterwards as well of programs that DARPA in the intelligence community has really gone after because they want to be able to, like from satellite imagery, reconstruct Osama bin Laden's compound and then be able to give that to the SEAL team, for instance, before they actually go out and do the race. They understand. Okay, I will have covered gear, I won't have covered gear etc. And then the area that we have gotten the most traction in that we're going after at our initial football is really the training aspect. So how can you actually can get somebody to understand what this environments going to look like? What this equipments going to look like these vehicles are going to look like when you don't have access to those physical vehicles, those physical environments. Can you capture from drone imagery can you capture it from handheld imagery, things like that? And so really excited to tell you more about this because we this is kind of where we are currently, and we think it's gonna get even crazier in the in the coming years and we think that we're going to be very well for where the direction that all of this is going and happy, excited to tell you more about it. Okay,
this is they be I will tell you what the alternative is. The alternative is what I've been using a you did this in the infantry I also do this on the workflow or the alternative is that you've got a topographical map, a protractor and a marker and everyone sits around the table and actually just utilizes that and it's getting incredibly fraught with air. I mean, you are and you get down to like the, you know, cooking on the map, but you know, where I have a two level of fidelity of like 100 meter so to speak, and you can be off by, you know, 10s of meters on anything for like, where your objective is where everything is at. It gets better when you start to do satellite imagery, or to do overhead, top down satellite imagery, you use a lot of information. And so I mean, I telling you, I'm looking over the shoulder, my geospatial intelligence analysts trying to decipher that the shadows out of those 10 tracks is on a trench and some of these like live combat zones. And so people they want this for things like battle damage assessment to understand that something, is the building actually been destroyed, or is it still standing? What the terrain actually looks like in a certain area. And as you get more of these tools, we're going to be leveraging 3d data, certainly all of the XR tooling that is going to be deployed requires that 3d data. There are countless examples and I can send this to you afterwards as well of programs that DARPA in the intelligence community has really gone after because they want to be able to, like from satellite imagery, reconstruct Osama bin Laden's compound and then be able to give that to the SEAL team, for instance, before they actually go out and do the race. They understand. Okay, I will have covered gear, I won't have covered gear etc. And then the area that we have gotten the most traction in that we're going after at our initial football is really the training aspect. So how can you actually can get somebody to understand what this environments going to look like? What this equipments going to look like these vehicles are going to look like when you don't have access to those physical vehicles, those physical environments. Can you capture from drone imagery can you capture it from handheld imagery, things like that? And so really excited to tell you more about this because we this is kind of where we are currently, and we think it's gonna get even crazier in the in the coming years and we think that we're going to be very well for where the direction that all of this is going and happy, excited to tell you more about it. Okay,
this is they be I will tell you what the alternative is. The alternative is what I've been using a you did this in the infantry I also do this on the workflow or the alternative is that you've got a topographical map, a protractor and a marker and everyone sits around the table and actually just utilizes that and it's getting incredibly fraught with air. I mean, you are and you get down to like the, you know, cooking on the map, but you know, where I have a two level of fidelity of like 100 meter so to speak, and you can be off by, you know, 10s of meters on anything for like, where your objective is where everything is at. It gets better when you start to do satellite imagery, or to do overhead, top down satellite imagery, you use a lot of information. And so I mean, I telling you, I'm looking over the shoulder, my geospatial intelligence analysts trying to decipher that the shadows out of those 10 tracks is on a trench and some of these like live combat zones. And so people they want this for things like battle damage assessment to understand that something, is the building actually been destroyed, or is it still standing? What the terrain actually looks like in a certain area. And as you get more of these tools, we're going to be leveraging 3d data, certainly all of the XR tooling that is going to be deployed requires that 3d data. There are countless examples and I can send this to you afterwards as well of programs that DARPA in the intelligence community has really gone after because they want to be able to, like from satellite imagery, reconstruct Osama bin Laden's compound and then be able to give that to the SEAL team, for instance, before they actually go out and do the race. They understand. Okay, I will have covered gear, I won't have covered gear etc. And then the area that we have gotten the most traction in that we're going after at our initial football is really the training aspect. So how can you actually can get somebody to understand what this environments going to look like? What this equipments going to look like these vehicles are going to look like when you don't have access to those physical vehicles, those physical environments. Can you capture from drone imagery can you capture it from handheld imagery, things like that? And so really excited to tell you more about this because we this is kind of where we are currently, and we think it's gonna get even crazier in the in the coming years and we think that we're going to be very well for where the direction that all of this is going and happy, excited to tell you more about it. Okay,
S Speaker 118:51that's good. No, they're good. Thank you can link to that Max or intelligence that you were showing?
that's good. No, they're good. Thank you can link to that Max or intelligence that you were showing?
that's good. No, they're good. Thank you can link to that Max or intelligence that you were showing?
that's good. No, they're good. Thank you can link to that Max or intelligence that you were showing?
S Speaker 122:06the quality of output doesn't get better if you have more input from sensors, like let's say what if you had RGB D IDs? Yes, RGB.
the quality of output doesn't get better if you have more input from sensors, like let's say what if you had RGB D IDs? Yes, RGB.
the quality of output doesn't get better if you have more input from sensors, like let's say what if you had RGB D IDs? Yes, RGB.
the quality of output doesn't get better if you have more input from sensors, like let's say what if you had RGB D IDs? Yes, RGB.
S Speaker 222:19Good vigilance. Yeah, absolutely. Yeah. The most important thing for us is already going through a proper structure for motion pipeline and against like the requisite information. So can we actually we want to hope to eventually take my call man out of the picture, but can you actually reconstruct the points the for from the camera that is the most time intensive piece of it and has the highest impact on the result in quality. And then, the other piece of this that we're super excited about, and we will show you exactly kind of what this means is that we want to be able to empower people to do more with the 3d data that they currently have the ability to do so that means being we've really experienced a lot and I think this is what excites us the most about where this field is going. Is that a difference between this and traditional photogrammetry is that you've got such photo realism that you can put semantic information inside of the scene itself. And so as you're doing that 3d reconstruction if you already have a generative model, multimodal model that is enabling you to get the semantic understanding of the scene, or that clip or segment anything or grounding dyno, you also have the ability to embed every notion in that one cloud with that semantic understanding. And so you get these feature fields now that you're able to actually catalog and then explore so you can query the scene and say show me this show me that or you can actually the way that we like to say it or and what is exciting, again with the pieces that you and Francesco have is one of you could just give the 3d asset itself to these models, these powerful models that are coming out and having had that as it's part of a drag system, whereas you can actually just use that information in any other model that you might have. And that is like this really exciting insight that we are just absolutely floored by and it is what is really getting us to go really far here because at the end of the day, it's not only can you scan the construction site, but you can upload this construction site the model and say show me where OSHA violations are, or scan the battlefield and say from our intelligence reporting and their intelligence reporting, where is the enemy position? Where do you think the enemy position as it's giving the physical world to these models in a way that they didn't happen before? And
Good vigilance. Yeah, absolutely. Yeah. The most important thing for us is already going through a proper structure for motion pipeline and against like the requisite information. So can we actually we want to hope to eventually take my call man out of the picture, but can you actually reconstruct the points the for from the camera that is the most time intensive piece of it and has the highest impact on the result in quality. And then, the other piece of this that we're super excited about, and we will show you exactly kind of what this means is that we want to be able to empower people to do more with the 3d data that they currently have the ability to do so that means being we've really experienced a lot and I think this is what excites us the most about where this field is going. Is that a difference between this and traditional photogrammetry is that you've got such photo realism that you can put semantic information inside of the scene itself. And so as you're doing that 3d reconstruction if you already have a generative model, multimodal model that is enabling you to get the semantic understanding of the scene, or that clip or segment anything or grounding dyno, you also have the ability to embed every notion in that one cloud with that semantic understanding. And so you get these feature fields now that you're able to actually catalog and then explore so you can query the scene and say show me this show me that or you can actually the way that we like to say it or and what is exciting, again with the pieces that you and Francesco have is one of you could just give the 3d asset itself to these models, these powerful models that are coming out and having had that as it's part of a drag system, whereas you can actually just use that information in any other model that you might have. And that is like this really exciting insight that we are just absolutely floored by and it is what is really getting us to go really far here because at the end of the day, it's not only can you scan the construction site, but you can upload this construction site the model and say show me where OSHA violations are, or scan the battlefield and say from our intelligence reporting and their intelligence reporting, where is the enemy position? Where do you think the enemy position as it's giving the physical world to these models in a way that they didn't happen before? And
Good vigilance. Yeah, absolutely. Yeah. The most important thing for us is already going through a proper structure for motion pipeline and against like the requisite information. So can we actually we want to hope to eventually take my call man out of the picture, but can you actually reconstruct the points the for from the camera that is the most time intensive piece of it and has the highest impact on the result in quality. And then, the other piece of this that we're super excited about, and we will show you exactly kind of what this means is that we want to be able to empower people to do more with the 3d data that they currently have the ability to do so that means being we've really experienced a lot and I think this is what excites us the most about where this field is going. Is that a difference between this and traditional photogrammetry is that you've got such photo realism that you can put semantic information inside of the scene itself. And so as you're doing that 3d reconstruction if you already have a generative model, multimodal model that is enabling you to get the semantic understanding of the scene, or that clip or segment anything or grounding dyno, you also have the ability to embed every notion in that one cloud with that semantic understanding. And so you get these feature fields now that you're able to actually catalog and then explore so you can query the scene and say show me this show me that or you can actually the way that we like to say it or and what is exciting, again with the pieces that you and Francesco have is one of you could just give the 3d asset itself to these models, these powerful models that are coming out and having had that as it's part of a drag system, whereas you can actually just use that information in any other model that you might have. And that is like this really exciting insight that we are just absolutely floored by and it is what is really getting us to go really far here because at the end of the day, it's not only can you scan the construction site, but you can upload this construction site the model and say show me where OSHA violations are, or scan the battlefield and say from our intelligence reporting and their intelligence reporting, where is the enemy position? Where do you think the enemy position as it's giving the physical world to these models in a way that they didn't happen before? And
Good vigilance. Yeah, absolutely. Yeah. The most important thing for us is already going through a proper structure for motion pipeline and against like the requisite information. So can we actually we want to hope to eventually take my call man out of the picture, but can you actually reconstruct the points the for from the camera that is the most time intensive piece of it and has the highest impact on the result in quality. And then, the other piece of this that we're super excited about, and we will show you exactly kind of what this means is that we want to be able to empower people to do more with the 3d data that they currently have the ability to do so that means being we've really experienced a lot and I think this is what excites us the most about where this field is going. Is that a difference between this and traditional photogrammetry is that you've got such photo realism that you can put semantic information inside of the scene itself. And so as you're doing that 3d reconstruction if you already have a generative model, multimodal model that is enabling you to get the semantic understanding of the scene, or that clip or segment anything or grounding dyno, you also have the ability to embed every notion in that one cloud with that semantic understanding. And so you get these feature fields now that you're able to actually catalog and then explore so you can query the scene and say show me this show me that or you can actually the way that we like to say it or and what is exciting, again with the pieces that you and Francesco have is one of you could just give the 3d asset itself to these models, these powerful models that are coming out and having had that as it's part of a drag system, whereas you can actually just use that information in any other model that you might have. And that is like this really exciting insight that we are just absolutely floored by and it is what is really getting us to go really far here because at the end of the day, it's not only can you scan the construction site, but you can upload this construction site the model and say show me where OSHA violations are, or scan the battlefield and say from our intelligence reporting and their intelligence reporting, where is the enemy position? Where do you think the enemy position as it's giving the physical world to these models in a way that they didn't happen before? And
S Speaker 124:51I think going down would you be building the foundation model for this?
I think going down would you be building the foundation model for this?
I think going down would you be building the foundation model for this?
I think going down would you be building the foundation model for this?
S Speaker 224:55So eventually, that depends on the customers and the money that we're eventually about to raise that honestly, that's what dictates it because you don't want to get the foundation model race if you don't have a lot of money to see it through
So eventually, that depends on the customers and the money that we're eventually about to raise that honestly, that's what dictates it because you don't want to get the foundation model race if you don't have a lot of money to see it through
So eventually, that depends on the customers and the money that we're eventually about to raise that honestly, that's what dictates it because you don't want to get the foundation model race if you don't have a lot of money to see it through
So eventually, that depends on the customers and the money that we're eventually about to raise that honestly, that's what dictates it because you don't want to get the foundation model race if you don't have a lot of money to see it through
S Speaker 125:10the company. Essentially you don't have to pay income tax take that money. And then, I mean, it'd be interesting I think, I think what the base foundation model gives me even better is somebody else trends, the base foundation model and the llama community. Yeah,
the company. Essentially you don't have to pay income tax take that money. And then, I mean, it'd be interesting I think, I think what the base foundation model gives me even better is somebody else trends, the base foundation model and the llama community. Yeah,
the company. Essentially you don't have to pay income tax take that money. And then, I mean, it'd be interesting I think, I think what the base foundation model gives me even better is somebody else trends, the base foundation model and the llama community. Yeah,
the company. Essentially you don't have to pay income tax take that money. And then, I mean, it'd be interesting I think, I think what the base foundation model gives me even better is somebody else trends, the base foundation model and the llama community. Yeah,
S Speaker 225:32to be honest, right now, the way we're positioning ourselves is can we just be the llama index connector, the data connector for 3d. That's all we need to be in the very beginning, but we need to collect as much 3d as we possibly can in order to in order to get this right. So we're you are you are exactly aligned with where we're going.
to be honest, right now, the way we're positioning ourselves is can we just be the llama index connector, the data connector for 3d. That's all we need to be in the very beginning, but we need to collect as much 3d as we possibly can in order to in order to get this right. So we're you are you are exactly aligned with where we're going.
to be honest, right now, the way we're positioning ourselves is can we just be the llama index connector, the data connector for 3d. That's all we need to be in the very beginning, but we need to collect as much 3d as we possibly can in order to in order to get this right. So we're you are you are exactly aligned with where we're going.
to be honest, right now, the way we're positioning ourselves is can we just be the llama index connector, the data connector for 3d. That's all we need to be in the very beginning, but we need to collect as much 3d as we possibly can in order to in order to get this right. So we're you are you are exactly aligned with where we're going.
S Speaker 125:53No, I'm excited about the potential here because I think I think I mean, we're there's multiple conversations that are now just beginning about spatial intelligence. Yes, or spatial intelligence is emerging. So it's, and it's really and I think, I think the question for you is, as for so far outside of military applications,
No, I'm excited about the potential here because I think I think I mean, we're there's multiple conversations that are now just beginning about spatial intelligence. Yes, or spatial intelligence is emerging. So it's, and it's really and I think, I think the question for you is, as for so far outside of military applications,
No, I'm excited about the potential here because I think I think I mean, we're there's multiple conversations that are now just beginning about spatial intelligence. Yes, or spatial intelligence is emerging. So it's, and it's really and I think, I think the question for you is, as for so far outside of military applications,
No, I'm excited about the potential here because I think I think I mean, we're there's multiple conversations that are now just beginning about spatial intelligence. Yes, or spatial intelligence is emerging. So it's, and it's really and I think, I think the question for you is, as for so far outside of military applications,
S Speaker 126:27you be able to reuse that data to even build tomorrow? I
you be able to reuse that data to even build tomorrow? I
you be able to reuse that data to even build tomorrow? I
you be able to reuse that data to even build tomorrow? I
S Speaker 226:34think the way that we were going about this kind of this new age of defense tech, a lot of this is open source, I think that there are certain data that we're not going to be able to reuse, you're absolutely correct. And that is like a for mapping all of Ukraine or something like that. But for the I would say for the more benign use cases, which I think is our entry point, which is a lot of the training use cases. It's it's scanning equipment or vehicles or landscapes for training bases and things like that, like Camp Pendleton or ranges, things of that nature. And as we get the pipeline down, we plan on expanding into enterprise like mining site use cases. are actually top of our list to go and explore. Once we start collecting more and more of the 3d data, we can really parse out what's going to be useful for for what type of vertical but we need to build out just a system in general. Actually, at this point, I want to kind of show you the demo that we're working on, right. Yeah, yeah. Yeah. So we've got two pilots that we are that we're currently going after one is the Dallas Fort Worth airport. So we did we've got this with a drone company. It's a $50,000 pilot and we're gonna get about $10,000 worth of that. And they're trying to just they are federally mandated through the FAA to inspect like 10,000 acres of runway safety or and which they obviously don't do is they just drive the runways they're trying to it's not the answer to the runways necessarily. It's the surrounding areas. It's is there water cooling over here is there is there an investment that's eroding something like that, so they want to see what the changes over time in that area? And we they were trying to use photogrammetry but it took eight hours to get a single scan. And so we're really trying to optimize Lauren's area scene reconstruction for them and then do the change. Let them do that automatically with the drought and then get the understanding of the changes over time. So you can say like, Okay, this investment is failing or or you have debris, the animal carcass that's in this area, things like that.
think the way that we were going about this kind of this new age of defense tech, a lot of this is open source, I think that there are certain data that we're not going to be able to reuse, you're absolutely correct. And that is like a for mapping all of Ukraine or something like that. But for the I would say for the more benign use cases, which I think is our entry point, which is a lot of the training use cases. It's it's scanning equipment or vehicles or landscapes for training bases and things like that, like Camp Pendleton or ranges, things of that nature. And as we get the pipeline down, we plan on expanding into enterprise like mining site use cases. are actually top of our list to go and explore. Once we start collecting more and more of the 3d data, we can really parse out what's going to be useful for for what type of vertical but we need to build out just a system in general. Actually, at this point, I want to kind of show you the demo that we're working on, right. Yeah, yeah. Yeah. So we've got two pilots that we are that we're currently going after one is the Dallas Fort Worth airport. So we did we've got this with a drone company. It's a $50,000 pilot and we're gonna get about $10,000 worth of that. And they're trying to just they are federally mandated through the FAA to inspect like 10,000 acres of runway safety or and which they obviously don't do is they just drive the runways they're trying to it's not the answer to the runways necessarily. It's the surrounding areas. It's is there water cooling over here is there is there an investment that's eroding something like that, so they want to see what the changes over time in that area? And we they were trying to use photogrammetry but it took eight hours to get a single scan. And so we're really trying to optimize Lauren's area scene reconstruction for them and then do the change. Let them do that automatically with the drought and then get the understanding of the changes over time. So you can say like, Okay, this investment is failing or or you have debris, the animal carcass that's in this area, things like that.
think the way that we were going about this kind of this new age of defense tech, a lot of this is open source, I think that there are certain data that we're not going to be able to reuse, you're absolutely correct. And that is like a for mapping all of Ukraine or something like that. But for the I would say for the more benign use cases, which I think is our entry point, which is a lot of the training use cases. It's it's scanning equipment or vehicles or landscapes for training bases and things like that, like Camp Pendleton or ranges, things of that nature. And as we get the pipeline down, we plan on expanding into enterprise like mining site use cases. are actually top of our list to go and explore. Once we start collecting more and more of the 3d data, we can really parse out what's going to be useful for for what type of vertical but we need to build out just a system in general. Actually, at this point, I want to kind of show you the demo that we're working on, right. Yeah, yeah. Yeah. So we've got two pilots that we are that we're currently going after one is the Dallas Fort Worth airport. So we did we've got this with a drone company. It's a $50,000 pilot and we're gonna get about $10,000 worth of that. And they're trying to just they are federally mandated through the FAA to inspect like 10,000 acres of runway safety or and which they obviously don't do is they just drive the runways they're trying to it's not the answer to the runways necessarily. It's the surrounding areas. It's is there water cooling over here is there is there an investment that's eroding something like that, so they want to see what the changes over time in that area? And we they were trying to use photogrammetry but it took eight hours to get a single scan. And so we're really trying to optimize Lauren's area scene reconstruction for them and then do the change. Let them do that automatically with the drought and then get the understanding of the changes over time. So you can say like, Okay, this investment is failing or or you have debris, the animal carcass that's in this area, things like that.
think the way that we were going about this kind of this new age of defense tech, a lot of this is open source, I think that there are certain data that we're not going to be able to reuse, you're absolutely correct. And that is like a for mapping all of Ukraine or something like that. But for the I would say for the more benign use cases, which I think is our entry point, which is a lot of the training use cases. It's it's scanning equipment or vehicles or landscapes for training bases and things like that, like Camp Pendleton or ranges, things of that nature. And as we get the pipeline down, we plan on expanding into enterprise like mining site use cases. are actually top of our list to go and explore. Once we start collecting more and more of the 3d data, we can really parse out what's going to be useful for for what type of vertical but we need to build out just a system in general. Actually, at this point, I want to kind of show you the demo that we're working on, right. Yeah, yeah. Yeah. So we've got two pilots that we are that we're currently going after one is the Dallas Fort Worth airport. So we did we've got this with a drone company. It's a $50,000 pilot and we're gonna get about $10,000 worth of that. And they're trying to just they are federally mandated through the FAA to inspect like 10,000 acres of runway safety or and which they obviously don't do is they just drive the runways they're trying to it's not the answer to the runways necessarily. It's the surrounding areas. It's is there water cooling over here is there is there an investment that's eroding something like that, so they want to see what the changes over time in that area? And we they were trying to use photogrammetry but it took eight hours to get a single scan. And so we're really trying to optimize Lauren's area scene reconstruction for them and then do the change. Let them do that automatically with the drought and then get the understanding of the changes over time. So you can say like, Okay, this investment is failing or or you have debris, the animal carcass that's in this area, things like that.
S Speaker 128:45And what were they using for photogrammetry was another company's product.
And what were they using for photogrammetry was another company's product.
And what were they using for photogrammetry was another company's product.
And what were they using for photogrammetry was another company's product.